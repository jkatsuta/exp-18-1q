python train.py --scenario wanderer2_2agents-1 --num-episodes 40000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
python train.py --scenario wanderer2_2agents-1 --num-episodes 40000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
python train.py --scenario wanderer2_2agents-1 --num-episodes 40000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
python train.py --scenario wanderer2_2agents-2 --num-episodes 40000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
python train.py --scenario wanderer2_2agents-2 --num-episodes 40000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
python train.py --scenario wanderer2_2agents-2 --num-episodes 40000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
python train.py --scenario wanderer2_2agents-3 --num-episodes 40000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
python train.py --scenario wanderer2_2agents-3 --num-episodes 40000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
python train.py --scenario wanderer2_2agents-3 --num-episodes 40000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
Using good policy ddpg and adv policy ddpg
Starting iterations of wanderer2_2agents-1__2018-07-13_10-46-22...
100 50
steps: 4950, episodes: 100, mean episode reward: -136.74027790778354, time: 14.944
agent0_energy_min, agent0_attention_min
[-16.44444444 -16.44444444]
agent1_energy_min, agent1_attention_min
[-17.29292929 -16.70707071]
200 50
steps: 9950, episodes: 200, mean episode reward: -151.07197470064304, time: 17.568
agent0_energy_min, agent0_attention_min
[-17.3  -16.05]
agent1_energy_min, agent1_attention_min
[-16.86 -16.69]
300 50
steps: 14950, episodes: 300, mean episode reward: -144.86737826590416, time: 18.481
agent0_energy_min, agent0_attention_min
[-16.59 -16.77]
agent1_energy_min, agent1_attention_min
[-17.16 -16.34]
400 50
steps: 19950, episodes: 400, mean episode reward: -148.47530212646532, time: 18.144
agent0_energy_min, agent0_attention_min
[-16.78 -15.98]
agent1_energy_min, agent1_attention_min
[-17.37 -16.25]
500 50
steps: 24950, episodes: 500, mean episode reward: -155.4632777639893, time: 17.869
agent0_energy_min, agent0_attention_min
[-16.42 -16.43]
agent1_energy_min, agent1_attention_min
[-16.68 -17.22]
600 50
steps: 29950, episodes: 600, mean episode reward: -177.9260842761991, time: 17.762
agent0_energy_min, agent0_attention_min
[-16.72 -16.56]
agent1_energy_min, agent1_attention_min
[-17.96 -16.43]
700 50
steps: 34950, episodes: 700, mean episode reward: -141.91435692664632, time: 18.373
agent0_energy_min, agent0_attention_min
[-16.11 -16.63]
agent1_energy_min, agent1_attention_min
[-17.64 -16.21]
800 50
steps: 39950, episodes: 800, mean episode reward: -150.24985561773076, time: 18.206
agent0_energy_min, agent0_attention_min
[-16.74 -16.3 ]
agent1_energy_min, agent1_attention_min
[-17.82 -16.25]
900 50
steps: 44950, episodes: 900, mean episode reward: -149.71073640012, time: 17.966
agent0_energy_min, agent0_attention_min
[-16.37 -16.54]
agent1_energy_min, agent1_attention_min
[-17.7 -16. ]
1000 50
steps: 49950, episodes: 1000, mean episode reward: -154.7539194645198, time: 17.357
agent0_energy_min, agent0_attention_min
[-16.65 -16.64]
agent1_energy_min, agent1_attention_min
[-17.83 -16.31]
1100 50
steps: 54950, episodes: 1100, mean episode reward: -590.8651394698427, time: 23.706
agent0_energy_min, agent0_attention_min
[-14.46 -18.23]
agent1_energy_min, agent1_attention_min
[-29.79  -6.72]
1200 50
steps: 59950, episodes: 1200, mean episode reward: -683.2333066435416, time: 24.68
agent0_energy_min, agent0_attention_min
[-19.87 -29.46]
agent1_energy_min, agent1_attention_min
[ -1.28 -30.25]
1300 50
steps: 64950, episodes: 1300, mean episode reward: -590.5649493887765, time: 25.215
agent0_energy_min, agent0_attention_min
[-21.55 -24.07]
agent1_energy_min, agent1_attention_min
[-22.43 -15.7 ]
1400 50
steps: 69950, episodes: 1400, mean episode reward: -258.5550125738699, time: 25.219
agent0_energy_min, agent0_attention_min
[-28.31  -5.41]
agent1_energy_min, agent1_attention_min
[-12.74 -11.96]
1500 50
steps: 74950, episodes: 1500, mean episode reward: -248.65021789501773, time: 24.647
agent0_energy_min, agent0_attention_min
[-25.87  -5.84]
agent1_energy_min, agent1_attention_min
[-17.64  -0.36]
1600 50
steps: 79950, episodes: 1600, mean episode reward: -235.1531000293623, time: 25.33
agent0_energy_min, agent0_attention_min
[ -0.59 -35.02]
agent1_energy_min, agent1_attention_min
[-29.39  -3.44]
1700 50
steps: 84950, episodes: 1700, mean episode reward: -189.70729523459514, time: 24.311
agent0_energy_min, agent0_attention_min
[ -0.24 -31.36]
agent1_energy_min, agent1_attention_min
[ -1.78 -20.75]
1800 50
steps: 89950, episodes: 1800, mean episode reward: -248.7765024864263, time: 24.058
agent0_energy_min, agent0_attention_min
[ -0.26 -42.86]
agent1_energy_min, agent1_attention_min
[ -2.56 -20.86]
1900 50
steps: 94950, episodes: 1900, mean episode reward: -129.62812995036091, time: 24.011
agent0_energy_min, agent0_attention_min
[ -0.34 -49.15]
agent1_energy_min, agent1_attention_min
[ -1.12 -24.61]
2000 50
steps: 99950, episodes: 2000, mean episode reward: -130.2360871732095, time: 23.362
agent0_energy_min, agent0_attention_min
[ -1.97 -47.42]
agent1_energy_min, agent1_attention_min
[ -0.82 -17.19]
2100 50
steps: 104950, episodes: 2100, mean episode reward: -126.92196590427028, time: 24.017
agent0_energy_min, agent0_attention_min
[ -2.45 -46.05]
agent1_energy_min, agent1_attention_min
[ -0.94 -17.24]
2200 50
steps: 109950, episodes: 2200, mean episode reward: -119.38398048069655, time: 24.232
agent0_energy_min, agent0_attention_min
[ -4.22 -43.39]
agent1_energy_min, agent1_attention_min
[ -5.79 -19.85]
2300 50
steps: 114950, episodes: 2300, mean episode reward: -118.04116499597322, time: 24.313
agent0_energy_min, agent0_attention_min
[ -6.15 -41.31]
agent1_energy_min, agent1_attention_min
[ -6.59 -30.15]
2400 50
steps: 119950, episodes: 2400, mean episode reward: -118.96376731894918, time: 24.388
agent0_energy_min, agent0_attention_min
[ -4.38 -44.29]
agent1_energy_min, agent1_attention_min
[ -9.37 -26.42]
2500 50
steps: 124950, episodes: 2500, mean episode reward: -109.69644503738698, time: 23.958
agent0_energy_min, agent0_attention_min
[ -6.87 -41.32]
agent1_energy_min, agent1_attention_min
[ -7.12 -22.  ]
2600 50
steps: 129950, episodes: 2600, mean episode reward: -110.67662647075245, time: 24.416
agent0_energy_min, agent0_attention_min
[ -6.07 -41.74]
agent1_energy_min, agent1_attention_min
[ -4.94 -36.79]
2700 50
steps: 134950, episodes: 2700, mean episode reward: -127.17429491008369, time: 24.015
agent0_energy_min, agent0_attention_min
[ -3.67 -43.87]
agent1_energy_min, agent1_attention_min
[ -7.31 -31.87]
2800 50
steps: 139950, episodes: 2800, mean episode reward: -113.44253554777357, time: 24.186
agent0_energy_min, agent0_attention_min
[ -9.7  -39.59]
agent1_energy_min, agent1_attention_min
[ -8.19 -34.03]
2900 50
steps: 144950, episodes: 2900, mean episode reward: -126.65156698314642, time: 24.548
agent0_energy_min, agent0_attention_min
[ -3.26 -45.6 ]
agent1_energy_min, agent1_attention_min
[ -8.29 -34.76]
3000 50
steps: 149950, episodes: 3000, mean episode reward: -110.3145547643433, time: 24.241
agent0_energy_min, agent0_attention_min
[ -6.47 -43.18]
agent1_energy_min, agent1_attention_min
[ -9.71 -31.74]
3100 50
steps: 154950, episodes: 3100, mean episode reward: -136.7433705521885, time: 24.645
agent0_energy_min, agent0_attention_min
[ -4.48 -45.1 ]
agent1_energy_min, agent1_attention_min
[ -1.01 -42.01]
3200 50
steps: 159950, episodes: 3200, mean episode reward: -125.96249750891346, time: 24.215
agent0_energy_min, agent0_attention_min
[ -2.2  -47.58]
agent1_energy_min, agent1_attention_min
[ -5.38 -41.23]
3300 50
steps: 164950, episodes: 3300, mean episode reward: -131.1171437509695, time: 24.355
agent0_energy_min, agent0_attention_min
[ -5.08 -44.4 ]
agent1_energy_min, agent1_attention_min
[ -9.35 -38.94]
3400 50
steps: 169950, episodes: 3400, mean episode reward: -111.32010888206248, time: 24.244
agent0_energy_min, agent0_attention_min
[-10.1 -39.5]
agent1_energy_min, agent1_attention_min
[-13.06 -34.01]
3500 50
steps: 174950, episodes: 3500, mean episode reward: -105.94181254863575, time: 23.949
agent0_energy_min, agent0_attention_min
[-10.22 -39.31]
agent1_energy_min, agent1_attention_min
[-23.51 -23.36]
3600 50
steps: 179950, episodes: 3600, mean episode reward: -121.86566577051423, time: 24.706
agent0_energy_min, agent0_attention_min
[-10.41 -39.06]
agent1_energy_min, agent1_attention_min
[-16.16 -31.35]
3700 50
steps: 184950, episodes: 3700, mean episode reward: -113.22826032399693, time: 24.637
agent0_energy_min, agent0_attention_min
[-12.3  -36.66]
agent1_energy_min, agent1_attention_min
[-18.58 -29.25]
3800 50
steps: 189950, episodes: 3800, mean episode reward: -104.92648460143137, time: 24.087
agent0_energy_min, agent0_attention_min
[-13.08 -36.08]
agent1_energy_min, agent1_attention_min
[-22.44 -24.9 ]
3900 50
steps: 194950, episodes: 3900, mean episode reward: -103.40054592690862, time: 24.024
agent0_energy_min, agent0_attention_min
[-12.08 -36.57]
agent1_energy_min, agent1_attention_min
[-29.84 -15.95]
4000 50
steps: 199950, episodes: 4000, mean episode reward: -94.74817554885476, time: 24.094Using good policy ddpg and adv policy ddpg
Starting iterations of wanderer2_2agents-1__2018-07-13_10-46-20...
100 50
steps: 4950, episodes: 100, mean episode reward: -151.04671054471729, time: 14.248
agent0_energy_min, agent0_attention_min
[-15.50505051 -18.09090909]
agent1_energy_min, agent1_attention_min
[-14.77777778 -20.55555556]
200 50
steps: 9950, episodes: 200, mean episode reward: -163.27937326319162, time: 17.948
agent0_energy_min, agent0_attention_min
[-16.09 -17.49]
agent1_energy_min, agent1_attention_min
[-15.16 -20.93]
300 50
steps: 14950, episodes: 300, mean episode reward: -145.06296266946964, time: 17.64
agent0_energy_min, agent0_attention_min
[-15.79 -17.5 ]
agent1_energy_min, agent1_attention_min
[-15.34 -20.63]
400 50
steps: 19950, episodes: 400, mean episode reward: -149.7049290340908, time: 17.988
agent0_energy_min, agent0_attention_min
[-15.71 -17.93]
agent1_energy_min, agent1_attention_min
[-15.49 -20.21]
500 50
steps: 24950, episodes: 500, mean episode reward: -137.57345775246728, time: 17.728
agent0_energy_min, agent0_attention_min
[-15.51 -18.4 ]
agent1_energy_min, agent1_attention_min
[-15.28 -19.95]
600 50
steps: 29950, episodes: 600, mean episode reward: -152.50338834051743, time: 17.584
agent0_energy_min, agent0_attention_min
[-15.94 -17.66]
agent1_energy_min, agent1_attention_min
[-15.04 -20.85]
700 50
steps: 34950, episodes: 700, mean episode reward: -135.1878569697151, time: 17.567
agent0_energy_min, agent0_attention_min
[-15.57 -18.46]
agent1_energy_min, agent1_attention_min
[-15.42 -20.24]
800 50
steps: 39950, episodes: 800, mean episode reward: -161.44685959043653, time: 17.548
agent0_energy_min, agent0_attention_min
[-16.02 -17.82]
agent1_energy_min, agent1_attention_min
[-15.   -19.84]
900 50
steps: 44950, episodes: 900, mean episode reward: -149.20327836313476, time: 18.02
agent0_energy_min, agent0_attention_min
[-15.38 -18.23]
agent1_energy_min, agent1_attention_min
[-15.27 -21.35]
1000 50
steps: 49950, episodes: 1000, mean episode reward: -133.51590620226875, time: 17.729
agent0_energy_min, agent0_attention_min
[-15.61 -17.87]
agent1_energy_min, agent1_attention_min
[-15.56 -20.11]
1100 50
steps: 54950, episodes: 1100, mean episode reward: -633.3979985365575, time: 22.915
agent0_energy_min, agent0_attention_min
[-22.35 -12.98]
agent1_energy_min, agent1_attention_min
[-14.71 -22.23]
1200 50
steps: 59950, episodes: 1200, mean episode reward: -361.4924614750069, time: 23.866
agent0_energy_min, agent0_attention_min
[-23.45 -14.34]
agent1_energy_min, agent1_attention_min
[ -8.18 -20.17]
1300 50
steps: 64950, episodes: 1300, mean episode reward: -193.2873003399465, time: 23.991
agent0_energy_min, agent0_attention_min
[-10.95  -3.17]
agent1_energy_min, agent1_attention_min
[-27.35  -9.1 ]
1400 50
steps: 69950, episodes: 1400, mean episode reward: -148.0581894516925, time: 24.373
agent0_energy_min, agent0_attention_min
[-28.31  -6.12]
agent1_energy_min, agent1_attention_min
[-15.45  -4.25]
1500 50
steps: 74950, episodes: 1500, mean episode reward: -131.56177028686426, time: 23.898
agent0_energy_min, agent0_attention_min
[-25.24  -6.02]
agent1_energy_min, agent1_attention_min
[-5.97 -9.18]
1600 50
steps: 79950, episodes: 1600, mean episode reward: -156.59773396979475, time: 25.03
agent0_energy_min, agent0_attention_min
[-15.47  -6.45]
agent1_energy_min, agent1_attention_min
[ -2.51 -23.04]
1700 50
steps: 84950, episodes: 1700, mean episode reward: -109.15902837650519, time: 24.025
agent0_energy_min, agent0_attention_min
[-24.51  -5.52]
agent1_energy_min, agent1_attention_min
[-17.85 -19.78]
1800 50
steps: 89950, episodes: 1800, mean episode reward: -82.79321018801167, time: 24.318
agent0_energy_min, agent0_attention_min
[-27.15  -2.14]
agent1_energy_min, agent1_attention_min
[-19.64 -13.93]
1900 50
steps: 94950, episodes: 1900, mean episode reward: -115.62443743108186, time: 24.318
agent0_energy_min, agent0_attention_min
[-27.55  -1.25]
agent1_energy_min, agent1_attention_min
[-21.89 -12.71]
2000 50
steps: 99950, episodes: 2000, mean episode reward: -126.41479136197034, time: 24.585
agent0_energy_min, agent0_attention_min
[-25.47  -1.39]
agent1_energy_min, agent1_attention_min
[-14.57 -26.75]
2100 50
steps: 104950, episodes: 2100, mean episode reward: -91.61193913394713, time: 26.275
agent0_energy_min, agent0_attention_min
[-32.16  -0.54]
agent1_energy_min, agent1_attention_min
[-15.78 -22.73]
2200 50
steps: 109950, episodes: 2200, mean episode reward: -112.3919613752527, time: 24.7
agent0_energy_min, agent0_attention_min
[-26.42  -2.6 ]
agent1_energy_min, agent1_attention_min
[-15.8  -26.59]
2300 50
steps: 114950, episodes: 2300, mean episode reward: -103.29402092678556, time: 24.33
agent0_energy_min, agent0_attention_min
[-31.41  -1.18]
agent1_energy_min, agent1_attention_min
[-11.36 -24.44]
2400 50
steps: 119950, episodes: 2400, mean episode reward: -93.48073672597312, time: 24.305
agent0_energy_min, agent0_attention_min
[-41.47  -0.3 ]
agent1_energy_min, agent1_attention_min
[-14.64 -28.72]
2500 50
steps: 124950, episodes: 2500, mean episode reward: -85.44291446670307, time: 24.513
agent0_energy_min, agent0_attention_min
[-41.29  -0.23]
agent1_energy_min, agent1_attention_min
[-23.24 -23.86]
2600 50
steps: 129950, episodes: 2600, mean episode reward: -104.06594208404609, time: 25.261
agent0_energy_min, agent0_attention_min
[-44.82  -0.37]
agent1_energy_min, agent1_attention_min
[-13.38 -31.71]
2700 50
steps: 134950, episodes: 2700, mean episode reward: -89.12305403573313, time: 24.622
agent0_energy_min, agent0_attention_min
[-46.49  -0.15]
agent1_energy_min, agent1_attention_min
[-27.26 -16.58]
2800 50
steps: 139950, episodes: 2800, mean episode reward: -72.52782665998028, time: 24.273
agent0_energy_min, agent0_attention_min
[-44.92  -0.14]
agent1_energy_min, agent1_attention_min
[-29.03 -17.89]
2900 50
steps: 144950, episodes: 2900, mean episode reward: -92.15500188989192, time: 24.875
agent0_energy_min, agent0_attention_min
[-46.76  -0.16]
agent1_energy_min, agent1_attention_min
[-22.56 -24.94]
3000 50
steps: 149950, episodes: 3000, mean episode reward: -95.78787906678541, time: 24.139
agent0_energy_min, agent0_attention_min
[-47.58  -0.16]
agent1_energy_min, agent1_attention_min
[-19.74 -29.58]
3100 50
steps: 154950, episodes: 3100, mean episode reward: -77.63146376059453, time: 25.113
agent0_energy_min, agent0_attention_min
[-47.71  -0.15]
agent1_energy_min, agent1_attention_min
[-21.94 -27.06]
3200 50
steps: 159950, episodes: 3200, mean episode reward: -71.24692939939129, time: 24.406
agent0_energy_min, agent0_attention_min
[-45.23  -0.18]
agent1_energy_min, agent1_attention_min
[-41.52  -5.03]
3300 50
steps: 164950, episodes: 3300, mean episode reward: -73.96466117886031, time: 24.355
agent0_energy_min, agent0_attention_min
[-44.79  -0.07]
agent1_energy_min, agent1_attention_min
[-40.96  -7.59]
3400 50
steps: 169950, episodes: 3400, mean episode reward: -76.69290745611411, time: 24.507
agent0_energy_min, agent0_attention_min
[-45.75  -0.07]
agent1_energy_min, agent1_attention_min
[-33.55 -16.2 ]
3500 50
steps: 174950, episodes: 3500, mean episode reward: -78.67061952225849, time: 24.924
agent0_energy_min, agent0_attention_min
[-47.98  -0.11]
agent1_energy_min, agent1_attention_min
[-35.13 -14.03]
3600 50
steps: 179950, episodes: 3600, mean episode reward: -75.04152111803204, time: 24.957
agent0_energy_min, agent0_attention_min
[-48.13  -0.06]
agent1_energy_min, agent1_attention_min
[-42.84  -6.41]
3700 50
steps: 184950, episodes: 3700, mean episode reward: -74.61910897476828, time: 24.839
agent0_energy_min, agent0_attention_min
[-48.69  -0.05]
agent1_energy_min, agent1_attention_min
[-43.49  -5.81]
3800 50
steps: 189950, episodes: 3800, mean episode reward: -73.02703756970621, time: 24.547
agent0_energy_min, agent0_attention_min
[-4.783e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-41.51  -6.99]
3900 50
steps: 194950, episodes: 3900, mean episode reward: -70.32160303764935, time: 24.771
agent0_energy_min, agent0_attention_min
[-47.46  -0.05]
agent1_energy_min, agent1_attention_min
[-41.55  -7.46]
4000 50
steps: 199950, episodes: 4000, mean episode reward: -66.45469688028612, time: 24.383Using good policy ddpg and adv policy ddpg
Starting iterations of wanderer2_2agents-1__2018-07-13_10-46-24...
100 50
steps: 4950, episodes: 100, mean episode reward: -152.2463167714332, time: 16.42
agent0_energy_min, agent0_attention_min
[-17.         -17.53535354]
agent1_energy_min, agent1_attention_min
[-15.93939394 -17.42424242]
200 50
steps: 9950, episodes: 200, mean episode reward: -144.35310726703173, time: 17.962
agent0_energy_min, agent0_attention_min
[-16.78 -18.01]
agent1_energy_min, agent1_attention_min
[-15.55 -17.2 ]
300 50
steps: 14950, episodes: 300, mean episode reward: -134.49700312698837, time: 18.547
agent0_energy_min, agent0_attention_min
[-17.14 -17.84]
agent1_energy_min, agent1_attention_min
[-15.95 -16.83]
400 50
steps: 19950, episodes: 400, mean episode reward: -157.66722186694108, time: 18.293
agent0_energy_min, agent0_attention_min
[-17.31 -17.44]
agent1_energy_min, agent1_attention_min
[-16.19 -17.5 ]
500 50
steps: 24950, episodes: 500, mean episode reward: -168.08908173219072, time: 18.269
agent0_energy_min, agent0_attention_min
[-17.12 -17.39]
agent1_energy_min, agent1_attention_min
[-15.44 -17.67]
600 50
steps: 29950, episodes: 600, mean episode reward: -128.70254265595048, time: 18.021
agent0_energy_min, agent0_attention_min
[-17.23 -17.76]
agent1_energy_min, agent1_attention_min
[-16.42 -16.98]
700 50
steps: 34950, episodes: 700, mean episode reward: -136.6848418212973, time: 18.126
agent0_energy_min, agent0_attention_min
[-17.34 -17.33]
agent1_energy_min, agent1_attention_min
[-15.59 -17.85]
800 50
steps: 39950, episodes: 800, mean episode reward: -169.40451462353832, time: 18.051
agent0_energy_min, agent0_attention_min
[-16.67 -17.73]
agent1_energy_min, agent1_attention_min
[-15.66 -17.43]
900 50
steps: 44950, episodes: 900, mean episode reward: -173.26630653299316, time: 18.532
agent0_energy_min, agent0_attention_min
[-17.54 -17.05]
agent1_energy_min, agent1_attention_min
[-15.75 -17.77]
1000 50
steps: 49950, episodes: 1000, mean episode reward: -144.0888107046499, time: 18.272
agent0_energy_min, agent0_attention_min
[-16.7  -17.31]
agent1_energy_min, agent1_attention_min
[-15.74 -17.2 ]
1100 50
steps: 54950, episodes: 1100, mean episode reward: -480.7432776287206, time: 24.355
agent0_energy_min, agent0_attention_min
[-16.42 -14.32]
agent1_energy_min, agent1_attention_min
[ -6.68 -26.74]
1200 50
steps: 59950, episodes: 1200, mean episode reward: -358.27120491085196, time: 24.959
agent0_energy_min, agent0_attention_min
[-15.86 -21.06]
agent1_energy_min, agent1_attention_min
[-16.13  -2.09]
1300 50
steps: 64950, episodes: 1300, mean episode reward: -232.8099275414188, time: 25.086
agent0_energy_min, agent0_attention_min
[-22.34  -8.09]
agent1_energy_min, agent1_attention_min
[-26.16  -0.32]
1400 50
steps: 69950, episodes: 1400, mean episode reward: -162.25394638517605, time: 24.964
agent0_energy_min, agent0_attention_min
[-23.21 -17.92]
agent1_energy_min, agent1_attention_min
[-2.51 -0.66]
1500 50
steps: 74950, episodes: 1500, mean episode reward: -129.60125838469546, time: 24.87
agent0_energy_min, agent0_attention_min
[-12.87 -25.28]
agent1_energy_min, agent1_attention_min
[-0.07 -0.04]
1600 50
steps: 79950, episodes: 1600, mean episode reward: -138.43542069156084, time: 25.988
agent0_energy_min, agent0_attention_min
[-13.59 -25.43]
agent1_energy_min, agent1_attention_min
[-0.03  0.  ]
1700 50
steps: 84950, episodes: 1700, mean episode reward: -156.65043460222606, time: 25.343
agent0_energy_min, agent0_attention_min
[ -5.61 -36.4 ]
agent1_energy_min, agent1_attention_min
[-0.13 -0.02]
1800 50
steps: 89950, episodes: 1800, mean episode reward: -136.27528084136807, time: 25.501
agent0_energy_min, agent0_attention_min
[ -7.35 -30.64]
agent1_energy_min, agent1_attention_min
[-0.06 -0.14]
1900 50
steps: 94950, episodes: 1900, mean episode reward: -131.8610914484557, time: 25.416
agent0_energy_min, agent0_attention_min
[ -8.92 -29.71]
agent1_energy_min, agent1_attention_min
[-0.82 -0.17]
2000 50
steps: 99950, episodes: 2000, mean episode reward: -172.92206809469306, time: 24.935
agent0_energy_min, agent0_attention_min
[ -9.28 -36.49]
agent1_energy_min, agent1_attention_min
[-0.79 -2.17]
2100 50
steps: 104950, episodes: 2100, mean episode reward: -220.690677714527, time: 25.507
agent0_energy_min, agent0_attention_min
[ -3.92 -42.73]
agent1_energy_min, agent1_attention_min
[-14.88 -15.62]
2200 50
steps: 109950, episodes: 2200, mean episode reward: -184.7531170599238, time: 25.038
agent0_energy_min, agent0_attention_min
[-15.37 -30.15]
agent1_energy_min, agent1_attention_min
[-12.76  -0.63]
2300 50
steps: 114950, episodes: 2300, mean episode reward: -116.79347949178303, time: 25.456
agent0_energy_min, agent0_attention_min
[-12.93 -29.88]
agent1_energy_min, agent1_attention_min
[-20.26  -0.15]
2400 50
steps: 119950, episodes: 2400, mean episode reward: -132.44704385777226, time: 25.583
agent0_energy_min, agent0_attention_min
[-18.81 -25.64]
agent1_energy_min, agent1_attention_min
[-32.29  -0.8 ]
2500 50
steps: 124950, episodes: 2500, mean episode reward: -141.0270687283004, time: 24.953
agent0_energy_min, agent0_attention_min
[-20.13 -25.01]
agent1_energy_min, agent1_attention_min
[-24.33  -2.26]
2600 50
steps: 129950, episodes: 2600, mean episode reward: -87.36033805577426, time: 25.353
agent0_energy_min, agent0_attention_min
[-20.65 -24.81]
agent1_energy_min, agent1_attention_min
[-15.54  -0.67]
2700 50
steps: 134950, episodes: 2700, mean episode reward: -99.84427111420146, time: 24.473
agent0_energy_min, agent0_attention_min
[-13.76 -33.19]
agent1_energy_min, agent1_attention_min
[-17.25  -0.28]
2800 50
steps: 139950, episodes: 2800, mean episode reward: -103.1800471929199, time: 24.812
agent0_energy_min, agent0_attention_min
[-18.45 -27.76]
agent1_energy_min, agent1_attention_min
[-22.27  -0.51]
2900 50
steps: 144950, episodes: 2900, mean episode reward: -112.33300215412953, time: 24.24
agent0_energy_min, agent0_attention_min
[-13.08 -35.55]
agent1_energy_min, agent1_attention_min
[-30.74  -0.47]
3000 50
steps: 149950, episodes: 3000, mean episode reward: -88.07094173212258, time: 24.138
agent0_energy_min, agent0_attention_min
[-15.71 -33.59]
agent1_energy_min, agent1_attention_min
[-28.99  -0.49]
3100 50
steps: 154950, episodes: 3100, mean episode reward: -97.77026369984107, time: 24.526
agent0_energy_min, agent0_attention_min
[ -8.39 -41.02]
agent1_energy_min, agent1_attention_min
[-38.72  -0.42]
3200 50
steps: 159950, episodes: 3200, mean episode reward: -101.73037568595443, time: 24.174
agent0_energy_min, agent0_attention_min
[-20.11 -29.45]
agent1_energy_min, agent1_attention_min
[-33.02  -1.08]
3300 50
steps: 164950, episodes: 3300, mean episode reward: -97.9638095965334, time: 23.834
agent0_energy_min, agent0_attention_min
[-14.23 -35.32]
agent1_energy_min, agent1_attention_min
[-41.6   -0.79]
3400 50
steps: 169950, episodes: 3400, mean episode reward: -85.37954668161902, time: 24.197
agent0_energy_min, agent0_attention_min
[-14.7 -34.4]
agent1_energy_min, agent1_attention_min
[-43.48  -0.32]
3500 50
steps: 174950, episodes: 3500, mean episode reward: -96.06944132329546, time: 24.147
agent0_energy_min, agent0_attention_min
[-18.98 -30.38]
agent1_energy_min, agent1_attention_min
[-33.37  -0.34]
3600 50
steps: 179950, episodes: 3600, mean episode reward: -96.3674609397935, time: 24.414
agent0_energy_min, agent0_attention_min
[-15.21 -34.53]
agent1_energy_min, agent1_attention_min
[-41.69  -0.16]
3700 50
steps: 184950, episodes: 3700, mean episode reward: -76.73040560615412, time: 23.928
agent0_energy_min, agent0_attention_min
[-22.57 -26.61]
agent1_energy_min, agent1_attention_min
[-43.6  -0.1]
3800 50
steps: 189950, episodes: 3800, mean episode reward: -85.04671926135053, time: 23.933
agent0_energy_min, agent0_attention_min
[-23.48 -26.17]
agent1_energy_min, agent1_attention_min
[-45.31  -0.16]
3900 50
steps: 194950, episodes: 3900, mean episode reward: -94.70467279093484, time: 23.943
agent0_energy_min, agent0_attention_min
[-31.52 -18.05]
agent1_energy_min, agent1_attention_min
[-41.06  -0.28]
4000 50
steps: 199950, episodes: 4000, mean episode reward: -75.87138928564067, time: 24.444
agent0_energy_min, agent0_attention_minUsing good policy ddpg and adv policy ddpg
Starting iterations of wanderer2_2agents-2__2018-07-13_10-46-27...
100 50
steps: 4950, episodes: 100, mean episode reward: -171.05545263253603, time: 16.395
agent0_energy_min, agent0_attention_min
[-16.08080808 -16.56565657]
agent1_energy_min, agent1_attention_min
[-15.70707071 -17.88888889]
200 50
steps: 9950, episodes: 200, mean episode reward: -168.0537021560249, time: 17.973
agent0_energy_min, agent0_attention_min
[-16.46 -16.41]
agent1_energy_min, agent1_attention_min
[-15.48 -17.93]
300 50
steps: 14950, episodes: 300, mean episode reward: -143.83312751174466, time: 18.134
agent0_energy_min, agent0_attention_min
[-15.75 -17.03]
agent1_energy_min, agent1_attention_min
[-16.23 -18.04]
400 50
steps: 19950, episodes: 400, mean episode reward: -157.24475399662276, time: 17.947
agent0_energy_min, agent0_attention_min
[-16.05 -16.76]
agent1_energy_min, agent1_attention_min
[-15.76 -18.03]
500 50
steps: 24950, episodes: 500, mean episode reward: -158.37128178112118, time: 18.379
agent0_energy_min, agent0_attention_min
[-16.55 -16.94]
agent1_energy_min, agent1_attention_min
[-16.04 -17.67]
600 50
steps: 29950, episodes: 600, mean episode reward: -169.74777118938297, time: 17.726
agent0_energy_min, agent0_attention_min
[-16.83 -16.51]
agent1_energy_min, agent1_attention_min
[-16.52 -17.38]
700 50
steps: 34950, episodes: 700, mean episode reward: -157.8889673111396, time: 17.84
agent0_energy_min, agent0_attention_min
[-16.78 -16.73]
agent1_energy_min, agent1_attention_min
[-15.96 -18.05]
800 50
steps: 39950, episodes: 800, mean episode reward: -161.71947658176043, time: 17.409
agent0_energy_min, agent0_attention_min
[-16.56 -16.92]
agent1_energy_min, agent1_attention_min
[-16.21 -17.15]
900 50
steps: 44950, episodes: 900, mean episode reward: -170.851078455751, time: 18.106
agent0_energy_min, agent0_attention_min
[-16.39 -16.63]
agent1_energy_min, agent1_attention_min
[-15.73 -17.55]
1000 50
steps: 49950, episodes: 1000, mean episode reward: -139.96218392077392, time: 17.563
agent0_energy_min, agent0_attention_min
[-16.33 -16.77]
agent1_energy_min, agent1_attention_min
[-15.84 -17.74]
1100 50
steps: 54950, episodes: 1100, mean episode reward: -417.94031646211175, time: 24.375
agent0_energy_min, agent0_attention_min
[-15.85 -22.48]
agent1_energy_min, agent1_attention_min
[-10.71 -16.52]
1200 50
steps: 59950, episodes: 1200, mean episode reward: -386.3323416087083, time: 24.892
agent0_energy_min, agent0_attention_min
[-16.94  -6.36]
agent1_energy_min, agent1_attention_min
[-27.87 -10.37]
1300 50
steps: 64950, episodes: 1300, mean episode reward: -213.7165755443526, time: 24.768
agent0_energy_min, agent0_attention_min
[-22.66 -22.72]
agent1_energy_min, agent1_attention_min
[-3.14 -3.76]
1400 50
steps: 69950, episodes: 1400, mean episode reward: -180.287405900412, time: 24.865
agent0_energy_min, agent0_attention_min
[-10.56 -10.49]
agent1_energy_min, agent1_attention_min
[-18.19  -2.2 ]
1500 50
steps: 74950, episodes: 1500, mean episode reward: -158.50521787904955, time: 24.633
agent0_energy_min, agent0_attention_min
[-1.83 -0.75]
agent1_energy_min, agent1_attention_min
[-5.1  -5.18]
1600 50
steps: 79950, episodes: 1600, mean episode reward: -138.48603499023582, time: 26.023
agent0_energy_min, agent0_attention_min
[-0.88 -2.14]
agent1_energy_min, agent1_attention_min
[ -2.46 -12.09]
1700 50
steps: 84950, episodes: 1700, mean episode reward: -149.28598109080897, time: 25.03
agent0_energy_min, agent0_attention_min
[-0.89 -2.26]
agent1_energy_min, agent1_attention_min
[ -1.41 -20.85]
1800 50
steps: 89950, episodes: 1800, mean episode reward: -143.8472352211728, time: 25.035
agent0_energy_min, agent0_attention_min
[-0.14 -0.19]
agent1_energy_min, agent1_attention_min
[ -1.99 -13.47]
1900 50
steps: 94950, episodes: 1900, mean episode reward: -149.11557505684092, time: 25.357
agent0_energy_min, agent0_attention_min
[-1.23 -2.36]
agent1_energy_min, agent1_attention_min
[ -1.87 -10.27]
2000 50
steps: 99950, episodes: 2000, mean episode reward: -142.45445346276227, time: 24.892
agent0_energy_min, agent0_attention_min
[-0.38 -2.73]
agent1_energy_min, agent1_attention_min
[-0.51 -6.94]
2100 50
steps: 104950, episodes: 2100, mean episode reward: -140.73146699813694, time: 25.912
agent0_energy_min, agent0_attention_min
[-0.58 -0.13]
agent1_energy_min, agent1_attention_min
[ -2.41 -10.61]
2200 50
steps: 109950, episodes: 2200, mean episode reward: -148.8105852094357, time: 25.284
agent0_energy_min, agent0_attention_min
[-0.26 -0.26]
agent1_energy_min, agent1_attention_min
[-12.59 -14.88]
2300 50
steps: 114950, episodes: 2300, mean episode reward: -126.50083397284183, time: 24.672
agent0_energy_min, agent0_attention_min
[-1.42 -0.44]
agent1_energy_min, agent1_attention_min
[-17.63 -13.77]
2400 50
steps: 119950, episodes: 2400, mean episode reward: -145.06443128631435, time: 25.814
agent0_energy_min, agent0_attention_min
[-0.14 -0.29]
agent1_energy_min, agent1_attention_min
[-30.26  -7.21]
2500 50
steps: 124950, episodes: 2500, mean episode reward: -137.44237647937243, time: 25.433
agent0_energy_min, agent0_attention_min
[ -7.29 -29.6 ]
agent1_energy_min, agent1_attention_min
[-47.07  -1.95]
2600 50
steps: 129950, episodes: 2600, mean episode reward: -121.94256066367548, time: 24.993
agent0_energy_min, agent0_attention_min
[ -8.15 -36.87]
agent1_energy_min, agent1_attention_min
[-31.54  -4.57]
2700 50
steps: 134950, episodes: 2700, mean episode reward: -128.56202466159584, time: 25.07
agent0_energy_min, agent0_attention_min
[ -6.74 -38.75]
agent1_energy_min, agent1_attention_min
[-42.65  -1.87]
2800 50
steps: 139950, episodes: 2800, mean episode reward: -120.90121756745022, time: 25.609
agent0_energy_min, agent0_attention_min
[-11.41 -35.42]
agent1_energy_min, agent1_attention_min
[-40.87  -2.45]
2900 50
steps: 144950, episodes: 2900, mean episode reward: -119.99092233385662, time: 24.762
agent0_energy_min, agent0_attention_min
[ -4.89 -42.6 ]
agent1_energy_min, agent1_attention_min
[-42.73  -1.69]
3000 50
steps: 149950, episodes: 3000, mean episode reward: -125.13222372973627, time: 24.834
agent0_energy_min, agent0_attention_min
[ -8.   -39.43]
agent1_energy_min, agent1_attention_min
[-41.53  -1.15]
3100 50
steps: 154950, episodes: 3100, mean episode reward: -121.32744852597013, time: 25.368
agent0_energy_min, agent0_attention_min
[ -8.7  -37.54]
agent1_energy_min, agent1_attention_min
[-39.77  -1.26]
3200 50
steps: 159950, episodes: 3200, mean episode reward: -113.48771142321384, time: 25.097
agent0_energy_min, agent0_attention_min
[ -5.67 -41.86]
agent1_energy_min, agent1_attention_min
[-41.67  -0.68]
3300 50
steps: 164950, episodes: 3300, mean episode reward: -127.18108248770397, time: 25.148
agent0_energy_min, agent0_attention_min
[-32.19 -16.43]
agent1_energy_min, agent1_attention_min
[-40.32  -0.36]
3400 50
steps: 169950, episodes: 3400, mean episode reward: -119.30834995604718, time: 24.935
agent0_energy_min, agent0_attention_min
[-15.42 -33.09]
agent1_energy_min, agent1_attention_min
[-38.28  -0.96]
3500 50
steps: 174950, episodes: 3500, mean episode reward: -112.57366672117813, time: 25.177
agent0_energy_min, agent0_attention_min
[ -5.5  -41.95]
agent1_energy_min, agent1_attention_min
[-42.24  -1.58]
3600 50
steps: 179950, episodes: 3600, mean episode reward: -121.03517766754348, time: 25.414
agent0_energy_min, agent0_attention_min
[-11.73 -37.09]
agent1_energy_min, agent1_attention_min
[-45.37  -0.78]
3700 50
steps: 184950, episodes: 3700, mean episode reward: -114.9105498528277, time: 25.281
agent0_energy_min, agent0_attention_min
[-13.99 -34.03]
agent1_energy_min, agent1_attention_min
[-47.54  -1.42]
3800 50
steps: 189950, episodes: 3800, mean episode reward: -117.00907147961698, time: 24.625
agent0_energy_min, agent0_attention_min
[-12.23 -36.44]
agent1_energy_min, agent1_attention_min
[-45.85  -1.85]
3900 50
steps: 194950, episodes: 3900, mean episode reward: -101.68097907252502, time: 24.978
agent0_energy_min, agent0_attention_min
[-16.25 -32.96]
agent1_energy_min, agent1_attention_min
[-47.83  -1.81]
4000 50
steps: 199950, episodes: 4000, mean episode reward: -118.41319782337955, time: 25.022
agent0_energy_min, agent0_attention_minUsing good policy ddpg and adv policy ddpg
Starting iterations of wanderer2_2agents-2__2018-07-13_10-46-29...
100 50
steps: 4950, episodes: 100, mean episode reward: -163.87347946189132, time: 17.092
agent0_energy_min, agent0_attention_min
[-18.08080808 -16.23232323]
agent1_energy_min, agent1_attention_min
[-15.70707071 -17.49494949]
200 50
steps: 9950, episodes: 200, mean episode reward: -168.1681277370526, time: 18.094
agent0_energy_min, agent0_attention_min
[-17.84 -16.35]
agent1_energy_min, agent1_attention_min
[-15.77 -17.4 ]
300 50
steps: 14950, episodes: 300, mean episode reward: -158.00716823922303, time: 18.109
agent0_energy_min, agent0_attention_min
[-19.01 -15.95]
agent1_energy_min, agent1_attention_min
[-16.59 -17.08]
400 50
steps: 19950, episodes: 400, mean episode reward: -165.42558009697038, time: 17.803
agent0_energy_min, agent0_attention_min
[-17.6  -16.59]
agent1_energy_min, agent1_attention_min
[-16.43 -17.04]
500 50
steps: 24950, episodes: 500, mean episode reward: -175.41163223629934, time: 18.05
agent0_energy_min, agent0_attention_min
[-18.72 -16.03]
agent1_energy_min, agent1_attention_min
[-16.09 -17.46]
600 50
steps: 29950, episodes: 600, mean episode reward: -148.87455470713857, time: 17.92
agent0_energy_min, agent0_attention_min
[-18.69 -15.22]
agent1_energy_min, agent1_attention_min
[-16.32 -17.59]
700 50
steps: 34950, episodes: 700, mean episode reward: -158.05375846107208, time: 17.963
agent0_energy_min, agent0_attention_min
[-18.16 -15.84]
agent1_energy_min, agent1_attention_min
[-16.57 -17.5 ]
800 50
steps: 39950, episodes: 800, mean episode reward: -178.39371380932124, time: 18.695
agent0_energy_min, agent0_attention_min
[-18.26 -16.12]
agent1_energy_min, agent1_attention_min
[-16.57 -17.39]
900 50
steps: 44950, episodes: 900, mean episode reward: -175.47462924989782, time: 17.897
agent0_energy_min, agent0_attention_min
[-17.78 -16.13]
agent1_energy_min, agent1_attention_min
[-16.81 -17.01]
1000 50
steps: 49950, episodes: 1000, mean episode reward: -141.6681459193628, time: 18.049
agent0_energy_min, agent0_attention_min
[-18.04 -16.34]
agent1_energy_min, agent1_attention_min
[-16.22 -17.34]
1100 50
steps: 54950, episodes: 1100, mean episode reward: -839.229888325381, time: 24.687
agent0_energy_min, agent0_attention_min
[-13.97 -16.65]
agent1_energy_min, agent1_attention_min
[-13.01 -15.7 ]
1200 50
steps: 59950, episodes: 1200, mean episode reward: -348.1937708937437, time: 24.891
agent0_energy_min, agent0_attention_min
[-18.72 -23.57]
agent1_energy_min, agent1_attention_min
[-22.89 -20.13]
1300 50
steps: 64950, episodes: 1300, mean episode reward: -275.03266436068645, time: 25.318
agent0_energy_min, agent0_attention_min
[-18.4  -6. ]
agent1_energy_min, agent1_attention_min
[-14.2   -6.47]
1400 50
steps: 69950, episodes: 1400, mean episode reward: -212.1187694241986, time: 24.994
agent0_energy_min, agent0_attention_min
[-26.42  -3.98]
agent1_energy_min, agent1_attention_min
[-21.38 -15.89]
1500 50
steps: 74950, episodes: 1500, mean episode reward: -246.72752593745545, time: 25.074
agent0_energy_min, agent0_attention_min
[-17.86 -10.54]
agent1_energy_min, agent1_attention_min
[-19.  -14.9]
1600 50
steps: 79950, episodes: 1600, mean episode reward: -189.4123951765534, time: 26.218
agent0_energy_min, agent0_attention_min
[ -3.36 -23.12]
agent1_energy_min, agent1_attention_min
[-31.88 -12.71]
1700 50
steps: 84950, episodes: 1700, mean episode reward: -153.92170938347593, time: 25.027
agent0_energy_min, agent0_attention_min
[ -5.5  -14.56]
agent1_energy_min, agent1_attention_min
[-19.14 -14.57]
1800 50
steps: 89950, episodes: 1800, mean episode reward: -142.73293148324873, time: 24.999
agent0_energy_min, agent0_attention_min
[ -5.76 -20.93]
agent1_energy_min, agent1_attention_min
[-10.1  -31.47]
1900 50
steps: 94950, episodes: 1900, mean episode reward: -108.09662616695621, time: 25.087
agent0_energy_min, agent0_attention_min
[-3.85 -8.49]
agent1_energy_min, agent1_attention_min
[ -4.71 -40.77]
2000 50
steps: 99950, episodes: 2000, mean episode reward: -101.12671890465944, time: 24.774
agent0_energy_min, agent0_attention_min
[ -2.52 -19.12]
agent1_energy_min, agent1_attention_min
[ -3.57 -41.8 ]
2100 50
steps: 104950, episodes: 2100, mean episode reward: -127.79655544691961, time: 25.904
agent0_energy_min, agent0_attention_min
[ -4.42 -14.  ]
agent1_energy_min, agent1_attention_min
[ -3.29 -43.07]
2200 50
steps: 109950, episodes: 2200, mean episode reward: -120.69800191007855, time: 24.564
agent0_energy_min, agent0_attention_min
[ -5.07 -23.89]
agent1_energy_min, agent1_attention_min
[ -2.11 -42.83]
2300 50
steps: 114950, episodes: 2300, mean episode reward: -125.80743094628147, time: 24.83
agent0_energy_min, agent0_attention_min
[ -7.36 -11.31]
agent1_energy_min, agent1_attention_min
[-15.96 -31.3 ]
2400 50
steps: 119950, episodes: 2400, mean episode reward: -127.26454944599897, time: 25.348
agent0_energy_min, agent0_attention_min
[-26.66  -1.85]
agent1_energy_min, agent1_attention_min
[ -5.81 -41.55]
2500 50
steps: 124950, episodes: 2500, mean episode reward: -118.18388304449009, time: 25.284
agent0_energy_min, agent0_attention_min
[-35.44  -0.24]
agent1_energy_min, agent1_attention_min
[-10.18 -37.36]
2600 50
steps: 129950, episodes: 2600, mean episode reward: -131.667791184745, time: 25.692
agent0_energy_min, agent0_attention_min
[-13.37  -7.28]
agent1_energy_min, agent1_attention_min
[ -7.16 -42.2 ]
2700 50
steps: 134950, episodes: 2700, mean episode reward: -115.22464194373582, time: 25.296
agent0_energy_min, agent0_attention_min
[-13.71 -10.43]
agent1_energy_min, agent1_attention_min
[ -4.71 -44.24]
2800 50
steps: 139950, episodes: 2800, mean episode reward: -117.35877684153293, time: 25.227
agent0_energy_min, agent0_attention_min
[ -7.22 -19.56]
agent1_energy_min, agent1_attention_min
[ -3.15 -45.49]
2900 50
steps: 144950, episodes: 2900, mean episode reward: -138.49310265728002, time: 25.164
agent0_energy_min, agent0_attention_min
[ -9.21 -13.43]
agent1_energy_min, agent1_attention_min
[ -7.7  -40.88]
3000 50
steps: 149950, episodes: 3000, mean episode reward: -122.57485607703477, time: 25.438
agent0_energy_min, agent0_attention_min
[-11.38 -16.17]
agent1_energy_min, agent1_attention_min
[ -8.09 -41.81]
3100 50
steps: 154950, episodes: 3100, mean episode reward: -117.62525238374045, time: 25.982
agent0_energy_min, agent0_attention_min
[-20.19 -17.6 ]
agent1_energy_min, agent1_attention_min
[ -6.43 -41.25]
3200 50
steps: 159950, episodes: 3200, mean episode reward: -98.98565752255855, time: 24.877
agent0_energy_min, agent0_attention_min
[-28.6 -11.9]
agent1_energy_min, agent1_attention_min
[-11.65 -38.16]
3300 50
steps: 164950, episodes: 3300, mean episode reward: -104.87178606046687, time: 24.636
agent0_energy_min, agent0_attention_min
[-30.52 -12.73]
agent1_energy_min, agent1_attention_min
[ -9.94 -39.61]
3400 50
steps: 169950, episodes: 3400, mean episode reward: -119.97487728684429, time: 25.411
agent0_energy_min, agent0_attention_min
[-33.62 -10.19]
agent1_energy_min, agent1_attention_min
[-10.25 -39.47]
3500 50
steps: 174950, episodes: 3500, mean episode reward: -101.76282313738602, time: 25.201
agent0_energy_min, agent0_attention_min
[-33.41  -9.76]
agent1_energy_min, agent1_attention_min
[ -8.55 -41.32]
3600 50
steps: 179950, episodes: 3600, mean episode reward: -99.23077880463065, time: 24.956
agent0_energy_min, agent0_attention_min
[-33.29  -7.74]
agent1_energy_min, agent1_attention_min
[ -8.99 -40.48]
3700 50
steps: 184950, episodes: 3700, mean episode reward: -106.37572592230812, time: 25.442
agent0_energy_min, agent0_attention_min
[-44.47  -1.84]
agent1_energy_min, agent1_attention_min
[-10.16 -39.25]
3800 50
steps: 189950, episodes: 3800, mean episode reward: -104.61118788469362, time: 25.107
agent0_energy_min, agent0_attention_min
[-48.54  -0.84]
agent1_energy_min, agent1_attention_min
[ -8.51 -40.96]
3900 50
steps: 194950, episodes: 3900, mean episode reward: -119.52491112122647, time: 25.589
agent0_energy_min, agent0_attention_min
[-48.93  -0.76]
agent1_energy_min, agent1_attention_min
[ -8.11 -41.7 ]
4000 50
steps: 199950, episodes: 4000, mean episode reward: -117.23280786417672, time: 25.423Using good policy ddpg and adv policy ddpg
Starting iterations of wanderer2_2agents-3__2018-07-13_10-46-37...
100 50
steps: 4950, episodes: 100, mean episode reward: -205.92004222101173, time: 17.402
agent0_energy_min, agent0_attention_min
[-17.96969697 -16.15151515]
agent1_energy_min, agent1_attention_min
[-17.2020202  -15.34343434]
200 50
steps: 9950, episodes: 200, mean episode reward: -200.82008351926663, time: 17.591
agent0_energy_min, agent0_attention_min
[-17.95 -16.59]
agent1_energy_min, agent1_attention_min
[-16.54 -15.68]
300 50
steps: 14950, episodes: 300, mean episode reward: -181.5650366035833, time: 18.187
agent0_energy_min, agent0_attention_min
[-17.55 -16.3 ]
agent1_energy_min, agent1_attention_min
[-17.04 -15.98]
400 50
steps: 19950, episodes: 400, mean episode reward: -221.63344349645905, time: 17.8
agent0_energy_min, agent0_attention_min
[-17.62 -16.64]
agent1_energy_min, agent1_attention_min
[-17.29 -15.67]
500 50
steps: 24950, episodes: 500, mean episode reward: -234.23150888585175, time: 18.12
agent0_energy_min, agent0_attention_min
[-18.23 -16.36]
agent1_energy_min, agent1_attention_min
[-16.32 -16.02]
600 50
steps: 29950, episodes: 600, mean episode reward: -214.03092298586233, time: 17.506
agent0_energy_min, agent0_attention_min
[-17.9  -16.54]
agent1_energy_min, agent1_attention_min
[-16.35 -15.85]
700 50
steps: 34950, episodes: 700, mean episode reward: -205.74900973252755, time: 17.56
agent0_energy_min, agent0_attention_min
[-18.13 -16.12]
agent1_energy_min, agent1_attention_min
[-17.52 -15.16]
800 50
steps: 39950, episodes: 800, mean episode reward: -196.00253029756493, time: 17.943
agent0_energy_min, agent0_attention_min
[-17.41 -17.03]
agent1_energy_min, agent1_attention_min
[-17.1  -15.26]
900 50
steps: 44950, episodes: 900, mean episode reward: -208.14952657230708, time: 17.927
agent0_energy_min, agent0_attention_min
[-17.7  -16.34]
agent1_energy_min, agent1_attention_min
[-16.91 -16.27]
1000 50
steps: 49950, episodes: 1000, mean episode reward: -203.2150928484403, time: 18.056
agent0_energy_min, agent0_attention_min
[-17.52 -16.71]
agent1_energy_min, agent1_attention_min
[-16.85 -15.63]
1100 50
steps: 54950, episodes: 1100, mean episode reward: -839.50574871784, time: 24.288
agent0_energy_min, agent0_attention_min
[-16.46 -16.36]
agent1_energy_min, agent1_attention_min
[-23.43  -5.91]
1200 50
steps: 59950, episodes: 1200, mean episode reward: -377.9557879513611, time: 24.956
agent0_energy_min, agent0_attention_min
[-20.67 -22.78]
agent1_energy_min, agent1_attention_min
[-7.51 -7.42]
1300 50
steps: 64950, episodes: 1300, mean episode reward: -280.739716153443, time: 24.413
agent0_energy_min, agent0_attention_min
[-27.74  -4.06]
agent1_energy_min, agent1_attention_min
[-37.56 -11.4 ]
1400 50
steps: 69950, episodes: 1400, mean episode reward: -244.76652603087817, time: 24.657
agent0_energy_min, agent0_attention_min
[-14.34  -4.34]
agent1_energy_min, agent1_attention_min
[-42.   -2.6]
1500 50
steps: 74950, episodes: 1500, mean episode reward: -177.52245573477475, time: 25.205
agent0_energy_min, agent0_attention_min
[-3.92 -2.03]
agent1_energy_min, agent1_attention_min
[-37.79  -0.41]
1600 50
steps: 79950, episodes: 1600, mean episode reward: -202.2754049598524, time: 25.494
agent0_energy_min, agent0_attention_min
[-0.89 -0.67]
agent1_energy_min, agent1_attention_min
[-39.6   -0.17]
1700 50
steps: 84950, episodes: 1700, mean episode reward: -163.81227494972748, time: 25.064
agent0_energy_min, agent0_attention_min
[-1.83 -0.8 ]
agent1_energy_min, agent1_attention_min
[-35.51  -0.16]
1800 50
steps: 89950, episodes: 1800, mean episode reward: -138.98127879100636, time: 24.733
agent0_energy_min, agent0_attention_min
[-0.03 -0.25]
agent1_energy_min, agent1_attention_min
[-31.41  -2.24]
1900 50
steps: 94950, episodes: 1900, mean episode reward: -138.52182092115137, time: 24.89
agent0_energy_min, agent0_attention_min
[ 0.   -0.09]
agent1_energy_min, agent1_attention_min
[-35.16  -0.3 ]
2000 50
steps: 99950, episodes: 2000, mean episode reward: -148.3942463017553, time: 24.656
agent0_energy_min, agent0_attention_min
[-0.01 -0.1 ]
agent1_energy_min, agent1_attention_min
[-34.69  -0.07]
2100 50
steps: 104950, episodes: 2100, mean episode reward: -135.5463347201155, time: 25.443
agent0_energy_min, agent0_attention_min
[-0.01 -0.04]
agent1_energy_min, agent1_attention_min
[-3.677e+01 -2.000e-02]
2200 50
steps: 109950, episodes: 2200, mean episode reward: -139.93196593190294, time: 24.93
agent0_energy_min, agent0_attention_min
[-0.2  -0.04]
agent1_energy_min, agent1_attention_min
[-32.91  -0.1 ]
2300 50
steps: 114950, episodes: 2300, mean episode reward: -137.27235401381142, time: 25.004
agent0_energy_min, agent0_attention_min
[ 0.   -0.01]
agent1_energy_min, agent1_attention_min
[-38.69  -0.06]
2400 50
steps: 119950, episodes: 2400, mean episode reward: -130.33008371036496, time: 24.912
agent0_energy_min, agent0_attention_min
[-0.01 -0.03]
agent1_energy_min, agent1_attention_min
[-35.4   -0.05]
2500 50
steps: 124950, episodes: 2500, mean episode reward: -150.02056730219772, time: 24.973
agent0_energy_min, agent0_attention_min
[0. 0.]
agent1_energy_min, agent1_attention_min
[-4.304e+01 -3.000e-02]
2600 50
steps: 129950, episodes: 2600, mean episode reward: -126.08662397860208, time: 24.849
agent0_energy_min, agent0_attention_min
[-0.01 -0.01]
agent1_energy_min, agent1_attention_min
[-4.145e+01 -2.000e-02]
2700 50
steps: 134950, episodes: 2700, mean episode reward: -133.20725764202382, time: 25.477
agent0_energy_min, agent0_attention_min
[-0.02 -0.02]
agent1_energy_min, agent1_attention_min
[-42.96  -0.06]
2800 50
steps: 139950, episodes: 2800, mean episode reward: -123.11394535215459, time: 25.22
agent0_energy_min, agent0_attention_min
[ 0.   -0.03]
agent1_energy_min, agent1_attention_min
[-4.449e+01 -4.000e-02]
2900 50
steps: 144950, episodes: 2900, mean episode reward: -136.0112704471178, time: 24.778
agent0_energy_min, agent0_attention_min
[-0.19 -0.01]
agent1_energy_min, agent1_attention_min
[-4.322e+01 -4.000e-02]
3000 50
steps: 149950, episodes: 3000, mean episode reward: -155.75249138463417, time: 25.341
agent0_energy_min, agent0_attention_min
[-0.11 -0.03]
agent1_energy_min, agent1_attention_min
[-43.6   -0.09]
3100 50
steps: 154950, episodes: 3100, mean episode reward: -121.91568562774025, time: 25.549
agent0_energy_min, agent0_attention_min
[ 0.   -0.02]
agent1_energy_min, agent1_attention_min
[-4.562e+01 -1.000e-02]
3200 50
steps: 159950, episodes: 3200, mean episode reward: -131.51341117866414, time: 25.031
agent0_energy_min, agent0_attention_min
[-0.12  0.  ]
agent1_energy_min, agent1_attention_min
[-37.79  -0.12]
3300 50
steps: 164950, episodes: 3300, mean episode reward: -123.55699663557178, time: 25.142
agent0_energy_min, agent0_attention_min
[-0.01 -0.03]
agent1_energy_min, agent1_attention_min
[-43.59  -0.07]
3400 50
steps: 169950, episodes: 3400, mean episode reward: -153.54658855234297, time: 25.023
agent0_energy_min, agent0_attention_min
[-0.11 -0.01]
agent1_energy_min, agent1_attention_min
[-37.08  -0.08]
3500 50
steps: 174950, episodes: 3500, mean episode reward: -129.4204939488658, time: 24.791
agent0_energy_min, agent0_attention_min
[ 0.   -0.02]
agent1_energy_min, agent1_attention_min
[-40.34  -0.05]
3600 50
steps: 179950, episodes: 3600, mean episode reward: -130.29062251666394, time: 25.704
agent0_energy_min, agent0_attention_min
[-0.01 -0.02]
agent1_energy_min, agent1_attention_min
[-4.187e+01 -3.000e-02]
3700 50
steps: 184950, episodes: 3700, mean episode reward: -126.32322831087926, time: 24.527
agent0_energy_min, agent0_attention_min
[-0.01  0.  ]
agent1_energy_min, agent1_attention_min
[-4.138e+01 -3.000e-02]
3800 50
steps: 189950, episodes: 3800, mean episode reward: -126.01567976471362, time: 24.661
agent0_energy_min, agent0_attention_min
[-0.01  0.  ]
agent1_energy_min, agent1_attention_min
[-41.47  -0.07]
3900 50
steps: 194950, episodes: 3900, mean episode reward: -121.77174720387528, time: 24.991
agent0_energy_min, agent0_attention_min
[-0.01 -0.03]
agent1_energy_min, agent1_attention_min
[-4.529e+01 -3.000e-02]
4000 50
steps: 199950, episodes: 4000, mean episode reward: -119.67358195377572, time: 24.815Using good policy ddpg and adv policy ddpg
Starting iterations of wanderer2_2agents-2__2018-07-13_10-46-31...
100 50
steps: 4950, episodes: 100, mean episode reward: -162.86481214929503, time: 17.336
agent0_energy_min, agent0_attention_min
[-14.8989899  -18.82828283]
agent1_energy_min, agent1_attention_min
[-17.35353535 -17.41414141]
200 50
steps: 9950, episodes: 200, mean episode reward: -175.89853790588776, time: 18.077
agent0_energy_min, agent0_attention_min
[-15.66 -18.5 ]
agent1_energy_min, agent1_attention_min
[-17.16 -17.66]
300 50
steps: 14950, episodes: 300, mean episode reward: -160.73082769793066, time: 18.15
agent0_energy_min, agent0_attention_min
[-15.13 -18.9 ]
agent1_energy_min, agent1_attention_min
[-16.69 -18.14]
400 50
steps: 19950, episodes: 400, mean episode reward: -172.51289350847853, time: 17.848
agent0_energy_min, agent0_attention_min
[-15.6  -18.03]
agent1_energy_min, agent1_attention_min
[-16.12 -18.21]
500 50
steps: 24950, episodes: 500, mean episode reward: -152.14754251890594, time: 18.039
agent0_energy_min, agent0_attention_min
[-15.58 -18.67]
agent1_energy_min, agent1_attention_min
[-16.33 -17.85]
600 50
steps: 29950, episodes: 600, mean episode reward: -173.02809839378443, time: 18.214
agent0_energy_min, agent0_attention_min
[-14.93 -19.11]
agent1_energy_min, agent1_attention_min
[-16.77 -17.65]
700 50
steps: 34950, episodes: 700, mean episode reward: -156.48310818694515, time: 18.145
agent0_energy_min, agent0_attention_min
[-15.13 -18.42]
agent1_energy_min, agent1_attention_min
[-16.63 -17.48]
800 50
steps: 39950, episodes: 800, mean episode reward: -160.73007825255988, time: 17.8
agent0_energy_min, agent0_attention_min
[-15.3  -18.39]
agent1_energy_min, agent1_attention_min
[-16.61 -17.97]
900 50
steps: 44950, episodes: 900, mean episode reward: -145.8915631973226, time: 18.015
agent0_energy_min, agent0_attention_min
[-15.85 -18.56]
agent1_energy_min, agent1_attention_min
[-16.94 -17.72]
1000 50
steps: 49950, episodes: 1000, mean episode reward: -140.6717460665467, time: 18.002
agent0_energy_min, agent0_attention_min
[-16.05 -18.12]
agent1_energy_min, agent1_attention_min
[-16.5  -17.48]
1100 50
steps: 54950, episodes: 1100, mean episode reward: -800.4486684553788, time: 24.505
agent0_energy_min, agent0_attention_min
[-18.15 -26.25]
agent1_energy_min, agent1_attention_min
[-10.8  -25.46]
1200 50
steps: 59950, episodes: 1200, mean episode reward: -463.46864627862493, time: 24.631
agent0_energy_min, agent0_attention_min
[-15.27  -9.98]
agent1_energy_min, agent1_attention_min
[-10.63 -16.63]
1300 50
steps: 64950, episodes: 1300, mean episode reward: -469.2239746900191, time: 25.248
agent0_energy_min, agent0_attention_min
[-17.75 -26.46]
agent1_energy_min, agent1_attention_min
[-41.53  -6.64]
1400 50
steps: 69950, episodes: 1400, mean episode reward: -373.3922996380796, time: 24.736
agent0_energy_min, agent0_attention_min
[-11.11 -13.05]
agent1_energy_min, agent1_attention_min
[ -0.23 -13.48]
1500 50
steps: 74950, episodes: 1500, mean episode reward: -159.5846752794067, time: 24.847
agent0_energy_min, agent0_attention_min
[-15.18 -27.04]
agent1_energy_min, agent1_attention_min
[-20.32 -10.31]
1600 50
steps: 79950, episodes: 1600, mean episode reward: -159.87741578807064, time: 26.216
agent0_energy_min, agent0_attention_min
[-14.34 -23.42]
agent1_energy_min, agent1_attention_min
[-23.54  -6.11]
1700 50
steps: 84950, episodes: 1700, mean episode reward: -145.91220130526173, time: 25.473
agent0_energy_min, agent0_attention_min
[ -9.58 -32.66]
agent1_energy_min, agent1_attention_min
[-14.05 -11.08]
1800 50
steps: 89950, episodes: 1800, mean episode reward: -148.5214864292934, time: 25.15
agent0_energy_min, agent0_attention_min
[ -7.4  -35.48]
agent1_energy_min, agent1_attention_min
[-17.47 -24.86]
1900 50
steps: 94950, episodes: 1900, mean episode reward: -132.1866310053847, time: 24.709
agent0_energy_min, agent0_attention_min
[ -7.47 -26.68]
agent1_energy_min, agent1_attention_min
[-11.54 -28.79]
2000 50
steps: 99950, episodes: 2000, mean episode reward: -145.83566548938475, time: 27.323
agent0_energy_min, agent0_attention_min
[-13.75 -26.53]
agent1_energy_min, agent1_attention_min
[-15.14 -29.47]
2100 50
steps: 104950, episodes: 2100, mean episode reward: -153.37851065474825, time: 25.184
agent0_energy_min, agent0_attention_min
[ -9.07 -25.81]
agent1_energy_min, agent1_attention_min
[ -5.9  -38.52]
2200 50
steps: 109950, episodes: 2200, mean episode reward: -130.52969767963444, time: 25.067
agent0_energy_min, agent0_attention_min
[ -4.55 -35.37]
agent1_energy_min, agent1_attention_min
[-13.27 -35.48]
2300 50
steps: 114950, episodes: 2300, mean episode reward: -131.108167205898, time: 24.745
agent0_energy_min, agent0_attention_min
[ -4.06 -34.66]
agent1_energy_min, agent1_attention_min
[-15.83 -31.62]
2400 50
steps: 119950, episodes: 2400, mean episode reward: -134.16337784186553, time: 25.584
agent0_energy_min, agent0_attention_min
[ -7.72 -33.85]
agent1_energy_min, agent1_attention_min
[-12.15 -33.75]
2500 50
steps: 124950, episodes: 2500, mean episode reward: -143.92315834183458, time: 25.908
agent0_energy_min, agent0_attention_min
[ -8.08 -29.89]
agent1_energy_min, agent1_attention_min
[-10.41 -36.53]
2600 50
steps: 129950, episodes: 2600, mean episode reward: -112.42455215166022, time: 25.653
agent0_energy_min, agent0_attention_min
[-11.28 -30.29]
agent1_energy_min, agent1_attention_min
[-15.09 -31.53]
2700 50
steps: 134950, episodes: 2700, mean episode reward: -131.03545447411344, time: 25.261
agent0_energy_min, agent0_attention_min
[-17.37 -20.58]
agent1_energy_min, agent1_attention_min
[-11.15 -37.1 ]
2800 50
steps: 139950, episodes: 2800, mean episode reward: -135.20593947253266, time: 24.813
agent0_energy_min, agent0_attention_min
[ -8.14 -36.71]
agent1_energy_min, agent1_attention_min
[-12.45 -32.67]
2900 50
steps: 144950, episodes: 2900, mean episode reward: -118.40871958075716, time: 24.732
agent0_energy_min, agent0_attention_min
[-25.97 -20.85]
agent1_energy_min, agent1_attention_min
[-10.81 -36.49]
3000 50
steps: 149950, episodes: 3000, mean episode reward: -129.5242695039234, time: 24.738
agent0_energy_min, agent0_attention_min
[-18.11 -25.62]
agent1_energy_min, agent1_attention_min
[-14.71 -32.76]
3100 50
steps: 154950, episodes: 3100, mean episode reward: -123.36534626986497, time: 25.747
agent0_energy_min, agent0_attention_min
[-28.63 -17.76]
agent1_energy_min, agent1_attention_min
[-10.33 -37.29]
3200 50
steps: 159950, episodes: 3200, mean episode reward: -119.28030851315043, time: 24.646
agent0_energy_min, agent0_attention_min
[-22.  -24.4]
agent1_energy_min, agent1_attention_min
[-12.19 -35.77]
3300 50
steps: 164950, episodes: 3300, mean episode reward: -123.3288421339389, time: 25.624
agent0_energy_min, agent0_attention_min
[-30.11 -18.63]
agent1_energy_min, agent1_attention_min
[-10.61 -38.21]
3400 50
steps: 169950, episodes: 3400, mean episode reward: -126.54975873157284, time: 24.728
agent0_energy_min, agent0_attention_min
[-24.28 -24.43]
agent1_energy_min, agent1_attention_min
[-13.7  -33.17]
3500 50
steps: 174950, episodes: 3500, mean episode reward: -111.85547824217534, time: 24.965
agent0_energy_min, agent0_attention_min
[-19.25 -28.44]
agent1_energy_min, agent1_attention_min
[-11.24 -37.95]
3600 50
steps: 179950, episodes: 3600, mean episode reward: -122.663935062337, time: 25.899
agent0_energy_min, agent0_attention_min
[-23.12 -26.5 ]
agent1_energy_min, agent1_attention_min
[-10.53 -37.87]
3700 50
steps: 184950, episodes: 3700, mean episode reward: -123.85637764587563, time: 25.081
agent0_energy_min, agent0_attention_min
[-17.65 -31.37]
agent1_energy_min, agent1_attention_min
[ -9.22 -40.05]
3800 50
steps: 189950, episodes: 3800, mean episode reward: -110.56849195897627, time: 24.973
agent0_energy_min, agent0_attention_min
[-15.26 -33.91]
agent1_energy_min, agent1_attention_min
[-11.94 -36.19]
3900 50
steps: 194950, episodes: 3900, mean episode reward: -128.38224385160527, time: 25.214
agent0_energy_min, agent0_attention_min
[-23.24 -26.13]
agent1_energy_min, agent1_attention_min
[ -7.6 -40.9]
4000 50
steps: 199950, episodes: 4000, mean episode reward: -123.04224251768818, time: 24.883Using good policy ddpg and adv policy ddpg
Starting iterations of wanderer2_2agents-3__2018-07-13_10-46-33...
100 50
steps: 4950, episodes: 100, mean episode reward: -208.41465004960537, time: 17.793
agent0_energy_min, agent0_attention_min
[-18.36363636 -15.66666667]
agent1_energy_min, agent1_attention_min
[-16.42424242 -15.26262626]
200 50
steps: 9950, episodes: 200, mean episode reward: -215.79280952323893, time: 18.169
agent0_energy_min, agent0_attention_min
[-18.6  -15.05]
agent1_energy_min, agent1_attention_min
[-16.15 -15.49]
300 50
steps: 14950, episodes: 300, mean episode reward: -209.63608192828417, time: 18.241
agent0_energy_min, agent0_attention_min
[-18.14 -15.84]
agent1_energy_min, agent1_attention_min
[-16.85 -15.06]
400 50
steps: 19950, episodes: 400, mean episode reward: -200.62083643690502, time: 18.199
agent0_energy_min, agent0_attention_min
[-18.31 -15.6 ]
agent1_energy_min, agent1_attention_min
[-16.49 -15.23]
500 50
steps: 24950, episodes: 500, mean episode reward: -200.45704978440162, time: 18.254
agent0_energy_min, agent0_attention_min
[-18.52 -15.7 ]
agent1_energy_min, agent1_attention_min
[-16.52 -15.7 ]
600 50
steps: 29950, episodes: 600, mean episode reward: -204.23298854757792, time: 17.862
agent0_energy_min, agent0_attention_min
[-18.18 -15.56]
agent1_energy_min, agent1_attention_min
[-16.34 -15.49]
700 50
steps: 34950, episodes: 700, mean episode reward: -199.22225193382639, time: 17.766
agent0_energy_min, agent0_attention_min
[-18.07 -15.83]
agent1_energy_min, agent1_attention_min
[-15.9  -15.54]
800 50
steps: 39950, episodes: 800, mean episode reward: -183.29572186208227, time: 17.608
agent0_energy_min, agent0_attention_min
[-18.49 -15.43]
agent1_energy_min, agent1_attention_min
[-16.29 -15.42]
900 50
steps: 44950, episodes: 900, mean episode reward: -201.66406078314293, time: 18.168
agent0_energy_min, agent0_attention_min
[-18.33 -15.37]
agent1_energy_min, agent1_attention_min
[-16.72 -15.51]
1000 50
steps: 49950, episodes: 1000, mean episode reward: -202.6064418804038, time: 18.253
agent0_energy_min, agent0_attention_min
[-18.2  -15.68]
agent1_energy_min, agent1_attention_min
[-16.48 -15.5 ]
1100 50
steps: 54950, episodes: 1100, mean episode reward: -643.1967553368708, time: 24.382
agent0_energy_min, agent0_attention_min
[-20.67 -17.84]
agent1_energy_min, agent1_attention_min
[-16.76 -10.53]
1200 50
steps: 59950, episodes: 1200, mean episode reward: -651.7646225682352, time: 24.648
agent0_energy_min, agent0_attention_min
[ -8.75 -11.05]
agent1_energy_min, agent1_attention_min
[-26.16  -9.37]
1300 50
steps: 64950, episodes: 1300, mean episode reward: -380.9566531234009, time: 25.086
agent0_energy_min, agent0_attention_min
[-14.91  -7.4 ]
agent1_energy_min, agent1_attention_min
[-19.09  -4.84]
1400 50
steps: 69950, episodes: 1400, mean episode reward: -405.63755015073514, time: 25.37
agent0_energy_min, agent0_attention_min
[-26.69  -6.47]
agent1_energy_min, agent1_attention_min
[-13.6   -0.73]
1500 50
steps: 74950, episodes: 1500, mean episode reward: -208.84821293633203, time: 25.089
agent0_energy_min, agent0_attention_min
[-31.41 -17.69]
agent1_energy_min, agent1_attention_min
[-14.35  -0.14]
1600 50
steps: 79950, episodes: 1600, mean episode reward: -187.5262325941786, time: 25.847
agent0_energy_min, agent0_attention_min
[-34.22 -13.25]
agent1_energy_min, agent1_attention_min
[-13.39  -0.32]
1700 50
steps: 84950, episodes: 1700, mean episode reward: -171.74513306105717, time: 24.82
agent0_energy_min, agent0_attention_min
[-25.74 -13.59]
agent1_energy_min, agent1_attention_min
[-0.08 -0.06]
1800 50
steps: 89950, episodes: 1800, mean episode reward: -141.78864584034923, time: 25.563
agent0_energy_min, agent0_attention_min
[-28.86  -9.26]
agent1_energy_min, agent1_attention_min
[-0.08 -0.01]
1900 50
steps: 94950, episodes: 1900, mean episode reward: -123.94591819207889, time: 24.936
agent0_energy_min, agent0_attention_min
[-33.14  -3.12]
agent1_energy_min, agent1_attention_min
[0. 0.]
2000 50
steps: 99950, episodes: 2000, mean episode reward: -141.85219027025553, time: 24.536
agent0_energy_min, agent0_attention_min
[-34.93  -1.03]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
2100 50
steps: 104950, episodes: 2100, mean episode reward: -129.08115357090233, time: 25.051
agent0_energy_min, agent0_attention_min
[-36.85  -0.3 ]
agent1_energy_min, agent1_attention_min
[0. 0.]
2200 50
steps: 109950, episodes: 2200, mean episode reward: -138.4795262728846, time: 25.342
agent0_energy_min, agent0_attention_min
[-38.3   -0.23]
agent1_energy_min, agent1_attention_min
[-0.02 -0.04]
2300 50
steps: 114950, episodes: 2300, mean episode reward: -139.76310208214235, time: 25.537
agent0_energy_min, agent0_attention_min
[-35.67  -0.08]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
2400 50
steps: 119950, episodes: 2400, mean episode reward: -145.07272582762144, time: 25.254
agent0_energy_min, agent0_attention_min
[-38.86  -0.15]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
2500 50
steps: 124950, episodes: 2500, mean episode reward: -136.02537692212252, time: 25.835
agent0_energy_min, agent0_attention_min
[-35.15  -0.06]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
2600 50
steps: 129950, episodes: 2600, mean episode reward: -130.5697795572858, time: 25.195
agent0_energy_min, agent0_attention_min
[-4.333e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
2700 50
steps: 134950, episodes: 2700, mean episode reward: -136.36080405034943, time: 25.292
agent0_energy_min, agent0_attention_min
[-37.54  -0.09]
agent1_energy_min, agent1_attention_min
[-0.09  0.  ]
2800 50
steps: 139950, episodes: 2800, mean episode reward: -130.1937979463325, time: 25.645
agent0_energy_min, agent0_attention_min
[-34.95  -0.11]
agent1_energy_min, agent1_attention_min
[0. 0.]
2900 50
steps: 144950, episodes: 2900, mean episode reward: -126.61205031971605, time: 25.044
agent0_energy_min, agent0_attention_min
[-40.87  -0.05]
agent1_energy_min, agent1_attention_min
[-0.03 -0.01]
3000 50
steps: 149950, episodes: 3000, mean episode reward: -115.67354330152834, time: 25.549
agent0_energy_min, agent0_attention_min
[-41.23  -0.14]
agent1_energy_min, agent1_attention_min
[-0.12  0.  ]
3100 50
steps: 154950, episodes: 3100, mean episode reward: -122.66910105479948, time: 25.457
agent0_energy_min, agent0_attention_min
[-37.58  -0.08]
agent1_energy_min, agent1_attention_min
[-0.02 -0.02]
3200 50
steps: 159950, episodes: 3200, mean episode reward: -127.46013275309939, time: 24.532
agent0_energy_min, agent0_attention_min
[-37.03  -0.09]
agent1_energy_min, agent1_attention_min
[0. 0.]
3300 50
steps: 164950, episodes: 3300, mean episode reward: -130.77406525740108, time: 25.429
agent0_energy_min, agent0_attention_min
[-3.691e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
3400 50
steps: 169950, episodes: 3400, mean episode reward: -119.85449763297802, time: 25.293
agent0_energy_min, agent0_attention_min
[-33.15  -0.04]
agent1_energy_min, agent1_attention_min
[0. 0.]
3500 50
steps: 174950, episodes: 3500, mean episode reward: -118.52861001477781, time: 24.926
agent0_energy_min, agent0_attention_min
[-3.588e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.09  0.  ]
3600 50
steps: 179950, episodes: 3600, mean episode reward: -118.49462111869556, time: 26.056
agent0_energy_min, agent0_attention_min
[-37.34  -0.1 ]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
3700 50
steps: 184950, episodes: 3700, mean episode reward: -130.13902994921114, time: 25.257
agent0_energy_min, agent0_attention_min
[-38.39  -0.1 ]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
3800 50
steps: 189950, episodes: 3800, mean episode reward: -110.5816682513966, time: 25.212
agent0_energy_min, agent0_attention_min
[-35.93  -0.07]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
3900 50
steps: 194950, episodes: 3900, mean episode reward: -117.90253991238734, time: 25.299
agent0_energy_min, agent0_attention_min
[-39.21  -0.05]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
4000 50
steps: 199950, episodes: 4000, mean episode reward: -106.72055376758637, time: 25.218
agent0_energy_min, agent0_attention_minUsing good policy ddpg and adv policy ddpg
Starting iterations of wanderer2_2agents-3__2018-07-13_10-46-35...
100 50
steps: 4950, episodes: 100, mean episode reward: -211.90813133341507, time: 17.162
agent0_energy_min, agent0_attention_min
[-17.         -17.80808081]
agent1_energy_min, agent1_attention_min
[-16.04040404 -18.83838384]
200 50
steps: 9950, episodes: 200, mean episode reward: -216.135833165428, time: 17.871
agent0_energy_min, agent0_attention_min
[-17.53 -16.82]
agent1_energy_min, agent1_attention_min
[-16.66 -18.65]
300 50
steps: 14950, episodes: 300, mean episode reward: -216.9377746632568, time: 17.88
agent0_energy_min, agent0_attention_min
[-17.02 -17.43]
agent1_energy_min, agent1_attention_min
[-16.66 -18.51]
400 50
steps: 19950, episodes: 400, mean episode reward: -186.18707723697895, time: 18.114
agent0_energy_min, agent0_attention_min
[-16.32 -16.89]
agent1_energy_min, agent1_attention_min
[-16.58 -18.79]
500 50
steps: 24950, episodes: 500, mean episode reward: -201.94698902119384, time: 18.193
agent0_energy_min, agent0_attention_min
[-17.36 -17.11]
agent1_energy_min, agent1_attention_min
[-16.2  -18.58]
600 50
steps: 29950, episodes: 600, mean episode reward: -217.67947614734732, time: 17.78
agent0_energy_min, agent0_attention_min
[-17.8  -16.63]
agent1_energy_min, agent1_attention_min
[-16.62 -18.2 ]
700 50
steps: 34950, episodes: 700, mean episode reward: -210.7508809041249, time: 18.259
agent0_energy_min, agent0_attention_min
[-17.27 -16.9 ]
agent1_energy_min, agent1_attention_min
[-16.38 -17.95]
800 50
steps: 39950, episodes: 800, mean episode reward: -217.32835495217634, time: 18.377
agent0_energy_min, agent0_attention_min
[-17.64 -16.35]
agent1_energy_min, agent1_attention_min
[-15.97 -18.43]
900 50
steps: 44950, episodes: 900, mean episode reward: -224.2735647799477, time: 18.045
agent0_energy_min, agent0_attention_min
[-17.08 -17.01]
agent1_energy_min, agent1_attention_min
[-16.42 -18.68]
1000 50
steps: 49950, episodes: 1000, mean episode reward: -223.38584608035617, time: 18.351
agent0_energy_min, agent0_attention_min
[-18.15 -16.4 ]
agent1_energy_min, agent1_attention_min
[-16.63 -18.04]
1100 50
steps: 54950, episodes: 1100, mean episode reward: -714.7296220824667, time: 24.415
agent0_energy_min, agent0_attention_min
[-22.09 -14.33]
agent1_energy_min, agent1_attention_min
[-13.07 -30.73]
1200 50
steps: 59950, episodes: 1200, mean episode reward: -530.9848871591566, time: 25.265
agent0_energy_min, agent0_attention_min
[ -6.1  -16.97]
agent1_energy_min, agent1_attention_min
[-9.21 -4.23]
1300 50
steps: 64950, episodes: 1300, mean episode reward: -757.5004856704135, time: 25.555
agent0_energy_min, agent0_attention_min
[-23.54  -4.1 ]
agent1_energy_min, agent1_attention_min
[-19.46  -0.68]
1400 50
steps: 69950, episodes: 1400, mean episode reward: -312.04291468347736, time: 24.212
agent0_energy_min, agent0_attention_min
[-16.85  -0.45]
agent1_energy_min, agent1_attention_min
[ -6.45 -15.68]
1500 50
steps: 74950, episodes: 1500, mean episode reward: -134.77290433543396, time: 25.281
agent0_energy_min, agent0_attention_min
[-2.53 -0.01]
agent1_energy_min, agent1_attention_min
[-0.09 -0.08]
1600 50
steps: 79950, episodes: 1600, mean episode reward: -145.73820015200437, time: 25.726
agent0_energy_min, agent0_attention_min
[-0.32  0.  ]
agent1_energy_min, agent1_attention_min
[-0.05 -0.02]
1700 50
steps: 84950, episodes: 1700, mean episode reward: -130.62743434656505, time: 25.207
agent0_energy_min, agent0_attention_min
[-0.6  -0.01]
agent1_energy_min, agent1_attention_min
[-0.07 -0.05]
1800 50
steps: 89950, episodes: 1800, mean episode reward: -124.12996341678235, time: 25.199
agent0_energy_min, agent0_attention_min
[-0.05  0.  ]
agent1_energy_min, agent1_attention_min
[-0.01 -0.03]
1900 50
steps: 94950, episodes: 1900, mean episode reward: -125.67611807218844, time: 25.249
agent0_energy_min, agent0_attention_min
[-0.04  0.  ]
agent1_energy_min, agent1_attention_min
[-0.02  0.  ]
2000 50
steps: 99950, episodes: 2000, mean episode reward: -130.92837780076107, time: 26.458
agent0_energy_min, agent0_attention_min
[-0.12 -0.02]
agent1_energy_min, agent1_attention_min
[-0.32 -0.01]
2100 50
steps: 104950, episodes: 2100, mean episode reward: -126.4696742417693, time: 25.191
agent0_energy_min, agent0_attention_min
[-0.08  0.  ]
agent1_energy_min, agent1_attention_min
[-0.04 -0.06]
2200 50
steps: 109950, episodes: 2200, mean episode reward: -117.55097304072684, time: 24.855
agent0_energy_min, agent0_attention_min
[-0.21  0.  ]
agent1_energy_min, agent1_attention_min
[-0.4  -0.06]
2300 50
steps: 114950, episodes: 2300, mean episode reward: -143.56959889592895, time: 25.107
agent0_energy_min, agent0_attention_min
[-0.08 -0.01]
agent1_energy_min, agent1_attention_min
[-0.01 -0.06]
2400 50
steps: 119950, episodes: 2400, mean episode reward: -129.12057203579562, time: 25.302
agent0_energy_min, agent0_attention_min
[-0.49  0.  ]
agent1_energy_min, agent1_attention_min
[-0.1  -0.07]
2500 50
steps: 124950, episodes: 2500, mean episode reward: -132.44410387964933, time: 24.968
agent0_energy_min, agent0_attention_min
[-0.58  0.  ]
agent1_energy_min, agent1_attention_min
[-0.25 -0.13]
2600 50
steps: 129950, episodes: 2600, mean episode reward: -122.93220183438754, time: 25.572
agent0_energy_min, agent0_attention_min
[-0.03  0.  ]
agent1_energy_min, agent1_attention_min
[-0.05 -0.14]
2700 50
steps: 134950, episodes: 2700, mean episode reward: -142.57485420601625, time: 25.279
agent0_energy_min, agent0_attention_min
[-0.24  0.  ]
agent1_energy_min, agent1_attention_min
[-0.5  -0.05]
2800 50
steps: 139950, episodes: 2800, mean episode reward: -122.14893597028828, time: 25.126
agent0_energy_min, agent0_attention_min
[-0.69  0.  ]
agent1_energy_min, agent1_attention_min
[-0.29 -0.04]
2900 50
steps: 144950, episodes: 2900, mean episode reward: -143.3640484393132, time: 24.718
agent0_energy_min, agent0_attention_min
[-0.25  0.  ]
agent1_energy_min, agent1_attention_min
[-0.11 -0.01]
3000 50
steps: 149950, episodes: 3000, mean episode reward: -136.07977919524427, time: 25.644
agent0_energy_min, agent0_attention_min
[-0.67 -0.01]
agent1_energy_min, agent1_attention_min
[-0.4  -0.05]
3100 50
steps: 154950, episodes: 3100, mean episode reward: -130.37182949867204, time: 25.56
agent0_energy_min, agent0_attention_min
[-0.77 -0.01]
agent1_energy_min, agent1_attention_min
[-0.28 -0.03]
3200 50
steps: 159950, episodes: 3200, mean episode reward: -137.30928775047747, time: 24.636
agent0_energy_min, agent0_attention_min
[0. 0.]
agent1_energy_min, agent1_attention_min
[-0.04 -0.07]
3300 50
steps: 164950, episodes: 3300, mean episode reward: -129.4640633434091, time: 25.016
agent0_energy_min, agent0_attention_min
[-0.95  0.  ]
agent1_energy_min, agent1_attention_min
[-2.32 -0.02]
3400 50
steps: 169950, episodes: 3400, mean episode reward: -142.59462000885438, time: 25.194
agent0_energy_min, agent0_attention_min
[-0.04  0.  ]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
3500 50
steps: 174950, episodes: 3500, mean episode reward: -140.71641816856018, time: 24.902
agent0_energy_min, agent0_attention_min
[-0.79  0.  ]
agent1_energy_min, agent1_attention_min
[-1.6 -0.1]
3600 50
steps: 179950, episodes: 3600, mean episode reward: -138.47505284110494, time: 25.115
agent0_energy_min, agent0_attention_min
[-0.24  0.  ]
agent1_energy_min, agent1_attention_min
[-0.47  0.  ]
3700 50
steps: 184950, episodes: 3700, mean episode reward: -135.30239625856063, time: 24.812
agent0_energy_min, agent0_attention_min
[-1.335e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.88 -0.09]
3800 50
steps: 189950, episodes: 3800, mean episode reward: -137.20340560438714, time: 25.52
agent0_energy_min, agent0_attention_min
[-0.05 -0.01]
agent1_energy_min, agent1_attention_min
[-0.35 -0.05]
3900 50
steps: 194950, episodes: 3900, mean episode reward: -128.34233066393, time: 24.985
agent0_energy_min, agent0_attention_min
[-0.07  0.  ]
agent1_energy_min, agent1_attention_min
[-1.31 -0.13]
4000 50
steps: 199950, episodes: 4000, mean episode reward: -137.27221956942722, time: 25.41
agent0_energy_min, agent0_attention_min
[-0.2  -0.03]
agent1_energy_min, agent1_attention_min
agent0_energy_min, agent0_attention_min
[-4.857e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-45.2   -3.41]
4100 50
steps: 204950, episodes: 4100, mean episode reward: -61.8322903892879, time: 24.982
agent0_energy_min, agent0_attention_min
[-4.849e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-41.96  -7.04]
4200 50
steps: 209950, episodes: 4200, mean episode reward: -55.56201034312412, time: 24.369
agent0_energy_min, agent0_attention_min
[-4.856e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-40.81  -8.05]
4300 50
steps: 214950, episodes: 4300, mean episode reward: -57.690519445046085, time: 26.339
agent0_energy_min, agent0_attention_min
[-4.862e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-45.17  -3.85]
4400 50
steps: 219950, episodes: 4400, mean episode reward: -73.4483464303719, time: 24.321
agent0_energy_min, agent0_attention_min
[-4.767e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-45.21  -3.63]
4500 50
steps: 224950, episodes: 4500, mean episode reward: -75.25115614841992, time: 24.536
agent0_energy_min, agent0_attention_min
[-46.06   0.  ]
agent1_energy_min, agent1_attention_min
[-47.01  -2.19]
4600 50
steps: 229950, episodes: 4600, mean episode reward: -66.9936329006578, time: 25.195
agent0_energy_min, agent0_attention_min
[-46.66  -0.06]
agent1_energy_min, agent1_attention_min
[-45.85  -3.  ]
4700 50
steps: 234950, episodes: 4700, mean episode reward: -51.06274445074095, time: 24.673
agent0_energy_min, agent0_attention_min
[-47.63  -0.06]
agent1_energy_min, agent1_attention_min
[-47.27  -2.14]
4800 50
steps: 239950, episodes: 4800, mean episode reward: -64.45864810563859, time: 24.241
agent0_energy_min, agent0_attention_min
[-48.04  -0.11]
agent1_energy_min, agent1_attention_min
[-47.22  -2.09]
4900 50
steps: 244950, episodes: 4900, mean episode reward: -56.78516750750032, time: 24.112
agent0_energy_min, agent0_attention_min
[-48.03   0.  ]
agent1_energy_min, agent1_attention_min
[-46.68  -2.82]
5000 50
steps: 249950, episodes: 5000, mean episode reward: -64.10570212551008, time: 24.817
agent0_energy_min, agent0_attention_min
[-47.43  -0.5 ]
agent1_energy_min, agent1_attention_min
[-48.35  -1.21]
5100 50
steps: 254950, episodes: 5100, mean episode reward: -60.563933867795704, time: 24.668
agent0_energy_min, agent0_attention_min
[-47.03  -0.6 ]
agent1_energy_min, agent1_attention_min
[-47.6   -1.71]
5200 50
steps: 259950, episodes: 5200, mean episode reward: -68.09972983954006, time: 24.462
agent0_energy_min, agent0_attention_min
[-46.4   -1.28]
agent1_energy_min, agent1_attention_min
[-47.93  -1.35]
5300 50
steps: 264950, episodes: 5300, mean episode reward: -71.40028871840651, time: 24.364
agent0_energy_min, agent0_attention_min
[-45.06  -0.62]
agent1_energy_min, agent1_attention_min
[-46.2   -2.03]
5400 50
steps: 269950, episodes: 5400, mean episode reward: -52.80474321373033, time: 24.212
agent0_energy_min, agent0_attention_min
[-47.32  -0.51]
agent1_energy_min, agent1_attention_min
[-45.74  -1.65]
5500 50
steps: 274950, episodes: 5500, mean episode reward: -51.45729256687731, time: 24.754
agent0_energy_min, agent0_attention_min
[-46.49  -0.67]
agent1_energy_min, agent1_attention_min
[-48.28  -0.72]
5600 50
steps: 279950, episodes: 5600, mean episode reward: -47.52459006508661, time: 25.241
agent0_energy_min, agent0_attention_min
[-47.39  -0.37]
agent1_energy_min, agent1_attention_min
[-48.92  -0.21]
5700 50
steps: 284950, episodes: 5700, mean episode reward: -60.02098511858991, time: 24.173
agent0_energy_min, agent0_attention_min
[-4.784e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-48.02  -0.42]
5800 50
steps: 289950, episodes: 5800, mean episode reward: -50.23022833325555, time: 24.618
agent0_energy_min, agent0_attention_min
[-4.865e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-49.54  -0.29]
5900 50
steps: 294950, episodes: 5900, mean episode reward: -54.70548615073206, time: 24.715
agent0_energy_min, agent0_attention_min
[-46.98  -0.28]
agent1_energy_min, agent1_attention_min
[-48.51  -0.25]
6000 50
steps: 299950, episodes: 6000, mean episode reward: -43.20735041064315, time: 24.508
agent0_energy_min, agent0_attention_min
[-45.82  -0.34]
agent1_energy_min, agent1_attention_min
[-46.81  -0.98]
6100 50
steps: 304950, episodes: 6100, mean episode reward: -40.99483751508128, time: 25.341
agent0_energy_min, agent0_attention_min
[-4.676e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-47.85  -0.36]
6200 50
steps: 309950, episodes: 6200, mean episode reward: -48.98873043989252, time: 24.876
agent0_energy_min, agent0_attention_min
[-47.07  -0.68]
agent1_energy_min, agent1_attention_min
[-48.48  -0.1 ]
6300 50
steps: 314950, episodes: 6300, mean episode reward: -44.9709090696491, time: 25.006
agent0_energy_min, agent0_attention_min
[-46.83  -0.37]
agent1_energy_min, agent1_attention_min
[-48.49  -0.21]
6400 50
steps: 319950, episodes: 6400, mean episode reward: -58.41369915793563, time: 24.102
agent0_energy_min, agent0_attention_min
[-46.07  -0.33]
agent1_energy_min, agent1_attention_min
[-46.94  -0.69]
6500 50
steps: 324950, episodes: 6500, mean episode reward: -58.5810450308825, time: 24.761
agent0_energy_min, agent0_attention_min
[-48.22  -0.07]
agent1_energy_min, agent1_attention_min
[-48.7  -0.2]
6600 50
steps: 329950, episodes: 6600, mean episode reward: -68.73395785926861, time: 25.357
agent0_energy_min, agent0_attention_min
[-4.778e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-47.51  -0.35]
6700 50
steps: 334950, episodes: 6700, mean episode reward: -55.3552225528894, time: 24.802
agent0_energy_min, agent0_attention_min
[-46.12  -0.82]
agent1_energy_min, agent1_attention_min
[-47.66  -0.65]
6800 50
steps: 339950, episodes: 6800, mean episode reward: -50.063316203585174, time: 24.485
agent0_energy_min, agent0_attention_min
[-4.79e+01 -2.00e-02]
agent1_energy_min, agent1_attention_min
[-48.61  -0.32]
6900 50
steps: 344950, episodes: 6900, mean episode reward: -85.70297354657569, time: 24.514
agent0_energy_min, agent0_attention_min
[-4.419e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-47.18  -0.55]
7000 50
steps: 349950, episodes: 7000, mean episode reward: -70.15049349107767, time: 24.463
agent0_energy_min, agent0_attention_min
[-46.48  -0.05]
agent1_energy_min, agent1_attention_min
[-47.8   -0.51]
7100 50
steps: 354950, episodes: 7100, mean episode reward: -55.88650136066583, time: 25.024
agent0_energy_min, agent0_attention_min
[-4.78e+01 -2.00e-02]
agent1_energy_min, agent1_attention_min
[-47.99  -0.26]
7200 50
steps: 359950, episodes: 7200, mean episode reward: -51.51460227679629, time: 24.772
agent0_energy_min, agent0_attention_min
[-4.727e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-48.61  -0.26]
7300 50
steps: 364950, episodes: 7300, mean episode reward: -53.61511678964027, time: 24.452
agent0_energy_min, agent0_attention_min
[-48.43   0.  ]
agent1_energy_min, agent1_attention_min
[-47.38  -0.86]
7400 50
steps: 369950, episodes: 7400, mean episode reward: -55.49176182132315, time: 24.363
agent0_energy_min, agent0_attention_min
[-4.735e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-48.22  -0.27]
7500 50
steps: 374950, episodes: 7500, mean episode reward: -53.06536880133775, time: 24.986
agent0_energy_min, agent0_attention_min
[-47.41  -0.53]
agent1_energy_min, agent1_attention_min
[-48.67  -0.22]
7600 50
steps: 379950, episodes: 7600, mean episode reward: -67.05788959898273, time: 24.759
agent0_energy_min, agent0_attention_min
[-4.894e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-48.05  -0.34]
7700 50
steps: 384950, episodes: 7700, mean episode reward: -62.19299334431792, time: 24.567
agent0_energy_min, agent0_attention_min
[-47.85  -0.19]
agent1_energy_min, agent1_attention_min
[-45.71  -0.36]
7800 50
steps: 389950, episodes: 7800, mean episode reward: -50.5148930205771, time: 24.706
agent0_energy_min, agent0_attention_min
[-48.34  -0.4 ]
agent1_energy_min, agent1_attention_min
[-48.09  -0.2 ]
7900 50
steps: 394950, episodes: 7900, mean episode reward: -65.79017882928301, time: 24.607
agent0_energy_min, agent0_attention_min
[-4.747e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
agent0_energy_min, agent0_attention_min
[-20.77 -28.22]
agent1_energy_min, agent1_attention_min
[-37.13  -8.71]
4100 50
steps: 204950, episodes: 4100, mean episode reward: -101.40224555213953, time: 24.637
agent0_energy_min, agent0_attention_min
[-17.04 -31.82]
agent1_energy_min, agent1_attention_min
[-37.49  -6.2 ]
4200 50
steps: 209950, episodes: 4200, mean episode reward: -109.29066207793709, time: 24.257
agent0_energy_min, agent0_attention_min
[-15.75 -32.95]
agent1_energy_min, agent1_attention_min
[-40.62  -7.13]
4300 50
steps: 214950, episodes: 4300, mean episode reward: -103.28301134684618, time: 23.907
agent0_energy_min, agent0_attention_min
[-21.96 -27.85]
agent1_energy_min, agent1_attention_min
[-41.33  -4.85]
4400 50
steps: 219950, episodes: 4400, mean episode reward: -105.66828628165194, time: 24.439
agent0_energy_min, agent0_attention_min
[-17.29 -32.29]
agent1_energy_min, agent1_attention_min
[-40.96  -4.72]
4500 50
steps: 224950, episodes: 4500, mean episode reward: -94.5031547477197, time: 24.545
agent0_energy_min, agent0_attention_min
[-19.6  -29.89]
agent1_energy_min, agent1_attention_min
[-41.56  -5.15]
4600 50
steps: 229950, episodes: 4600, mean episode reward: -107.63370070400438, time: 24.56
agent0_energy_min, agent0_attention_min
[-20.66 -28.83]
agent1_energy_min, agent1_attention_min
[-39.27  -8.52]
4700 50
steps: 234950, episodes: 4700, mean episode reward: -97.8218911433168, time: 24.119
agent0_energy_min, agent0_attention_min
[-23.67 -26.21]
agent1_energy_min, agent1_attention_min
[-44.68  -4.69]
4800 50
steps: 239950, episodes: 4800, mean episode reward: -104.12263264328907, time: 23.935
agent0_energy_min, agent0_attention_min
[-21.57 -27.39]
agent1_energy_min, agent1_attention_min
[-43.51  -5.75]
4900 50
steps: 244950, episodes: 4900, mean episode reward: -100.61577017259737, time: 24.427
agent0_energy_min, agent0_attention_min
[-24.51 -25.11]
agent1_energy_min, agent1_attention_min
[-45.06  -3.81]
5000 50
steps: 249950, episodes: 5000, mean episode reward: -95.50292282841929, time: 24.284
agent0_energy_min, agent0_attention_min
[-20.88 -28.32]
agent1_energy_min, agent1_attention_min
[-47.17  -2.29]
5100 50
steps: 254950, episodes: 5100, mean episode reward: -81.27539277738448, time: 24.434
agent0_energy_min, agent0_attention_min
[-30.27 -19.45]
agent1_energy_min, agent1_attention_min
[-46.03  -3.16]
5200 50
steps: 259950, episodes: 5200, mean episode reward: -95.56277287218977, time: 24.631
agent0_energy_min, agent0_attention_min
[-25.17 -24.18]
agent1_energy_min, agent1_attention_min
[-48.85  -1.01]
5300 50
steps: 264950, episodes: 5300, mean episode reward: -98.54382992326488, time: 24.274
agent0_energy_min, agent0_attention_min
[-45.19  -4.42]
agent1_energy_min, agent1_attention_min
[-48.37  -1.46]
5400 50
steps: 269950, episodes: 5400, mean episode reward: -90.57168154066362, time: 24.143
agent0_energy_min, agent0_attention_min
[-38.18 -11.12]
agent1_energy_min, agent1_attention_min
[-47.95  -1.77]
5500 50
steps: 274950, episodes: 5500, mean episode reward: -91.09392996081287, time: 23.821
agent0_energy_min, agent0_attention_min
[-31.78 -17.16]
agent1_energy_min, agent1_attention_min
[-46.31  -3.44]
5600 50
steps: 279950, episodes: 5600, mean episode reward: -92.59815377669044, time: 25.276
agent0_energy_min, agent0_attention_min
[-31.34 -17.77]
agent1_energy_min, agent1_attention_min
[-47.42  -2.31]
5700 50
steps: 284950, episodes: 5700, mean episode reward: -86.26596621530202, time: 23.713
agent0_energy_min, agent0_attention_min
[-28.4  -20.88]
agent1_energy_min, agent1_attention_min
[-48.8   -0.97]
5800 50
steps: 289950, episodes: 5800, mean episode reward: -79.501860256708, time: 24.098
agent0_energy_min, agent0_attention_min
[-44.    -5.22]
agent1_energy_min, agent1_attention_min
[-47.71  -2.13]
5900 50
steps: 294950, episodes: 5900, mean episode reward: -69.00726518774732, time: 24.301
agent0_energy_min, agent0_attention_min
[-46.93  -2.72]
agent1_energy_min, agent1_attention_min
[-48.52  -1.15]
6000 50
steps: 299950, episodes: 6000, mean episode reward: -77.43774986808728, time: 24.319
agent0_energy_min, agent0_attention_min
[-45.69  -2.74]
agent1_energy_min, agent1_attention_min
[-47.49  -2.22]
6100 50
steps: 304950, episodes: 6100, mean episode reward: -74.87733372941405, time: 24.726
agent0_energy_min, agent0_attention_min
[-44.78  -3.72]
agent1_energy_min, agent1_attention_min
[-43.89  -3.57]
6200 50
steps: 309950, episodes: 6200, mean episode reward: -63.947275780510175, time: 24.041
agent0_energy_min, agent0_attention_min
[-46.81  -1.95]
agent1_energy_min, agent1_attention_min
[-46.65  -1.86]
6300 50
steps: 314950, episodes: 6300, mean episode reward: -66.95756436210368, time: 24.585
agent0_energy_min, agent0_attention_min
[-47.96  -1.48]
agent1_energy_min, agent1_attention_min
[-46.95  -1.17]
6400 50
steps: 319950, episodes: 6400, mean episode reward: -75.20004426589281, time: 24.56
agent0_energy_min, agent0_attention_min
[-46.23  -2.06]
agent1_energy_min, agent1_attention_min
[-46.89  -1.36]
6500 50
steps: 324950, episodes: 6500, mean episode reward: -58.98579587407627, time: 24.32
agent0_energy_min, agent0_attention_min
[-47.72  -1.83]
agent1_energy_min, agent1_attention_min
[-47.44  -1.87]
6600 50
steps: 329950, episodes: 6600, mean episode reward: -65.46008299871004, time: 25.493
agent0_energy_min, agent0_attention_min
[-47.73  -1.  ]
agent1_energy_min, agent1_attention_min
[-47.51  -1.24]
6700 50
steps: 334950, episodes: 6700, mean episode reward: -67.44439181748535, time: 24.701
agent0_energy_min, agent0_attention_min
[-47.47  -2.07]
agent1_energy_min, agent1_attention_min
[-45.75  -1.77]
6800 50
steps: 339950, episodes: 6800, mean episode reward: -71.1289675400787, time: 24.402
agent0_energy_min, agent0_attention_min
[-49.13  -0.68]
agent1_energy_min, agent1_attention_min
[-43.31  -1.87]
6900 50
steps: 344950, episodes: 6900, mean episode reward: -73.9811880426336, time: 24.396
agent0_energy_min, agent0_attention_min
[-49.62  -0.24]
agent1_energy_min, agent1_attention_min
[-47.11  -1.15]
7000 50
steps: 349950, episodes: 7000, mean episode reward: -58.60466373618029, time: 24.255
agent0_energy_min, agent0_attention_min
[-49.92  -0.05]
agent1_energy_min, agent1_attention_min
[-47.69  -1.11]
7100 50
steps: 354950, episodes: 7100, mean episode reward: -53.99641374155941, time: 24.939
agent0_energy_min, agent0_attention_min
[-49.64  -0.31]
agent1_energy_min, agent1_attention_min
[-47.73  -1.24]
7200 50
steps: 359950, episodes: 7200, mean episode reward: -56.66519621714054, time: 24.495
agent0_energy_min, agent0_attention_min
[-49.27  -0.53]
agent1_energy_min, agent1_attention_min
[-47.49  -1.24]
7300 50
steps: 364950, episodes: 7300, mean episode reward: -62.292809472358904, time: 24.537
agent0_energy_min, agent0_attention_min
[-49.1   -0.65]
agent1_energy_min, agent1_attention_min
[-48.11  -0.84]
7400 50
steps: 369950, episodes: 7400, mean episode reward: -52.1162242282254, time: 24.27
agent0_energy_min, agent0_attention_min
[-48.66  -1.14]
agent1_energy_min, agent1_attention_min
[-47.35  -1.43]
7500 50
steps: 374950, episodes: 7500, mean episode reward: -52.38803997187841, time: 24.339
agent0_energy_min, agent0_attention_min
[-49.25  -0.55]
agent1_energy_min, agent1_attention_min
[-47.79  -1.16]
7600 50
steps: 379950, episodes: 7600, mean episode reward: -54.03585365232312, time: 25.737
agent0_energy_min, agent0_attention_min
[-49.37  -0.53]
agent1_energy_min, agent1_attention_min
[-47.77  -1.27]
7700 50
steps: 384950, episodes: 7700, mean episode reward: -60.573066215015245, time: 24.287
agent0_energy_min, agent0_attention_min
[-47.62  -1.08]
agent1_energy_min, agent1_attention_min
[-47.94  -1.15]
7800 50
steps: 389950, episodes: 7800, mean episode reward: -66.40918519757969, time: 24.252
agent0_energy_min, agent0_attention_min
[-48.94  -0.57]
agent1_energy_min, agent1_attention_min
[-46.34  -2.43]
7900 50
steps: 394950, episodes: 7900, mean episode reward: -53.73631773758932, time: 24.44
agent0_energy_min, agent0_attention_min
[-49.16  -0.32]
agent1_energy_min, agent1_attention_min
[-47.54  -1.71]
8000 50
steps: 399950, episodes: 8000, mean episode reward: -53.18217267822537, time: 24.657
[-39.92  -9.84]
agent1_energy_min, agent1_attention_min
[-42.8   -0.62]
4100 50
steps: 204950, episodes: 4100, mean episode reward: -77.70622594286777, time: 24.575
agent0_energy_min, agent0_attention_min
[-47.76  -1.86]
agent1_energy_min, agent1_attention_min
[-44.77  -0.36]
4200 50
steps: 209950, episodes: 4200, mean episode reward: -67.98941729942301, time: 23.88
agent0_energy_min, agent0_attention_min
[-41.82  -7.92]
agent1_energy_min, agent1_attention_min
[-45.12  -0.09]
4300 50
steps: 214950, episodes: 4300, mean episode reward: -81.19772027699477, time: 24.281
agent0_energy_min, agent0_attention_min
[-46.53  -3.19]
agent1_energy_min, agent1_attention_min
[-44.03  -0.12]
4400 50
steps: 219950, episodes: 4400, mean episode reward: -65.5190887504515, time: 24.576
agent0_energy_min, agent0_attention_min
[-46.7   -3.06]
agent1_energy_min, agent1_attention_min
[-44.52  -0.46]
4500 50
steps: 224950, episodes: 4500, mean episode reward: -74.20595134966283, time: 24.189
agent0_energy_min, agent0_attention_min
[-46.28  -3.48]
agent1_energy_min, agent1_attention_min
[-43.73  -0.1 ]
4600 50
steps: 229950, episodes: 4600, mean episode reward: -75.5799778400008, time: 25.02
agent0_energy_min, agent0_attention_min
[-48.67  -1.12]
agent1_energy_min, agent1_attention_min
[-42.39  -0.35]
4700 50
steps: 234950, episodes: 4700, mean episode reward: -72.4709243688345, time: 24.254
agent0_energy_min, agent0_attention_min
[-48.46  -1.29]
agent1_energy_min, agent1_attention_min
[-46.51  -0.72]
4800 50
steps: 239950, episodes: 4800, mean episode reward: -125.27398624336409, time: 24.163
agent0_energy_min, agent0_attention_min
[-46.92  -2.76]
agent1_energy_min, agent1_attention_min
[-44.22  -0.94]
4900 50
steps: 244950, episodes: 4900, mean episode reward: -106.40167319295406, time: 24.448
agent0_energy_min, agent0_attention_min
[-43.93  -5.41]
agent1_energy_min, agent1_attention_min
[-43.96  -1.78]
5000 50
steps: 249950, episodes: 5000, mean episode reward: -76.65602288744009, time: 24.023
agent0_energy_min, agent0_attention_min
[-43.96  -5.74]
agent1_energy_min, agent1_attention_min
[-47.95  -0.16]
5100 50
steps: 254950, episodes: 5100, mean episode reward: -71.82595569107575, time: 24.42
agent0_energy_min, agent0_attention_min
[-44.81  -4.4 ]
agent1_energy_min, agent1_attention_min
[-47.71  -0.13]
5200 50
steps: 259950, episodes: 5200, mean episode reward: -73.27919291181259, time: 24.123
agent0_energy_min, agent0_attention_min
[-46.63  -2.78]
agent1_energy_min, agent1_attention_min
[-47.41  -0.38]
5300 50
steps: 264950, episodes: 5300, mean episode reward: -67.24422557800935, time: 24.219
agent0_energy_min, agent0_attention_min
[-39.12 -10.27]
agent1_energy_min, agent1_attention_min
[-44.75  -0.23]
5400 50
steps: 269950, episodes: 5400, mean episode reward: -61.447845147177446, time: 24.055
agent0_energy_min, agent0_attention_min
[-46.88  -2.37]
agent1_energy_min, agent1_attention_min
[-47.39  -0.24]
5500 50
steps: 274950, episodes: 5500, mean episode reward: -61.268753585410444, time: 23.728
agent0_energy_min, agent0_attention_min
[-42.32  -3.28]
agent1_energy_min, agent1_attention_min
[-46.01  -0.44]
5600 50
steps: 279950, episodes: 5600, mean episode reward: -64.10332667508924, time: 24.677
agent0_energy_min, agent0_attention_min
[-42.81  -3.68]
agent1_energy_min, agent1_attention_min
[-45.03  -0.62]
5700 50
steps: 284950, episodes: 5700, mean episode reward: -56.33040729778173, time: 24.098
agent0_energy_min, agent0_attention_min
[-44.76  -4.7 ]
agent1_energy_min, agent1_attention_min
[-47.17  -0.43]
5800 50
steps: 289950, episodes: 5800, mean episode reward: -57.27860958542157, time: 24.217
agent0_energy_min, agent0_attention_min
[-44.1   -5.27]
agent1_energy_min, agent1_attention_min
[-46.07  -1.06]
5900 50
steps: 294950, episodes: 5900, mean episode reward: -64.15456319979579, time: 23.941
agent0_energy_min, agent0_attention_min
[-44.48  -5.2 ]
agent1_energy_min, agent1_attention_min
[-46.77  -0.59]
6000 50
steps: 299950, episodes: 6000, mean episode reward: -62.526317118051544, time: 24.338
agent0_energy_min, agent0_attention_min
[-44.97  -4.46]
agent1_energy_min, agent1_attention_min
[-48.08  -0.43]
6100 50
steps: 304950, episodes: 6100, mean episode reward: -58.12107779552335, time: 25.555
agent0_energy_min, agent0_attention_min
[-47.82  -2.13]
agent1_energy_min, agent1_attention_min
[-47.38  -0.79]
6200 50
steps: 309950, episodes: 6200, mean episode reward: -52.527363196066084, time: 24.168
agent0_energy_min, agent0_attention_min
[-45.75  -3.71]
agent1_energy_min, agent1_attention_min
[-46.42  -0.77]
6300 50
steps: 314950, episodes: 6300, mean episode reward: -63.533291957595495, time: 24.303
agent0_energy_min, agent0_attention_min
[-46.28  -3.59]
agent1_energy_min, agent1_attention_min
[-47.63  -0.35]
6400 50
steps: 319950, episodes: 6400, mean episode reward: -55.93347174191854, time: 23.895
agent0_energy_min, agent0_attention_min
[-45.4   -4.36]
agent1_energy_min, agent1_attention_min
[-47.04  -0.39]
6500 50
steps: 324950, episodes: 6500, mean episode reward: -54.911948031715404, time: 24.372
agent0_energy_min, agent0_attention_min
[-44.17  -5.72]
agent1_energy_min, agent1_attention_min
[-46.98  -0.55]
6600 50
steps: 329950, episodes: 6600, mean episode reward: -50.73007657373626, time: 25.006
agent0_energy_min, agent0_attention_min
[-45.77  -4.03]
agent1_energy_min, agent1_attention_min
[-46.92  -0.25]
6700 50
steps: 334950, episodes: 6700, mean episode reward: -47.76743658586309, time: 24.943
agent0_energy_min, agent0_attention_min
[-42.63  -6.12]
agent1_energy_min, agent1_attention_min
[-46.97  -0.76]
6800 50
steps: 339950, episodes: 6800, mean episode reward: -63.59611155106746, time: 24.278
agent0_energy_min, agent0_attention_min
[-45.95  -2.83]
agent1_energy_min, agent1_attention_min
[-45.54  -1.51]
6900 50
steps: 344950, episodes: 6900, mean episode reward: -68.05110558323253, time: 24.571
agent0_energy_min, agent0_attention_min
[-41.93  -6.74]
agent1_energy_min, agent1_attention_min
[-46.49  -0.7 ]
7000 50
steps: 349950, episodes: 7000, mean episode reward: -70.30551097450298, time: 24.272
agent0_energy_min, agent0_attention_min
[-41.62  -7.82]
agent1_energy_min, agent1_attention_min
[-45.8   -0.54]
7100 50
steps: 354950, episodes: 7100, mean episode reward: -84.62513548878923, time: 25.11
agent0_energy_min, agent0_attention_min
[-46.09  -3.79]
agent1_energy_min, agent1_attention_min
[-46.17  -0.5 ]
7200 50
steps: 359950, episodes: 7200, mean episode reward: -55.21813517630624, time: 23.841
agent0_energy_min, agent0_attention_min
[-45.19  -4.64]
agent1_energy_min, agent1_attention_min
[-44.98  -0.59]
7300 50
steps: 364950, episodes: 7300, mean episode reward: -69.03982367002743, time: 24.066
agent0_energy_min, agent0_attention_min
[-43.68  -5.77]
agent1_energy_min, agent1_attention_min
[-48.31  -0.24]
7400 50
steps: 369950, episodes: 7400, mean episode reward: -61.51353677215145, time: 24.584
agent0_energy_min, agent0_attention_min
[-44.02  -5.26]
agent1_energy_min, agent1_attention_min
[-47.42  -0.4 ]
7500 50
steps: 374950, episodes: 7500, mean episode reward: -61.38906839821593, time: 25.046
agent0_energy_min, agent0_attention_min
[-41.6   -7.65]
agent1_energy_min, agent1_attention_min
[-48.29  -0.14]
7600 50
steps: 379950, episodes: 7600, mean episode reward: -55.30979099541497, time: 24.617
agent0_energy_min, agent0_attention_min
[-40.95  -8.5 ]
agent1_energy_min, agent1_attention_min
[-47.75  -0.44]
7700 50
steps: 384950, episodes: 7700, mean episode reward: -61.89652435713839, time: 24.137
agent0_energy_min, agent0_attention_min
[-45.35  -4.33]
agent1_energy_min, agent1_attention_min
[-47.81  -0.3 ]
7800 50
steps: 389950, episodes: 7800, mean episode reward: -56.95525398711362, time: 24.411
agent0_energy_min, agent0_attention_min
[-42.22  -6.51]
agent1_energy_min, agent1_attention_min
[-47.73  -0.42]
7900 50
steps: 394950, episodes: 7900, mean episode reward: -67.53079982877188, time: 24.289
agent0_energy_min, agent0_attention_min
[-43.82  -5.29]
agent1_energy_min, agent1_attention_min
[-46.    -0.17]
8000 50
steps: 399950, episodes: 8000, mean episode reward: -58.443986263058434, time: 24.507
agent0_energy_min, agent0_attention_min
[-12.6  -35.98]
agent1_energy_min, agent1_attention_min
[-47.28  -1.59]
4100 50
steps: 204950, episodes: 4100, mean episode reward: -108.76221959892098, time: 25.415
agent0_energy_min, agent0_attention_min
[-15.13 -32.86]
agent1_energy_min, agent1_attention_min
[-46.33  -3.18]
4200 50
steps: 209950, episodes: 4200, mean episode reward: -95.85793382866653, time: 26.789
agent0_energy_min, agent0_attention_min
[-17.13 -31.23]
agent1_energy_min, agent1_attention_min
[-47.62  -1.71]
4300 50
steps: 214950, episodes: 4300, mean episode reward: -110.40093788175, time: 24.663
agent0_energy_min, agent0_attention_min
[-16.07 -31.9 ]
agent1_energy_min, agent1_attention_min
[-46.02  -2.83]
4400 50
steps: 219950, episodes: 4400, mean episode reward: -84.04168925812395, time: 24.315
agent0_energy_min, agent0_attention_min
[-16.1  -31.31]
agent1_energy_min, agent1_attention_min
[-47.6   -1.75]
4500 50
steps: 224950, episodes: 4500, mean episode reward: -93.90333681630948, time: 24.766
agent0_energy_min, agent0_attention_min
[ -8.49 -35.25]
agent1_energy_min, agent1_attention_min
[-46.82  -1.54]
4600 50
steps: 229950, episodes: 4600, mean episode reward: -98.98605021065512, time: 24.744
agent0_energy_min, agent0_attention_min
[-16.92 -30.64]
agent1_energy_min, agent1_attention_min
[-46.    -1.07]
4700 50
steps: 234950, episodes: 4700, mean episode reward: -88.61338704063974, time: 24.25
agent0_energy_min, agent0_attention_min
[-17.94 -29.84]
agent1_energy_min, agent1_attention_min
[-47.23  -1.24]
4800 50
steps: 239950, episodes: 4800, mean episode reward: -93.38930939518104, time: 24.165
agent0_energy_min, agent0_attention_min
[-15.9  -32.08]
agent1_energy_min, agent1_attention_min
[-47.53  -1.65]
4900 50
steps: 244950, episodes: 4900, mean episode reward: -102.68707202805672, time: 24.098
agent0_energy_min, agent0_attention_min
[-21.49 -26.48]
agent1_energy_min, agent1_attention_min
[-45.38  -2.87]
5000 50
steps: 249950, episodes: 5000, mean episode reward: -92.31210558349838, time: 23.728
agent0_energy_min, agent0_attention_min
[-22.72 -25.08]
agent1_energy_min, agent1_attention_min
[-48.1  -1.4]
5100 50
steps: 254950, episodes: 5100, mean episode reward: -90.18523074598617, time: 24.691
agent0_energy_min, agent0_attention_min
[-25.96 -22.96]
agent1_energy_min, agent1_attention_min
[-47.79  -1.5 ]
5200 50
steps: 259950, episodes: 5200, mean episode reward: -91.64821945833448, time: 24.06
agent0_energy_min, agent0_attention_min
[-19.68 -26.63]
agent1_energy_min, agent1_attention_min
[-48.28  -1.33]
5300 50
steps: 264950, episodes: 5300, mean episode reward: -104.12954269304505, time: 23.702
agent0_energy_min, agent0_attention_min
[-21.48 -25.43]
agent1_energy_min, agent1_attention_min
[-48.43  -1.13]
5400 50
steps: 269950, episodes: 5400, mean episode reward: -94.74711250102824, time: 23.786
agent0_energy_min, agent0_attention_min
[-21.99 -25.34]
agent1_energy_min, agent1_attention_min
[-47.74  -1.63]
5500 50
steps: 274950, episodes: 5500, mean episode reward: -101.22954393880974, time: 24.146
agent0_energy_min, agent0_attention_min
[-28.95 -20.18]
agent1_energy_min, agent1_attention_min
[-47.76  -1.93]
5600 50
steps: 279950, episodes: 5600, mean episode reward: -89.89402153149915, time: 23.915
agent0_energy_min, agent0_attention_min
[-35.81 -13.55]
agent1_energy_min, agent1_attention_min
[-48.42  -1.5 ]
5700 50
steps: 284950, episodes: 5700, mean episode reward: -100.31201811637489, time: 24.042
agent0_energy_min, agent0_attention_min
[-23.5 -24.6]
agent1_energy_min, agent1_attention_min
[-48.72  -1.13]
5800 50
steps: 289950, episodes: 5800, mean episode reward: -112.45227288695878, time: 23.988
agent0_energy_min, agent0_attention_min
[-29.62 -19.23]
agent1_energy_min, agent1_attention_min
[-47.56  -1.94]
5900 50
steps: 294950, episodes: 5900, mean episode reward: -95.27880364741246, time: 24.006
agent0_energy_min, agent0_attention_min
[-27.7  -21.48]
agent1_energy_min, agent1_attention_min
[-48.35  -1.  ]
6000 50
steps: 299950, episodes: 6000, mean episode reward: -79.3513311785605, time: 24.223
agent0_energy_min, agent0_attention_min
[-26.95 -22.08]
agent1_energy_min, agent1_attention_min
[-48.7   -0.63]
6100 50
steps: 304950, episodes: 6100, mean episode reward: -88.32489814751032, time: 24.776
agent0_energy_min, agent0_attention_min
[-25.7  -23.11]
agent1_energy_min, agent1_attention_min
[-48.1   -1.11]
6200 50
steps: 309950, episodes: 6200, mean episode reward: -91.05184239642676, time: 23.794
agent0_energy_min, agent0_attention_min
[-26.89 -22.82]
agent1_energy_min, agent1_attention_min
[-48.4  -1.1]
6300 50
steps: 314950, episodes: 6300, mean episode reward: -83.39117071490747, time: 24.188
agent0_energy_min, agent0_attention_min
[-26.04 -23.5 ]
agent1_energy_min, agent1_attention_min
[-47.84  -1.2 ]
6400 50
steps: 319950, episodes: 6400, mean episode reward: -90.61649366736691, time: 23.917
agent0_energy_min, agent0_attention_min
[-32.26 -17.24]
agent1_energy_min, agent1_attention_min
[-48.07  -0.51]
6500 50
steps: 324950, episodes: 6500, mean episode reward: -107.28994562279664, time: 24.368
agent0_energy_min, agent0_attention_min
[-35.25 -14.46]
agent1_energy_min, agent1_attention_min
[-46.12  -0.18]
6600 50
steps: 329950, episodes: 6600, mean episode reward: -92.74900957431993, time: 24.343
agent0_energy_min, agent0_attention_min
[-36.52 -13.14]
agent1_energy_min, agent1_attention_min
[-46.4   -0.31]
6700 50
steps: 334950, episodes: 6700, mean episode reward: -90.49004392787772, time: 23.896
agent0_energy_min, agent0_attention_min
[-33.86 -16.04]
agent1_energy_min, agent1_attention_min
[-45.2   -0.97]
6800 50
steps: 339950, episodes: 6800, mean episode reward: -83.26432902538214, time: 23.919
agent0_energy_min, agent0_attention_min
[-38.88 -10.74]
agent1_energy_min, agent1_attention_min
[-48.12  -1.51]
6900 50
steps: 344950, episodes: 6900, mean episode reward: -74.43292863705929, time: 23.878
agent0_energy_min, agent0_attention_min
[-32.41 -17.01]
agent1_energy_min, agent1_attention_min
[-48.59  -1.13]
7000 50
steps: 349950, episodes: 7000, mean episode reward: -78.49117501274507, time: 24.441
agent0_energy_min, agent0_attention_min
[-35.19 -13.44]
agent1_energy_min, agent1_attention_min
[-48.87  -0.83]
7100 50
steps: 354950, episodes: 7100, mean episode reward: -100.18785473870555, time: 24.411
agent0_energy_min, agent0_attention_min
[-40.98  -8.88]
agent1_energy_min, agent1_attention_min
[-48.45  -0.89]
7200 50
steps: 359950, episodes: 7200, mean episode reward: -107.10954268419607, time: 24.031
agent0_energy_min, agent0_attention_min
[-40.32  -9.6 ]
agent1_energy_min, agent1_attention_min
[-48.11  -0.92]
7300 50
steps: 364950, episodes: 7300, mean episode reward: -114.78446770776003, time: 23.832
agent0_energy_min, agent0_attention_min
[-41.44  -7.72]
agent1_energy_min, agent1_attention_min
[-47.02  -1.72]
7400 50
steps: 369950, episodes: 7400, mean episode reward: -98.00113415843165, time: 24.354
agent0_energy_min, agent0_attention_min
[-47.74  -2.13]
agent1_energy_min, agent1_attention_min
[-48.11  -1.34]
7500 50
steps: 374950, episodes: 7500, mean episode reward: -117.58792901925843, time: 24.349
agent0_energy_min, agent0_attention_min
[-48.31  -1.55]
agent1_energy_min, agent1_attention_min
[-47.96  -1.59]
7600 50
steps: 379950, episodes: 7600, mean episode reward: -84.56113718063318, time: 24.445
agent0_energy_min, agent0_attention_min
[-46.94  -2.38]
agent1_energy_min, agent1_attention_min
[-48.45  -1.11]
7700 50
steps: 384950, episodes: 7700, mean episode reward: -95.60210317847168, time: 24.463
agent0_energy_min, agent0_attention_min
[-42.69  -6.89]
agent1_energy_min, agent1_attention_min
[-47.17  -1.22]
7800 50
steps: 389950, episodes: 7800, mean episode reward: -109.19527853315483, time: 24.005
agent0_energy_min, agent0_attention_min
[-42.62  -7.31]
agent1_energy_min, agent1_attention_min
[-47.72  -0.56]
7900 50
steps: 394950, episodes: 7900, mean episode reward: -65.71736363790271, time: 24.445
agent0_energy_min, agent0_attention_min
[-43.28  -6.47]
agent1_energy_min, agent1_attention_min
[-48.87  -0.57]
8000 50
steps: 399950, episodes: 8000, mean episode reward: -78.40647468921185, time: 24.015
agent0_energy_min, agent0_attention_min
agent0_energy_min, agent0_attention_min
[-46.52  -2.71]
agent1_energy_min, agent1_attention_min
[-10.77 -38.8 ]
4100 50
steps: 204950, episodes: 4100, mean episode reward: -106.1652021288294, time: 25.555
agent0_energy_min, agent0_attention_min
[-33.87 -14.37]
agent1_energy_min, agent1_attention_min
[ -6.49 -42.96]
4200 50
steps: 209950, episodes: 4200, mean episode reward: -116.58560542653895, time: 25.128
agent0_energy_min, agent0_attention_min
[-32.76 -16.61]
agent1_energy_min, agent1_attention_min
[ -7.94 -41.41]
4300 50
steps: 214950, episodes: 4300, mean episode reward: -108.91872227174277, time: 25.117
agent0_energy_min, agent0_attention_min
[-46.69  -2.85]
agent1_energy_min, agent1_attention_min
[ -7.93 -41.56]
4400 50
steps: 219950, episodes: 4400, mean episode reward: -112.18024530039125, time: 25.248
agent0_energy_min, agent0_attention_min
[-40.3   -8.72]
agent1_energy_min, agent1_attention_min
[-15.46 -33.82]
4500 50
steps: 224950, episodes: 4500, mean episode reward: -115.60634022954652, time: 25.521
agent0_energy_min, agent0_attention_min
[-34.82  -7.78]
agent1_energy_min, agent1_attention_min
[ -6.41 -40.69]
4600 50
steps: 229950, episodes: 4600, mean episode reward: -111.50791386821813, time: 26.065
agent0_energy_min, agent0_attention_min
[-44.52  -4.27]
agent1_energy_min, agent1_attention_min
[ -7.44 -39.52]
4700 50
steps: 234950, episodes: 4700, mean episode reward: -104.15919647643908, time: 25.357
agent0_energy_min, agent0_attention_min
[-45.38  -4.16]
agent1_energy_min, agent1_attention_min
[-10.38 -38.02]
4800 50
steps: 239950, episodes: 4800, mean episode reward: -105.90888030338974, time: 25.318
agent0_energy_min, agent0_attention_min
[-47.48  -1.79]
agent1_energy_min, agent1_attention_min
[ -7.44 -40.3 ]
4900 50
steps: 244950, episodes: 4900, mean episode reward: -112.31022758185978, time: 24.85
agent0_energy_min, agent0_attention_min
[-48.5   -1.05]
agent1_energy_min, agent1_attention_min
[-11.88 -35.77]
5000 50
steps: 249950, episodes: 5000, mean episode reward: -94.27036949972528, time: 25.321
agent0_energy_min, agent0_attention_min
[-47.83  -1.78]
agent1_energy_min, agent1_attention_min
[ -9.75 -38.17]
5100 50
steps: 254950, episodes: 5100, mean episode reward: -112.19438604857578, time: 25.632
agent0_energy_min, agent0_attention_min
[-46.12  -3.18]
agent1_energy_min, agent1_attention_min
[-12.16 -35.67]
5200 50
steps: 259950, episodes: 5200, mean episode reward: -109.2554734406195, time: 25.048
agent0_energy_min, agent0_attention_min
[-46.42  -2.32]
agent1_energy_min, agent1_attention_min
[ -8.31 -37.37]
5300 50
steps: 264950, episodes: 5300, mean episode reward: -101.73883832523578, time: 25.042
agent0_energy_min, agent0_attention_min
[-43.19  -6.12]
agent1_energy_min, agent1_attention_min
[ -5.18 -41.22]
5400 50
steps: 269950, episodes: 5400, mean episode reward: -130.97060894607267, time: 25.139
agent0_energy_min, agent0_attention_min
[-45.52  -3.84]
agent1_energy_min, agent1_attention_min
[-10.86 -33.02]
5500 50
steps: 274950, episodes: 5500, mean episode reward: -208.51330570122198, time: 24.587
agent0_energy_min, agent0_attention_min
[-40.43  -6.07]
agent1_energy_min, agent1_attention_min
[ -8.61 -35.45]
5600 50
steps: 279950, episodes: 5600, mean episode reward: -105.07152506248335, time: 25.258
agent0_energy_min, agent0_attention_min
[-44.53  -1.51]
agent1_energy_min, agent1_attention_min
[ -8.07 -39.76]
5700 50
steps: 284950, episodes: 5700, mean episode reward: -95.53875747748467, time: 24.579
agent0_energy_min, agent0_attention_min
[-45.99  -1.63]
agent1_energy_min, agent1_attention_min
[ -7.59 -41.75]
5800 50
steps: 289950, episodes: 5800, mean episode reward: -95.27326282592574, time: 24.853
agent0_energy_min, agent0_attention_min
[-42.55  -1.91]
agent1_energy_min, agent1_attention_min
[ -6.05 -43.2 ]
5900 50
steps: 294950, episodes: 5900, mean episode reward: -104.21104093348248, time: 24.795
agent0_energy_min, agent0_attention_min
[-46.94  -0.55]
agent1_energy_min, agent1_attention_min
[ -6.43 -42.27]
6000 50
steps: 299950, episodes: 6000, mean episode reward: -92.94720467154515, time: 25.408
agent0_energy_min, agent0_attention_min
[-46.43  -1.06]
agent1_energy_min, agent1_attention_min
[ -4.8  -44.03]
6100 50
steps: 304950, episodes: 6100, mean episode reward: -105.3025055882661, time: 25.571
agent0_energy_min, agent0_attention_min
[-40.03  -2.21]
agent1_energy_min, agent1_attention_min
[ -7.23 -41.42]
6200 50
steps: 309950, episodes: 6200, mean episode reward: -109.71140565221941, time: 24.879
agent0_energy_min, agent0_attention_min
[-42.09  -3.84]
agent1_energy_min, agent1_attention_min
[ -9.52 -39.88]
6300 50
steps: 314950, episodes: 6300, mean episode reward: -90.23205445452889, time: 24.229
agent0_energy_min, agent0_attention_min
[-43.57  -1.78]
agent1_energy_min, agent1_attention_min
[ -7.11 -42.18]
6400 50
steps: 319950, episodes: 6400, mean episode reward: -112.01069043972437, time: 24.51
agent0_energy_min, agent0_attention_min
[-39.05  -8.15]
agent1_energy_min, agent1_attention_min
[ -8.98 -38.95]
6500 50
steps: 324950, episodes: 6500, mean episode reward: -103.27140498562747, time: 24.721
agent0_energy_min, agent0_attention_min
[-44.05  -2.45]
agent1_energy_min, agent1_attention_min
[ -7.79 -40.77]
6600 50
steps: 329950, episodes: 6600, mean episode reward: -106.20666401062643, time: 25.171
agent0_energy_min, agent0_attention_min
[-40.34  -6.43]
agent1_energy_min, agent1_attention_min
[ -9.76 -39.58]
6700 50
steps: 334950, episodes: 6700, mean episode reward: -100.00788183620506, time: 24.04
agent0_energy_min, agent0_attention_min
[-40.14  -7.59]
agent1_energy_min, agent1_attention_min
[ -5.34 -43.97]
6800 50
steps: 339950, episodes: 6800, mean episode reward: -102.66541479889769, time: 24.118
agent0_energy_min, agent0_attention_min
[-40.99  -5.52]
agent1_energy_min, agent1_attention_min
[ -6.   -42.95]
6900 50
steps: 344950, episodes: 6900, mean episode reward: -104.16717052608224, time: 24.145
agent0_energy_min, agent0_attention_min
[-39.52  -7.86]
agent1_energy_min, agent1_attention_min
[ -6.38 -42.39]
7000 50
steps: 349950, episodes: 7000, mean episode reward: -103.80860145656348, time: 24.033
agent0_energy_min, agent0_attention_min
[-46.74  -1.33]
agent1_energy_min, agent1_attention_min
[ -9.2  -38.49]
7100 50
steps: 354950, episodes: 7100, mean episode reward: -85.08334593366213, time: 24.717
agent0_energy_min, agent0_attention_min
[-44.3   -4.86]
agent1_energy_min, agent1_attention_min
[ -5.42 -43.27]
7200 50
steps: 359950, episodes: 7200, mean episode reward: -85.93330233340184, time: 24.113
agent0_energy_min, agent0_attention_min
[-45.42  -2.11]
agent1_energy_min, agent1_attention_min
[ -4.65 -44.21]
7300 50
steps: 364950, episodes: 7300, mean episode reward: -109.96982489333588, time: 24.182
agent0_energy_min, agent0_attention_min
[-43.42  -3.29]
agent1_energy_min, agent1_attention_min
[ -7.62 -41.93]
7400 50
steps: 369950, episodes: 7400, mean episode reward: -86.86453926211374, time: 24.597
agent0_energy_min, agent0_attention_min
[-45.44  -2.32]
agent1_energy_min, agent1_attention_min
[ -9.1  -39.07]
7500 50
steps: 374950, episodes: 7500, mean episode reward: -99.87595616018083, time: 24.288
agent0_energy_min, agent0_attention_min
[-43.68  -4.15]
agent1_energy_min, agent1_attention_min
[ -5.88 -41.53]
7600 50
steps: 379950, episodes: 7600, mean episode reward: -85.90442979697515, time: 24.908
agent0_energy_min, agent0_attention_min
[-45.77  -2.06]
agent1_energy_min, agent1_attention_min
[ -5.48 -42.37]
7700 50
steps: 384950, episodes: 7700, mean episode reward: -100.59648756709282, time: 24.045
agent0_energy_min, agent0_attention_min
[-46.01  -1.75]
agent1_energy_min, agent1_attention_min
[ -3.9  -43.56]
7800 50
steps: 389950, episodes: 7800, mean episode reward: -81.6970548718184, time: 24.205
agent0_energy_min, agent0_attention_min
[-45.12  -1.48]
agent1_energy_min, agent1_attention_min
[ -6.33 -43.29]
7900 50
steps: 394950, episodes: 7900, mean episode reward: -96.23296316915999, time: 24.15
agent0_energy_min, agent0_attention_min
[-45.71  -1.5 ]
agent1_energy_min, agent1_attention_min
[ -7.68 -40.66]
8000 50
steps: 399950, episodes: 8000, mean episode reward: -91.26312247447476, time: 24.114
agent0_energy_min, agent0_attention_min
[ 0.   -0.04]
agent1_energy_min, agent1_attention_min
[-3.674e+01 -2.000e-02]
4100 50
steps: 204950, episodes: 4100, mean episode reward: -141.87828739258288, time: 25.752
agent0_energy_min, agent0_attention_min
[ 0.   -0.01]
agent1_energy_min, agent1_attention_min
[-39.98  -0.04]
4200 50
steps: 209950, episodes: 4200, mean episode reward: -142.75987439489566, time: 24.939
agent0_energy_min, agent0_attention_min
[-0.01  0.  ]
agent1_energy_min, agent1_attention_min
[-37.6   -0.07]
4300 50
steps: 214950, episodes: 4300, mean episode reward: -132.79340224574764, time: 24.908
agent0_energy_min, agent0_attention_min
[0. 0.]
agent1_energy_min, agent1_attention_min
[-4.046e+01 -3.000e-02]
4400 50
steps: 219950, episodes: 4400, mean episode reward: -137.8303236868962, time: 25.332
agent0_energy_min, agent0_attention_min
[-0.02 -0.01]
agent1_energy_min, agent1_attention_min
[-38.25  -0.1 ]
4500 50
steps: 224950, episodes: 4500, mean episode reward: -144.0550790870082, time: 25.164
agent0_energy_min, agent0_attention_min
[-0.02 -0.05]
agent1_energy_min, agent1_attention_min
[-37.52  -0.08]
4600 50
steps: 229950, episodes: 4600, mean episode reward: -130.9046077724661, time: 25.821
agent0_energy_min, agent0_attention_min
[-0.04 -0.02]
agent1_energy_min, agent1_attention_min
[-4.171e+01 -3.000e-02]
4700 50
steps: 234950, episodes: 4700, mean episode reward: -127.20154579624845, time: 24.905
agent0_energy_min, agent0_attention_min
[-0.01 -0.01]
agent1_energy_min, agent1_attention_min
[-4.242e+01 -3.000e-02]
4800 50
steps: 239950, episodes: 4800, mean episode reward: -125.47451820464671, time: 25.454
agent0_energy_min, agent0_attention_min
[-0.52 -0.03]
agent1_energy_min, agent1_attention_min
[-40.65  -0.08]
4900 50
steps: 244950, episodes: 4900, mean episode reward: -125.89559407594975, time: 24.826
agent0_energy_min, agent0_attention_min
[-0.01 -0.02]
agent1_energy_min, agent1_attention_min
[-42.3   -0.08]
5000 50
steps: 249950, episodes: 5000, mean episode reward: -132.69803718290316, time: 24.939
agent0_energy_min, agent0_attention_min
[-0.13 -0.02]
agent1_energy_min, agent1_attention_min
[-37.85  -0.08]
5100 50
steps: 254950, episodes: 5100, mean episode reward: -125.8382662772375, time: 25.16
agent0_energy_min, agent0_attention_min
[-0.03 -0.04]
agent1_energy_min, agent1_attention_min
[-38.38  -0.07]
5200 50
steps: 259950, episodes: 5200, mean episode reward: -140.59009676625797, time: 24.547
agent0_energy_min, agent0_attention_min
[-0.01 -0.02]
agent1_energy_min, agent1_attention_min
[-35.19  -0.09]
5300 50
steps: 264950, episodes: 5300, mean episode reward: -125.9860854246301, time: 24.956
agent0_energy_min, agent0_attention_min
[-0.01 -0.01]
agent1_energy_min, agent1_attention_min
[-3.902e+01 -2.000e-02]
5400 50
steps: 269950, episodes: 5400, mean episode reward: -110.53512672033601, time: 25.046
agent0_energy_min, agent0_attention_min
[0. 0.]
agent1_energy_min, agent1_attention_min
[-41.87   0.  ]
5500 50
steps: 274950, episodes: 5500, mean episode reward: -126.83102275760633, time: 24.782
agent0_energy_min, agent0_attention_min
[-0.12 -0.05]
agent1_energy_min, agent1_attention_min
[-4.181e+01 -2.000e-02]
5600 50
steps: 279950, episodes: 5600, mean episode reward: -129.3146261054626, time: 25.527
agent0_energy_min, agent0_attention_min
[-0.15  0.  ]
agent1_energy_min, agent1_attention_min
[-40.47  -0.05]
5700 50
steps: 284950, episodes: 5700, mean episode reward: -124.4373486672747, time: 25.232
agent0_energy_min, agent0_attention_min
[-0.08 -0.01]
agent1_energy_min, agent1_attention_min
[-40.33  -0.05]
5800 50
steps: 289950, episodes: 5800, mean episode reward: -116.57510393364704, time: 25.013
agent0_energy_min, agent0_attention_min
[-0.04 -0.02]
agent1_energy_min, agent1_attention_min
[-4.324e+01 -2.000e-02]
5900 50
steps: 294950, episodes: 5900, mean episode reward: -116.51075320698257, time: 24.771
agent0_energy_min, agent0_attention_min
[-0.49 -0.01]
agent1_energy_min, agent1_attention_min
[-43.39  -0.05]
6000 50
steps: 299950, episodes: 6000, mean episode reward: -108.14346686542518, time: 25.643
agent0_energy_min, agent0_attention_min
[-0.01  0.  ]
agent1_energy_min, agent1_attention_min
[-44.62  -0.17]
6100 50
steps: 304950, episodes: 6100, mean episode reward: -137.69103008472675, time: 25.684
agent0_energy_min, agent0_attention_min
[-0.17  0.  ]
agent1_energy_min, agent1_attention_min
[-42.18  -0.12]
6200 50
steps: 309950, episodes: 6200, mean episode reward: -119.3498667891076, time: 25.371
agent0_energy_min, agent0_attention_min
[-0.18 -0.02]
agent1_energy_min, agent1_attention_min
[-42.03  -0.12]
6300 50
steps: 314950, episodes: 6300, mean episode reward: -115.79865332538031, time: 24.965
agent0_energy_min, agent0_attention_min
[-0.03 -0.02]
agent1_energy_min, agent1_attention_min
[-41.86  -0.07]
6400 50
steps: 319950, episodes: 6400, mean episode reward: -128.04939863774058, time: 25.065
agent0_energy_min, agent0_attention_min
[-0.28 -0.01]
agent1_energy_min, agent1_attention_min
[-43.68  -0.14]
6500 50
steps: 324950, episodes: 6500, mean episode reward: -121.89154012458053, time: 25.395
agent0_energy_min, agent0_attention_min
[-0.05 -0.01]
agent1_energy_min, agent1_attention_min
[-4.433e+01 -4.000e-02]
6600 50
steps: 329950, episodes: 6600, mean episode reward: -111.24148895205617, time: 25.391
agent0_energy_min, agent0_attention_min
[-0.02 -0.01]
agent1_energy_min, agent1_attention_min
[-4.458e+01 -4.000e-02]
6700 50
steps: 334950, episodes: 6700, mean episode reward: -121.47905102159658, time: 25.161
agent0_energy_min, agent0_attention_min
[-0.5  -0.03]
agent1_energy_min, agent1_attention_min
[-4.328e+01 -3.000e-02]
6800 50
steps: 339950, episodes: 6800, mean episode reward: -131.66259956955895, time: 25.049
agent0_energy_min, agent0_attention_min
[-0.06 -0.01]
agent1_energy_min, agent1_attention_min
[-4.004e+01 -2.000e-02]
6900 50
steps: 344950, episodes: 6900, mean episode reward: -129.8068269805467, time: 24.904
agent0_energy_min, agent0_attention_min
[-14.27  -0.38]
agent1_energy_min, agent1_attention_min
[-42.81  -0.1 ]
7000 50
steps: 349950, episodes: 7000, mean episode reward: -114.30329319986673, time: 24.826
agent0_energy_min, agent0_attention_min
[-36.08  -1.77]
agent1_energy_min, agent1_attention_min
[-40.6   -0.07]
7100 50
steps: 354950, episodes: 7100, mean episode reward: -127.90184029065611, time: 25.42
agent0_energy_min, agent0_attention_min
[-19.25  -2.44]
agent1_energy_min, agent1_attention_min
[-4.152e+01 -4.000e-02]
7200 50
steps: 359950, episodes: 7200, mean episode reward: -118.46396601412972, time: 24.802
agent0_energy_min, agent0_attention_min
[-0.11  0.  ]
agent1_energy_min, agent1_attention_min
[-4.157e+01 -3.000e-02]
7300 50
steps: 364950, episodes: 7300, mean episode reward: -125.483402770795, time: 25.577
agent0_energy_min, agent0_attention_min
[ 0.   -0.01]
agent1_energy_min, agent1_attention_min
[-4.338e+01 -1.000e-02]
7400 50
steps: 369950, episodes: 7400, mean episode reward: -125.08727976957373, time: 24.438
agent0_energy_min, agent0_attention_min
[ 0.   -0.01]
agent1_energy_min, agent1_attention_min
[-43.12  -0.1 ]
7500 50
steps: 374950, episodes: 7500, mean episode reward: -129.9273227203794, time: 25.144
agent0_energy_min, agent0_attention_min
[-0.02 -0.09]
agent1_energy_min, agent1_attention_min
[-40.71  -0.08]
7600 50
steps: 379950, episodes: 7600, mean episode reward: -131.30195763192307, time: 25.513
agent0_energy_min, agent0_attention_min
[-0.12 -0.02]
agent1_energy_min, agent1_attention_min
[-42.05  -0.06]
7700 50
steps: 384950, episodes: 7700, mean episode reward: -113.12618222625359, time: 24.632
agent0_energy_min, agent0_attention_min
[-0.54 -0.12]
agent1_energy_min, agent1_attention_min
[-40.87  -0.18]
7800 50
steps: 389950, episodes: 7800, mean episode reward: -145.01941718749083, time: 25.435
agent0_energy_min, agent0_attention_min
[-0.01 -0.04]
agent1_energy_min, agent1_attention_min
[-40.26  -0.07]
7900 50
steps: 394950, episodes: 7900, mean episode reward: -128.00349033453006, time: 25.192
agent0_energy_min, agent0_attention_min
[-0.81 -0.03]
agent1_energy_min, agent1_attention_min
[-40.61  -0.15]
8000 50
steps: 399950, episodes: 8000, mean episode reward: -134.4786569291707, time: 25.504
agent0_energy_min, agent0_attention_min
[-25.2 -23.8]
agent1_energy_min, agent1_attention_min
[-15.14 -33.83]
4100 50
steps: 204950, episodes: 4100, mean episode reward: -128.1556312123102, time: 25.108
agent0_energy_min, agent0_attention_min
[-15.08 -34.44]
agent1_energy_min, agent1_attention_min
[-13.13 -35.95]
4200 50
steps: 209950, episodes: 4200, mean episode reward: -114.65244247644671, time: 25.249
agent0_energy_min, agent0_attention_min
[-20.18 -29.02]
agent1_energy_min, agent1_attention_min
[-12.8  -36.26]
4300 50
steps: 214950, episodes: 4300, mean episode reward: -104.6561935253808, time: 24.986
agent0_energy_min, agent0_attention_min
[-16.13 -32.43]
agent1_energy_min, agent1_attention_min
[-13.28 -34.24]
4400 50
steps: 219950, episodes: 4400, mean episode reward: -115.65854116140004, time: 25.517
agent0_energy_min, agent0_attention_min
[-24.29 -24.4 ]
agent1_energy_min, agent1_attention_min
[ -9.31 -37.3 ]
4500 50
steps: 224950, episodes: 4500, mean episode reward: -110.49649830274795, time: 25.542
agent0_energy_min, agent0_attention_min
[-19.36 -29.94]
agent1_energy_min, agent1_attention_min
[ -5.51 -42.75]
4600 50
steps: 229950, episodes: 4600, mean episode reward: -119.78675915106605, time: 25.595
agent0_energy_min, agent0_attention_min
[-18.64 -31.19]
agent1_energy_min, agent1_attention_min
[ -7.51 -37.54]
4700 50
steps: 234950, episodes: 4700, mean episode reward: -106.6070788331773, time: 25.022
agent0_energy_min, agent0_attention_min
[-33.88 -15.69]
agent1_energy_min, agent1_attention_min
[ -8.64 -38.13]
4800 50
steps: 239950, episodes: 4800, mean episode reward: -112.4124602863561, time: 24.459
agent0_energy_min, agent0_attention_min
[-31.02 -18.4 ]
agent1_energy_min, agent1_attention_min
[ -6.32 -40.21]
4900 50
steps: 244950, episodes: 4900, mean episode reward: -112.38026215632706, time: 25.017
agent0_energy_min, agent0_attention_min
[-24.96 -24.37]
agent1_energy_min, agent1_attention_min
[ -9.32 -36.07]
5000 50
steps: 249950, episodes: 5000, mean episode reward: -113.43711286368922, time: 25.286
agent0_energy_min, agent0_attention_min
[-23.82 -25.74]
agent1_energy_min, agent1_attention_min
[ -7.75 -39.17]
5100 50
steps: 254950, episodes: 5100, mean episode reward: -110.967531710407, time: 25.841
agent0_energy_min, agent0_attention_min
[-46.47  -3.34]
agent1_energy_min, agent1_attention_min
[ -5.36 -40.21]
5200 50
steps: 259950, episodes: 5200, mean episode reward: -102.15685621060449, time: 24.9
agent0_energy_min, agent0_attention_min
[-37.92 -11.7 ]
agent1_energy_min, agent1_attention_min
[ -9.59 -37.74]
5300 50
steps: 264950, episodes: 5300, mean episode reward: -123.76220452017955, time: 25.03
agent0_energy_min, agent0_attention_min
[-27.22 -22.18]
agent1_energy_min, agent1_attention_min
[ -7.15 -37.51]
5400 50
steps: 269950, episodes: 5400, mean episode reward: -114.60886806489992, time: 25.463
agent0_energy_min, agent0_attention_min
[-33.69 -15.92]
agent1_energy_min, agent1_attention_min
[ -5.95 -38.07]
5500 50
steps: 274950, episodes: 5500, mean episode reward: -113.2469944349561, time: 24.747
agent0_energy_min, agent0_attention_min
[-40.16  -6.87]
agent1_energy_min, agent1_attention_min
[ -7.65 -40.24]
5600 50
steps: 279950, episodes: 5600, mean episode reward: -122.66002873171158, time: 25.779
agent0_energy_min, agent0_attention_min
[-47.29  -1.56]
agent1_energy_min, agent1_attention_min
[ -9.6  -37.47]
5700 50
steps: 284950, episodes: 5700, mean episode reward: -98.62814483308479, time: 25.245
agent0_energy_min, agent0_attention_min
[-42.76  -6.25]
agent1_energy_min, agent1_attention_min
[ -7.35 -39.19]
5800 50
steps: 289950, episodes: 5800, mean episode reward: -108.0643362583204, time: 24.863
agent0_energy_min, agent0_attention_min
[-28.05 -21.36]
agent1_energy_min, agent1_attention_min
[-12.58 -36.18]
5900 50
steps: 294950, episodes: 5900, mean episode reward: -102.8414744001226, time: 25.117
agent0_energy_min, agent0_attention_min
[-33.29 -16.18]
agent1_energy_min, agent1_attention_min
[ -6.38 -42.19]
6000 50
steps: 299950, episodes: 6000, mean episode reward: -112.01787109833704, time: 25.617
agent0_energy_min, agent0_attention_min
[-27.72 -21.96]
agent1_energy_min, agent1_attention_min
[ -8.47 -38.53]
6100 50
steps: 304950, episodes: 6100, mean episode reward: -116.55994297238266, time: 25.839
agent0_energy_min, agent0_attention_min
[-26.87 -22.82]
agent1_energy_min, agent1_attention_min
[ -4.01 -41.76]
6200 50
steps: 309950, episodes: 6200, mean episode reward: -122.4991261622061, time: 24.513
agent0_energy_min, agent0_attention_min
[-18.44 -30.9 ]
agent1_energy_min, agent1_attention_min
[ -5.05 -41.23]
6300 50
steps: 314950, episodes: 6300, mean episode reward: -118.05197433349689, time: 25.247
agent0_energy_min, agent0_attention_min
[-19.53 -28.92]
agent1_energy_min, agent1_attention_min
[ -5.61 -41.69]
6400 50
steps: 319950, episodes: 6400, mean episode reward: -119.65095298923758, time: 25.525
agent0_energy_min, agent0_attention_min
[-28.76 -19.48]
agent1_energy_min, agent1_attention_min
[-13.87 -34.6 ]
6500 50
steps: 324950, episodes: 6500, mean episode reward: -100.21933154030326, time: 24.852
agent0_energy_min, agent0_attention_min
[-24.66 -22.93]
agent1_energy_min, agent1_attention_min
[-12.13 -36.32]
6600 50
steps: 329950, episodes: 6600, mean episode reward: -111.92207069154556, time: 25.398
agent0_energy_min, agent0_attention_min
[-41.52  -8.13]
agent1_energy_min, agent1_attention_min
[ -8.51 -40.84]
6700 50
steps: 334950, episodes: 6700, mean episode reward: -100.72876849436325, time: 25.263
agent0_energy_min, agent0_attention_min
[-36.82 -11.44]
agent1_energy_min, agent1_attention_min
[ -7.69 -40.87]
6800 50
steps: 339950, episodes: 6800, mean episode reward: -115.88423407259948, time: 24.949
agent0_energy_min, agent0_attention_min
[-28.76 -19.39]
agent1_energy_min, agent1_attention_min
[-10.8  -38.11]
6900 50
steps: 344950, episodes: 6900, mean episode reward: -115.63639758682804, time: 25.351
agent0_energy_min, agent0_attention_min
[-31.43 -15.06]
agent1_energy_min, agent1_attention_min
[-15.2  -33.12]
7000 50
steps: 349950, episodes: 7000, mean episode reward: -112.87444331235983, time: 25.493
agent0_energy_min, agent0_attention_min
[-38.74  -7.46]
agent1_energy_min, agent1_attention_min
[-11.5  -37.77]
7100 50
steps: 354950, episodes: 7100, mean episode reward: -98.38426402265985, time: 25.709
agent0_energy_min, agent0_attention_min
[-45.    -3.89]
agent1_energy_min, agent1_attention_min
[ -8.15 -40.43]
7200 50
steps: 359950, episodes: 7200, mean episode reward: -100.44015802984701, time: 25.118
agent0_energy_min, agent0_attention_min
[-44.64  -4.79]
agent1_energy_min, agent1_attention_min
[-11.59 -37.2 ]
7300 50
steps: 364950, episodes: 7300, mean episode reward: -105.39561839270104, time: 25.852
agent0_energy_min, agent0_attention_min
[-41.99  -7.39]
agent1_energy_min, agent1_attention_min
[-11.77 -35.83]
7400 50
steps: 369950, episodes: 7400, mean episode reward: -106.40175123468221, time: 25.068
agent0_energy_min, agent0_attention_min
[-33.15 -15.44]
agent1_energy_min, agent1_attention_min
[-12.22 -37.34]
7500 50
steps: 374950, episodes: 7500, mean episode reward: -85.58512612867595, time: 25.366
agent0_energy_min, agent0_attention_min
[-41.62  -7.88]
agent1_energy_min, agent1_attention_min
[ -6.76 -42.31]
7600 50
steps: 379950, episodes: 7600, mean episode reward: -99.08841385745637, time: 25.923
agent0_energy_min, agent0_attention_min
[-37.7  -11.75]
agent1_energy_min, agent1_attention_min
[ -6.99 -42.07]
7700 50
steps: 384950, episodes: 7700, mean episode reward: -124.95226062454391, time: 24.93
agent0_energy_min, agent0_attention_min
[-32.93 -15.55]
agent1_energy_min, agent1_attention_min
[ -3.32 -44.93]
7800 50
steps: 389950, episodes: 7800, mean episode reward: -94.90036629160531, time: 25.191
agent0_energy_min, agent0_attention_min
[-42.11  -6.1 ]
agent1_energy_min, agent1_attention_min
[ -7.98 -40.93]
7900 50
steps: 394950, episodes: 7900, mean episode reward: -105.28394324414995, time: 25.218
agent0_energy_min, agent0_attention_min
[-45.78  -2.63]
agent1_energy_min, agent1_attention_min
[ -5.13 -42.33]
8000 50
steps: 399950, episodes: 8000, mean episode reward: -88.62612170722826, time: 25.232
[-36.95  -0.04]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
4100 50
steps: 204950, episodes: 4100, mean episode reward: -104.7037007392055, time: 25.774
agent0_energy_min, agent0_attention_min
[-37.77  -0.05]
agent1_energy_min, agent1_attention_min
[-0.1  -0.02]
4200 50
steps: 209950, episodes: 4200, mean episode reward: -105.88700891746807, time: 25.121
agent0_energy_min, agent0_attention_min
[-38.43  -0.08]
agent1_energy_min, agent1_attention_min
[ 0.   -0.02]
4300 50
steps: 214950, episodes: 4300, mean episode reward: -115.20012179576999, time: 25.192
agent0_energy_min, agent0_attention_min
[-39.95  -0.08]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
4400 50
steps: 219950, episodes: 4400, mean episode reward: -119.22958275062598, time: 25.726
agent0_energy_min, agent0_attention_min
[-4.114e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-0.05 -0.05]
4500 50
steps: 224950, episodes: 4500, mean episode reward: -132.10712691327518, time: 25.053
agent0_energy_min, agent0_attention_min
[-35.6   -0.04]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
4600 50
steps: 229950, episodes: 4600, mean episode reward: -111.09195583406489, time: 25.872
agent0_energy_min, agent0_attention_min
[-36.54  -0.06]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
4700 50
steps: 234950, episodes: 4700, mean episode reward: -108.81428667585888, time: 25.563
agent0_energy_min, agent0_attention_min
[-37.56  -0.06]
agent1_energy_min, agent1_attention_min
[-0.03  0.  ]
4800 50
steps: 239950, episodes: 4800, mean episode reward: -112.73183422971204, time: 25.592
agent0_energy_min, agent0_attention_min
[-3.72e+01 -1.00e-02]
agent1_energy_min, agent1_attention_min
[-0.04 -0.01]
4900 50
steps: 244950, episodes: 4900, mean episode reward: -107.96200725664033, time: 25.161
agent0_energy_min, agent0_attention_min
[-36.54  -0.04]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
5000 50
steps: 249950, episodes: 5000, mean episode reward: -107.22842965411758, time: 25.512
agent0_energy_min, agent0_attention_min
[-37.08  -0.04]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
5100 50
steps: 254950, episodes: 5100, mean episode reward: -123.79108205570091, time: 25.841
agent0_energy_min, agent0_attention_min
[-4.199e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.07 -0.01]
5200 50
steps: 259950, episodes: 5200, mean episode reward: -113.41859105510767, time: 25.731
agent0_energy_min, agent0_attention_min
[-34.39  -0.05]
agent1_energy_min, agent1_attention_min
[-0.05 -0.02]
5300 50
steps: 264950, episodes: 5300, mean episode reward: -109.05642146306226, time: 25.117
agent0_energy_min, agent0_attention_min
[-3.78e+01 -1.00e-02]
agent1_energy_min, agent1_attention_min
[-0.03  0.  ]
5400 50
steps: 269950, episodes: 5400, mean episode reward: -117.05210153386595, time: 25.091
agent0_energy_min, agent0_attention_min
[-3.543e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
5500 50
steps: 274950, episodes: 5500, mean episode reward: -110.29716631759914, time: 24.979
agent0_energy_min, agent0_attention_min
[-3.688e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.03]
5600 50
steps: 279950, episodes: 5600, mean episode reward: -103.02823597251499, time: 25.131
agent0_energy_min, agent0_attention_min
[-38.44   0.  ]
agent1_energy_min, agent1_attention_min
[-0.02 -0.02]
5700 50
steps: 284950, episodes: 5700, mean episode reward: -117.23679036972412, time: 25.859
agent0_energy_min, agent0_attention_min
[-37.61  -0.04]
agent1_energy_min, agent1_attention_min
[-0.05 -0.01]
5800 50
steps: 289950, episodes: 5800, mean episode reward: -109.20067203281182, time: 24.756
agent0_energy_min, agent0_attention_min
[-38.44  -0.04]
agent1_energy_min, agent1_attention_min
[-0.02  0.  ]
5900 50
steps: 294950, episodes: 5900, mean episode reward: -108.82913057952233, time: 25.638
agent0_energy_min, agent0_attention_min
[-37.08   0.  ]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
6000 50
steps: 299950, episodes: 6000, mean episode reward: -108.70400285502124, time: 25.615
agent0_energy_min, agent0_attention_min
[-3.604e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.02  0.  ]
6100 50
steps: 304950, episodes: 6100, mean episode reward: -100.01953262010707, time: 25.863
agent0_energy_min, agent0_attention_min
[-3.543e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.03]
6200 50
steps: 309950, episodes: 6200, mean episode reward: -111.22722708653127, time: 24.899
agent0_energy_min, agent0_attention_min
[-40.85  -0.06]
agent1_energy_min, agent1_attention_min
[-0.02 -0.02]
6300 50
steps: 314950, episodes: 6300, mean episode reward: -121.88271504396269, time: 24.963
agent0_energy_min, agent0_attention_min
[-38.65  -0.04]
agent1_energy_min, agent1_attention_min
[-0.02 -0.02]
6400 50
steps: 319950, episodes: 6400, mean episode reward: -109.13904838775932, time: 25.534
agent0_energy_min, agent0_attention_min
[-3.445e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
6500 50
steps: 324950, episodes: 6500, mean episode reward: -108.77274124121855, time: 25.457
agent0_energy_min, agent0_attention_min
[-4.033e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-0.02  0.  ]
6600 50
steps: 329950, episodes: 6600, mean episode reward: -117.30422127686512, time: 25.825
agent0_energy_min, agent0_attention_min
[-3.985e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.03 -0.02]
6700 50
steps: 334950, episodes: 6700, mean episode reward: -106.99999076906306, time: 25.697
agent0_energy_min, agent0_attention_min
[-3.76e+01 -2.00e-02]
agent1_energy_min, agent1_attention_min
[-0.02 -0.03]
6800 50
steps: 339950, episodes: 6800, mean episode reward: -110.43201802057366, time: 24.722
agent0_energy_min, agent0_attention_min
[-3.955e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.02 -0.03]
6900 50
steps: 344950, episodes: 6900, mean episode reward: -101.53893673322595, time: 25.293
agent0_energy_min, agent0_attention_min
[-3.473e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.03  0.  ]
7000 50
steps: 349950, episodes: 7000, mean episode reward: -125.25581092827768, time: 25.814
agent0_energy_min, agent0_attention_min
[-37.8   -0.04]
agent1_energy_min, agent1_attention_min
[0. 0.]
7100 50
steps: 354950, episodes: 7100, mean episode reward: -113.0423683789275, time: 25.427
agent0_energy_min, agent0_attention_min
[-4.027e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.03 -0.02]
7200 50
steps: 359950, episodes: 7200, mean episode reward: -104.87253585984699, time: 25.218
agent0_energy_min, agent0_attention_min
[-3.686e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[0. 0.]
7300 50
steps: 364950, episodes: 7300, mean episode reward: -98.1730723375713, time: 25.325
agent0_energy_min, agent0_attention_min
[-39.02   0.  ]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
7400 50
steps: 369950, episodes: 7400, mean episode reward: -105.57258702077046, time: 24.968
agent0_energy_min, agent0_attention_min
[-4.006e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.04  0.  ]
7500 50
steps: 374950, episodes: 7500, mean episode reward: -113.46247149137064, time: 25.066
agent0_energy_min, agent0_attention_min
[-4.219e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
7600 50
steps: 379950, episodes: 7600, mean episode reward: -100.02239376973785, time: 25.628
agent0_energy_min, agent0_attention_min
[-3.842e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.02]
7700 50
steps: 384950, episodes: 7700, mean episode reward: -99.88352098759475, time: 25.117
agent0_energy_min, agent0_attention_min
[-35.46  -0.05]
agent1_energy_min, agent1_attention_min
[-0.04  0.  ]
7800 50
steps: 389950, episodes: 7800, mean episode reward: -115.07007123190034, time: 25.153
agent0_energy_min, agent0_attention_min
[-4.127e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.02 -0.03]
7900 50
steps: 394950, episodes: 7900, mean episode reward: -94.5074045597998, time: 25.133
agent0_energy_min, agent0_attention_min
[-39.37  -0.04]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
8000 50
steps: 399950, episodes: 8000, mean episode reward: -108.85224109939263, time: 25.732
[-0.99 -0.01]
4100 50
steps: 204950, episodes: 4100, mean episode reward: -125.06925402046978, time: 24.905
agent0_energy_min, agent0_attention_min
[-0.68  0.  ]
agent1_energy_min, agent1_attention_min
[-0.99 -0.07]
4200 50
steps: 209950, episodes: 4200, mean episode reward: -136.93395459925773, time: 24.872
agent0_energy_min, agent0_attention_min
[-1.376e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.78 -0.05]
4300 50
steps: 214950, episodes: 4300, mean episode reward: -122.54112521905766, time: 25.63
agent0_energy_min, agent0_attention_min
[-0.01 -0.02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
4400 50
steps: 219950, episodes: 4400, mean episode reward: -134.95654868914622, time: 24.938
agent0_energy_min, agent0_attention_min
[-0.8  0. ]
agent1_energy_min, agent1_attention_min
[-0.48 -0.01]
4500 50
steps: 224950, episodes: 4500, mean episode reward: -143.76498046488922, time: 25.216
agent0_energy_min, agent0_attention_min
[-5.69  0.  ]
agent1_energy_min, agent1_attention_min
[-0.44  0.  ]
4600 50
steps: 229950, episodes: 4600, mean episode reward: -138.42835650455444, time: 25.864
agent0_energy_min, agent0_attention_min
[-0.1  0. ]
agent1_energy_min, agent1_attention_min
[-5.08 -0.03]
4700 50
steps: 234950, episodes: 4700, mean episode reward: -139.80619771607934, time: 25.022
agent0_energy_min, agent0_attention_min
[-3.15  0.  ]
agent1_energy_min, agent1_attention_min
[-3.56 -0.04]
4800 50
steps: 239950, episodes: 4800, mean episode reward: -136.71241448530142, time: 25.26
agent0_energy_min, agent0_attention_min
[-0.01 -0.02]
agent1_energy_min, agent1_attention_min
[-1.81 -0.09]
4900 50
steps: 244950, episodes: 4900, mean episode reward: -130.6129931483288, time: 24.654
agent0_energy_min, agent0_attention_min
[-0.92 -0.01]
agent1_energy_min, agent1_attention_min
[-2.12 -0.11]
5000 50
steps: 249950, episodes: 5000, mean episode reward: -136.51641570188104, time: 25.371
agent0_energy_min, agent0_attention_min
[-2.18e+01 -1.00e-02]
agent1_energy_min, agent1_attention_min
[-7.86 -0.03]
5100 50
steps: 254950, episodes: 5100, mean episode reward: -134.77015589054218, time: 25.431
agent0_energy_min, agent0_attention_min
[-0.21  0.  ]
agent1_energy_min, agent1_attention_min
[-5.12 -0.09]
5200 50
steps: 259950, episodes: 5200, mean episode reward: -132.49786670513114, time: 25.172
agent0_energy_min, agent0_attention_min
[-6.61 -0.05]
agent1_energy_min, agent1_attention_min
[-0.34 -0.04]
5300 50
steps: 264950, episodes: 5300, mean episode reward: -124.05537305984224, time: 25.733
agent0_energy_min, agent0_attention_min
[-0.49 -0.01]
agent1_energy_min, agent1_attention_min
[-10.04  -0.36]
5400 50
steps: 269950, episodes: 5400, mean episode reward: -137.93526106163858, time: 25.217
agent0_energy_min, agent0_attention_min
[-7.21 -0.01]
agent1_energy_min, agent1_attention_min
[-14.5   -0.05]
5500 50
steps: 274950, episodes: 5500, mean episode reward: -155.55262626236203, time: 24.797
agent0_energy_min, agent0_attention_min
[-0.33  0.  ]
agent1_energy_min, agent1_attention_min
[-20.45  -1.07]
5600 50
steps: 279950, episodes: 5600, mean episode reward: -133.86465578742332, time: 25.746
agent0_energy_min, agent0_attention_min
[-1.27  0.  ]
agent1_energy_min, agent1_attention_min
[-8.06 -0.35]
5700 50
steps: 284950, episodes: 5700, mean episode reward: -137.29411559133843, time: 25.293
agent0_energy_min, agent0_attention_min
[-0.02  0.  ]
agent1_energy_min, agent1_attention_min
[-15.73  -0.94]
5800 50
steps: 289950, episodes: 5800, mean episode reward: -128.4499931408484, time: 25.062
agent0_energy_min, agent0_attention_min
[-8.3  -0.02]
agent1_energy_min, agent1_attention_min
[-4.75 -0.02]
5900 50
steps: 294950, episodes: 5900, mean episode reward: -136.43193174270195, time: 25.216
agent0_energy_min, agent0_attention_min
[-42.63  -0.1 ]
agent1_energy_min, agent1_attention_min
[-37.95  -0.62]
6000 50
steps: 299950, episodes: 6000, mean episode reward: -138.40303732519757, time: 25.219
agent0_energy_min, agent0_attention_min
[-5.01 -0.02]
agent1_energy_min, agent1_attention_min
[-45.2   -0.16]
6100 50
steps: 304950, episodes: 6100, mean episode reward: -145.28769827884562, time: 25.813
agent0_energy_min, agent0_attention_min
[-0.63 -0.01]
agent1_energy_min, agent1_attention_min
[-17.88  -0.26]
6200 50
steps: 309950, episodes: 6200, mean episode reward: -142.02195523595245, time: 25.203
agent0_energy_min, agent0_attention_min
[-5.74 -0.01]
agent1_energy_min, agent1_attention_min
[-23.55  -0.03]
6300 50
steps: 314950, episodes: 6300, mean episode reward: -154.7346532232226, time: 24.832
agent0_energy_min, agent0_attention_min
[-0.44 -0.02]
agent1_energy_min, agent1_attention_min
[-20.04  -0.58]
6400 50
steps: 319950, episodes: 6400, mean episode reward: -128.8577263011489, time: 25.837
agent0_energy_min, agent0_attention_min
[-0.72  0.  ]
agent1_energy_min, agent1_attention_min
[-6.44 -0.07]
6500 50
steps: 324950, episodes: 6500, mean episode reward: -121.28210655744611, time: 25.084
agent0_energy_min, agent0_attention_min
[-0.98 -0.04]
agent1_energy_min, agent1_attention_min
[0. 0.]
6600 50
steps: 329950, episodes: 6600, mean episode reward: -142.54051289599113, time: 25.785
agent0_energy_min, agent0_attention_min
[-31.93  -0.59]
agent1_energy_min, agent1_attention_min
[-6.03 -0.1 ]
6700 50
steps: 334950, episodes: 6700, mean episode reward: -151.59226784590444, time: 25.313
agent0_energy_min, agent0_attention_min
[-24.51  -0.17]
agent1_energy_min, agent1_attention_min
[-0.79  0.  ]
6800 50
steps: 339950, episodes: 6800, mean episode reward: -130.12985282775807, time: 25.345
agent0_energy_min, agent0_attention_min
[-2.43 -0.06]
agent1_energy_min, agent1_attention_min
[-0.35 -0.02]
6900 50
steps: 344950, episodes: 6900, mean episode reward: -159.28552263875582, time: 25.125
agent0_energy_min, agent0_attention_min
[-11.1   -3.47]
agent1_energy_min, agent1_attention_min
[-0.02  0.  ]
7000 50
steps: 349950, episodes: 7000, mean episode reward: -138.76013277473632, time: 25.575
agent0_energy_min, agent0_attention_min
[-5.22 -1.7 ]
agent1_energy_min, agent1_attention_min
[-0.87 -0.02]
7100 50
steps: 354950, episodes: 7100, mean episode reward: -140.11376032750616, time: 26.12
agent0_energy_min, agent0_attention_min
[-0.03 -0.02]
agent1_energy_min, agent1_attention_min
[-0.03  0.  ]
7200 50
steps: 359950, episodes: 7200, mean episode reward: -146.57504134725875, time: 25.397
agent0_energy_min, agent0_attention_min
[-0.61 -0.01]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
7300 50
steps: 364950, episodes: 7300, mean episode reward: -121.64443893423972, time: 25.35
agent0_energy_min, agent0_attention_min
[-0.62 -0.02]
agent1_energy_min, agent1_attention_min
[-0.02 -0.01]
7400 50
steps: 369950, episodes: 7400, mean episode reward: -125.93859414503113, time: 25.29
agent0_energy_min, agent0_attention_min
[-2.44  0.  ]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
7500 50
steps: 374950, episodes: 7500, mean episode reward: -124.46740746006644, time: 25.296
agent0_energy_min, agent0_attention_min
[-0.56 -0.03]
agent1_energy_min, agent1_attention_min
[-0.16 -0.01]
7600 50
steps: 379950, episodes: 7600, mean episode reward: -138.9520902220982, time: 26.086
agent0_energy_min, agent0_attention_min
[-1.43 -0.01]
agent1_energy_min, agent1_attention_min
[-0.48 -0.03]
7700 50
steps: 384950, episodes: 7700, mean episode reward: -135.77956922328187, time: 25.117
agent0_energy_min, agent0_attention_min
[-0.63 -0.01]
agent1_energy_min, agent1_attention_min
[-1.13 -0.01]
7800 50
steps: 389950, episodes: 7800, mean episode reward: -120.46921160052803, time: 24.775
agent0_energy_min, agent0_attention_min
[-0.74  0.  ]
agent1_energy_min, agent1_attention_min
[-0.88 -0.01]
7900 50
steps: 394950, episodes: 7900, mean episode reward: -110.04002118400209, time: 25.326
agent0_energy_min, agent0_attention_min
[-6.17 -0.01]
agent1_energy_min, agent1_attention_min
[-0.82  0.  ]
8000 50
steps: 399950, episodes: 8000, mean episode reward: -135.36943907172966, time: 25.612
agent0_energy_min, agent0_attention_min
[-2.16 -0.01]
agent1_energy_min, agent1_attention_min
[-0.3  -0.01]
8100 50
steps: 404950, episodes: 8100, mean episode reward: -129.87416255670146, time: 25.773
[-48.47  -0.06]
8000 50
steps: 399950, episodes: 8000, mean episode reward: -47.0935480309652, time: 24.384
agent0_energy_min, agent0_attention_min
[-4.905e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-47.29  -0.28]
8100 50
steps: 404950, episodes: 8100, mean episode reward: -54.791706267971584, time: 24.661
agent0_energy_min, agent0_attention_min
[-4.708e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-47.73  -0.39]
8200 50
steps: 409950, episodes: 8200, mean episode reward: -57.44281851715351, time: 24.762
agent0_energy_min, agent0_attention_min
[-4.458e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-48.24  -0.26]
8300 50
steps: 414950, episodes: 8300, mean episode reward: -53.75933763707846, time: 24.833
agent0_energy_min, agent0_attention_min
[-4.832e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-46.88  -0.2 ]
8400 50
steps: 419950, episodes: 8400, mean episode reward: -61.6145954753186, time: 24.326
agent0_energy_min, agent0_attention_min
[-4.739e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-46.36  -0.17]
8500 50
steps: 424950, episodes: 8500, mean episode reward: -66.89168341638555, time: 24.186
agent0_energy_min, agent0_attention_min
[-4.684e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-45.26  -0.31]
8600 50
steps: 429950, episodes: 8600, mean episode reward: -48.82748734053289, time: 25.124
agent0_energy_min, agent0_attention_min
[-48.85  -0.13]
agent1_energy_min, agent1_attention_min
[-45.7   -0.44]
8700 50
steps: 434950, episodes: 8700, mean episode reward: -52.64123205008555, time: 24.907
agent0_energy_min, agent0_attention_min
[-48.72  -0.07]
agent1_energy_min, agent1_attention_min
[-45.68  -0.24]
8800 50
steps: 439950, episodes: 8800, mean episode reward: -55.7661799553159, time: 24.994
agent0_energy_min, agent0_attention_min
[-4.77e+01 -4.00e-02]
agent1_energy_min, agent1_attention_min
[-45.24  -0.25]
8900 50
steps: 444950, episodes: 8900, mean episode reward: -47.382562715274716, time: 24.453
agent0_energy_min, agent0_attention_min
[-4.882e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-47.62  -0.12]
9000 50
steps: 449950, episodes: 9000, mean episode reward: -52.11862946651244, time: 24.855
agent0_energy_min, agent0_attention_min
[-48.18  -0.09]
agent1_energy_min, agent1_attention_min
[-45.82  -0.19]
9100 50
steps: 454950, episodes: 9100, mean episode reward: -55.523049989052936, time: 25.172
agent0_energy_min, agent0_attention_min
[-4.838e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-46.22  -0.15]
9200 50
steps: 459950, episodes: 9200, mean episode reward: -48.70275440587474, time: 24.311
agent0_energy_min, agent0_attention_min
[-47.95  -0.22]
agent1_energy_min, agent1_attention_min
[-45.32  -0.19]
9300 50
steps: 464950, episodes: 9300, mean episode reward: -54.32947113363375, time: 24.255
agent0_energy_min, agent0_attention_min
[-48.    -0.12]
agent1_energy_min, agent1_attention_min
[-46.06  -0.28]
9400 50
steps: 469950, episodes: 9400, mean episode reward: -55.3889440897387, time: 24.498
agent0_energy_min, agent0_attention_min
[-48.28  -0.35]
agent1_energy_min, agent1_attention_min
[-45.37  -0.18]
9500 50
steps: 474950, episodes: 9500, mean episode reward: -59.30457506540857, time: 24.881
agent0_energy_min, agent0_attention_min
[-47.67  -0.42]
agent1_energy_min, agent1_attention_min
[-45.72  -0.34]
9600 50
steps: 479950, episodes: 9600, mean episode reward: -86.21950511342216, time: 25.124
agent0_energy_min, agent0_attention_min
[-48.51  -0.23]
agent1_energy_min, agent1_attention_min
[-46.04  -0.4 ]
9700 50
steps: 484950, episodes: 9700, mean episode reward: -64.77709875675505, time: 24.916
agent0_energy_min, agent0_attention_min
[-48.8   -0.13]
agent1_energy_min, agent1_attention_min
[-44.6   -0.44]
9800 50
steps: 489950, episodes: 9800, mean episode reward: -51.60186576305019, time: 24.215
agent0_energy_min, agent0_attention_min
[-48.43  -0.29]
agent1_energy_min, agent1_attention_min
[-46.72  -0.5 ]
9900 50
steps: 494950, episodes: 9900, mean episode reward: -53.147238125434896, time: 24.4
agent0_energy_min, agent0_attention_min
[-48.27  -0.09]
agent1_energy_min, agent1_attention_min
[-46.61  -0.39]
10000 50
steps: 499950, episodes: 10000, mean episode reward: -140.76957150588126, time: 25.201
agent0_energy_min, agent0_attention_min
[-48.14  -0.46]
agent1_energy_min, agent1_attention_min
[-46.87  -0.1 ]
10100 50
steps: 504950, episodes: 10100, mean episode reward: -46.685733259652665, time: 25.766
agent0_energy_min, agent0_attention_min
[-48.53  -0.1 ]
agent1_energy_min, agent1_attention_min
[-4.692e+01 -4.000e-02]
10200 50
steps: 509950, episodes: 10200, mean episode reward: -58.158996769379364, time: 24.973
agent0_energy_min, agent0_attention_min
[-47.83  -0.29]
agent1_energy_min, agent1_attention_min
[-47.98  -0.18]
10300 50
steps: 514950, episodes: 10300, mean episode reward: -56.289772143678384, time: 24.346
agent0_energy_min, agent0_attention_min
[-47.43  -0.24]
agent1_energy_min, agent1_attention_min
[-4.906e+01 -2.000e-02]
10400 50
steps: 519950, episodes: 10400, mean episode reward: -51.885554026709244, time: 26.277
agent0_energy_min, agent0_attention_min
[-48.    -0.29]
agent1_energy_min, agent1_attention_min
[-4.935e+01 -2.000e-02]
10500 50
steps: 524950, episodes: 10500, mean episode reward: -53.3614082438717, time: 25.116
agent0_energy_min, agent0_attention_min
[-48.57  -0.23]
agent1_energy_min, agent1_attention_min
[-48.25  -0.13]
10600 50
steps: 529950, episodes: 10600, mean episode reward: -53.833210479434975, time: 25.305
agent0_energy_min, agent0_attention_min
[-48.55  -0.12]
agent1_energy_min, agent1_attention_min
[-47.51  -0.24]
10700 50
steps: 534950, episodes: 10700, mean episode reward: -37.323670816384606, time: 24.901
agent0_energy_min, agent0_attention_min
[-48.25  -0.69]
agent1_energy_min, agent1_attention_min
[-48.48  -0.06]
10800 50
steps: 539950, episodes: 10800, mean episode reward: -53.81485983682331, time: 24.75
agent0_energy_min, agent0_attention_min
[-48.5   -0.16]
agent1_energy_min, agent1_attention_min
[-4.89e+01 -3.00e-02]
10900 50
steps: 544950, episodes: 10900, mean episode reward: -198.59319549268508, time: 24.357
agent0_energy_min, agent0_attention_min
[-47.85  -0.13]
agent1_energy_min, agent1_attention_min
[-48.57  -0.08]
11000 50
steps: 549950, episodes: 11000, mean episode reward: -51.97146805084462, time: 24.997
agent0_energy_min, agent0_attention_min
[-47.32  -1.01]
agent1_energy_min, agent1_attention_min
[-48.6   -0.14]
11100 50
steps: 554950, episodes: 11100, mean episode reward: -45.509307678753785, time: 25.412
agent0_energy_min, agent0_attention_min
[-46.96  -0.99]
agent1_energy_min, agent1_attention_min
[-48.25  -0.07]
11200 50
steps: 559950, episodes: 11200, mean episode reward: -72.86351816419227, time: 24.347
agent0_energy_min, agent0_attention_min
[-42.72  -0.96]
agent1_energy_min, agent1_attention_min
[-47.64  -0.49]
11300 50
steps: 564950, episodes: 11300, mean episode reward: -53.00354207612368, time: 24.76
agent0_energy_min, agent0_attention_min
[-47.89  -1.28]
agent1_energy_min, agent1_attention_min
[-48.97  -0.4 ]
11400 50
steps: 569950, episodes: 11400, mean episode reward: -67.7870978243185, time: 24.291
agent0_energy_min, agent0_attention_min
[-47.78  -1.47]
agent1_energy_min, agent1_attention_min
[-48.61  -0.21]
11500 50
steps: 574950, episodes: 11500, mean episode reward: -64.32926108232698, time: 24.327
agent0_energy_min, agent0_attention_min
[-47.08  -0.88]
agent1_energy_min, agent1_attention_min
[-49.18  -0.33]
11600 50
steps: 579950, episodes: 11600, mean episode reward: -62.701203403813714, time: 24.808
agent0_energy_min, agent0_attention_min
[-47.48  -0.95]
agent1_energy_min, agent1_attention_min
[-49.19  -0.2 ]
11700 50
steps: 584950, episodes: 11700, mean episode reward: -37.381500639849804, time: 24.272
agent0_energy_min, agent0_attention_min
[-48.72  -0.53]
agent1_energy_min, agent1_attention_min
[-47.86  -1.01]
11800 50
steps: 589950, episodes: 11800, mean episode reward: -44.80163958931148, time: 24.75
agent0_energy_min, agent0_attention_min
[-48.88  -0.32]
agent1_energy_min, agent1_attention_min
[-48.18  -0.46]
11900 50
steps: 594950, episodes: 11900, mean episode reward: -47.43155744686506, time: 24.525
agent0_energy_min, agent0_attention_min
[-49.14  -0.29]
agent1_energy_min, agent1_attention_min
[-47.68  -1.64]
8100 50
steps: 404950, episodes: 8100, mean episode reward: -51.27848953193824, time: 24.974
agent0_energy_min, agent0_attention_min
[-49.12  -0.59]
agent1_energy_min, agent1_attention_min
[-46.94  -1.98]
8200 50
steps: 409950, episodes: 8200, mean episode reward: -56.899826213464934, time: 24.045
agent0_energy_min, agent0_attention_min
[-48.49  -0.35]
agent1_energy_min, agent1_attention_min
[-47.71  -1.32]
8300 50
steps: 414950, episodes: 8300, mean episode reward: -52.02481733495846, time: 24.376
agent0_energy_min, agent0_attention_min
[-48.79  -1.03]
agent1_energy_min, agent1_attention_min
[-48.46  -0.86]
8400 50
steps: 419950, episodes: 8400, mean episode reward: -55.4561251457807, time: 24.542
agent0_energy_min, agent0_attention_min
[-48.75  -1.18]
agent1_energy_min, agent1_attention_min
[-47.77  -0.98]
8500 50
steps: 424950, episodes: 8500, mean episode reward: -65.59739784654204, time: 24.116
agent0_energy_min, agent0_attention_min
[-49.35  -0.55]
agent1_energy_min, agent1_attention_min
[-47.55  -1.34]
8600 50
steps: 429950, episodes: 8600, mean episode reward: -50.87671018102427, time: 24.607
agent0_energy_min, agent0_attention_min
[-49.76  -0.21]
agent1_energy_min, agent1_attention_min
[-48.51  -0.8 ]
8700 50
steps: 434950, episodes: 8700, mean episode reward: -59.89108695437261, time: 24.477
agent0_energy_min, agent0_attention_min
[-49.49  -0.26]
agent1_energy_min, agent1_attention_min
[-48.31  -0.72]
8800 50
steps: 439950, episodes: 8800, mean episode reward: -56.14142769360719, time: 24.284
agent0_energy_min, agent0_attention_min
[-49.58  -0.17]
agent1_energy_min, agent1_attention_min
[-48.26  -1.02]
8900 50
steps: 444950, episodes: 8900, mean episode reward: -54.79124278020443, time: 24.559
agent0_energy_min, agent0_attention_min
[-48.84  -0.55]
agent1_energy_min, agent1_attention_min
[-47.79  -1.35]
9000 50
steps: 449950, episodes: 9000, mean episode reward: -57.73743398918399, time: 24.977
agent0_energy_min, agent0_attention_min
[-47.12  -0.66]
agent1_energy_min, agent1_attention_min
[-47.08  -1.2 ]
9100 50
steps: 454950, episodes: 9100, mean episode reward: -60.86274955530784, time: 24.703
agent0_energy_min, agent0_attention_min
[-47.14  -1.  ]
agent1_energy_min, agent1_attention_min
[-48.49  -1.14]
9200 50
steps: 459950, episodes: 9200, mean episode reward: -69.64409359613038, time: 24.284
agent0_energy_min, agent0_attention_min
[-47.87  -1.55]
agent1_energy_min, agent1_attention_min
[-47.47  -1.48]
9300 50
steps: 464950, episodes: 9300, mean episode reward: -43.21319882673852, time: 23.956
agent0_energy_min, agent0_attention_min
[-48.61  -1.39]
agent1_energy_min, agent1_attention_min
[-48.71  -1.  ]
9400 50
steps: 469950, episodes: 9400, mean episode reward: -48.93325535942395, time: 24.479
agent0_energy_min, agent0_attention_min
[-49.62  -0.29]
agent1_energy_min, agent1_attention_min
[-48.71  -0.83]
9500 50
steps: 474950, episodes: 9500, mean episode reward: -56.25274495102759, time: 23.801
agent0_energy_min, agent0_attention_min
[-49.75  -0.16]
agent1_energy_min, agent1_attention_min
[-48.29  -1.09]
9600 50
steps: 479950, episodes: 9600, mean episode reward: -53.83711549949292, time: 25.237
agent0_energy_min, agent0_attention_min
[-49.29  -0.21]
agent1_energy_min, agent1_attention_min
[-47.85  -1.75]
9700 50
steps: 484950, episodes: 9700, mean episode reward: -52.52947387138319, time: 24.665
agent0_energy_min, agent0_attention_min
[-49.66  -0.14]
agent1_energy_min, agent1_attention_min
[-48.08  -1.18]
9800 50
steps: 489950, episodes: 9800, mean episode reward: -48.71377741313359, time: 23.919
agent0_energy_min, agent0_attention_min
[-49.7   -0.12]
agent1_energy_min, agent1_attention_min
[-48.14  -1.27]
9900 50
steps: 494950, episodes: 9900, mean episode reward: -46.40735516294315, time: 24.361
agent0_energy_min, agent0_attention_min
[-49.39  -0.06]
agent1_energy_min, agent1_attention_min
[-48.31  -1.15]
10000 50
steps: 499950, episodes: 10000, mean episode reward: -49.60733644237086, time: 24.732
agent0_energy_min, agent0_attention_min
[-49.03  -0.16]
agent1_energy_min, agent1_attention_min
[-48.21  -1.4 ]
10100 50
steps: 504950, episodes: 10100, mean episode reward: -74.61636517727312, time: 24.674
agent0_energy_min, agent0_attention_min
[-47.48  -0.06]
agent1_energy_min, agent1_attention_min
[-48.12  -1.34]
10200 50
steps: 509950, episodes: 10200, mean episode reward: -57.72828932641724, time: 25.152
agent0_energy_min, agent0_attention_min
[-49.34  -0.06]
agent1_energy_min, agent1_attention_min
[-48.55  -0.82]
10300 50
steps: 514950, episodes: 10300, mean episode reward: -59.88154457736116, time: 24.684
agent0_energy_min, agent0_attention_min
[-49.41  -0.22]
agent1_energy_min, agent1_attention_min
[-48.42  -1.04]
10400 50
steps: 519950, episodes: 10400, mean episode reward: -57.69255315543087, time: 23.951
agent0_energy_min, agent0_attention_min
[-48.95  -0.17]
agent1_energy_min, agent1_attention_min
[-47.76  -1.85]
10500 50
steps: 524950, episodes: 10500, mean episode reward: -49.201765383460554, time: 24.544
agent0_energy_min, agent0_attention_min
[-49.74  -0.21]
agent1_energy_min, agent1_attention_min
[-48.41  -1.43]
10600 50
steps: 529950, episodes: 10600, mean episode reward: -44.79374748974508, time: 25.004
agent0_energy_min, agent0_attention_min
[-49.76  -0.14]
agent1_energy_min, agent1_attention_min
[-48.49  -1.17]
10700 50
steps: 534950, episodes: 10700, mean episode reward: -46.344513357253575, time: 24.401
agent0_energy_min, agent0_attention_min
[-49.16  -0.42]
agent1_energy_min, agent1_attention_min
[-48.82  -0.47]
10800 50
steps: 539950, episodes: 10800, mean episode reward: -47.298732121631375, time: 25.003
agent0_energy_min, agent0_attention_min
[-48.77  -0.33]
agent1_energy_min, agent1_attention_min
[-48.37  -1.06]
10900 50
steps: 544950, episodes: 10900, mean episode reward: -49.374073501654685, time: 24.413
agent0_energy_min, agent0_attention_min
[-49.74  -0.17]
agent1_energy_min, agent1_attention_min
[-47.98  -1.08]
11000 50
steps: 549950, episodes: 11000, mean episode reward: -44.40918224016212, time: 24.548
agent0_energy_min, agent0_attention_min
[-49.78  -0.22]
agent1_energy_min, agent1_attention_min
[-48.54  -1.15]
11100 50
steps: 554950, episodes: 11100, mean episode reward: -55.253668038170765, time: 25.055
agent0_energy_min, agent0_attention_min
[-49.01  -0.27]
agent1_energy_min, agent1_attention_min
[-48.03  -1.36]
11200 50
steps: 559950, episodes: 11200, mean episode reward: -68.47194201429076, time: 24.723
agent0_energy_min, agent0_attention_min
[-48.36  -0.32]
agent1_energy_min, agent1_attention_min
[-47.51  -1.68]
11300 50
steps: 564950, episodes: 11300, mean episode reward: -60.17954364280663, time: 24.26
agent0_energy_min, agent0_attention_min
[-48.68  -0.77]
agent1_energy_min, agent1_attention_min
[-47.68  -1.69]
11400 50
steps: 569950, episodes: 11400, mean episode reward: -48.07684765931579, time: 24.008
agent0_energy_min, agent0_attention_min
[-49.    -0.56]
agent1_energy_min, agent1_attention_min
[-48.07  -1.33]
11500 50
steps: 574950, episodes: 11500, mean episode reward: -49.26694784541468, time: 24.49
agent0_energy_min, agent0_attention_min
[-49.37  -0.44]
agent1_energy_min, agent1_attention_min
[-46.83  -1.94]
11600 50
steps: 579950, episodes: 11600, mean episode reward: -57.55913742153639, time: 24.851
agent0_energy_min, agent0_attention_min
[-48.84  -0.69]
agent1_energy_min, agent1_attention_min
[-46.94  -1.57]
11700 50
steps: 584950, episodes: 11700, mean episode reward: -65.80705951895374, time: 24.452
agent0_energy_min, agent0_attention_min
[-48.36  -0.35]
agent1_energy_min, agent1_attention_min
[-46.73  -2.05]
11800 50
steps: 589950, episodes: 11800, mean episode reward: -70.68135596002547, time: 23.965
agent0_energy_min, agent0_attention_min
[-48.17  -0.78]
agent1_energy_min, agent1_attention_min
[-47.3   -1.79]
11900 50
steps: 594950, episodes: 11900, mean episode reward: -53.74572461330568, time: 24.351
agent0_energy_min, agent0_attention_min
[-49.2   -0.44]
agent1_energy_min, agent1_attention_min
[-47.31  -1.43]
12000 50
steps: 599950, episodes: 12000, mean episode reward: -47.94199836615901, time: 24.218
[-49.32  -0.57]
agent1_energy_min, agent1_attention_min
[-47.3   -1.95]
8100 50
steps: 404950, episodes: 8100, mean episode reward: -80.27186469301003, time: 24.573
agent0_energy_min, agent0_attention_min
[-49.07  -0.9 ]
agent1_energy_min, agent1_attention_min
[-47.37  -1.76]
8200 50
steps: 409950, episodes: 8200, mean episode reward: -87.93597451014594, time: 24.532
agent0_energy_min, agent0_attention_min
[-48.13  -1.66]
agent1_energy_min, agent1_attention_min
[-46.25  -2.07]
8300 50
steps: 414950, episodes: 8300, mean episode reward: -83.12827163326314, time: 24.15
agent0_energy_min, agent0_attention_min
[-49.44  -0.39]
agent1_energy_min, agent1_attention_min
[-46.86  -2.38]
8400 50
steps: 419950, episodes: 8400, mean episode reward: -68.6304463539501, time: 23.892
agent0_energy_min, agent0_attention_min
[-49.53  -0.3 ]
agent1_energy_min, agent1_attention_min
[-47.54  -2.03]
8500 50
steps: 424950, episodes: 8500, mean episode reward: -74.47479018256331, time: 24.116
agent0_energy_min, agent0_attention_min
[-48.15  -1.57]
agent1_energy_min, agent1_attention_min
[-47.48  -1.51]
8600 50
steps: 429950, episodes: 8600, mean episode reward: -72.03063158337417, time: 24.492
agent0_energy_min, agent0_attention_min
[-48.78  -1.21]
agent1_energy_min, agent1_attention_min
[-46.57  -1.65]
8700 50
steps: 434950, episodes: 8700, mean episode reward: -66.67746083084313, time: 24.332
agent0_energy_min, agent0_attention_min
[-47.62  -2.37]
agent1_energy_min, agent1_attention_min
[-47.68  -1.24]
8800 50
steps: 439950, episodes: 8800, mean episode reward: -62.64691867084662, time: 23.922
agent0_energy_min, agent0_attention_min
[-48.2   -1.77]
agent1_energy_min, agent1_attention_min
[-47.28  -1.77]
8900 50
steps: 444950, episodes: 8900, mean episode reward: -67.40905624591694, time: 24.195
agent0_energy_min, agent0_attention_min
[-47.17  -2.81]
agent1_energy_min, agent1_attention_min
[-47.77  -1.67]
9000 50
steps: 449950, episodes: 9000, mean episode reward: -72.68653455631825, time: 24.094
agent0_energy_min, agent0_attention_min
[-49.47  -0.5 ]
agent1_energy_min, agent1_attention_min
[-47.5   -1.48]
9100 50
steps: 454950, episodes: 9100, mean episode reward: -80.48671509259232, time: 24.64
agent0_energy_min, agent0_attention_min
[-49.83  -0.1 ]
agent1_energy_min, agent1_attention_min
[-47.13  -1.32]
9200 50
steps: 459950, episodes: 9200, mean episode reward: -67.1441453102222, time: 24.037
agent0_energy_min, agent0_attention_min
[-49.47  -0.47]
agent1_energy_min, agent1_attention_min
[-47.68  -1.58]
9300 50
steps: 464950, episodes: 9300, mean episode reward: -69.80053628670944, time: 24.02
agent0_energy_min, agent0_attention_min
[-49.55  -0.31]
agent1_energy_min, agent1_attention_min
[-48.21  -1.08]
9400 50
steps: 469950, episodes: 9400, mean episode reward: -73.29444658154928, time: 23.9
agent0_energy_min, agent0_attention_min
[-49.43  -0.43]
agent1_energy_min, agent1_attention_min
[-47.65  -1.  ]
9500 50
steps: 474950, episodes: 9500, mean episode reward: -71.49294510797567, time: 24.614
agent0_energy_min, agent0_attention_min
[-49.88  -0.1 ]
agent1_energy_min, agent1_attention_min
[-48.1   -1.11]
9600 50
steps: 479950, episodes: 9600, mean episode reward: -106.5549889124518, time: 24.975
agent0_energy_min, agent0_attention_min
[-49.76  -0.23]
agent1_energy_min, agent1_attention_min
[-47.48  -1.74]
9700 50
steps: 484950, episodes: 9700, mean episode reward: -67.01199488659023, time: 23.875
agent0_energy_min, agent0_attention_min
[-49.37  -0.61]
agent1_energy_min, agent1_attention_min
[-47.25  -1.9 ]
9800 50
steps: 489950, episodes: 9800, mean episode reward: -61.86289232602397, time: 23.757
agent0_energy_min, agent0_attention_min
[-48.97  -0.99]
agent1_energy_min, agent1_attention_min
[-46.3   -1.95]
9900 50
steps: 494950, episodes: 9900, mean episode reward: -68.09128306442742, time: 24.302
agent0_energy_min, agent0_attention_min
[-49.59  -0.4 ]
agent1_energy_min, agent1_attention_min
[-47.69  -0.97]
10000 50
steps: 499950, episodes: 10000, mean episode reward: -64.12161099332738, time: 24.31
agent0_energy_min, agent0_attention_min
[-49.09  -0.89]
agent1_energy_min, agent1_attention_min
[-47.5   -1.27]
10100 50
steps: 504950, episodes: 10100, mean episode reward: -68.1450724403623, time: 25.342
agent0_energy_min, agent0_attention_min
[-49.07  -0.75]
agent1_energy_min, agent1_attention_min
[-47.85  -1.03]
10200 50
steps: 509950, episodes: 10200, mean episode reward: -63.033248964194954, time: 23.9
agent0_energy_min, agent0_attention_min
[-49.47  -0.48]
agent1_energy_min, agent1_attention_min
[-47.96  -1.76]
10300 50
steps: 514950, episodes: 10300, mean episode reward: -73.70834416348514, time: 24.904
agent0_energy_min, agent0_attention_min
[-49.18  -0.63]
agent1_energy_min, agent1_attention_min
[-46.68  -1.97]
10400 50
steps: 519950, episodes: 10400, mean episode reward: -89.74193108224519, time: 24.84
agent0_energy_min, agent0_attention_min
[-49.32  -0.64]
agent1_energy_min, agent1_attention_min
[-48.33  -1.07]
10500 50
steps: 524950, episodes: 10500, mean episode reward: -76.18668862798984, time: 24.328
agent0_energy_min, agent0_attention_min
[-49.42  -0.52]
agent1_energy_min, agent1_attention_min
[-48.07  -1.41]
10600 50
steps: 529950, episodes: 10600, mean episode reward: -70.05455931598566, time: 25.034
agent0_energy_min, agent0_attention_min
[-49.28  -0.66]
agent1_energy_min, agent1_attention_min
[-48.33  -1.3 ]
10700 50
steps: 534950, episodes: 10700, mean episode reward: -71.31887213293246, time: 24.508
agent0_energy_min, agent0_attention_min
[-49.67  -0.25]
agent1_energy_min, agent1_attention_min
[-47.98  -1.5 ]
10800 50
steps: 539950, episodes: 10800, mean episode reward: -59.45237419297363, time: 24.745
agent0_energy_min, agent0_attention_min
[-49.4   -0.58]
agent1_energy_min, agent1_attention_min
[-48.25  -1.42]
10900 50
steps: 544950, episodes: 10900, mean episode reward: -66.75716299215877, time: 24.777
agent0_energy_min, agent0_attention_min
[-49.1  -0.9]
agent1_energy_min, agent1_attention_min
[-48.26  -1.06]
11000 50
steps: 549950, episodes: 11000, mean episode reward: -79.19460026836187, time: 24.331
agent0_energy_min, agent0_attention_min
[-48.41  -1.58]
agent1_energy_min, agent1_attention_min
[-48.2  -1.6]
11100 50
steps: 554950, episodes: 11100, mean episode reward: -66.49931749968754, time: 24.331
agent0_energy_min, agent0_attention_min
[-48.16  -1.81]
agent1_energy_min, agent1_attention_min
[-48.06  -1.55]
11200 50
steps: 559950, episodes: 11200, mean episode reward: -68.26119329799408, time: 24.002
agent0_energy_min, agent0_attention_min
[-49.27  -0.7 ]
agent1_energy_min, agent1_attention_min
[-48.06  -1.43]
11300 50
steps: 564950, episodes: 11300, mean episode reward: -64.21580849892646, time: 24.444
agent0_energy_min, agent0_attention_min
[-49.41  -0.57]
agent1_energy_min, agent1_attention_min
[-49.15  -0.64]
11400 50
steps: 569950, episodes: 11400, mean episode reward: -59.12851765382663, time: 24.016
agent0_energy_min, agent0_attention_min
[-48.02  -1.93]
agent1_energy_min, agent1_attention_min
[-48.04  -0.69]
11500 50
steps: 574950, episodes: 11500, mean episode reward: -66.21489852889975, time: 24.518
agent0_energy_min, agent0_attention_min
[-49.13  -0.81]
agent1_energy_min, agent1_attention_min
[-48.29  -0.59]
11600 50
steps: 579950, episodes: 11600, mean episode reward: -95.16642335857534, time: 24.752
agent0_energy_min, agent0_attention_min
[-43.78  -5.95]
agent1_energy_min, agent1_attention_min
[-48.8   -0.75]
11700 50
steps: 584950, episodes: 11700, mean episode reward: -116.58862566407859, time: 24.006
agent0_energy_min, agent0_attention_min
[-44.26  -4.52]
agent1_energy_min, agent1_attention_min
[-47.82  -1.22]
11800 50
steps: 589950, episodes: 11800, mean episode reward: -75.75437470790143, time: 24.311
agent0_energy_min, agent0_attention_min
[-48.95  -0.49]
agent1_energy_min, agent1_attention_min
[-48.91  -0.82]
11900 50
steps: 594950, episodes: 11900, mean episode reward: -71.79216315177575, time: 23.989
agent0_energy_min, agent0_attention_min
[-49.36  -0.58]
agent1_energy_min, agent1_attention_min
[-47.67  -1.72]
12000 50
steps: 599950, episodes: 12000, mean episode reward: -65.77142776203269, time: 24.591
agent0_energy_min, agent0_attention_min
[-41.2   -8.07]
agent1_energy_min, agent1_attention_min
[-47.45  -0.27]
8100 50
steps: 404950, episodes: 8100, mean episode reward: -69.32275937788977, time: 24.767
agent0_energy_min, agent0_attention_min
[-44.05  -5.6 ]
agent1_energy_min, agent1_attention_min
[-45.31  -0.62]
8200 50
steps: 409950, episodes: 8200, mean episode reward: -50.72578366214374, time: 24.517
agent0_energy_min, agent0_attention_min
[-43.19  -5.52]
agent1_energy_min, agent1_attention_min
[-47.02  -0.81]
8300 50
steps: 414950, episodes: 8300, mean episode reward: -77.03517904636263, time: 24.343
agent0_energy_min, agent0_attention_min
[-42.44  -6.61]
agent1_energy_min, agent1_attention_min
[-47.85  -0.45]
8400 50
steps: 419950, episodes: 8400, mean episode reward: -116.95667199886252, time: 23.484
agent0_energy_min, agent0_attention_min
[-42.46  -6.1 ]
agent1_energy_min, agent1_attention_min
[-46.54  -1.01]
8500 50
steps: 424950, episodes: 8500, mean episode reward: -89.36928016142788, time: 24.247
agent0_energy_min, agent0_attention_min
[-45.38  -4.4 ]
agent1_energy_min, agent1_attention_min
[-47.94  -0.42]
8600 50
steps: 429950, episodes: 8600, mean episode reward: -59.4961633887996, time: 24.78
agent0_energy_min, agent0_attention_min
[-42.8   -6.52]
agent1_energy_min, agent1_attention_min
[-48.63  -0.26]
8700 50
steps: 434950, episodes: 8700, mean episode reward: -56.89077179950093, time: 25.087
agent0_energy_min, agent0_attention_min
[-44.62  -4.64]
agent1_energy_min, agent1_attention_min
[-47.63  -0.43]
8800 50
steps: 439950, episodes: 8800, mean episode reward: -78.17138942178552, time: 24.872
agent0_energy_min, agent0_attention_min
[-43.36  -5.16]
agent1_energy_min, agent1_attention_min
[-46.54  -0.95]
8900 50
steps: 444950, episodes: 8900, mean episode reward: -69.15921069480827, time: 24.465
agent0_energy_min, agent0_attention_min
[-46.42  -3.15]
agent1_energy_min, agent1_attention_min
[-47.31  -1.02]
9000 50
steps: 449950, episodes: 9000, mean episode reward: -61.87909762063526, time: 24.216
agent0_energy_min, agent0_attention_min
[-44.57  -5.18]
agent1_energy_min, agent1_attention_min
[-48.04  -0.24]
9100 50
steps: 454950, episodes: 9100, mean episode reward: -66.55816052456065, time: 24.479
agent0_energy_min, agent0_attention_min
[-40.3   -9.27]
agent1_energy_min, agent1_attention_min
[-47.99  -0.72]
9200 50
steps: 459950, episodes: 9200, mean episode reward: -64.68011067055409, time: 24.29
agent0_energy_min, agent0_attention_min
[-45.48  -3.82]
agent1_energy_min, agent1_attention_min
[-47.22  -0.54]
9300 50
steps: 464950, episodes: 9300, mean episode reward: -94.25207499397224, time: 24.611
agent0_energy_min, agent0_attention_min
[-47.6   -2.02]
agent1_energy_min, agent1_attention_min
[-45.33  -1.69]
9400 50
steps: 469950, episodes: 9400, mean episode reward: -71.89753795327105, time: 23.957
agent0_energy_min, agent0_attention_min
[-44.82  -4.8 ]
agent1_energy_min, agent1_attention_min
[-46.43  -0.37]
9500 50
steps: 474950, episodes: 9500, mean episode reward: -74.35624578242673, time: 24.358
agent0_energy_min, agent0_attention_min
[-42.27  -7.13]
agent1_energy_min, agent1_attention_min
[-47.23  -0.26]
9600 50
steps: 479950, episodes: 9600, mean episode reward: -48.01135974238485, time: 25.021
agent0_energy_min, agent0_attention_min
[-45.01  -4.52]
agent1_energy_min, agent1_attention_min
[-46.4   -0.51]
9700 50
steps: 484950, episodes: 9700, mean episode reward: -46.92487487519617, time: 24.458
agent0_energy_min, agent0_attention_min
[-42.59  -6.52]
agent1_energy_min, agent1_attention_min
[-47.96  -0.51]
9800 50
steps: 489950, episodes: 9800, mean episode reward: -59.36811883602474, time: 25.923
agent0_energy_min, agent0_attention_min
[-45.46  -3.54]
agent1_energy_min, agent1_attention_min
[-47.23  -0.51]
9900 50
steps: 494950, episodes: 9900, mean episode reward: -83.6997234987412, time: 24.43
agent0_energy_min, agent0_attention_min
[-45.39  -3.57]
agent1_energy_min, agent1_attention_min
[-43.7   -0.56]
10000 50
steps: 499950, episodes: 10000, mean episode reward: -53.53088391183736, time: 24.243
agent0_energy_min, agent0_attention_min
[-45.2   -4.54]
agent1_energy_min, agent1_attention_min
[-46.92  -0.19]
10100 50
steps: 504950, episodes: 10100, mean episode reward: -59.305551360308215, time: 25.074
agent0_energy_min, agent0_attention_min
[-44.17  -5.44]
agent1_energy_min, agent1_attention_min
[-45.68  -0.18]
10200 50
steps: 509950, episodes: 10200, mean episode reward: -54.194382265947176, time: 24.313
agent0_energy_min, agent0_attention_min
[-45.02  -4.58]
agent1_energy_min, agent1_attention_min
[-46.49  -0.11]
10300 50
steps: 514950, episodes: 10300, mean episode reward: -53.72034647282537, time: 25.872
agent0_energy_min, agent0_attention_min
[-45.31  -4.12]
agent1_energy_min, agent1_attention_min
[-46.86  -0.23]
10400 50
steps: 519950, episodes: 10400, mean episode reward: -52.438777366562206, time: 25.03
agent0_energy_min, agent0_attention_min
[-46.14  -3.31]
agent1_energy_min, agent1_attention_min
[-46.27  -0.12]
10500 50
steps: 524950, episodes: 10500, mean episode reward: -52.700213619571876, time: 24.456
agent0_energy_min, agent0_attention_min
[-47.05  -2.63]
agent1_energy_min, agent1_attention_min
[-4.674e+01 -1.000e-02]
10600 50
steps: 529950, episodes: 10600, mean episode reward: -62.248312508861225, time: 24.779
agent0_energy_min, agent0_attention_min
[-45.86  -3.14]
agent1_energy_min, agent1_attention_min
[-4.365e+01 -4.000e-02]
10700 50
steps: 534950, episodes: 10700, mean episode reward: -71.04245046764659, time: 24.19
agent0_energy_min, agent0_attention_min
[-46.53  -2.85]
agent1_energy_min, agent1_attention_min
[-46.34   0.  ]
10800 50
steps: 539950, episodes: 10800, mean episode reward: -53.65241253713849, time: 24.832
agent0_energy_min, agent0_attention_min
[-45.68  -3.79]
agent1_energy_min, agent1_attention_min
[-46.79  -0.06]
10900 50
steps: 544950, episodes: 10900, mean episode reward: -56.86031561356033, time: 24.722
agent0_energy_min, agent0_attention_min
[-47.15  -2.47]
agent1_energy_min, agent1_attention_min
[-47.13  -0.44]
11000 50
steps: 549950, episodes: 11000, mean episode reward: -51.525334924329584, time: 24.698
agent0_energy_min, agent0_attention_min
[-46.76  -2.81]
agent1_energy_min, agent1_attention_min
[-4.71e+01 -3.00e-02]
11100 50
steps: 554950, episodes: 11100, mean episode reward: -46.36170225651179, time: 24.339
agent0_energy_min, agent0_attention_min
[-44.23  -5.43]
agent1_energy_min, agent1_attention_min
[-46.33   0.  ]
11200 50
steps: 559950, episodes: 11200, mean episode reward: -61.97310958752254, time: 26.993
agent0_energy_min, agent0_attention_min
[-44.74  -4.34]
agent1_energy_min, agent1_attention_min
[-4.68e+01 -1.00e-02]
11300 50
steps: 564950, episodes: 11300, mean episode reward: -61.44668256930082, time: 24.381
agent0_energy_min, agent0_attention_min
[-46.5   -2.11]
agent1_energy_min, agent1_attention_min
[-4.636e+01 -3.000e-02]
11400 50
steps: 569950, episodes: 11400, mean episode reward: -58.60620959222999, time: 24.89
agent0_energy_min, agent0_attention_min
[-47.53  -2.31]
agent1_energy_min, agent1_attention_min
[-46.52  -0.06]
11500 50
steps: 574950, episodes: 11500, mean episode reward: -58.484252627483954, time: 24.365
agent0_energy_min, agent0_attention_min
[-47.06  -2.34]
agent1_energy_min, agent1_attention_min
[-46.91  -0.51]
11600 50
steps: 579950, episodes: 11600, mean episode reward: -55.811174217759174, time: 24.649
agent0_energy_min, agent0_attention_min
[-47.59  -1.88]
agent1_energy_min, agent1_attention_min
[-4.62e+01 -3.00e-02]
11700 50
steps: 584950, episodes: 11700, mean episode reward: -51.31027406627333, time: 24.218
agent0_energy_min, agent0_attention_min
[-47.1   -2.74]
agent1_energy_min, agent1_attention_min
[-46.37  -0.1 ]
11800 50
steps: 589950, episodes: 11800, mean episode reward: -57.5896786274721, time: 24.484
agent0_energy_min, agent0_attention_min
[-47.83  -1.98]
agent1_energy_min, agent1_attention_min
[-4.643e+01 -2.000e-02]
11900 50
steps: 594950, episodes: 11900, mean episode reward: -50.89203107747289, time: 24.508
agent0_energy_min, agent0_attention_min
[-47.71  -1.81]
agent1_energy_min, agent1_attention_min
[-45.37  -0.05]
12000 50
steps: 599950, episodes: 12000, mean episode reward: -55.47099861082356, time: 24.457
agent0_energy_min, agent0_attention_min
[-45.25  -2.07]
agent1_energy_min, agent1_attention_min
[ -4.99 -44.79]
8100 50
steps: 404950, episodes: 8100, mean episode reward: -92.4151234652086, time: 24.731
agent0_energy_min, agent0_attention_min
[-46.65  -1.12]
agent1_energy_min, agent1_attention_min
[ -6.38 -43.37]
8200 50
steps: 409950, episodes: 8200, mean episode reward: -106.05799565111562, time: 23.987
agent0_energy_min, agent0_attention_min
[-44.69  -2.02]
agent1_energy_min, agent1_attention_min
[ -8.63 -39.92]
8300 50
steps: 414950, episodes: 8300, mean episode reward: -94.81312564297434, time: 24.338
agent0_energy_min, agent0_attention_min
[-43.91  -0.99]
agent1_energy_min, agent1_attention_min
[ -9.33 -40.49]
8400 50
steps: 419950, episodes: 8400, mean episode reward: -98.07748828792629, time: 24.233
agent0_energy_min, agent0_attention_min
[-43.74  -1.2 ]
agent1_energy_min, agent1_attention_min
[-11.03 -38.21]
8500 50
steps: 424950, episodes: 8500, mean episode reward: -85.39288485308532, time: 24.108
agent0_energy_min, agent0_attention_min
[-45.23  -0.98]
agent1_energy_min, agent1_attention_min
[ -7.94 -41.08]
8600 50
steps: 429950, episodes: 8600, mean episode reward: -94.09405216816238, time: 24.775
agent0_energy_min, agent0_attention_min
[-43.96  -1.23]
agent1_energy_min, agent1_attention_min
[ -9.05 -38.28]
8700 50
steps: 434950, episodes: 8700, mean episode reward: -96.10984371089036, time: 24.32
agent0_energy_min, agent0_attention_min
[-42.86  -0.98]
agent1_energy_min, agent1_attention_min
[ -7.05 -40.73]
8800 50
steps: 439950, episodes: 8800, mean episode reward: -92.90971983272146, time: 24.209
agent0_energy_min, agent0_attention_min
[-44.95  -0.98]
agent1_energy_min, agent1_attention_min
[ -6.06 -40.35]
8900 50
steps: 444950, episodes: 8900, mean episode reward: -119.9645813977426, time: 23.98
agent0_energy_min, agent0_attention_min
[-41.19  -0.79]
agent1_energy_min, agent1_attention_min
[ -5.54 -40.55]
9000 50
steps: 449950, episodes: 9000, mean episode reward: -108.93354186700037, time: 24.028
agent0_energy_min, agent0_attention_min
[-45.18  -0.88]
agent1_energy_min, agent1_attention_min
[ -4.42 -41.81]
9100 50
steps: 454950, episodes: 9100, mean episode reward: -92.61451710474422, time: 24.532
agent0_energy_min, agent0_attention_min
[-45.93  -0.81]
agent1_energy_min, agent1_attention_min
[ -8.94 -38.85]
9200 50
steps: 459950, episodes: 9200, mean episode reward: -87.63187373935354, time: 23.835
agent0_energy_min, agent0_attention_min
[-40.72  -1.02]
agent1_energy_min, agent1_attention_min
[ -7.69 -40.87]
9300 50
steps: 464950, episodes: 9300, mean episode reward: -108.53321462098899, time: 24.008
agent0_energy_min, agent0_attention_min
[-39.48  -0.8 ]
agent1_energy_min, agent1_attention_min
[ -8.37 -41.04]
9400 50
steps: 469950, episodes: 9400, mean episode reward: -76.56519122164441, time: 24.49
agent0_energy_min, agent0_attention_min
[-42.98  -0.87]
agent1_energy_min, agent1_attention_min
[ -6.18 -42.78]
9500 50
steps: 474950, episodes: 9500, mean episode reward: -90.3417388758025, time: 24.517
agent0_energy_min, agent0_attention_min
[-42.06  -1.09]
agent1_energy_min, agent1_attention_min
[ -7.92 -41.36]
9600 50
steps: 479950, episodes: 9600, mean episode reward: -80.66779206376069, time: 24.584
agent0_energy_min, agent0_attention_min
[-44.91  -1.38]
agent1_energy_min, agent1_attention_min
[ -7.1  -42.73]
9700 50
steps: 484950, episodes: 9700, mean episode reward: -98.06946000738989, time: 25.927
agent0_energy_min, agent0_attention_min
[-45.87  -1.4 ]
agent1_energy_min, agent1_attention_min
[ -4.03 -45.25]
9800 50
steps: 489950, episodes: 9800, mean episode reward: -85.05762513783431, time: 24.331
agent0_energy_min, agent0_attention_min
[-44.03  -0.7 ]
agent1_energy_min, agent1_attention_min
[ -4.04 -45.1 ]
9900 50
steps: 494950, episodes: 9900, mean episode reward: -84.2505003561894, time: 24.453
agent0_energy_min, agent0_attention_min
[-42.05  -0.4 ]
agent1_energy_min, agent1_attention_min
[ -2.97 -45.22]
10000 50
steps: 499950, episodes: 10000, mean episode reward: -85.60711916335549, time: 24.53
agent0_energy_min, agent0_attention_min
[-42.38  -0.64]
agent1_energy_min, agent1_attention_min
[ -6.67 -41.42]
10100 50
steps: 504950, episodes: 10100, mean episode reward: -83.10768734770332, time: 25.322
agent0_energy_min, agent0_attention_min
[-44.26  -2.42]
agent1_energy_min, agent1_attention_min
[ -5.08 -44.51]
10200 50
steps: 509950, episodes: 10200, mean episode reward: -77.20892636357024, time: 23.335
agent0_energy_min, agent0_attention_min
[-43.18  -1.27]
agent1_energy_min, agent1_attention_min
[ -4.19 -44.62]
10300 50
steps: 514950, episodes: 10300, mean episode reward: -93.43323418661346, time: 24.585
agent0_energy_min, agent0_attention_min
[-42.08  -0.38]
agent1_energy_min, agent1_attention_min
[ -6.52 -41.31]
10400 50
steps: 519950, episodes: 10400, mean episode reward: -86.91402347832866, time: 24.515
agent0_energy_min, agent0_attention_min
[-43.34  -1.29]
agent1_energy_min, agent1_attention_min
[ -9.12 -39.66]
10500 50
steps: 524950, episodes: 10500, mean episode reward: -85.23175375858538, time: 24.328
agent0_energy_min, agent0_attention_min
[-38.17  -1.2 ]
agent1_energy_min, agent1_attention_min
[ -5.3  -43.07]
10600 50
steps: 529950, episodes: 10600, mean episode reward: -97.08863351259537, time: 25.511
agent0_energy_min, agent0_attention_min
[-37.28  -1.37]
agent1_energy_min, agent1_attention_min
[ -4.23 -42.91]
10700 50
steps: 534950, episodes: 10700, mean episode reward: -82.99314246034686, time: 24.313
agent0_energy_min, agent0_attention_min
[-42.02  -1.42]
agent1_energy_min, agent1_attention_min
[ -5.66 -42.86]
10800 50
steps: 539950, episodes: 10800, mean episode reward: -81.11165183817842, time: 24.899
agent0_energy_min, agent0_attention_min
[-43.74  -2.43]
agent1_energy_min, agent1_attention_min
[ -9.69 -39.86]
10900 50
steps: 544950, episodes: 10900, mean episode reward: -92.92639534310197, time: 24.403
agent0_energy_min, agent0_attention_min
[-44.23  -1.65]
agent1_energy_min, agent1_attention_min
[ -6.08 -42.2 ]
11000 50
steps: 549950, episodes: 11000, mean episode reward: -89.79677269739658, time: 24.603
agent0_energy_min, agent0_attention_min
[-40.94  -2.5 ]
agent1_energy_min, agent1_attention_min
[ -5.18 -44.03]
11100 50
steps: 554950, episodes: 11100, mean episode reward: -119.14346497172228, time: 27.733
agent0_energy_min, agent0_attention_min
[-34.61  -1.01]
agent1_energy_min, agent1_attention_min
[ -1.33 -46.17]
11200 50
steps: 559950, episodes: 11200, mean episode reward: -85.25273920304876, time: 24.558
agent0_energy_min, agent0_attention_min
[-44.9   -1.25]
agent1_energy_min, agent1_attention_min
[ -4.38 -44.31]
11300 50
steps: 564950, episodes: 11300, mean episode reward: -83.3161290711783, time: 24.058
agent0_energy_min, agent0_attention_min
[-42.74  -1.66]
agent1_energy_min, agent1_attention_min
[ -2.07 -46.83]
11400 50
steps: 569950, episodes: 11400, mean episode reward: -77.91362884789284, time: 24.336
agent0_energy_min, agent0_attention_min
[-40.84  -1.68]
agent1_energy_min, agent1_attention_min
[ -5.35 -44.19]
11500 50
steps: 574950, episodes: 11500, mean episode reward: -84.86254188889635, time: 24.728
agent0_energy_min, agent0_attention_min
[-39.44  -0.68]
agent1_energy_min, agent1_attention_min
[ -8.02 -41.7 ]
11600 50
steps: 579950, episodes: 11600, mean episode reward: -77.77931731708247, time: 24.547
agent0_energy_min, agent0_attention_min
[-38.18  -2.82]
agent1_energy_min, agent1_attention_min
[ -7.89 -41.65]
11700 50
steps: 584950, episodes: 11700, mean episode reward: -81.04656992709751, time: 24.363
agent0_energy_min, agent0_attention_min
[-31.36  -5.6 ]
agent1_energy_min, agent1_attention_min
[ -3.69 -45.46]
11800 50
steps: 589950, episodes: 11800, mean episode reward: -71.25268059325407, time: 24.589
agent0_energy_min, agent0_attention_min
[-35.31  -2.98]
agent1_energy_min, agent1_attention_min
[ -5.88 -43.84]
11900 50
steps: 594950, episodes: 11900, mean episode reward: -73.593152294081, time: 24.051
agent0_energy_min, agent0_attention_min
[-41.58  -1.51]
agent1_energy_min, agent1_attention_min
[ -7.65 -42.03]
12000 50
steps: 599950, episodes: 12000, mean episode reward: -79.90185544570959, time: 24.988
agent0_energy_min, agent0_attention_min
[-47.51  -1.91]
agent1_energy_min, agent1_attention_min
[ -8.02 -40.74]
8100 50
steps: 404950, episodes: 8100, mean episode reward: -96.96464960224266, time: 25.34
agent0_energy_min, agent0_attention_min
[-45.99  -3.77]
agent1_energy_min, agent1_attention_min
[ -7.68 -41.38]
8200 50
steps: 409950, episodes: 8200, mean episode reward: -108.7928404386782, time: 24.408
agent0_energy_min, agent0_attention_min
[-45.91  -2.82]
agent1_energy_min, agent1_attention_min
[ -9.18 -39.2 ]
8300 50
steps: 414950, episodes: 8300, mean episode reward: -109.48296434152074, time: 25.091
agent0_energy_min, agent0_attention_min
[-46.91  -1.66]
agent1_energy_min, agent1_attention_min
[ -7.94 -40.98]
8400 50
steps: 419950, episodes: 8400, mean episode reward: -83.74832073013062, time: 24.459
agent0_energy_min, agent0_attention_min
[-46.64  -2.42]
agent1_energy_min, agent1_attention_min
[ -7.12 -41.88]
8500 50
steps: 424950, episodes: 8500, mean episode reward: -81.80855551073567, time: 24.979
agent0_energy_min, agent0_attention_min
[-47.84  -1.73]
agent1_energy_min, agent1_attention_min
[ -5.36 -42.93]
8600 50
steps: 429950, episodes: 8600, mean episode reward: -132.4069251324522, time: 25.235
agent0_energy_min, agent0_attention_min
[-44.95  -3.68]
agent1_energy_min, agent1_attention_min
[ -4.89 -43.52]
8700 50
steps: 434950, episodes: 8700, mean episode reward: -99.07518803897892, time: 24.729
agent0_energy_min, agent0_attention_min
[-45.64  -2.45]
agent1_energy_min, agent1_attention_min
[ -5.87 -43.6 ]
8800 50
steps: 439950, episodes: 8800, mean episode reward: -77.95317805639942, time: 24.893
agent0_energy_min, agent0_attention_min
[-47.09  -2.18]
agent1_energy_min, agent1_attention_min
[ -6.9  -42.48]
8900 50
steps: 444950, episodes: 8900, mean episode reward: -85.98181036970458, time: 24.468
agent0_energy_min, agent0_attention_min
[-48.35  -1.43]
agent1_energy_min, agent1_attention_min
[ -9.28 -39.62]
9000 50
steps: 449950, episodes: 9000, mean episode reward: -73.56745690996917, time: 23.873
agent0_energy_min, agent0_attention_min
[-48.05  -1.38]
agent1_energy_min, agent1_attention_min
[ -7.85 -40.74]
9100 50
steps: 454950, episodes: 9100, mean episode reward: -71.66964733333977, time: 24.509
agent0_energy_min, agent0_attention_min
[-47.97  -0.93]
agent1_energy_min, agent1_attention_min
[ -7.29 -41.15]
9200 50
steps: 459950, episodes: 9200, mean episode reward: -79.19268389655912, time: 24.123
agent0_energy_min, agent0_attention_min
[-47.15  -1.27]
agent1_energy_min, agent1_attention_min
[ -6.05 -41.99]
9300 50
steps: 464950, episodes: 9300, mean episode reward: -72.2800896074333, time: 24.67
agent0_energy_min, agent0_attention_min
[-48.66  -0.93]
agent1_energy_min, agent1_attention_min
[ -7.4  -41.61]
9400 50
steps: 469950, episodes: 9400, mean episode reward: -83.35659205592565, time: 24.686
agent0_energy_min, agent0_attention_min
[-47.33  -0.97]
agent1_energy_min, agent1_attention_min
[ -6.79 -42.33]
9500 50
steps: 474950, episodes: 9500, mean episode reward: -84.7254175951031, time: 24.357
agent0_energy_min, agent0_attention_min
[-46.55  -3.28]
agent1_energy_min, agent1_attention_min
[-12.   -37.48]
9600 50
steps: 479950, episodes: 9600, mean episode reward: -83.41297038317315, time: 25.102
agent0_energy_min, agent0_attention_min
[-47.97  -1.89]
agent1_energy_min, agent1_attention_min
[ -9.07 -39.56]
9700 50
steps: 484950, episodes: 9700, mean episode reward: -76.75697720541379, time: 23.962
agent0_energy_min, agent0_attention_min
[-47.95  -1.8 ]
agent1_energy_min, agent1_attention_min
[ -9.03 -39.41]
9800 50
steps: 489950, episodes: 9800, mean episode reward: -91.36132946059013, time: 24.187
agent0_energy_min, agent0_attention_min
[-45.92  -0.99]
agent1_energy_min, agent1_attention_min
[ -9.39 -40.14]
9900 50
steps: 494950, episodes: 9900, mean episode reward: -99.86463496654396, time: 24.824
agent0_energy_min, agent0_attention_min
[-48.4   -1.51]
agent1_energy_min, agent1_attention_min
[ -8.06 -41.54]
10000 50
steps: 499950, episodes: 10000, mean episode reward: -79.55053350653878, time: 23.852
agent0_energy_min, agent0_attention_min
[-48.62  -1.13]
agent1_energy_min, agent1_attention_min
[ -9.  -40.2]
10100 50
steps: 504950, episodes: 10100, mean episode reward: -81.72646906019611, time: 24.156
agent0_energy_min, agent0_attention_min
[-47.78  -1.05]
agent1_energy_min, agent1_attention_min
[-15.9  -33.46]
10200 50
steps: 509950, episodes: 10200, mean episode reward: -74.22591192827706, time: 24.434
agent0_energy_min, agent0_attention_min
[-47.62  -1.32]
agent1_energy_min, agent1_attention_min
[ -7.97 -41.35]
10300 50
steps: 514950, episodes: 10300, mean episode reward: -65.67253454025098, time: 24.457
agent0_energy_min, agent0_attention_min
[-49.35  -0.34]
agent1_energy_min, agent1_attention_min
[-13.54 -35.99]
10400 50
steps: 519950, episodes: 10400, mean episode reward: -78.17186954705643, time: 24.049
agent0_energy_min, agent0_attention_min
[-49.12  -0.46]
agent1_energy_min, agent1_attention_min
[ -6.2  -43.25]
10500 50
steps: 524950, episodes: 10500, mean episode reward: -87.1684294883493, time: 24.217
agent0_energy_min, agent0_attention_min
[-48.31  -1.63]
agent1_energy_min, agent1_attention_min
[ -6.23 -43.37]
10600 50
steps: 529950, episodes: 10600, mean episode reward: -84.24993547141585, time: 24.273
agent0_energy_min, agent0_attention_min
[-47.94  -1.86]
agent1_energy_min, agent1_attention_min
[-10.86 -38.65]
10700 50
steps: 534950, episodes: 10700, mean episode reward: -82.14583373673254, time: 24.149
agent0_energy_min, agent0_attention_min
[-49.26  -0.52]
agent1_energy_min, agent1_attention_min
[ -8.51 -40.91]
10800 50
steps: 539950, episodes: 10800, mean episode reward: -83.40401342436627, time: 24.191
agent0_energy_min, agent0_attention_min
[-48.86  -0.96]
agent1_energy_min, agent1_attention_min
[ -9.66 -39.36]
10900 50
steps: 544950, episodes: 10900, mean episode reward: -79.83877386054479, time: 24.048
agent0_energy_min, agent0_attention_min
[-49.28  -0.64]
agent1_energy_min, agent1_attention_min
[ -6.79 -42.82]
11000 50
steps: 549950, episodes: 11000, mean episode reward: -70.7312804289808, time: 23.793
agent0_energy_min, agent0_attention_min
[-49.46  -0.4 ]
agent1_energy_min, agent1_attention_min
[ -9.28 -40.45]
11100 50
steps: 554950, episodes: 11100, mean episode reward: -73.97107767191275, time: 24.974
agent0_energy_min, agent0_attention_min
[-48.95  -0.86]
agent1_energy_min, agent1_attention_min
[ -7.76 -41.78]
11200 50
steps: 559950, episodes: 11200, mean episode reward: -73.47035860431731, time: 23.389
agent0_energy_min, agent0_attention_min
[-48.6   -1.31]
agent1_energy_min, agent1_attention_min
[-12.5 -37.2]
11300 50
steps: 564950, episodes: 11300, mean episode reward: -71.87208300871717, time: 24.084
agent0_energy_min, agent0_attention_min
[-49.51  -0.36]
agent1_energy_min, agent1_attention_min
[ -9.04 -40.44]
11400 50
steps: 569950, episodes: 11400, mean episode reward: -87.9597867085632, time: 23.764
agent0_energy_min, agent0_attention_min
[-49.25  -0.58]
agent1_energy_min, agent1_attention_min
[ -9.89 -39.88]
11500 50
steps: 574950, episodes: 11500, mean episode reward: -73.62441568386511, time: 24.098
agent0_energy_min, agent0_attention_min
[-48.93  -0.62]
agent1_energy_min, agent1_attention_min
[ -5.65 -43.99]
11600 50
steps: 579950, episodes: 11600, mean episode reward: -70.96426952957016, time: 24.524
agent0_energy_min, agent0_attention_min
[-48.48  -0.84]
agent1_energy_min, agent1_attention_min
[ -8.4  -41.08]
11700 50
steps: 584950, episodes: 11700, mean episode reward: -75.52454867730178, time: 24.017
agent0_energy_min, agent0_attention_min
[-48.42  -0.92]
agent1_energy_min, agent1_attention_min
[ -9.26 -40.47]
11800 50
steps: 589950, episodes: 11800, mean episode reward: -71.26176008855465, time: 24.417
agent0_energy_min, agent0_attention_min
[-48.7  -0.5]
agent1_energy_min, agent1_attention_min
[ -8.91 -40.84]
11900 50
steps: 594950, episodes: 11900, mean episode reward: -86.37655480403755, time: 24.067
agent0_energy_min, agent0_attention_min
[-48.73  -0.8 ]
agent1_energy_min, agent1_attention_min
[ -8.95 -40.29]
12000 50
steps: 599950, episodes: 12000, mean episode reward: -83.4815438928829, time: 24.276
agent0_energy_min, agent0_attention_min
[-0.16 -0.1 ]
agent1_energy_min, agent1_attention_min
[-41.01  -0.2 ]
8100 50
steps: 404950, episodes: 8100, mean episode reward: -133.83287656673838, time: 25.318
agent0_energy_min, agent0_attention_min
[-1.34 -0.04]
agent1_energy_min, agent1_attention_min
[-4.151e+01 -3.000e-02]
8200 50
steps: 409950, episodes: 8200, mean episode reward: -143.03530767116305, time: 24.921
agent0_energy_min, agent0_attention_min
[-0.07 -0.06]
agent1_energy_min, agent1_attention_min
[-3.915e+01 -3.000e-02]
8300 50
steps: 414950, episodes: 8300, mean episode reward: -124.67177509968336, time: 25.485
agent0_energy_min, agent0_attention_min
[-0.22 -0.02]
agent1_energy_min, agent1_attention_min
[-4.31e+01 -3.00e-02]
8400 50
steps: 419950, episodes: 8400, mean episode reward: -116.62017208108219, time: 25.035
agent0_energy_min, agent0_attention_min
[-1.47 -0.12]
agent1_energy_min, agent1_attention_min
[-4.543e+01 -2.000e-02]
8500 50
steps: 424950, episodes: 8500, mean episode reward: -114.57753400918878, time: 25.05
agent0_energy_min, agent0_attention_min
[-1.32 -0.09]
agent1_energy_min, agent1_attention_min
[-4.607e+01 -1.000e-02]
8600 50
steps: 429950, episodes: 8600, mean episode reward: -116.09209876754602, time: 25.837
agent0_energy_min, agent0_attention_min
[-0.18 -0.01]
agent1_energy_min, agent1_attention_min
[-4.373e+01 -4.000e-02]
8700 50
steps: 434950, episodes: 8700, mean episode reward: -124.78179164234102, time: 25.23
agent0_energy_min, agent0_attention_min
[-0.73 -0.22]
agent1_energy_min, agent1_attention_min
[-4.267e+01 -3.000e-02]
8800 50
steps: 439950, episodes: 8800, mean episode reward: -130.64289553887377, time: 24.882
agent0_energy_min, agent0_attention_min
[-1.97 -0.29]
agent1_energy_min, agent1_attention_min
[-4.47e+01 -1.00e-02]
8900 50
steps: 444950, episodes: 8900, mean episode reward: -134.8482955447269, time: 25.094
agent0_energy_min, agent0_attention_min
[-1.33 -0.05]
agent1_energy_min, agent1_attention_min
[-4.384e+01 -4.000e-02]
9000 50
steps: 449950, episodes: 9000, mean episode reward: -128.7838144378117, time: 25.104
agent0_energy_min, agent0_attention_min
[-1.16 -0.1 ]
agent1_energy_min, agent1_attention_min
[-4.226e+01 -4.000e-02]
9100 50
steps: 454950, episodes: 9100, mean episode reward: -110.32572475980342, time: 25.319
agent0_energy_min, agent0_attention_min
[-0.32 -0.1 ]
agent1_energy_min, agent1_attention_min
[-4.516e+01 -2.000e-02]
9200 50
steps: 459950, episodes: 9200, mean episode reward: -104.22176794395946, time: 24.987
agent0_energy_min, agent0_attention_min
[-1.55 -0.05]
agent1_energy_min, agent1_attention_min
[-4.686e+01 -4.000e-02]
9300 50
steps: 464950, episodes: 9300, mean episode reward: -103.49145176749282, time: 25.224
agent0_energy_min, agent0_attention_min
[-1.24 -0.18]
agent1_energy_min, agent1_attention_min
[-4.685e+01 -1.000e-02]
9400 50
steps: 469950, episodes: 9400, mean episode reward: -113.08814862407458, time: 24.953
agent0_energy_min, agent0_attention_min
[-1.94 -0.07]
agent1_energy_min, agent1_attention_min
[-4.446e+01 -2.000e-02]
9500 50
steps: 474950, episodes: 9500, mean episode reward: -107.9044183576002, time: 27.133
agent0_energy_min, agent0_attention_min
[-2.28 -0.12]
agent1_energy_min, agent1_attention_min
[-4.621e+01 -3.000e-02]
9600 50
steps: 479950, episodes: 9600, mean episode reward: -97.8554539526005, time: 25.585
agent0_energy_min, agent0_attention_min
[-1.89 -0.06]
agent1_energy_min, agent1_attention_min
[-46.84   0.  ]
9700 50
steps: 484950, episodes: 9700, mean episode reward: -130.89152162394606, time: 24.996
agent0_energy_min, agent0_attention_min
[-17.28  -0.42]
agent1_energy_min, agent1_attention_min
[-4.561e+01 -2.000e-02]
9800 50
steps: 489950, episodes: 9800, mean episode reward: -127.38559991293117, time: 25.448
agent0_energy_min, agent0_attention_min
[-1.24 -0.1 ]
agent1_energy_min, agent1_attention_min
[-46.65   0.  ]
9900 50
steps: 494950, episodes: 9900, mean episode reward: -115.3374914264552, time: 25.029
agent0_energy_min, agent0_attention_min
[-1.56 -0.01]
agent1_energy_min, agent1_attention_min
[-4.657e+01 -2.000e-02]
10000 50
steps: 499950, episodes: 10000, mean episode reward: -103.1919137282825, time: 24.462
agent0_energy_min, agent0_attention_min
[-1.11 -0.05]
agent1_energy_min, agent1_attention_min
[-4.728e+01 -2.000e-02]
10100 50
steps: 504950, episodes: 10100, mean episode reward: -106.35638463559525, time: 26.882
agent0_energy_min, agent0_attention_min
[-4.48 -0.18]
agent1_energy_min, agent1_attention_min
[-47.64  -0.06]
10200 50
steps: 509950, episodes: 10200, mean episode reward: -99.42471254434291, time: 25.399
agent0_energy_min, agent0_attention_min
[-5.3  -0.27]
agent1_energy_min, agent1_attention_min
[-4.763e+01 -1.000e-02]
10300 50
steps: 514950, episodes: 10300, mean episode reward: -103.66574406806507, time: 25.096
agent0_energy_min, agent0_attention_min
[-28.25  -0.2 ]
agent1_energy_min, agent1_attention_min
[-47.58   0.  ]
10400 50
steps: 519950, episodes: 10400, mean episode reward: -233.7099789736632, time: 24.674
agent0_energy_min, agent0_attention_min
[-26.23 -15.37]
agent1_energy_min, agent1_attention_min
[-4.769e+01 -1.000e-02]
10500 50
steps: 524950, episodes: 10500, mean episode reward: -109.32860184244315, time: 24.846
agent0_energy_min, agent0_attention_min
[-26.98  -2.85]
agent1_energy_min, agent1_attention_min
[-4.824e+01 -3.000e-02]
10600 50
steps: 529950, episodes: 10600, mean episode reward: -105.65949792289217, time: 25.644
agent0_energy_min, agent0_attention_min
[-33.58  -4.71]
agent1_energy_min, agent1_attention_min
[-4.861e+01 -2.000e-02]
10700 50
steps: 534950, episodes: 10700, mean episode reward: -116.95638842943538, time: 24.823
agent0_energy_min, agent0_attention_min
[-40.08  -1.99]
agent1_energy_min, agent1_attention_min
[-48.33   0.  ]
10800 50
steps: 539950, episodes: 10800, mean episode reward: -99.62447328901607, time: 24.884
agent0_energy_min, agent0_attention_min
[-13.43  -0.55]
agent1_energy_min, agent1_attention_min
[-4.903e+01 -1.000e-02]
10900 50
steps: 544950, episodes: 10900, mean episode reward: -98.45794899638949, time: 24.59
agent0_energy_min, agent0_attention_min
[-41.59  -2.42]
agent1_energy_min, agent1_attention_min
[-4.919e+01 -1.000e-02]
11000 50
steps: 549950, episodes: 11000, mean episode reward: -99.40305645501927, time: 25.531
agent0_energy_min, agent0_attention_min
[-12.95  -0.38]
agent1_energy_min, agent1_attention_min
[-4.929e+01 -2.000e-02]
11100 50
steps: 554950, episodes: 11100, mean episode reward: -103.6151701715338, time: 25.405
agent0_energy_min, agent0_attention_min
[-0.7 -0.1]
agent1_energy_min, agent1_attention_min
[-4.933e+01 -2.000e-02]
11200 50
steps: 559950, episodes: 11200, mean episode reward: -185.25896292349887, time: 25.416
agent0_energy_min, agent0_attention_min
[-1.57 -0.1 ]
agent1_energy_min, agent1_attention_min
[-4.828e+01 -2.000e-02]
11300 50
steps: 564950, episodes: 11300, mean episode reward: -149.4585081889817, time: 25.129
agent0_energy_min, agent0_attention_min
[-12.03  -0.67]
agent1_energy_min, agent1_attention_min
[-48.84   0.  ]
11400 50
steps: 569950, episodes: 11400, mean episode reward: -127.01791491246625, time: 24.733
agent0_energy_min, agent0_attention_min
[-36.54  -0.25]
agent1_energy_min, agent1_attention_min
[-49.03   0.  ]
11500 50
steps: 574950, episodes: 11500, mean episode reward: -99.5300274040548, time: 25.003
agent0_energy_min, agent0_attention_min
[-38.17  -0.44]
agent1_energy_min, agent1_attention_min
[-48.82   0.  ]
11600 50
steps: 579950, episodes: 11600, mean episode reward: -94.07395387451088, time: 25.306
agent0_energy_min, agent0_attention_min
[-41.99  -0.36]
agent1_energy_min, agent1_attention_min
[-4.889e+01 -1.000e-02]
11700 50
steps: 584950, episodes: 11700, mean episode reward: -109.74270410692036, time: 24.809
agent0_energy_min, agent0_attention_min
[-36.07  -0.29]
agent1_energy_min, agent1_attention_min
[-4.628e+01 -4.000e-02]
11800 50
steps: 589950, episodes: 11800, mean episode reward: -91.79672008258926, time: 24.904
agent0_energy_min, agent0_attention_min
[-34.97  -0.12]
agent1_energy_min, agent1_attention_min
[-4.76e+01 -2.00e-02]
11900 50
steps: 594950, episodes: 11900, mean episode reward: -143.44281926804007, time: 25.429
agent0_energy_min, agent0_attention_min
[-39.19  -0.06]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
8100 50
steps: 404950, episodes: 8100, mean episode reward: -111.79355198378101, time: 25.277
agent0_energy_min, agent0_attention_min
[-3.82e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-0.02 -0.01]
8200 50
steps: 409950, episodes: 8200, mean episode reward: -109.6336092362667, time: 25.535
agent0_energy_min, agent0_attention_min
[-3.755e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.03]
8300 50
steps: 414950, episodes: 8300, mean episode reward: -113.48489731804467, time: 25.313
agent0_energy_min, agent0_attention_min
[-38.64   0.  ]
agent1_energy_min, agent1_attention_min
[-0.02  0.  ]
8400 50
steps: 419950, episodes: 8400, mean episode reward: -109.63987507169233, time: 25.4
agent0_energy_min, agent0_attention_min
[-4.07e+01 -2.00e-02]
agent1_energy_min, agent1_attention_min
[-0.03  0.  ]
8500 50
steps: 424950, episodes: 8500, mean episode reward: -100.82053572717696, time: 25.703
agent0_energy_min, agent0_attention_min
[-3.844e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.06  0.  ]
8600 50
steps: 429950, episodes: 8600, mean episode reward: -114.30490605269839, time: 25.661
agent0_energy_min, agent0_attention_min
[-4.028e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.1  -0.03]
8700 50
steps: 434950, episodes: 8700, mean episode reward: -114.94896692319335, time: 25.107
agent0_energy_min, agent0_attention_min
[-37.43  -0.08]
agent1_energy_min, agent1_attention_min
[-0.04 -0.03]
8800 50
steps: 439950, episodes: 8800, mean episode reward: -110.83533949020826, time: 25.407
agent0_energy_min, agent0_attention_min
[-3.98e+01 -1.00e-02]
agent1_energy_min, agent1_attention_min
[-0.06 -0.01]
8900 50
steps: 444950, episodes: 8900, mean episode reward: -119.38379177317329, time: 25.04
agent0_energy_min, agent0_attention_min
[-3.878e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.1  -0.04]
9000 50
steps: 449950, episodes: 9000, mean episode reward: -108.69187617252796, time: 24.795
agent0_energy_min, agent0_attention_min
[-3.744e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.07 -0.01]
9100 50
steps: 454950, episodes: 9100, mean episode reward: -106.9493282138323, time: 25.447
agent0_energy_min, agent0_attention_min
[-3.8e+01 -2.0e-02]
agent1_energy_min, agent1_attention_min
[-0.04 -0.02]
9200 50
steps: 459950, episodes: 9200, mean episode reward: -106.7716343825107, time: 25.156
agent0_energy_min, agent0_attention_min
[-3.95e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-0.04  0.  ]
9300 50
steps: 464950, episodes: 9300, mean episode reward: -95.66993663927752, time: 25.752
agent0_energy_min, agent0_attention_min
[-4.09e+01 -2.00e-02]
agent1_energy_min, agent1_attention_min
[0. 0.]
9400 50
steps: 469950, episodes: 9400, mean episode reward: -104.67501388763411, time: 25.038
agent0_energy_min, agent0_attention_min
[-3.709e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
9500 50
steps: 474950, episodes: 9500, mean episode reward: -119.36737403887574, time: 24.765
agent0_energy_min, agent0_attention_min
[-3.94e+01 -1.00e-02]
agent1_energy_min, agent1_attention_min
[0. 0.]
9600 50
steps: 479950, episodes: 9600, mean episode reward: -100.64036718730424, time: 26.123
agent0_energy_min, agent0_attention_min
[-3.773e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[0. 0.]
9700 50
steps: 484950, episodes: 9700, mean episode reward: -98.99788834902724, time: 25.383
agent0_energy_min, agent0_attention_min
[-39.16  -0.07]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
9800 50
steps: 489950, episodes: 9800, mean episode reward: -115.31289082138747, time: 25.717
agent0_energy_min, agent0_attention_min
[-37.14  -0.04]
agent1_energy_min, agent1_attention_min
[-0.03  0.  ]
9900 50
steps: 494950, episodes: 9900, mean episode reward: -107.65646838301178, time: 25.267
agent0_energy_min, agent0_attention_min
[-39.88  -0.04]
agent1_energy_min, agent1_attention_min
[-0.01 -0.03]
10000 50
steps: 499950, episodes: 10000, mean episode reward: -100.4815253290901, time: 25.004
agent0_energy_min, agent0_attention_min
[-3.666e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
10100 50
steps: 504950, episodes: 10100, mean episode reward: -115.6407115631922, time: 26.154
agent0_energy_min, agent0_attention_min
[-3.947e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.46 -0.01]
10200 50
steps: 509950, episodes: 10200, mean episode reward: -101.20180678499909, time: 25.509
agent0_energy_min, agent0_attention_min
[-34.95  -0.04]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
10300 50
steps: 514950, episodes: 10300, mean episode reward: -108.09038736189484, time: 25.176
agent0_energy_min, agent0_attention_min
[-3.852e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
10400 50
steps: 519950, episodes: 10400, mean episode reward: -96.65586397151623, time: 25.503
agent0_energy_min, agent0_attention_min
[-4.118e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.03]
10500 50
steps: 524950, episodes: 10500, mean episode reward: -100.6308579201252, time: 24.94
agent0_energy_min, agent0_attention_min
[-43.17   0.  ]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
10600 50
steps: 529950, episodes: 10600, mean episode reward: -106.25070449950812, time: 26.246
agent0_energy_min, agent0_attention_min
[-39.93   0.  ]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
10700 50
steps: 534950, episodes: 10700, mean episode reward: -109.51690277484191, time: 24.989
agent0_energy_min, agent0_attention_min
[-38.91  -0.05]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
10800 50
steps: 539950, episodes: 10800, mean episode reward: -104.02638541338897, time: 25.761
agent0_energy_min, agent0_attention_min
[-4.049e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.11 -0.02]
10900 50
steps: 544950, episodes: 10900, mean episode reward: -97.61781265340915, time: 25.144
agent0_energy_min, agent0_attention_min
[-3.788e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
11000 50
steps: 549950, episodes: 11000, mean episode reward: -108.43282105230854, time: 25.015
agent0_energy_min, agent0_attention_min
[-39.92  -0.09]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
11100 50
steps: 554950, episodes: 11100, mean episode reward: -107.51987176531755, time: 25.635
agent0_energy_min, agent0_attention_min
[-3.859e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
11200 50
steps: 559950, episodes: 11200, mean episode reward: -95.33958561597484, time: 24.768
agent0_energy_min, agent0_attention_min
[-3.656e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.02]
11300 50
steps: 564950, episodes: 11300, mean episode reward: -101.01822103308842, time: 24.643
agent0_energy_min, agent0_attention_min
[-39.    -0.09]
agent1_energy_min, agent1_attention_min
[-0.03 -0.02]
11400 50
steps: 569950, episodes: 11400, mean episode reward: -108.64566788351607, time: 24.758
agent0_energy_min, agent0_attention_min
[-3.668e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
11500 50
steps: 574950, episodes: 11500, mean episode reward: -87.77090507034563, time: 25.394
agent0_energy_min, agent0_attention_min
[-35.17  -0.05]
agent1_energy_min, agent1_attention_min
[-0.02  0.  ]
11600 50
steps: 579950, episodes: 11600, mean episode reward: -103.1689190195163, time: 25.696
agent0_energy_min, agent0_attention_min
[-3.618e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.02  0.  ]
11700 50
steps: 584950, episodes: 11700, mean episode reward: -108.78444651814293, time: 25.059
agent0_energy_min, agent0_attention_min
[-3.826e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
11800 50
steps: 589950, episodes: 11800, mean episode reward: -103.77123067962252, time: 24.76
agent0_energy_min, agent0_attention_min
[-3.964e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
11900 50
steps: 594950, episodes: 11900, mean episode reward: -99.4805152543385, time: 24.878
agent0_energy_min, agent0_attention_min
[-35.72   0.  ]
agent0_energy_min, agent0_attention_min
[-0.19 -0.01]
agent1_energy_min, agent1_attention_min
[-1.56  0.  ]
8200 50
steps: 409950, episodes: 8200, mean episode reward: -135.94743472991985, time: 24.728
agent0_energy_min, agent0_attention_min
[-0.43 -0.01]
agent1_energy_min, agent1_attention_min
[-0.05 -0.01]
8300 50
steps: 414950, episodes: 8300, mean episode reward: -129.24888945500797, time: 25.297
agent0_energy_min, agent0_attention_min
[-0.25  0.  ]
agent1_energy_min, agent1_attention_min
[-1.71  0.  ]
8400 50
steps: 419950, episodes: 8400, mean episode reward: -131.86444789365873, time: 25.17
agent0_energy_min, agent0_attention_min
[-1.61  0.  ]
agent1_energy_min, agent1_attention_min
[-1.44 -0.03]
8500 50
steps: 424950, episodes: 8500, mean episode reward: -130.84045520043907, time: 25.29
agent0_energy_min, agent0_attention_min
[-0.73 -0.03]
agent1_energy_min, agent1_attention_min
[-3.3  -0.01]
8600 50
steps: 429950, episodes: 8600, mean episode reward: -135.56949117062086, time: 25.771
agent0_energy_min, agent0_attention_min
[-5.27 -0.46]
agent1_energy_min, agent1_attention_min
[-0.1  -0.02]
8700 50
steps: 434950, episodes: 8700, mean episode reward: -140.5099694513374, time: 25.117
agent0_energy_min, agent0_attention_min
[-1.83 -0.65]
agent1_energy_min, agent1_attention_min
[-2.11 -0.17]
8800 50
steps: 439950, episodes: 8800, mean episode reward: -125.14733440375687, time: 25.232
agent0_energy_min, agent0_attention_min
[-0.76 -0.01]
agent1_energy_min, agent1_attention_min
[-0.03 -0.01]
8900 50
steps: 444950, episodes: 8900, mean episode reward: -127.51718789367719, time: 25.408
agent0_energy_min, agent0_attention_min
[-1.17 -0.04]
agent1_energy_min, agent1_attention_min
[-2.67 -0.32]
9000 50
steps: 449950, episodes: 9000, mean episode reward: -147.06014918681763, time: 25.218
agent0_energy_min, agent0_attention_min
[-0.54 -0.01]
agent1_energy_min, agent1_attention_min
[-2.3  -0.15]
9100 50
steps: 454950, episodes: 9100, mean episode reward: -133.1869833721421, time: 25.426
agent0_energy_min, agent0_attention_min
[-0.1  0. ]
agent1_energy_min, agent1_attention_min
[-0.03 -0.01]
9200 50
steps: 459950, episodes: 9200, mean episode reward: -121.2199950419314, time: 25.086
agent0_energy_min, agent0_attention_min
[-4.75 -0.02]
agent1_energy_min, agent1_attention_min
[-0.38 -0.07]
9300 50
steps: 464950, episodes: 9300, mean episode reward: -131.80952918715465, time: 25.227
agent0_energy_min, agent0_attention_min
[-1.1  -0.01]
agent1_energy_min, agent1_attention_min
[-0.02  0.  ]
9400 50
steps: 469950, episodes: 9400, mean episode reward: -133.547957275015, time: 25.125
agent0_energy_min, agent0_attention_min
[-0.04 -0.02]
agent1_energy_min, agent1_attention_min
[-0.2  -0.11]
9500 50
steps: 474950, episodes: 9500, mean episode reward: -123.93805633718665, time: 24.993
agent0_energy_min, agent0_attention_min
[-0.3  0. ]
agent1_energy_min, agent1_attention_min
[-0.62 -0.02]
9600 50
steps: 479950, episodes: 9600, mean episode reward: -133.87755760360108, time: 25.688
agent0_energy_min, agent0_attention_min
[-0.46  0.  ]
agent1_energy_min, agent1_attention_min
[-1.71 -0.02]
9700 50
steps: 484950, episodes: 9700, mean episode reward: -122.36004134799326, time: 25.712
agent0_energy_min, agent0_attention_min
[-0.71  0.  ]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
9800 50
steps: 489950, episodes: 9800, mean episode reward: -135.1061816464968, time: 25.849
agent0_energy_min, agent0_attention_min
[-0.72 -0.01]
agent1_energy_min, agent1_attention_min
[-0.68 -0.04]
9900 50
steps: 494950, episodes: 9900, mean episode reward: -119.26125866380573, time: 25.474
agent0_energy_min, agent0_attention_min
[-4.166e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.66 -0.01]
10000 50
steps: 499950, episodes: 10000, mean episode reward: -146.30477947241684, time: 24.649
agent0_energy_min, agent0_attention_min
[-45.9   -0.06]
agent1_energy_min, agent1_attention_min
[-0.08 -0.01]
10100 50
steps: 504950, episodes: 10100, mean episode reward: -144.99948206291555, time: 25.653
agent0_energy_min, agent0_attention_min
[-4.666e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-1.297e+01 -1.000e-02]
10200 50
steps: 509950, episodes: 10200, mean episode reward: -113.19881630945967, time: 25.116
agent0_energy_min, agent0_attention_min
[-46.4   0. ]
agent1_energy_min, agent1_attention_min
[-0.37 -0.01]
10300 50
steps: 514950, episodes: 10300, mean episode reward: -120.9979453406205, time: 25.213
agent0_energy_min, agent0_attention_min
[-4.624e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.21 -0.01]
10400 50
steps: 519950, episodes: 10400, mean episode reward: -121.5814494264898, time: 25.541
agent0_energy_min, agent0_attention_min
[-38.9   -0.07]
agent1_energy_min, agent1_attention_min
[-0.66 -0.01]
10500 50
steps: 524950, episodes: 10500, mean episode reward: -177.24490540734058, time: 25.453
agent0_energy_min, agent0_attention_min
[-45.19  -0.06]
agent1_energy_min, agent1_attention_min
[-0.37 -0.01]
10600 50
steps: 529950, episodes: 10600, mean episode reward: -140.10870388087352, time: 25.419
agent0_energy_min, agent0_attention_min
[-45.15  -0.3 ]
agent1_energy_min, agent1_attention_min
[-3.19 -0.06]
10700 50
steps: 534950, episodes: 10700, mean episode reward: -134.28003649379085, time: 25.367
agent0_energy_min, agent0_attention_min
[-19.68  -0.09]
agent1_energy_min, agent1_attention_min
[-0.01 -0.06]
10800 50
steps: 539950, episodes: 10800, mean episode reward: -143.05170476645796, time: 25.501
agent0_energy_min, agent0_attention_min
[-1.39 -0.01]
agent1_energy_min, agent1_attention_min
[-0.14 -0.01]
10900 50
steps: 544950, episodes: 10900, mean episode reward: -123.49280836079355, time: 24.605
agent0_energy_min, agent0_attention_min
[-2.41 -0.07]
agent1_energy_min, agent1_attention_min
[-0.26 -0.03]
11000 50
steps: 549950, episodes: 11000, mean episode reward: -136.65159208423867, time: 25.4
agent0_energy_min, agent0_attention_min
[-0.35 -0.01]
agent1_energy_min, agent1_attention_min
[ 0.   -0.03]
11100 50
steps: 554950, episodes: 11100, mean episode reward: -141.06608789291656, time: 26.207
agent0_energy_min, agent0_attention_min
[-0.13  0.  ]
agent1_energy_min, agent1_attention_min
[-2.63 -0.01]
11200 50
steps: 559950, episodes: 11200, mean episode reward: -125.87766650564832, time: 24.627
agent0_energy_min, agent0_attention_min
[-0.01  0.  ]
agent1_energy_min, agent1_attention_min
[-0.94  0.  ]
11300 50
steps: 564950, episodes: 11300, mean episode reward: -138.1457912799904, time: 24.982
agent0_energy_min, agent0_attention_min
[-7.39  0.  ]
agent1_energy_min, agent1_attention_min
[-1.27  0.  ]
11400 50
steps: 569950, episodes: 11400, mean episode reward: -131.93527218470078, time: 24.525
agent0_energy_min, agent0_attention_min
[-8.18  0.  ]
agent1_energy_min, agent1_attention_min
[-0.59  0.  ]
11500 50
steps: 574950, episodes: 11500, mean episode reward: -123.63926280325796, time: 25.187
agent0_energy_min, agent0_attention_min
[-0.85 -0.01]
agent1_energy_min, agent1_attention_min
[-3.46 -0.02]
11600 50
steps: 579950, episodes: 11600, mean episode reward: -120.02176602968913, time: 26.133
agent0_energy_min, agent0_attention_min
[-16.21  -0.02]
agent1_energy_min, agent1_attention_min
[-2.08 -0.01]
11700 50
steps: 584950, episodes: 11700, mean episode reward: -131.6177961801476, time: 25.141
agent0_energy_min, agent0_attention_min
[-5.98 -0.01]
agent1_energy_min, agent1_attention_min
[-1.19  0.  ]
11800 50
steps: 589950, episodes: 11800, mean episode reward: -130.6305911722108, time: 25.364
agent0_energy_min, agent0_attention_min
[-5.87  0.  ]
agent1_energy_min, agent1_attention_min
[-21.65  -0.13]
11900 50
steps: 594950, episodes: 11900, mean episode reward: -141.38197859118037, time: 25.091
agent0_energy_min, agent0_attention_min
[-4.56 -0.01]
agent1_energy_min, agent1_attention_min
[-37.57  -0.05]
12000 50
steps: 599950, episodes: 12000, mean episode reward: -135.35958445455051, time: 24.521
agent0_energy_min, agent0_attention_min
[-3.96  0.  ]
agent1_energy_min, agent1_attention_min
[-30.61  -0.06]
12100 50
steps: 604950, episodes: 12100, mean episode reward: -144.29364715749668, time: 25.469
agent0_energy_min, agent0_attention_min
agent0_energy_min, agent0_attention_min
[-46.69  -0.64]
agent1_energy_min, agent1_attention_min
[-48.44  -0.82]
12000 50
steps: 599950, episodes: 12000, mean episode reward: -48.877383912157576, time: 24.825
agent0_energy_min, agent0_attention_min
[-48.35  -0.35]
agent1_energy_min, agent1_attention_min
[-48.88  -0.66]
12100 50
steps: 604950, episodes: 12100, mean episode reward: -43.77416250583449, time: 25.182
agent0_energy_min, agent0_attention_min
[-48.8   -0.43]
agent1_energy_min, agent1_attention_min
[-49.26  -0.46]
12200 50
steps: 609950, episodes: 12200, mean episode reward: -60.73519900077742, time: 24.876
agent0_energy_min, agent0_attention_min
[-48.95  -0.42]
agent1_energy_min, agent1_attention_min
[-49.65  -0.23]
12300 50
steps: 614950, episodes: 12300, mean episode reward: -51.68339593222978, time: 24.271
agent0_energy_min, agent0_attention_min
[-49.02  -0.46]
agent1_energy_min, agent1_attention_min
[-48.09  -0.42]
12400 50
steps: 619950, episodes: 12400, mean episode reward: -50.00349105792325, time: 24.655
agent0_energy_min, agent0_attention_min
[-49.56  -0.08]
agent1_energy_min, agent1_attention_min
[-48.74  -1.05]
12500 50
steps: 624950, episodes: 12500, mean episode reward: -38.74225301446379, time: 24.282
agent0_energy_min, agent0_attention_min
[-4.955e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-48.11  -0.62]
12600 50
steps: 629950, episodes: 12600, mean episode reward: -51.66577607573299, time: 24.525
agent0_energy_min, agent0_attention_min
[-49.13  -0.08]
agent1_energy_min, agent1_attention_min
[-48.7   -0.34]
12700 50
steps: 634950, episodes: 12700, mean episode reward: -47.34866668191018, time: 24.243
agent0_energy_min, agent0_attention_min
[-48.19  -0.22]
agent1_energy_min, agent1_attention_min
[-48.19  -0.44]
12800 50
steps: 639950, episodes: 12800, mean episode reward: -47.351042229876775, time: 24.481
agent0_energy_min, agent0_attention_min
[-48.33  -0.17]
agent1_energy_min, agent1_attention_min
[-47.13  -0.71]
12900 50
steps: 644950, episodes: 12900, mean episode reward: -57.97856195408863, time: 24.524
agent0_energy_min, agent0_attention_min
[-48.78  -0.12]
agent1_energy_min, agent1_attention_min
[-47.29  -0.85]
13000 50
steps: 649950, episodes: 13000, mean episode reward: -40.46400132414883, time: 24.556
agent0_energy_min, agent0_attention_min
[-48.38  -0.1 ]
agent1_energy_min, agent1_attention_min
[-47.72  -1.5 ]
13100 50
steps: 654950, episodes: 13100, mean episode reward: -55.70822749925236, time: 24.934
agent0_energy_min, agent0_attention_min
[-4.892e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-48.01  -1.42]
13200 50
steps: 659950, episodes: 13200, mean episode reward: -57.88504455687831, time: 24.308
agent0_energy_min, agent0_attention_min
[-49.07  -0.06]
agent1_energy_min, agent1_attention_min
[-48.03  -0.7 ]
13300 50
steps: 664950, episodes: 13300, mean episode reward: -82.58264010534302, time: 24.853
agent0_energy_min, agent0_attention_min
[-4.948e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-46.75  -2.55]
13400 50
steps: 669950, episodes: 13400, mean episode reward: -47.66939351128715, time: 25.04
agent0_energy_min, agent0_attention_min
[-4.925e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-40.78  -7.34]
13500 50
steps: 674950, episodes: 13500, mean episode reward: -43.538351176774405, time: 24.116
agent0_energy_min, agent0_attention_min
[-4.888e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-37.04 -10.54]
13600 50
steps: 679950, episodes: 13600, mean episode reward: -53.604113729281806, time: 25.441
agent0_energy_min, agent0_attention_min
[-4.93e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-41.69  -6.78]
13700 50
steps: 684950, episodes: 13700, mean episode reward: -58.26559359904576, time: 24.579
agent0_energy_min, agent0_attention_min
[-4.867e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-39.43  -8.97]
13800 50
steps: 689950, episodes: 13800, mean episode reward: -43.1184356951468, time: 24.123
agent0_energy_min, agent0_attention_min
[-4.887e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-41.2   -6.87]
13900 50
steps: 694950, episodes: 13900, mean episode reward: -49.55301394911589, time: 25.01
agent0_energy_min, agent0_attention_min
[-4.925e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-42.13  -6.28]
14000 50
steps: 699950, episodes: 14000, mean episode reward: -51.84727439420109, time: 24.608
agent0_energy_min, agent0_attention_min
[-4.868e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-35.78 -12.48]
14100 50
steps: 704950, episodes: 14100, mean episode reward: -46.541884653237275, time: 25.246
agent0_energy_min, agent0_attention_min
[-4.934e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-37.95  -9.89]
14200 50
steps: 709950, episodes: 14200, mean episode reward: -49.79064476991234, time: 24.319
agent0_energy_min, agent0_attention_min
[-4.92e+01 -2.00e-02]
agent1_energy_min, agent1_attention_min
[-43.27  -4.73]
14300 50
steps: 714950, episodes: 14300, mean episode reward: -72.90991618327813, time: 24.281
agent0_energy_min, agent0_attention_min
[-4.93e+01 -2.00e-02]
agent1_energy_min, agent1_attention_min
[-41.98  -5.42]
14400 50
steps: 719950, episodes: 14400, mean episode reward: -61.13597496058888, time: 24.372
agent0_energy_min, agent0_attention_min
[-4.956e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-45.5   -2.35]
14500 50
steps: 724950, episodes: 14500, mean episode reward: -60.63982455972249, time: 24.887
agent0_energy_min, agent0_attention_min
[-4.87e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-46.47  -1.6 ]
14600 50
steps: 729950, episodes: 14600, mean episode reward: -73.51160649653059, time: 24.995
agent0_energy_min, agent0_attention_min
[-4.261e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-46.3   -2.21]
14700 50
steps: 734950, episodes: 14700, mean episode reward: -61.10606786503327, time: 24.903
agent0_energy_min, agent0_attention_min
[-42.49  -0.06]
agent1_energy_min, agent1_attention_min
[-42.1   -5.93]
14800 50
steps: 739950, episodes: 14800, mean episode reward: -52.20225077096645, time: 25.231
agent0_energy_min, agent0_attention_min
[-4.578e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-41.6   -5.97]
14900 50
steps: 744950, episodes: 14900, mean episode reward: -95.86060491236918, time: 24.173
agent0_energy_min, agent0_attention_min
[-44.15  -0.1 ]
agent1_energy_min, agent1_attention_min
[-37.78  -8.76]
15000 50
steps: 749950, episodes: 15000, mean episode reward: -60.58164796441524, time: 24.573
agent0_energy_min, agent0_attention_min
[-41.09  -0.3 ]
agent1_energy_min, agent1_attention_min
[-39.57  -8.44]
15100 50
steps: 754950, episodes: 15100, mean episode reward: -50.56331213173875, time: 25.03
agent0_energy_min, agent0_attention_min
[-45.76  -0.24]
agent1_energy_min, agent1_attention_min
[-40.86  -8.2 ]
15200 50
steps: 759950, episodes: 15200, mean episode reward: -46.69106242888614, time: 24.163
agent0_energy_min, agent0_attention_min
[-43.7   -0.37]
agent1_energy_min, agent1_attention_min
[-45.35  -2.5 ]
15300 50
steps: 764950, episodes: 15300, mean episode reward: -46.98376472212722, time: 25.113
agent0_energy_min, agent0_attention_min
[-42.25  -3.02]
agent1_energy_min, agent1_attention_min
[-38.28  -2.49]
15400 50
steps: 769950, episodes: 15400, mean episode reward: -49.54151146800938, time: 24.87
agent0_energy_min, agent0_attention_min
[-43.74  -0.67]
agent1_energy_min, agent1_attention_min
[-37.94  -0.69]
15500 50
steps: 774950, episodes: 15500, mean episode reward: -45.01595764661185, time: 24.771
agent0_energy_min, agent0_attention_min
[-45.17  -0.25]
agent1_energy_min, agent1_attention_min
[-36.43  -1.07]
15600 50
steps: 779950, episodes: 15600, mean episode reward: -44.271559337826965, time: 24.837
agent0_energy_min, agent0_attention_min
[-4.562e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-39.59  -1.59]
15700 50
steps: 784950, episodes: 15700, mean episode reward: -54.48172239103853, time: 25.024
agent0_energy_min, agent0_attention_min
[-47.57  -0.12]
agent1_energy_min, agent1_attention_min
[-45.3   -2.59]
15800 50
steps: 789950, episodes: 15800, mean episode reward: -52.66925967906368, time: 24.868
agent0_energy_min, agent0_attention_min
[-49.65  -0.29]
agent1_energy_min, agent1_attention_min
[-47.23  -1.43]
12100 50
steps: 604950, episodes: 12100, mean episode reward: -61.15510547059015, time: 25.408
agent0_energy_min, agent0_attention_min
[-49.08  -0.4 ]
agent1_energy_min, agent1_attention_min
[-47.46  -1.46]
12200 50
steps: 609950, episodes: 12200, mean episode reward: -47.40390279032178, time: 24.634
agent0_energy_min, agent0_attention_min
[-49.18  -0.8 ]
agent1_energy_min, agent1_attention_min
[-47.49  -1.42]
12300 50
steps: 614950, episodes: 12300, mean episode reward: -46.95436836685692, time: 24.8
agent0_energy_min, agent0_attention_min
[-49.55  -0.12]
agent1_energy_min, agent1_attention_min
[-47.96  -1.04]
12400 50
steps: 619950, episodes: 12400, mean episode reward: -50.39246131804736, time: 24.318
agent0_energy_min, agent0_attention_min
[-48.84  -0.45]
agent1_energy_min, agent1_attention_min
[-47.04  -1.62]
12500 50
steps: 624950, episodes: 12500, mean episode reward: -60.82656339513824, time: 23.991
agent0_energy_min, agent0_attention_min
[-48.33  -0.7 ]
agent1_energy_min, agent1_attention_min
[-46.52  -1.68]
12600 50
steps: 629950, episodes: 12600, mean episode reward: -53.17998971744162, time: 24.885
agent0_energy_min, agent0_attention_min
[-48.98  -0.92]
agent1_energy_min, agent1_attention_min
[-47.08  -2.09]
12700 50
steps: 634950, episodes: 12700, mean episode reward: -44.500838807343605, time: 24.515
agent0_energy_min, agent0_attention_min
[-49.15  -0.72]
agent1_energy_min, agent1_attention_min
[-47.49  -1.65]
12800 50
steps: 639950, episodes: 12800, mean episode reward: -54.289153145188074, time: 24.389
agent0_energy_min, agent0_attention_min
[-49.25  -0.2 ]
agent1_energy_min, agent1_attention_min
[-48.22  -1.11]
12900 50
steps: 644950, episodes: 12900, mean episode reward: -53.58553200176818, time: 23.859
agent0_energy_min, agent0_attention_min
[-48.99  -0.39]
agent1_energy_min, agent1_attention_min
[-48.05  -1.11]
13000 50
steps: 649950, episodes: 13000, mean episode reward: -63.17193637661528, time: 24.204
agent0_energy_min, agent0_attention_min
[-48.22  -1.19]
agent1_energy_min, agent1_attention_min
[-48.15  -1.03]
13100 50
steps: 654950, episodes: 13100, mean episode reward: -56.88309033909809, time: 25.201
agent0_energy_min, agent0_attention_min
[-49.06  -0.49]
agent1_energy_min, agent1_attention_min
[-48.27  -1.  ]
13200 50
steps: 659950, episodes: 13200, mean episode reward: -43.81959121021331, time: 24.557
agent0_energy_min, agent0_attention_min
[-49.16  -0.43]
agent1_energy_min, agent1_attention_min
[-48.58  -1.  ]
13300 50
steps: 664950, episodes: 13300, mean episode reward: -60.86627838890262, time: 24.047
agent0_energy_min, agent0_attention_min
[-49.03  -0.63]
agent1_energy_min, agent1_attention_min
[-47.79  -1.76]
13400 50
steps: 669950, episodes: 13400, mean episode reward: -46.456341123832196, time: 24.826
agent0_energy_min, agent0_attention_min
[-49.28  -0.6 ]
agent1_energy_min, agent1_attention_min
[-47.81  -1.47]
13500 50
steps: 674950, episodes: 13500, mean episode reward: -56.87724181012175, time: 23.948
agent0_energy_min, agent0_attention_min
[-48.81  -0.83]
agent1_energy_min, agent1_attention_min
[-47.77  -1.46]
13600 50
steps: 679950, episodes: 13600, mean episode reward: -50.18241956659156, time: 24.875
agent0_energy_min, agent0_attention_min
[-49.01  -0.84]
agent1_energy_min, agent1_attention_min
[-48.43  -0.86]
13700 50
steps: 684950, episodes: 13700, mean episode reward: -51.387723547812655, time: 23.946
agent0_energy_min, agent0_attention_min
[-49.5   -0.18]
agent1_energy_min, agent1_attention_min
[-48.3   -1.16]
13800 50
steps: 689950, episodes: 13800, mean episode reward: -57.652590622387834, time: 24.328
agent0_energy_min, agent0_attention_min
[-49.47  -0.42]
agent1_energy_min, agent1_attention_min
[-46.96  -2.06]
13900 50
steps: 694950, episodes: 13900, mean episode reward: -39.95589754568302, time: 23.94
agent0_energy_min, agent0_attention_min
[-48.78  -1.21]
agent1_energy_min, agent1_attention_min
[-48.07  -1.07]
14000 50
steps: 699950, episodes: 14000, mean episode reward: -44.3439446177151, time: 24.729
agent0_energy_min, agent0_attention_min
[-49.33  -0.67]
agent1_energy_min, agent1_attention_min
[-47.98  -1.25]
14100 50
steps: 704950, episodes: 14100, mean episode reward: -49.90533194170653, time: 24.391
agent0_energy_min, agent0_attention_min
[-49.51  -0.45]
agent1_energy_min, agent1_attention_min
[-46.75  -1.63]
14200 50
steps: 709950, episodes: 14200, mean episode reward: -50.93132848118837, time: 24.414
agent0_energy_min, agent0_attention_min
[-49.61  -0.19]
agent1_energy_min, agent1_attention_min
[-48.07  -1.14]
14300 50
steps: 714950, episodes: 14300, mean episode reward: -61.15721188969209, time: 23.858
agent0_energy_min, agent0_attention_min
[-49.59  -0.23]
agent1_energy_min, agent1_attention_min
[-48.27  -1.34]
14400 50
steps: 719950, episodes: 14400, mean episode reward: -51.245807931710814, time: 24.007
agent0_energy_min, agent0_attention_min
[-49.17  -0.24]
agent1_energy_min, agent1_attention_min
[-48.45  -0.82]
14500 50
steps: 724950, episodes: 14500, mean episode reward: -44.34491800250186, time: 24.624
agent0_energy_min, agent0_attention_min
[-48.52  -0.62]
agent1_energy_min, agent1_attention_min
[-47.11  -1.65]
14600 50
steps: 729950, episodes: 14600, mean episode reward: -53.50569991229622, time: 24.891
agent0_energy_min, agent0_attention_min
[-48.12  -1.08]
agent1_energy_min, agent1_attention_min
[-46.98  -2.01]
14700 50
steps: 734950, episodes: 14700, mean episode reward: -50.77551147808254, time: 24.485
agent0_energy_min, agent0_attention_min
[-46.23  -0.43]
agent1_energy_min, agent1_attention_min
[-47.99  -1.27]
14800 50
steps: 739950, episodes: 14800, mean episode reward: -66.89045075734886, time: 24.088
agent0_energy_min, agent0_attention_min
[-48.46  -0.29]
agent1_energy_min, agent1_attention_min
[-47.49  -1.22]
14900 50
steps: 744950, episodes: 14900, mean episode reward: -54.56391487549361, time: 25.009
agent0_energy_min, agent0_attention_min
[-49.02  -0.59]
agent1_energy_min, agent1_attention_min
[-48.29  -0.87]
15000 50
steps: 749950, episodes: 15000, mean episode reward: -39.6094377568841, time: 24.225
agent0_energy_min, agent0_attention_min
[-48.94  -0.65]
agent1_energy_min, agent1_attention_min
[-47.59  -0.91]
15100 50
steps: 754950, episodes: 15100, mean episode reward: -55.06782696906806, time: 24.972
agent0_energy_min, agent0_attention_min
[-49.13  -0.24]
agent1_energy_min, agent1_attention_min
[-47.59  -1.27]
15200 50
steps: 759950, episodes: 15200, mean episode reward: -51.70875843229967, time: 24.302
agent0_energy_min, agent0_attention_min
[-49.01  -0.11]
agent1_energy_min, agent1_attention_min
[-47.08  -1.59]
15300 50
steps: 764950, episodes: 15300, mean episode reward: -48.31858364404563, time: 23.702
agent0_energy_min, agent0_attention_min
[-49.31  -0.08]
agent1_energy_min, agent1_attention_min
[-48.11  -1.33]
15400 50
steps: 769950, episodes: 15400, mean episode reward: -53.37132191116795, time: 24.084
agent0_energy_min, agent0_attention_min
[-49.09  -0.11]
agent1_energy_min, agent1_attention_min
[-48.18  -1.14]
15500 50
steps: 774950, episodes: 15500, mean episode reward: -49.96967353733388, time: 24.801
agent0_energy_min, agent0_attention_min
[-49.33  -0.12]
agent1_energy_min, agent1_attention_min
[-48.53  -0.97]
15600 50
steps: 779950, episodes: 15600, mean episode reward: -53.822613467933145, time: 24.808
agent0_energy_min, agent0_attention_min
[-49.42  -0.28]
agent1_energy_min, agent1_attention_min
[-47.77  -1.75]
15700 50
steps: 784950, episodes: 15700, mean episode reward: -60.745348186767096, time: 24.255
agent0_energy_min, agent0_attention_min
[-49.14  -0.34]
agent1_energy_min, agent1_attention_min
[-47.73  -1.25]
15800 50
steps: 789950, episodes: 15800, mean episode reward: -43.00073063749953, time: 24.448
agent0_energy_min, agent0_attention_min
[-49.06  -0.63]
agent1_energy_min, agent1_attention_min
[-48.28  -1.25]
15900 50
steps: 794950, episodes: 15900, mean episode reward: -81.86883658830835, time: 24.281
agent0_energy_min, agent0_attention_min
[-48.9   -0.85]
agent1_energy_min, agent1_attention_min
[-47.81  -1.5 ]
16000
agent0_energy_min, agent0_attention_min
[-47.75  -1.77]
agent1_energy_min, agent1_attention_min
[-4.609e+01 -2.000e-02]
12100 50
steps: 604950, episodes: 12100, mean episode reward: -61.69267520152878, time: 25.26
agent0_energy_min, agent0_attention_min
[-47.69  -1.93]
agent1_energy_min, agent1_attention_min
[-4.623e+01 -2.000e-02]
12200 50
steps: 609950, episodes: 12200, mean episode reward: -51.767475720654204, time: 24.21
agent0_energy_min, agent0_attention_min
[-48.23  -1.65]
agent1_energy_min, agent1_attention_min
[-46.33  -0.09]
12300 50
steps: 614950, episodes: 12300, mean episode reward: -63.20634809256294, time: 24.226
agent0_energy_min, agent0_attention_min
[-47.3   -2.31]
agent1_energy_min, agent1_attention_min
[-44.26  -3.21]
12400 50
steps: 619950, episodes: 12400, mean episode reward: -92.32077221176912, time: 24.047
agent0_energy_min, agent0_attention_min
[-47.44  -1.85]
agent1_energy_min, agent1_attention_min
[-38.34  -0.14]
12500 50
steps: 624950, episodes: 12500, mean episode reward: -67.14941023332527, time: 24.163
agent0_energy_min, agent0_attention_min
[-47.67  -1.72]
agent1_energy_min, agent1_attention_min
[-43.51  -0.05]
12600 50
steps: 629950, episodes: 12600, mean episode reward: -137.66779935198272, time: 24.702
agent0_energy_min, agent0_attention_min
[-48.67  -1.11]
agent1_energy_min, agent1_attention_min
[-43.65  -0.07]
12700 50
steps: 634950, episodes: 12700, mean episode reward: -73.90111329790699, time: 24.185
agent0_energy_min, agent0_attention_min
[-46.29  -3.51]
agent1_energy_min, agent1_attention_min
[-4.197e+01 -3.000e-02]
12800 50
steps: 639950, episodes: 12800, mean episode reward: -65.59089109172682, time: 24.698
agent0_energy_min, agent0_attention_min
[-48.18  -1.46]
agent1_energy_min, agent1_attention_min
[-44.26   0.  ]
12900 50
steps: 644950, episodes: 12900, mean episode reward: -69.43010678793074, time: 24.43
agent0_energy_min, agent0_attention_min
[-47.49  -2.08]
agent1_energy_min, agent1_attention_min
[-44.43  -0.47]
13000 50
steps: 649950, episodes: 13000, mean episode reward: -95.04407436440313, time: 25.07
agent0_energy_min, agent0_attention_min
[-46.57  -2.65]
agent1_energy_min, agent1_attention_min
[-40.37  -4.78]
13100 50
steps: 654950, episodes: 13100, mean episode reward: -71.06773745694508, time: 24.914
agent0_energy_min, agent0_attention_min
[-45.68  -3.83]
agent1_energy_min, agent1_attention_min
[-41.86  -0.86]
13200 50
steps: 659950, episodes: 13200, mean episode reward: -66.8864609829625, time: 24.206
agent0_energy_min, agent0_attention_min
[-45.55  -3.61]
agent1_energy_min, agent1_attention_min
[-42.51   0.  ]
13300 50
steps: 664950, episodes: 13300, mean episode reward: -58.893049111229196, time: 24.239
agent0_energy_min, agent0_attention_min
[-48.68  -0.8 ]
agent1_energy_min, agent1_attention_min
[-44.53  -0.07]
13400 50
steps: 669950, episodes: 13400, mean episode reward: -74.18116229663318, time: 24.565
agent0_energy_min, agent0_attention_min
[-46.27  -3.11]
agent1_energy_min, agent1_attention_min
[-42.68  -0.05]
13500 50
steps: 674950, episodes: 13500, mean episode reward: -62.38069730343236, time: 24.037
agent0_energy_min, agent0_attention_min
[-45.83  -3.79]
agent1_energy_min, agent1_attention_min
[-43.92  -0.3 ]
13600 50
steps: 679950, episodes: 13600, mean episode reward: -52.60180335202236, time: 24.802
agent0_energy_min, agent0_attention_min
[-44.97  -4.67]
agent1_energy_min, agent1_attention_min
[-45.3   -0.14]
13700 50
steps: 684950, episodes: 13700, mean episode reward: -55.16310383466767, time: 24.483
agent0_energy_min, agent0_attention_min
[-45.83  -3.88]
agent1_energy_min, agent1_attention_min
[-46.13  -0.57]
13800 50
steps: 689950, episodes: 13800, mean episode reward: -57.548114511375076, time: 24.464
agent0_energy_min, agent0_attention_min
[-49.02  -0.65]
agent1_energy_min, agent1_attention_min
[-45.66  -0.31]
13900 50
steps: 694950, episodes: 13900, mean episode reward: -52.412797979307406, time: 24.847
agent0_energy_min, agent0_attention_min
[-46.68  -2.09]
agent1_energy_min, agent1_attention_min
[-47.65  -0.51]
14000 50
steps: 699950, episodes: 14000, mean episode reward: -50.26874792682272, time: 28.302
agent0_energy_min, agent0_attention_min
[-45.28  -4.41]
agent1_energy_min, agent1_attention_min
[-46.82  -0.25]
14100 50
steps: 704950, episodes: 14100, mean episode reward: -56.976674874890875, time: 25.118
agent0_energy_min, agent0_attention_min
[-46.08  -3.67]
agent1_energy_min, agent1_attention_min
[-46.96  -0.1 ]
14200 50
steps: 709950, episodes: 14200, mean episode reward: -55.41784334779157, time: 24.147
agent0_energy_min, agent0_attention_min
[-44.9   -4.75]
agent1_energy_min, agent1_attention_min
[-44.94  -0.21]
14300 50
steps: 714950, episodes: 14300, mean episode reward: -48.90488580897919, time: 24.718
agent0_energy_min, agent0_attention_min
[-47.21  -2.56]
agent1_energy_min, agent1_attention_min
[-47.    -0.05]
14400 50
steps: 719950, episodes: 14400, mean episode reward: -69.59782884715273, time: 24.024
agent0_energy_min, agent0_attention_min
[-46.55  -3.27]
agent1_energy_min, agent1_attention_min
[-47.16  -0.16]
14500 50
steps: 724950, episodes: 14500, mean episode reward: -42.9028312679149, time: 23.94
agent0_energy_min, agent0_attention_min
[-48.63  -1.24]
agent1_energy_min, agent1_attention_min
[-47.9   -0.09]
14600 50
steps: 729950, episodes: 14600, mean episode reward: -50.2799198230981, time: 24.907
agent0_energy_min, agent0_attention_min
[-46.86  -3.03]
agent1_energy_min, agent1_attention_min
[-47.15  -0.11]
14700 50
steps: 734950, episodes: 14700, mean episode reward: -49.10271586432571, time: 24.372
agent0_energy_min, agent0_attention_min
[-45.26  -4.55]
agent1_energy_min, agent1_attention_min
[-4.701e+01 -3.000e-02]
14800 50
steps: 739950, episodes: 14800, mean episode reward: -55.930527508053444, time: 25.115
agent0_energy_min, agent0_attention_min
[-47.44  -2.41]
agent1_energy_min, agent1_attention_min
[-45.85  -0.21]
14900 50
steps: 744950, episodes: 14900, mean episode reward: -43.79042515192984, time: 24.428
agent0_energy_min, agent0_attention_min
[-46.51  -3.22]
agent1_energy_min, agent1_attention_min
[-47.34  -0.74]
15000 50
steps: 749950, episodes: 15000, mean episode reward: -46.14561590553336, time: 23.831
agent0_energy_min, agent0_attention_min
[-45.48  -4.36]
agent1_energy_min, agent1_attention_min
[-44.49  -2.  ]
15100 50
steps: 754950, episodes: 15100, mean episode reward: -37.60234999169248, time: 24.808
agent0_energy_min, agent0_attention_min
[-44.43  -5.23]
agent1_energy_min, agent1_attention_min
[-45.77  -2.22]
15200 50
steps: 759950, episodes: 15200, mean episode reward: -67.53415084096204, time: 24.23
agent0_energy_min, agent0_attention_min
[-35.55 -10.62]
agent1_energy_min, agent1_attention_min
[-46.84  -1.26]
15300 50
steps: 764950, episodes: 15300, mean episode reward: -104.4256188428757, time: 24.543
agent0_energy_min, agent0_attention_min
[-32.88 -15.42]
agent1_energy_min, agent1_attention_min
[-46.36  -1.21]
15400 50
steps: 769950, episodes: 15400, mean episode reward: -74.99907356798602, time: 24.691
agent0_energy_min, agent0_attention_min
[-38.66 -10.73]
agent1_energy_min, agent1_attention_min
[-47.88  -1.  ]
15500 50
steps: 774950, episodes: 15500, mean episode reward: -51.29324128235494, time: 24.04
agent0_energy_min, agent0_attention_min
[-44.52  -5.26]
agent1_energy_min, agent1_attention_min
[-47.8   -0.37]
15600 50
steps: 779950, episodes: 15600, mean episode reward: -52.40485831888666, time: 24.577
agent0_energy_min, agent0_attention_min
[-38.49 -10.88]
agent1_energy_min, agent1_attention_min
[-48.13  -0.11]
15700 50
steps: 784950, episodes: 15700, mean episode reward: -59.25235311346858, time: 23.959
agent0_energy_min, agent0_attention_min
[-34.77 -15.  ]
agent1_energy_min, agent1_attention_min
[-47.76  -0.05]
15800 50
steps: 789950, episodes: 15800, mean episode reward: -54.425609985959206, time: 24.544
agent0_energy_min, agent0_attention_min
[-36.24 -13.19]
agent1_energy_min, agent1_attention_min
[-4.8e+01 -1.0e-02]
15900 50
steps: 794950, episodes: 15900, mean episode reward: -54.558793875391345, time: 24.646
agent0_energy_min, agent0_attention_min
[-36.85 -11.95]
agent1_energy_min, agent1_attention_min
[-49.26  -0.71]
agent1_energy_min, agent1_attention_min
[-48.3   -1.39]
12100 50
steps: 604950, episodes: 12100, mean episode reward: -69.44968925618306, time: 24.675
agent0_energy_min, agent0_attention_min
[-48.37  -1.61]
agent1_energy_min, agent1_attention_min
[-48.79  -0.75]
12200 50
steps: 609950, episodes: 12200, mean episode reward: -55.44032828757853, time: 24.62
agent0_energy_min, agent0_attention_min
[-49.37  -0.56]
agent1_energy_min, agent1_attention_min
[-48.54  -1.01]
12300 50
steps: 614950, episodes: 12300, mean episode reward: -68.11788275695599, time: 24.3
agent0_energy_min, agent0_attention_min
[-47.69  -1.01]
agent1_energy_min, agent1_attention_min
[-47.92  -1.62]
12400 50
steps: 619950, episodes: 12400, mean episode reward: -67.10213062473575, time: 23.822
agent0_energy_min, agent0_attention_min
[-48.68  -1.07]
agent1_energy_min, agent1_attention_min
[-48.46  -0.95]
12500 50
steps: 624950, episodes: 12500, mean episode reward: -74.22991868668268, time: 24.104
agent0_energy_min, agent0_attention_min
[-49.19  -0.6 ]
agent1_energy_min, agent1_attention_min
[-47.44  -0.96]
12600 50
steps: 629950, episodes: 12600, mean episode reward: -77.25720114545119, time: 24.429
agent0_energy_min, agent0_attention_min
[-49.21  -0.67]
agent1_energy_min, agent1_attention_min
[-47.42  -1.44]
12700 50
steps: 634950, episodes: 12700, mean episode reward: -66.88619730851687, time: 24.038
agent0_energy_min, agent0_attention_min
[-48.74  -1.21]
agent1_energy_min, agent1_attention_min
[-48.55  -0.87]
12800 50
steps: 639950, episodes: 12800, mean episode reward: -79.18966757493261, time: 24.22
agent0_energy_min, agent0_attention_min
[-49.36  -0.62]
agent1_energy_min, agent1_attention_min
[-47.98  -1.52]
12900 50
steps: 644950, episodes: 12900, mean episode reward: -68.88817378779599, time: 23.568
agent0_energy_min, agent0_attention_min
[-47.97  -1.97]
agent1_energy_min, agent1_attention_min
[-47.64  -1.52]
13000 50
steps: 649950, episodes: 13000, mean episode reward: -100.22158714675575, time: 24.622
agent0_energy_min, agent0_attention_min
[-46.45  -3.45]
agent1_energy_min, agent1_attention_min
[-46.5   -2.12]
13100 50
steps: 654950, episodes: 13100, mean episode reward: -70.1509794898896, time: 24.875
agent0_energy_min, agent0_attention_min
[-43.14  -6.79]
agent1_energy_min, agent1_attention_min
[-48.17  -1.52]
13200 50
steps: 659950, episodes: 13200, mean episode reward: -95.49745320230228, time: 23.787
agent0_energy_min, agent0_attention_min
[-45.55  -4.44]
agent1_energy_min, agent1_attention_min
[-44.34  -2.85]
13300 50
steps: 664950, episodes: 13300, mean episode reward: -70.67706928902965, time: 24.041
agent0_energy_min, agent0_attention_min
[-45.43  -4.55]
agent1_energy_min, agent1_attention_min
[-47.33  -1.97]
13400 50
steps: 669950, episodes: 13400, mean episode reward: -70.1027278474639, time: 24.233
agent0_energy_min, agent0_attention_min
[-40.88  -9.07]
agent1_energy_min, agent1_attention_min
[-47.64  -1.6 ]
13500 50
steps: 674950, episodes: 13500, mean episode reward: -71.02052738702555, time: 24.602
agent0_energy_min, agent0_attention_min
[-45.77  -4.18]
agent1_energy_min, agent1_attention_min
[-47.51  -2.07]
13600 50
steps: 679950, episodes: 13600, mean episode reward: -68.54415266253577, time: 24.846
agent0_energy_min, agent0_attention_min
[-44.41  -5.57]
agent1_energy_min, agent1_attention_min
[-46.71  -2.93]
13700 50
steps: 684950, episodes: 13700, mean episode reward: -73.13426802999629, time: 23.984
agent0_energy_min, agent0_attention_min
[-45.54  -4.42]
agent1_energy_min, agent1_attention_min
[-48.41  -1.19]
13800 50
steps: 689950, episodes: 13800, mean episode reward: -84.05387832771682, time: 24.376
agent0_energy_min, agent0_attention_min
[-43.52  -6.44]
agent1_energy_min, agent1_attention_min
[-48.81  -0.88]
13900 50
steps: 694950, episodes: 13900, mean episode reward: -73.281326909194, time: 24.285
agent0_energy_min, agent0_attention_min
[-43.63  -6.37]
agent1_energy_min, agent1_attention_min
[-47.9   -1.83]
14000 50
steps: 699950, episodes: 14000, mean episode reward: -66.84275776738849, time: 24.27
agent0_energy_min, agent0_attention_min
[-43.8   -6.17]
agent1_energy_min, agent1_attention_min
[-47.82  -1.98]
14100 50
steps: 704950, episodes: 14100, mean episode reward: -67.55195765282895, time: 25.182
agent0_energy_min, agent0_attention_min
[-45.78  -4.2 ]
agent1_energy_min, agent1_attention_min
[-47.9   -1.56]
14200 50
steps: 709950, episodes: 14200, mean episode reward: -71.57212078051829, time: 24.49
agent0_energy_min, agent0_attention_min
[-41.64  -8.33]
agent1_energy_min, agent1_attention_min
[-47.08  -2.52]
14300 50
steps: 714950, episodes: 14300, mean episode reward: -65.92406395532714, time: 24.157
agent0_energy_min, agent0_attention_min
[-42.85  -7.06]
agent1_energy_min, agent1_attention_min
[-48.25  -1.46]
14400 50
steps: 719950, episodes: 14400, mean episode reward: -144.87770961207514, time: 24.214
agent0_energy_min, agent0_attention_min
[-44.32  -5.62]
agent1_energy_min, agent1_attention_min
[-47.85  -1.64]
14500 50
steps: 724950, episodes: 14500, mean episode reward: -108.8054661366869, time: 24.494
agent0_energy_min, agent0_attention_min
[-45.74  -4.23]
agent1_energy_min, agent1_attention_min
[-49.21  -0.67]
14600 50
steps: 729950, episodes: 14600, mean episode reward: -61.11267312674844, time: 24.626
agent0_energy_min, agent0_attention_min
[-39.56 -10.42]
agent1_energy_min, agent1_attention_min
[-49.42  -0.45]
14700 50
steps: 734950, episodes: 14700, mean episode reward: -92.40694442660602, time: 24.406
agent0_energy_min, agent0_attention_min
[-44.34  -5.65]
agent1_energy_min, agent1_attention_min
[-48.72  -0.91]
14800 50
steps: 739950, episodes: 14800, mean episode reward: -67.38136730008878, time: 24.893
agent0_energy_min, agent0_attention_min
[-43.02  -6.97]
agent1_energy_min, agent1_attention_min
[-48.52  -1.24]
14900 50
steps: 744950, episodes: 14900, mean episode reward: -71.51254945186716, time: 23.832
agent0_energy_min, agent0_attention_min
[-44.5   -5.37]
agent1_energy_min, agent1_attention_min
[-48.54  -1.19]
15000 50
steps: 749950, episodes: 15000, mean episode reward: -73.65714808709313, time: 24.247
agent0_energy_min, agent0_attention_min
[-45.96  -3.31]
agent1_energy_min, agent1_attention_min
[-48.59  -1.26]
15100 50
steps: 754950, episodes: 15100, mean episode reward: -59.53301492589972, time: 24.627
agent0_energy_min, agent0_attention_min
[-43.31  -6.65]
agent1_energy_min, agent1_attention_min
[-48.39  -1.47]
15200 50
steps: 759950, episodes: 15200, mean episode reward: -68.58355423219092, time: 24.248
agent0_energy_min, agent0_attention_min
[-37.09 -12.77]
agent1_energy_min, agent1_attention_min
[-48.47  -1.49]
15300 50
steps: 764950, episodes: 15300, mean episode reward: -71.2083368187014, time: 23.928
agent0_energy_min, agent0_attention_min
[-43.1  -6.8]
agent1_energy_min, agent1_attention_min
[-47.82  -2.14]
15400 50
steps: 769950, episodes: 15400, mean episode reward: -62.92096182727002, time: 24.485
agent0_energy_min, agent0_attention_min
[-42.46  -7.52]
agent1_energy_min, agent1_attention_min
[-48.29  -1.68]
15500 50
steps: 774950, episodes: 15500, mean episode reward: -70.7671001397741, time: 24.221
agent0_energy_min, agent0_attention_min
[-42.19  -7.68]
agent1_energy_min, agent1_attention_min
[-47.33  -2.61]
15600 50
steps: 779950, episodes: 15600, mean episode reward: -85.47202078212729, time: 24.751
agent0_energy_min, agent0_attention_min
[-41.76  -8.18]
agent1_energy_min, agent1_attention_min
[-45.8   -3.98]
15700 50
steps: 784950, episodes: 15700, mean episode reward: -68.57108123663608, time: 24.206
agent0_energy_min, agent0_attention_min
[-37.15 -12.78]
agent1_energy_min, agent1_attention_min
[-48.73  -1.  ]
15800 50
steps: 789950, episodes: 15800, mean episode reward: -67.19146881582145, time: 23.956
agent0_energy_min, agent0_attention_min
[-47.88  -1.97]
agent1_energy_min, agent1_attention_min
[-49.41  -0.49]
15900 50
steps: 794950, episodes: 15900, mean episode reward: -77.49901816552239, time: 24.004
agent0_energy_min, agent0_attention_min
[-42.25  -7.59]
agent1_energy_min, agent1_attention_min
[-48.27  -0.99]
16000 50
steps: 799950, episodes: 16000, mean episode reward: -95.48335051928409, time: 24.304
agent0_energy_min, agent0_attention_min
[-41.    -2.49]
agent1_energy_min, agent1_attention_min
[ -5.35 -44.12]
12100 50
steps: 604950, episodes: 12100, mean episode reward: -158.00959968470852, time: 24.819
agent0_energy_min, agent0_attention_min
[-19.69  -5.89]
agent1_energy_min, agent1_attention_min
[-10.81 -37.9 ]
12200 50
steps: 609950, episodes: 12200, mean episode reward: -100.41867544108123, time: 24.383
agent0_energy_min, agent0_attention_min
[-33.92  -0.18]
agent1_energy_min, agent1_attention_min
[ -5.23 -42.48]
12300 50
steps: 614950, episodes: 12300, mean episode reward: -73.29344816546671, time: 24.083
agent0_energy_min, agent0_attention_min
[-33.56  -0.31]
agent1_energy_min, agent1_attention_min
[ -7.45 -41.23]
12400 50
steps: 619950, episodes: 12400, mean episode reward: -81.71907220811903, time: 24.195
agent0_energy_min, agent0_attention_min
[-25.17  -0.13]
agent1_energy_min, agent1_attention_min
[ -7.9  -40.94]
12500 50
steps: 624950, episodes: 12500, mean episode reward: -81.19026341346228, time: 24.469
agent0_energy_min, agent0_attention_min
[-26.49  -0.67]
agent1_energy_min, agent1_attention_min
[ -4.69 -43.43]
12600 50
steps: 629950, episodes: 12600, mean episode reward: -109.66026843327803, time: 24.81
agent0_energy_min, agent0_attention_min
[-26.53  -1.48]
agent1_energy_min, agent1_attention_min
[ -4.69 -44.61]
12700 50
steps: 634950, episodes: 12700, mean episode reward: -103.29047226313659, time: 24.691
agent0_energy_min, agent0_attention_min
[-23.96  -1.43]
agent1_energy_min, agent1_attention_min
[ -6.96 -42.11]
12800 50
steps: 639950, episodes: 12800, mean episode reward: -60.15798922614571, time: 24.376
agent0_energy_min, agent0_attention_min
[-34.56  -1.61]
agent1_energy_min, agent1_attention_min
[ -3.83 -45.08]
12900 50
steps: 644950, episodes: 12900, mean episode reward: -74.06051968119598, time: 23.762
agent0_energy_min, agent0_attention_min
[-37.31  -2.11]
agent1_energy_min, agent1_attention_min
[ -3.27 -45.99]
13000 50
steps: 649950, episodes: 13000, mean episode reward: -72.49888229022254, time: 23.822
agent0_energy_min, agent0_attention_min
[-35.7   -2.39]
agent1_energy_min, agent1_attention_min
[ -3.42 -44.38]
13100 50
steps: 654950, episodes: 13100, mean episode reward: -70.41280283002914, time: 24.74
agent0_energy_min, agent0_attention_min
[-31.27  -2.8 ]
agent1_energy_min, agent1_attention_min
[ -2.4  -46.15]
13200 50
steps: 659950, episodes: 13200, mean episode reward: -62.349840191512016, time: 24.349
agent0_energy_min, agent0_attention_min
[-33.69  -1.79]
agent1_energy_min, agent1_attention_min
[ -5.24 -43.65]
13300 50
steps: 664950, episodes: 13300, mean episode reward: -65.96279761998443, time: 24.679
agent0_energy_min, agent0_attention_min
[-33.13  -0.69]
agent1_energy_min, agent1_attention_min
[ -6.01 -42.77]
13400 50
steps: 669950, episodes: 13400, mean episode reward: -63.858269619939335, time: 24.42
agent0_energy_min, agent0_attention_min
[-33.19  -1.06]
agent1_energy_min, agent1_attention_min
[ -5.48 -43.48]
13500 50
steps: 674950, episodes: 13500, mean episode reward: -77.96002122607523, time: 24.543
agent0_energy_min, agent0_attention_min
[-31.02  -2.88]
agent1_energy_min, agent1_attention_min
[ -9.79 -38.76]
13600 50
steps: 679950, episodes: 13600, mean episode reward: -69.86658209158523, time: 24.899
agent0_energy_min, agent0_attention_min
[-30.68  -2.73]
agent1_energy_min, agent1_attention_min
[ -5.45 -43.76]
13700 50
steps: 684950, episodes: 13700, mean episode reward: -94.45033383356689, time: 24.2
agent0_energy_min, agent0_attention_min
[-27.27 -12.36]
agent1_energy_min, agent1_attention_min
[ -6.32 -42.76]
13800 50
steps: 689950, episodes: 13800, mean episode reward: -74.60000156775077, time: 24.36
agent0_energy_min, agent0_attention_min
[-33.85  -2.98]
agent1_energy_min, agent1_attention_min
[ -8.31 -41.24]
13900 50
steps: 694950, episodes: 13900, mean episode reward: -59.50064927368881, time: 23.993
agent0_energy_min, agent0_attention_min
[-30.05  -1.26]
agent1_energy_min, agent1_attention_min
[ -9.51 -40.11]
14000 50
steps: 699950, episodes: 14000, mean episode reward: -71.18815173667763, time: 24.959
agent0_energy_min, agent0_attention_min
[-39.15  -1.25]
agent1_energy_min, agent1_attention_min
[ -5.75 -43.91]
14100 50
steps: 704950, episodes: 14100, mean episode reward: -78.19024192170033, time: 24.656
agent0_energy_min, agent0_attention_min
[-36.39  -0.84]
agent1_energy_min, agent1_attention_min
[ -9.02 -40.72]
14200 50
steps: 709950, episodes: 14200, mean episode reward: -71.35801093573927, time: 24.39
agent0_energy_min, agent0_attention_min
[-31.11  -0.96]
agent1_energy_min, agent1_attention_min
[-10.56 -38.47]
14300 50
steps: 714950, episodes: 14300, mean episode reward: -56.5185299890614, time: 24.198
agent0_energy_min, agent0_attention_min
[-33.49  -0.5 ]
agent1_energy_min, agent1_attention_min
[ -6.93 -42.31]
14400 50
steps: 719950, episodes: 14400, mean episode reward: -72.17764505575505, time: 24.296
agent0_energy_min, agent0_attention_min
[-37.54  -1.33]
agent1_energy_min, agent1_attention_min
[ -8.02 -41.65]
14500 50
steps: 724950, episodes: 14500, mean episode reward: -64.26944636811513, time: 24.475
agent0_energy_min, agent0_attention_min
[-34.55  -1.63]
agent1_energy_min, agent1_attention_min
[ -6.98 -42.73]
14600 50
steps: 729950, episodes: 14600, mean episode reward: -67.87677037242428, time: 24.558
agent0_energy_min, agent0_attention_min
[-33.04  -1.54]
agent1_energy_min, agent1_attention_min
[ -9.47 -40.07]
14700 50
steps: 734950, episodes: 14700, mean episode reward: -73.04944305603391, time: 24.596
agent0_energy_min, agent0_attention_min
[-35.06  -1.05]
agent1_energy_min, agent1_attention_min
[ -9.91 -39.79]
14800 50
steps: 739950, episodes: 14800, mean episode reward: -69.6527217740836, time: 24.341
agent0_energy_min, agent0_attention_min
[-30.47  -0.78]
agent1_energy_min, agent1_attention_min
[-12.25 -37.54]
14900 50
steps: 744950, episodes: 14900, mean episode reward: -69.91817492555165, time: 24.327
agent0_energy_min, agent0_attention_min
[-35.83  -0.9 ]
agent1_energy_min, agent1_attention_min
[ -9.54 -40.26]
15000 50
steps: 749950, episodes: 15000, mean episode reward: -59.44453528050562, time: 24.432
agent0_energy_min, agent0_attention_min
[-34.71  -0.88]
agent1_energy_min, agent1_attention_min
[ -9.47 -40.4 ]
15100 50
steps: 754950, episodes: 15100, mean episode reward: -69.4966295452307, time: 24.588
agent0_energy_min, agent0_attention_min
[-36.77  -0.38]
agent1_energy_min, agent1_attention_min
[ -8.93 -40.57]
15200 50
steps: 759950, episodes: 15200, mean episode reward: -66.16638114693485, time: 24.126
agent0_energy_min, agent0_attention_min
[-35.3  -1. ]
agent1_energy_min, agent1_attention_min
[ -9.78 -39.48]
15300 50
steps: 764950, episodes: 15300, mean episode reward: -59.12421365887156, time: 24.734
agent0_energy_min, agent0_attention_min
[-36.49  -1.06]
agent1_energy_min, agent1_attention_min
[-10.15 -39.08]
15400 50
steps: 769950, episodes: 15400, mean episode reward: -66.97991900896062, time: 24.323
agent0_energy_min, agent0_attention_min
[-35.84  -1.11]
agent1_energy_min, agent1_attention_min
[ -9.34 -39.81]
15500 50
steps: 774950, episodes: 15500, mean episode reward: -71.29061429783935, time: 24.231
agent0_energy_min, agent0_attention_min
[-31.81  -0.88]
agent1_energy_min, agent1_attention_min
[ -7.8  -41.64]
15600 50
steps: 779950, episodes: 15600, mean episode reward: -71.98291053125092, time: 24.769
agent0_energy_min, agent0_attention_min
[-26.41  -0.81]
agent1_energy_min, agent1_attention_min
[ -9.2  -40.17]
15700 50
steps: 784950, episodes: 15700, mean episode reward: -67.421961610256, time: 23.995
agent0_energy_min, agent0_attention_min
[-30.08  -0.47]
agent1_energy_min, agent1_attention_min
[ -8.66 -40.95]
15800 50
steps: 789950, episodes: 15800, mean episode reward: -63.85683290399084, time: 24.494
agent0_energy_min, agent0_attention_min
[-30.42  -0.86]
agent1_energy_min, agent1_attention_min
[ -8.86 -40.87]
15900 50
steps: 794950, episodes: 15900, mean episode reward: -60.82072763530596, time: 24.377
agent0_energy_min, agent0_attention_min
[-31.91  -1.22]
agent1_energy_min, agent1_attention_min
[ -6.58 -43.04]
16000 50
steps: 799950, episodes: 16000, mean episode reward: -72.65080792985329, time: 25.021
agent0_energy_min, agent0_attention_min
[-49.07  -0.81]
agent1_energy_min, agent1_attention_min
[ -6.17 -43.31]
12100 50
steps: 604950, episodes: 12100, mean episode reward: -82.66148236317672, time: 24.598
agent0_energy_min, agent0_attention_min
[-49.13  -0.78]
agent1_energy_min, agent1_attention_min
[ -8.34 -41.28]
12200 50
steps: 609950, episodes: 12200, mean episode reward: -82.98894394901792, time: 23.586
agent0_energy_min, agent0_attention_min
[-49.17  -0.74]
agent1_energy_min, agent1_attention_min
[ -9.67 -40.09]
12300 50
steps: 614950, episodes: 12300, mean episode reward: -91.6311070564888, time: 24.215
agent0_energy_min, agent0_attention_min
[-47.96  -1.81]
agent1_energy_min, agent1_attention_min
[ -6.98 -42.82]
12400 50
steps: 619950, episodes: 12400, mean episode reward: -79.84036284334961, time: 23.748
agent0_energy_min, agent0_attention_min
[-49.    -0.65]
agent1_energy_min, agent1_attention_min
[ -9.95 -39.51]
12500 50
steps: 624950, episodes: 12500, mean episode reward: -66.61035411708419, time: 23.921
agent0_energy_min, agent0_attention_min
[-49.33  -0.59]
agent1_energy_min, agent1_attention_min
[ -7.5  -42.36]
12600 50
steps: 629950, episodes: 12600, mean episode reward: -83.58427369903687, time: 24.29
agent0_energy_min, agent0_attention_min
[-49.31  -0.46]
agent1_energy_min, agent1_attention_min
[-10.25 -39.25]
12700 50
steps: 634950, episodes: 12700, mean episode reward: -95.85775937118275, time: 24.203
agent0_energy_min, agent0_attention_min
[-49.07  -0.43]
agent1_energy_min, agent1_attention_min
[ -7.92 -37.99]
12800 50
steps: 639950, episodes: 12800, mean episode reward: -83.49947075578302, time: 24.173
agent0_energy_min, agent0_attention_min
[-48.58  -0.7 ]
agent1_energy_min, agent1_attention_min
[ -8.44 -35.82]
12900 50
steps: 644950, episodes: 12900, mean episode reward: -90.87021022837001, time: 24.204
agent0_energy_min, agent0_attention_min
[-48.31  -0.43]
agent1_energy_min, agent1_attention_min
[-15.98 -31.75]
13000 50
steps: 649950, episodes: 13000, mean episode reward: -93.32989564958677, time: 24.106
agent0_energy_min, agent0_attention_min
[-47.21  -0.63]
agent1_energy_min, agent1_attention_min
[-12.48 -36.12]
13100 50
steps: 654950, episodes: 13100, mean episode reward: -68.20853406257221, time: 24.612
agent0_energy_min, agent0_attention_min
[-47.89  -0.58]
agent1_energy_min, agent1_attention_min
[-11.82 -36.09]
13200 50
steps: 659950, episodes: 13200, mean episode reward: -78.75973756549516, time: 24.188
agent0_energy_min, agent0_attention_min
[-49.05  -0.57]
agent1_energy_min, agent1_attention_min
[-16.45 -31.83]
13300 50
steps: 664950, episodes: 13300, mean episode reward: -83.31124076589359, time: 24.096
agent0_energy_min, agent0_attention_min
[-48.98  -0.4 ]
agent1_energy_min, agent1_attention_min
[-14.69 -32.61]
13400 50
steps: 669950, episodes: 13400, mean episode reward: -71.81226042175476, time: 24.079
agent0_energy_min, agent0_attention_min
[-48.6   -0.27]
agent1_energy_min, agent1_attention_min
[-12.82 -33.63]
13500 50
steps: 674950, episodes: 13500, mean episode reward: -80.48581809352996, time: 24.02
agent0_energy_min, agent0_attention_min
[-47.74  -0.4 ]
agent1_energy_min, agent1_attention_min
[ -9.1  -37.95]
13600 50
steps: 679950, episodes: 13600, mean episode reward: -66.44090461218714, time: 24.57
agent0_energy_min, agent0_attention_min
[-48.48  -0.46]
agent1_energy_min, agent1_attention_min
[-13.94 -34.01]
13700 50
steps: 684950, episodes: 13700, mean episode reward: -89.0330211613508, time: 24.366
agent0_energy_min, agent0_attention_min
[-48.65  -0.27]
agent1_energy_min, agent1_attention_min
[-19.34 -27.32]
13800 50
steps: 689950, episodes: 13800, mean episode reward: -82.63039067120582, time: 23.706
agent0_energy_min, agent0_attention_min
[-48.79  -0.47]
agent1_energy_min, agent1_attention_min
[-11.29 -36.38]
13900 50
steps: 694950, episodes: 13900, mean episode reward: -83.90370559620537, time: 24.308
agent0_energy_min, agent0_attention_min
[-49.51  -0.35]
agent1_energy_min, agent1_attention_min
[-10.12 -35.99]
14000 50
steps: 699950, episodes: 14000, mean episode reward: -84.1491036179181, time: 24.407
agent0_energy_min, agent0_attention_min
[-49.58  -0.3 ]
agent1_energy_min, agent1_attention_min
[-13.15 -34.13]
14100 50
steps: 704950, episodes: 14100, mean episode reward: -91.40027076535335, time: 24.39
agent0_energy_min, agent0_attention_min
[-49.26  -0.48]
agent1_energy_min, agent1_attention_min
[-11.73 -34.17]
14200 50
steps: 709950, episodes: 14200, mean episode reward: -88.9582730972679, time: 24.306
agent0_energy_min, agent0_attention_min
[-48.58  -0.54]
agent1_energy_min, agent1_attention_min
[-12.91 -35.37]
14300 50
steps: 714950, episodes: 14300, mean episode reward: -73.16559582273146, time: 24.122
agent0_energy_min, agent0_attention_min
[-48.78  -0.59]
agent1_energy_min, agent1_attention_min
[-14.94 -30.75]
14400 50
steps: 719950, episodes: 14400, mean episode reward: -80.4212422407465, time: 23.475
agent0_energy_min, agent0_attention_min
[-48.66  -1.01]
agent1_energy_min, agent1_attention_min
[-13.13 -34.41]
14500 50
steps: 724950, episodes: 14500, mean episode reward: -79.97557445993382, time: 24.009
agent0_energy_min, agent0_attention_min
[-48.68  -0.91]
agent1_energy_min, agent1_attention_min
[-14.82 -32.34]
14600 50
steps: 729950, episodes: 14600, mean episode reward: -85.30139596934731, time: 24.576
agent0_energy_min, agent0_attention_min
[-49.02  -0.5 ]
agent1_energy_min, agent1_attention_min
[-16.13 -31.47]
14700 50
steps: 734950, episodes: 14700, mean episode reward: -78.94553689630499, time: 24.329
agent0_energy_min, agent0_attention_min
[-49.24  -0.59]
agent1_energy_min, agent1_attention_min
[-14.36 -32.24]
14800 50
steps: 739950, episodes: 14800, mean episode reward: -84.37824575038796, time: 23.449
agent0_energy_min, agent0_attention_min
[-49.53  -0.42]
agent1_energy_min, agent1_attention_min
[-21.2  -26.54]
14900 50
steps: 744950, episodes: 14900, mean episode reward: -120.55398014374033, time: 24.075
agent0_energy_min, agent0_attention_min
[-48.63  -1.05]
agent1_energy_min, agent1_attention_min
[-23.42 -23.63]
15000 50
steps: 749950, episodes: 15000, mean episode reward: -84.75809764017413, time: 24.255
agent0_energy_min, agent0_attention_min
[-49.03  -0.34]
agent1_energy_min, agent1_attention_min
[-14.88 -33.35]
15100 50
steps: 754950, episodes: 15100, mean episode reward: -64.72928919658597, time: 24.331
agent0_energy_min, agent0_attention_min
[-49.65  -0.21]
agent1_energy_min, agent1_attention_min
[-14.9 -33.2]
15200 50
steps: 759950, episodes: 15200, mean episode reward: -78.31026313975627, time: 23.991
agent0_energy_min, agent0_attention_min
[-49.31  -0.42]
agent1_energy_min, agent1_attention_min
[-20.05 -27.59]
15300 50
steps: 764950, episodes: 15300, mean episode reward: -70.41240362044228, time: 24.134
agent0_energy_min, agent0_attention_min
[-49.17  -0.27]
agent1_energy_min, agent1_attention_min
[-22.84 -25.09]
15400 50
steps: 769950, episodes: 15400, mean episode reward: -78.02862579991645, time: 24.047
agent0_energy_min, agent0_attention_min
[-49.4   -0.29]
agent1_energy_min, agent1_attention_min
[-18.5  -29.49]
15500 50
steps: 774950, episodes: 15500, mean episode reward: -87.84986703155913, time: 23.93
agent0_energy_min, agent0_attention_min
[-48.25  -0.21]
agent1_energy_min, agent1_attention_min
[-15.09 -31.04]
15600 50
steps: 779950, episodes: 15600, mean episode reward: -80.86404746825936, time: 24.512
agent0_energy_min, agent0_attention_min
[-48.65  -0.26]
agent1_energy_min, agent1_attention_min
[-17.06 -29.93]
15700 50
steps: 784950, episodes: 15700, mean episode reward: -81.93044563267759, time: 24.175
agent0_energy_min, agent0_attention_min
[-49.43  -0.19]
agent1_energy_min, agent1_attention_min
[-13.77 -30.06]
15800 50
steps: 789950, episodes: 15800, mean episode reward: -90.15994245286203, time: 24.368
agent0_energy_min, agent0_attention_min
[-48.94  -0.2 ]
agent1_energy_min, agent1_attention_min
[-17.35 -27.74]
15900 50
steps: 794950, episodes: 15900, mean episode reward: -90.40193419150437, time: 24.318
agent0_energy_min, agent0_attention_min
[-48.92  -0.24]
agent1_energy_min, agent1_attention_min
[-17.42 -27.82]
16000 50
steps: 799950, episodes: 16000, mean episode reward: -107.50569720420248, time: 24.04
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
12000 50
steps: 599950, episodes: 12000, mean episode reward: -115.85281613949012, time: 24.465
agent0_energy_min, agent0_attention_min
[-4.038e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
12100 50
steps: 604950, episodes: 12100, mean episode reward: -100.2062935527111, time: 24.601
agent0_energy_min, agent0_attention_min
[-3.699e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.02]
12200 50
steps: 609950, episodes: 12200, mean episode reward: -115.16865517594091, time: 24.408
agent0_energy_min, agent0_attention_min
[-37.83  -0.04]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
12300 50
steps: 614950, episodes: 12300, mean episode reward: -105.68238128350666, time: 24.337
agent0_energy_min, agent0_attention_min
[-3.666e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
12400 50
steps: 619950, episodes: 12400, mean episode reward: -119.25017512107587, time: 24.043
agent0_energy_min, agent0_attention_min
[-38.15  -0.04]
agent1_energy_min, agent1_attention_min
[-0.02  0.  ]
12500 50
steps: 624950, episodes: 12500, mean episode reward: -115.7903179091855, time: 24.297
agent0_energy_min, agent0_attention_min
[-3.639e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
12600 50
steps: 629950, episodes: 12600, mean episode reward: -114.21061161857315, time: 24.961
agent0_energy_min, agent0_attention_min
[-36.52  -0.04]
agent1_energy_min, agent1_attention_min
[-0.04 -0.02]
12700 50
steps: 634950, episodes: 12700, mean episode reward: -105.4499352036071, time: 24.363
agent0_energy_min, agent0_attention_min
[-34.98  -0.12]
agent1_energy_min, agent1_attention_min
[-0.03 -0.02]
12800 50
steps: 639950, episodes: 12800, mean episode reward: -96.15028994970639, time: 24.259
agent0_energy_min, agent0_attention_min
[-37.81  -0.18]
agent1_energy_min, agent1_attention_min
[-0.11 -0.02]
12900 50
steps: 644950, episodes: 12900, mean episode reward: -103.29643691515385, time: 24.628
agent0_energy_min, agent0_attention_min
[-36.89  -0.13]
agent1_energy_min, agent1_attention_min
[-2.69 -0.05]
13000 50
steps: 649950, episodes: 13000, mean episode reward: -97.51733607947146, time: 24.844
agent0_energy_min, agent0_attention_min
[-32.68  -0.06]
agent1_energy_min, agent1_attention_min
[-0.08 -0.01]
13100 50
steps: 654950, episodes: 13100, mean episode reward: -103.95287932223575, time: 25.228
agent0_energy_min, agent0_attention_min
[-31.74  -0.04]
agent1_energy_min, agent1_attention_min
[-0.06  0.  ]
13200 50
steps: 659950, episodes: 13200, mean episode reward: -116.71032457634807, time: 24.263
agent0_energy_min, agent0_attention_min
[-35.39  -0.05]
agent1_energy_min, agent1_attention_min
[-0.07  0.  ]
13300 50
steps: 664950, episodes: 13300, mean episode reward: -110.14384564783761, time: 24.132
agent0_energy_min, agent0_attention_min
[-3.817e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.02 -0.01]
13400 50
steps: 669950, episodes: 13400, mean episode reward: -102.1149820121878, time: 24.307
agent0_energy_min, agent0_attention_min
[-34.06  -0.04]
agent1_energy_min, agent1_attention_min
[-0.03 -0.02]
13500 50
steps: 674950, episodes: 13500, mean episode reward: -100.7198017206766, time: 24.174
agent0_energy_min, agent0_attention_min
[-3.44e+01 -1.00e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.03]
13600 50
steps: 679950, episodes: 13600, mean episode reward: -96.2672237422057, time: 24.853
agent0_energy_min, agent0_attention_min
[-3.375e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.08]
13700 50
steps: 684950, episodes: 13700, mean episode reward: -104.42679411471394, time: 24.002
agent0_energy_min, agent0_attention_min
[-38.24  -0.04]
agent1_energy_min, agent1_attention_min
[-0.02 -0.07]
13800 50
steps: 689950, episodes: 13800, mean episode reward: -99.39670524472929, time: 24.202
agent0_energy_min, agent0_attention_min
[-3.38e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-0.03 -0.01]
13900 50
steps: 694950, episodes: 13900, mean episode reward: -124.06307970420598, time: 24.151
agent0_energy_min, agent0_attention_min
[-3.543e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.02 -0.03]
14000 50
steps: 699950, episodes: 14000, mean episode reward: -107.55275582271855, time: 24.705
agent0_energy_min, agent0_attention_min
[-38.94  -0.06]
agent1_energy_min, agent1_attention_min
[-0.02 -0.02]
14100 50
steps: 704950, episodes: 14100, mean episode reward: -101.82929248659222, time: 25.071
agent0_energy_min, agent0_attention_min
[-34.86   0.  ]
agent1_energy_min, agent1_attention_min
[-0.03 -0.04]
14200 50
steps: 709950, episodes: 14200, mean episode reward: -108.31122334128747, time: 24.059
agent0_energy_min, agent0_attention_min
[-3.225e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.03  0.  ]
14300 50
steps: 714950, episodes: 14300, mean episode reward: -98.88047082133139, time: 24.226
agent0_energy_min, agent0_attention_min
[-3.293e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.2  -0.08]
14400 50
steps: 719950, episodes: 14400, mean episode reward: -109.06995272666947, time: 24.038
agent0_energy_min, agent0_attention_min
[-29.98  -0.03]
agent1_energy_min, agent1_attention_min
[-0.06 -0.01]
14500 50
steps: 724950, episodes: 14500, mean episode reward: -117.20785659854067, time: 24.328
agent0_energy_min, agent0_attention_min
[-3.648e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.03 -0.03]
14600 50
steps: 729950, episodes: 14600, mean episode reward: -103.28229408184073, time: 24.877
agent0_energy_min, agent0_attention_min
[-35.55  -0.05]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
14700 50
steps: 734950, episodes: 14700, mean episode reward: -101.53851318247261, time: 24.597
agent0_energy_min, agent0_attention_min
[-36.25  -0.07]
agent1_energy_min, agent1_attention_min
[-0.02 -0.01]
14800 50
steps: 739950, episodes: 14800, mean episode reward: -109.1383171358652, time: 23.966
agent0_energy_min, agent0_attention_min
[-39.54  -0.04]
agent1_energy_min, agent1_attention_min
[-0.03 -0.01]
14900 50
steps: 744950, episodes: 14900, mean episode reward: -98.4185311385482, time: 23.7
agent0_energy_min, agent0_attention_min
[-38.17  -0.05]
agent1_energy_min, agent1_attention_min
[-0.12 -0.01]
15000 50
steps: 749950, episodes: 15000, mean episode reward: -99.80274342293862, time: 24.194
agent0_energy_min, agent0_attention_min
[-3.358e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.06 -0.02]
15100 50
steps: 754950, episodes: 15100, mean episode reward: -112.77039530288441, time: 24.854
agent0_energy_min, agent0_attention_min
[-3.405e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.13 -0.02]
15200 50
steps: 759950, episodes: 15200, mean episode reward: -105.74235487721448, time: 23.815
agent0_energy_min, agent0_attention_min
[-3.258e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.04]
15300 50
steps: 764950, episodes: 15300, mean episode reward: -118.48198503942649, time: 24.223
agent0_energy_min, agent0_attention_min
[-33.3   -0.06]
agent1_energy_min, agent1_attention_min
[-0.01 -0.04]
15400 50
steps: 769950, episodes: 15400, mean episode reward: -128.70729358012161, time: 23.877
agent0_energy_min, agent0_attention_min
[-30.65  -0.1 ]
agent1_energy_min, agent1_attention_min
[-0.4 -0.2]
15500 50
steps: 774950, episodes: 15500, mean episode reward: -152.29222889872537, time: 24.414
agent0_energy_min, agent0_attention_min
[-33.57  -0.06]
agent1_energy_min, agent1_attention_min
[ 0.   -0.03]
15600 50
steps: 779950, episodes: 15600, mean episode reward: -108.17940701991054, time: 24.827
agent0_energy_min, agent0_attention_min
[-3.362e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.84 -0.03]
15700 50
steps: 784950, episodes: 15700, mean episode reward: -112.18419320464831, time: 24.535
agent0_energy_min, agent0_attention_min
[-33.74   0.  ]
agent1_energy_min, agent1_attention_min
[-0.64 -0.05]
15800 50
steps: 789950, episodes: 15800, mean episode reward: -114.64556972547602, time: 24.462
agent0_energy_min, agent0_attention_min
[-35.66  -0.04]
agent1_energy_min, agent1_attention_min
[-0.01 -0.04]
agent0_energy_min, agent0_attention_min
[-38.3   -0.29]
agent1_energy_min, agent1_attention_min
[-46.23  -0.06]
12000 50
steps: 599950, episodes: 12000, mean episode reward: -113.37054524505807, time: 25.309
agent0_energy_min, agent0_attention_min
[-42.34  -0.13]
agent1_energy_min, agent1_attention_min
[-45.67  -0.06]
12100 50
steps: 604950, episodes: 12100, mean episode reward: -127.48030651962655, time: 25.667
agent0_energy_min, agent0_attention_min
[-46.23  -0.11]
agent1_energy_min, agent1_attention_min
[-47.21  -0.05]
12200 50
steps: 609950, episodes: 12200, mean episode reward: -134.94966273643166, time: 25.037
agent0_energy_min, agent0_attention_min
[-45.44  -0.16]
agent1_energy_min, agent1_attention_min
[-4.387e+01 -2.000e-02]
12300 50
steps: 614950, episodes: 12300, mean episode reward: -116.17562611013598, time: 24.956
agent0_energy_min, agent0_attention_min
[-44.65  -0.16]
agent1_energy_min, agent1_attention_min
[-45.66  -0.05]
12400 50
steps: 619950, episodes: 12400, mean episode reward: -117.1441666210811, time: 24.921
agent0_energy_min, agent0_attention_min
[-37.7   -0.23]
agent1_energy_min, agent1_attention_min
[-4.337e+01 -3.000e-02]
12500 50
steps: 624950, episodes: 12500, mean episode reward: -104.72590669466392, time: 24.963
agent0_energy_min, agent0_attention_min
[-42.01  -0.21]
agent1_energy_min, agent1_attention_min
[-4.392e+01 -2.000e-02]
12600 50
steps: 629950, episodes: 12600, mean episode reward: -102.58652053636779, time: 25.932
agent0_energy_min, agent0_attention_min
[-39.81  -0.16]
agent1_energy_min, agent1_attention_min
[-4.252e+01 -1.000e-02]
12700 50
steps: 634950, episodes: 12700, mean episode reward: -110.04584400575773, time: 25.013
agent0_energy_min, agent0_attention_min
[-16.5   -0.11]
agent1_energy_min, agent1_attention_min
[-4.385e+01 -4.000e-02]
12800 50
steps: 639950, episodes: 12800, mean episode reward: -89.02652171691119, time: 24.66
agent0_energy_min, agent0_attention_min
[-44.66  -0.07]
agent1_energy_min, agent1_attention_min
[-43.77  -0.05]
12900 50
steps: 644950, episodes: 12900, mean episode reward: -97.74866970539715, time: 24.896
agent0_energy_min, agent0_attention_min
[-26.14  -0.58]
agent1_energy_min, agent1_attention_min
[-4.734e+01 -3.000e-02]
13000 50
steps: 649950, episodes: 13000, mean episode reward: -100.16391893463549, time: 25.405
agent0_energy_min, agent0_attention_min
[-0.66 -0.05]
agent1_energy_min, agent1_attention_min
[-4.741e+01 -3.000e-02]
13100 50
steps: 654950, episodes: 13100, mean episode reward: -106.60793544349421, time: 25.748
agent0_energy_min, agent0_attention_min
[-3.82 -0.14]
agent1_energy_min, agent1_attention_min
[-46.74  -0.05]
13200 50
steps: 659950, episodes: 13200, mean episode reward: -95.17680700634428, time: 24.694
agent0_energy_min, agent0_attention_min
[-41.46  -0.53]
agent1_energy_min, agent1_attention_min
[-4.814e+01 -2.000e-02]
13300 50
steps: 664950, episodes: 13300, mean episode reward: -94.51517848721628, time: 24.932
agent0_energy_min, agent0_attention_min
[-46.95  -0.5 ]
agent1_energy_min, agent1_attention_min
[-4.75e+01 -1.00e-02]
13400 50
steps: 669950, episodes: 13400, mean episode reward: -99.48434529865034, time: 25.199
agent0_energy_min, agent0_attention_min
[-47.36  -0.39]
agent1_energy_min, agent1_attention_min
[-4.446e+01 -4.000e-02]
13500 50
steps: 674950, episodes: 13500, mean episode reward: -102.36420277969111, time: 25.05
agent0_energy_min, agent0_attention_min
[-47.53  -0.25]
agent1_energy_min, agent1_attention_min
[-4.774e+01 -1.000e-02]
13600 50
steps: 679950, episodes: 13600, mean episode reward: -84.0900552393714, time: 25.938
agent0_energy_min, agent0_attention_min
[-42.92  -0.36]
agent1_energy_min, agent1_attention_min
[-4.79e+01 -1.00e-02]
13700 50
steps: 684950, episodes: 13700, mean episode reward: -112.14757209064152, time: 24.732
agent0_energy_min, agent0_attention_min
[-33.12  -0.67]
agent1_energy_min, agent1_attention_min
[-47.78   0.  ]
13800 50
steps: 689950, episodes: 13800, mean episode reward: -94.56240832860462, time: 25.44
agent0_energy_min, agent0_attention_min
[-30.74  -1.19]
agent1_energy_min, agent1_attention_min
[-4.722e+01 -1.000e-02]
13900 50
steps: 694950, episodes: 13900, mean episode reward: -101.78127027072054, time: 24.705
agent0_energy_min, agent0_attention_min
[-37.36  -0.65]
agent1_energy_min, agent1_attention_min
[-4.754e+01 -4.000e-02]
14000 50
steps: 699950, episodes: 14000, mean episode reward: -97.78596085615871, time: 24.524
agent0_energy_min, agent0_attention_min
[-43.88  -1.55]
agent1_energy_min, agent1_attention_min
[-48.12   0.  ]
14100 50
steps: 704950, episodes: 14100, mean episode reward: -103.15433075202591, time: 25.574
agent0_energy_min, agent0_attention_min
[-43.55  -0.98]
agent1_energy_min, agent1_attention_min
[-4.731e+01 -2.000e-02]
14200 50
steps: 709950, episodes: 14200, mean episode reward: -110.50411315040614, time: 24.648
agent0_energy_min, agent0_attention_min
[-43.32  -2.33]
agent1_energy_min, agent1_attention_min
[-4.66e+01 -1.00e-02]
14300 50
steps: 714950, episodes: 14300, mean episode reward: -102.04728806191657, time: 25.121
agent0_energy_min, agent0_attention_min
[-45.21  -1.42]
agent1_energy_min, agent1_attention_min
[-4.868e+01 -2.000e-02]
14400 50
steps: 719950, episodes: 14400, mean episode reward: -98.6063159873995, time: 25.028
agent0_energy_min, agent0_attention_min
[-43.97  -1.95]
agent1_energy_min, agent1_attention_min
[-47.86   0.  ]
14500 50
steps: 724950, episodes: 14500, mean episode reward: -93.94134180465306, time: 24.818
agent0_energy_min, agent0_attention_min
[-42.85  -1.9 ]
agent1_energy_min, agent1_attention_min
[-48.68   0.  ]
14600 50
steps: 729950, episodes: 14600, mean episode reward: -99.17910161317083, time: 25.006
agent0_energy_min, agent0_attention_min
[-45.11  -1.65]
agent1_energy_min, agent1_attention_min
[-44.44   0.  ]
14700 50
steps: 734950, episodes: 14700, mean episode reward: -118.04328210326386, time: 24.999
agent0_energy_min, agent0_attention_min
[-46.08  -0.84]
agent1_energy_min, agent1_attention_min
[-4.788e+01 -1.000e-02]
14800 50
steps: 739950, episodes: 14800, mean episode reward: -82.61525532540553, time: 24.957
agent0_energy_min, agent0_attention_min
[-45.16  -1.67]
agent1_energy_min, agent1_attention_min
[-4.865e+01 -1.000e-02]
14900 50
steps: 744950, episodes: 14900, mean episode reward: -89.70892609407962, time: 25.002
agent0_energy_min, agent0_attention_min
[-43.    -1.58]
agent1_energy_min, agent1_attention_min
[-4.924e+01 -2.000e-02]
15000 50
steps: 749950, episodes: 15000, mean episode reward: -110.6940826892893, time: 25.082
agent0_energy_min, agent0_attention_min
[-22.    -0.88]
agent1_energy_min, agent1_attention_min
[-4.955e+01 -1.000e-02]
15100 50
steps: 754950, episodes: 15100, mean episode reward: -85.6047080128837, time: 25.624
agent0_energy_min, agent0_attention_min
[-19.1   -0.58]
agent1_energy_min, agent1_attention_min
[-4.82e+01 -4.00e-02]
15200 50
steps: 759950, episodes: 15200, mean episode reward: -87.43863622132564, time: 24.333
agent0_energy_min, agent0_attention_min
[-45.2   -2.34]
agent1_energy_min, agent1_attention_min
[-4.783e+01 -2.000e-02]
15300 50
steps: 764950, episodes: 15300, mean episode reward: -87.14455161771205, time: 24.432
agent0_energy_min, agent0_attention_min
[-42.54  -1.06]
agent1_energy_min, agent1_attention_min
[-4.889e+01 -3.000e-02]
15400 50
steps: 769950, episodes: 15400, mean episode reward: -84.51149411609691, time: 24.566
agent0_energy_min, agent0_attention_min
[-44.15  -1.23]
agent1_energy_min, agent1_attention_min
[-4.701e+01 -2.000e-02]
15500 50
steps: 774950, episodes: 15500, mean episode reward: -74.65218927773066, time: 24.929
agent0_energy_min, agent0_attention_min
[-46.86  -0.61]
agent1_energy_min, agent1_attention_min
[-46.47   0.  ]
15600 50
steps: 779950, episodes: 15600, mean episode reward: -75.90784382073961, time: 25.273
agent0_energy_min, agent0_attention_min
[-46.95  -0.81]
agent1_energy_min, agent1_attention_min
[-45.17   0.  ]
15700 50
steps: 784950, episodes: 15700, mean episode reward: -91.3555013298562, time: 25.119
agent0_energy_min, agent0_attention_min
[-46.62  -1.39]
agent1_energy_min, agent1_attention_min
[-4.07e+01 -1.00e-02]
15800 50
steps: 789950, episodes: 15800, mean episode reward: -80.30498592062564, time: 24.665
[-12.55   0.  ]
agent1_energy_min, agent1_attention_min
[-6.15 -0.03]
12200 50
steps: 609950, episodes: 12200, mean episode reward: -130.40302717910205, time: 24.455
agent0_energy_min, agent0_attention_min
[-2.121e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-19.42  -0.26]
12300 50
steps: 614950, episodes: 12300, mean episode reward: -168.26118257147274, time: 25.126
agent0_energy_min, agent0_attention_min
[-24.99  -0.04]
agent1_energy_min, agent1_attention_min
[-18.16  -0.32]
12400 50
steps: 619950, episodes: 12400, mean episode reward: -125.16836216862781, time: 25.545
agent0_energy_min, agent0_attention_min
[-19.31  -0.04]
agent1_energy_min, agent1_attention_min
[-2.92 -0.04]
12500 50
steps: 624950, episodes: 12500, mean episode reward: -136.92977672854812, time: 25.466
agent0_energy_min, agent0_attention_min
[-14.94   0.  ]
agent1_energy_min, agent1_attention_min
[-0.99  0.  ]
12600 50
steps: 629950, episodes: 12600, mean episode reward: -128.9701013341649, time: 25.88
agent0_energy_min, agent0_attention_min
[-12.32   0.  ]
agent1_energy_min, agent1_attention_min
[-1.93 -0.01]
12700 50
steps: 634950, episodes: 12700, mean episode reward: -128.69546610736543, time: 25.253
agent0_energy_min, agent0_attention_min
[-36.04   0.  ]
agent1_energy_min, agent1_attention_min
[-0.08  0.  ]
12800 50
steps: 639950, episodes: 12800, mean episode reward: -130.3438474370446, time: 24.817
agent0_energy_min, agent0_attention_min
[-2.665e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.41 -0.01]
12900 50
steps: 644950, episodes: 12900, mean episode reward: -119.92353117813023, time: 24.823
agent0_energy_min, agent0_attention_min
[-10.5   -0.05]
agent1_energy_min, agent1_attention_min
[-0.11  0.  ]
13000 50
steps: 649950, episodes: 13000, mean episode reward: -128.84149068469404, time: 25.125
agent0_energy_min, agent0_attention_min
[-30.36  -0.52]
agent1_energy_min, agent1_attention_min
[-5.22 -0.05]
13100 50
steps: 654950, episodes: 13100, mean episode reward: -118.92767109259583, time: 25.195
agent0_energy_min, agent0_attention_min
[-38.96  -2.26]
agent1_energy_min, agent1_attention_min
[-31.69  -0.07]
13200 50
steps: 659950, episodes: 13200, mean episode reward: -124.67502700833124, time: 25.055
agent0_energy_min, agent0_attention_min
[-43.73  -0.7 ]
agent1_energy_min, agent1_attention_min
[-3.91 -0.03]
13300 50
steps: 664950, episodes: 13300, mean episode reward: -127.06203709734214, time: 25.536
agent0_energy_min, agent0_attention_min
[-37.    -0.34]
agent1_energy_min, agent1_attention_min
[-2.34  0.  ]
13400 50
steps: 669950, episodes: 13400, mean episode reward: -134.06801102943976, time: 24.914
agent0_energy_min, agent0_attention_min
[-32.68  -0.25]
agent1_energy_min, agent1_attention_min
[-23.31  -0.06]
13500 50
steps: 674950, episodes: 13500, mean episode reward: -132.23601978291333, time: 25.101
agent0_energy_min, agent0_attention_min
[-41.69  -0.16]
agent1_energy_min, agent1_attention_min
[-35.17  -0.08]
13600 50
steps: 679950, episodes: 13600, mean episode reward: -125.36740957675849, time: 24.86
agent0_energy_min, agent0_attention_min
[-32.27  -0.08]
agent1_energy_min, agent1_attention_min
[-35.63  -0.22]
13700 50
steps: 684950, episodes: 13700, mean episode reward: -126.58115423429261, time: 24.772
agent0_energy_min, agent0_attention_min
[-21.55  -0.13]
agent1_energy_min, agent1_attention_min
[-29.95  -0.14]
13800 50
steps: 689950, episodes: 13800, mean episode reward: -134.17388305363477, time: 25.159
agent0_energy_min, agent0_attention_min
[-27.65  -0.3 ]
agent1_energy_min, agent1_attention_min
[-3.56 -0.01]
13900 50
steps: 694950, episodes: 13900, mean episode reward: -129.49668273824756, time: 24.985
agent0_energy_min, agent0_attention_min
[-33.84  -0.37]
agent1_energy_min, agent1_attention_min
[-5.33 -0.04]
14000 50
steps: 699950, episodes: 14000, mean episode reward: -118.2748347702683, time: 24.66
agent0_energy_min, agent0_attention_min
[-33.09  -0.35]
agent1_energy_min, agent1_attention_min
[-2.708e+01 -2.000e-02]
14100 50
steps: 704950, episodes: 14100, mean episode reward: -123.13436619614161, time: 25.163
agent0_energy_min, agent0_attention_min
[-34.61  -0.4 ]
agent1_energy_min, agent1_attention_min
[-18.58  -0.03]
14200 50
steps: 709950, episodes: 14200, mean episode reward: -130.50229092735202, time: 25.116
agent0_energy_min, agent0_attention_min
[-12.    -0.15]
agent1_energy_min, agent1_attention_min
[-20.68   0.  ]
14300 50
steps: 714950, episodes: 14300, mean episode reward: -124.12416206228933, time: 24.004
agent0_energy_min, agent0_attention_min
[-32.23  -0.51]
agent1_energy_min, agent1_attention_min
[-23.45  -0.05]
14400 50
steps: 719950, episodes: 14400, mean episode reward: -115.74857516681715, time: 25.525
agent0_energy_min, agent0_attention_min
[-31.72  -0.65]
agent1_energy_min, agent1_attention_min
[-9.04  0.  ]
14500 50
steps: 724950, episodes: 14500, mean episode reward: -122.14468610643999, time: 24.828
agent0_energy_min, agent0_attention_min
[-32.16  -0.12]
agent1_energy_min, agent1_attention_min
[-3.16 -0.01]
14600 50
steps: 729950, episodes: 14600, mean episode reward: -126.1510604450194, time: 25.793
agent0_energy_min, agent0_attention_min
[-31.08  -0.15]
agent1_energy_min, agent1_attention_min
[-1.78 -0.01]
14700 50
steps: 734950, episodes: 14700, mean episode reward: -124.75648650478945, time: 24.93
agent0_energy_min, agent0_attention_min
[-29.36  -0.03]
agent1_energy_min, agent1_attention_min
[-1.23 -0.02]
14800 50
steps: 739950, episodes: 14800, mean episode reward: -100.61010238664414, time: 24.824
agent0_energy_min, agent0_attention_min
[-36.29  -0.1 ]
agent1_energy_min, agent1_attention_min
[-1.47  0.  ]
14900 50
steps: 744950, episodes: 14900, mean episode reward: -132.9105857701143, time: 25.199
agent0_energy_min, agent0_attention_min
[-33.85  -0.07]
agent1_energy_min, agent1_attention_min
[-3.67  0.  ]
15000 50
steps: 749950, episodes: 15000, mean episode reward: -151.53230383196708, time: 24.709
agent0_energy_min, agent0_attention_min
[-24.06  -0.07]
agent1_energy_min, agent1_attention_min
[-1.49  0.  ]
15100 50
steps: 754950, episodes: 15100, mean episode reward: -119.19698027223627, time: 25.199
agent0_energy_min, agent0_attention_min
[-3.321e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-3.81 -0.01]
15200 50
steps: 759950, episodes: 15200, mean episode reward: -115.30050955718414, time: 24.723
agent0_energy_min, agent0_attention_min
[-3.93e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-14.44  -0.02]
15300 50
steps: 764950, episodes: 15300, mean episode reward: -111.79142412985345, time: 24.522
agent0_energy_min, agent0_attention_min
[-4.43e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-15.11  -0.04]
15400 50
steps: 769950, episodes: 15400, mean episode reward: -124.9687105787749, time: 24.679
agent0_energy_min, agent0_attention_min
[-43.93  -0.12]
agent1_energy_min, agent1_attention_min
[-2.646e+01 -2.000e-02]
15500 50
steps: 774950, episodes: 15500, mean episode reward: -117.16851783745747, time: 24.684
agent0_energy_min, agent0_attention_min
[-4.824e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.93 -0.04]
15600 50
steps: 779950, episodes: 15600, mean episode reward: -108.41931943920189, time: 24.419
agent0_energy_min, agent0_attention_min
[-4.826e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-41.62   0.  ]
15700 50
steps: 784950, episodes: 15700, mean episode reward: -92.66370155015376, time: 24.641
agent0_energy_min, agent0_attention_min
[-47.51  -0.07]
agent1_energy_min, agent1_attention_min
[-34.67  -0.22]
15800 50
steps: 789950, episodes: 15800, mean episode reward: -103.20973742850065, time: 24.413
agent0_energy_min, agent0_attention_min
[-4.807e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-15.57  -0.12]
15900 50
steps: 794950, episodes: 15900, mean episode reward: -97.1593415509867, time: 24.455
agent0_energy_min, agent0_attention_min
[-4.852e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-6.26 -0.02]
16000 50
steps: 799950, episodes: 16000, mean episode reward: -110.52897872711705, time: 24.806
agent0_energy_min, agent0_attention_min
[-4.801e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
agent0_energy_min, agent0_attention_min
[-4.842e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-43.36  -4.66]
15900 50
steps: 794950, episodes: 15900, mean episode reward: -54.792955838986074, time: 25.033
agent0_energy_min, agent0_attention_min
[-49.13  -0.09]
agent1_energy_min, agent1_attention_min
[-42.82  -5.79]
16000 50
steps: 799950, episodes: 16000, mean episode reward: -48.46057108260948, time: 24.33
agent0_energy_min, agent0_attention_min
[-4.929e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-44.86  -1.07]
16100 50
steps: 804950, episodes: 16100, mean episode reward: -40.94568181459646, time: 25.259
agent0_energy_min, agent0_attention_min
[-49.18  -0.05]
agent1_energy_min, agent1_attention_min
[-45.5   -1.81]
16200 50
steps: 809950, episodes: 16200, mean episode reward: -45.06016940877942, time: 24.004
agent0_energy_min, agent0_attention_min
[-4.902e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-45.42  -2.58]
16300 50
steps: 814950, episodes: 16300, mean episode reward: -52.36101538013392, time: 24.602
agent0_energy_min, agent0_attention_min
[-49.15  -0.15]
agent1_energy_min, agent1_attention_min
[-47.43  -0.38]
16400 50
steps: 819950, episodes: 16400, mean episode reward: -46.556528639658644, time: 25.045
agent0_energy_min, agent0_attention_min
[-48.99  -0.18]
agent1_energy_min, agent1_attention_min
[-46.26  -0.87]
16500 50
steps: 824950, episodes: 16500, mean episode reward: -54.053386388317676, time: 24.845
agent0_energy_min, agent0_attention_min
[-4.813e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-45.02  -1.97]
16600 50
steps: 829950, episodes: 16600, mean episode reward: -52.27533765211952, time: 25.195
agent0_energy_min, agent0_attention_min
[-49.02  -0.12]
agent1_energy_min, agent1_attention_min
[-44.02  -2.83]
16700 50
steps: 834950, episodes: 16700, mean episode reward: -42.34671115829799, time: 25.074
agent0_energy_min, agent0_attention_min
[-4.905e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-41.88  -2.53]
16800 50
steps: 839950, episodes: 16800, mean episode reward: -51.46773620918981, time: 24.486
agent0_energy_min, agent0_attention_min
[-49.26  -0.15]
agent1_energy_min, agent1_attention_min
[-42.09  -3.74]
16900 50
steps: 844950, episodes: 16900, mean episode reward: -36.764259010623064, time: 24.724
agent0_energy_min, agent0_attention_min
[-49.61   0.  ]
agent1_energy_min, agent1_attention_min
[-43.88  -4.57]
17000 50
steps: 849950, episodes: 17000, mean episode reward: -52.12393059644638, time: 24.512
agent0_energy_min, agent0_attention_min
[-4.916e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-45.27  -1.24]
17100 50
steps: 854950, episodes: 17100, mean episode reward: -45.35711588657105, time: 25.488
agent0_energy_min, agent0_attention_min
[-49.04  -0.07]
agent1_energy_min, agent1_attention_min
[-43.79  -1.24]
17200 50
steps: 859950, episodes: 17200, mean episode reward: -46.65125885901333, time: 25.217
agent0_energy_min, agent0_attention_min
[-4.846e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-43.78  -3.52]
17300 50
steps: 864950, episodes: 17300, mean episode reward: -41.96049981552708, time: 25.129
agent0_energy_min, agent0_attention_min
[-4.94e+01 -1.00e-02]
agent1_energy_min, agent1_attention_min
[-46.46  -1.82]
17400 50
steps: 869950, episodes: 17400, mean episode reward: -48.07950014909671, time: 24.839
agent0_energy_min, agent0_attention_min
[-4.938e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-45.56  -2.81]
17500 50
steps: 874950, episodes: 17500, mean episode reward: -44.24576791025828, time: 25.383
agent0_energy_min, agent0_attention_min
[-4.947e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-45.48  -3.38]
17600 50
steps: 879950, episodes: 17600, mean episode reward: -45.14890644613004, time: 25.22
agent0_energy_min, agent0_attention_min
[-4.921e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-44.9   -3.11]
17700 50
steps: 884950, episodes: 17700, mean episode reward: -56.392502130240956, time: 24.976
agent0_energy_min, agent0_attention_min
[-4.887e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-46.13  -2.03]
17800 50
steps: 889950, episodes: 17800, mean episode reward: -47.49931892044294, time: 24.684
agent0_energy_min, agent0_attention_min
[-47.78   0.  ]
agent1_energy_min, agent1_attention_min
[-46.1   -2.01]
17900 50
steps: 894950, episodes: 17900, mean episode reward: -44.15349080740867, time: 24.123
agent0_energy_min, agent0_attention_min
[-49.02  -0.05]
agent1_energy_min, agent1_attention_min
[-46.34  -2.73]
18000 50
steps: 899950, episodes: 18000, mean episode reward: -42.41403383629472, time: 24.653
agent0_energy_min, agent0_attention_min
[-4.816e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-40.12  -8.29]
18100 50
steps: 904950, episodes: 18100, mean episode reward: -48.05560336586558, time: 25.314
agent0_energy_min, agent0_attention_min
[-4.925e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-41.19  -6.37]
18200 50
steps: 909950, episodes: 18200, mean episode reward: -76.48987233933228, time: 24.552
agent0_energy_min, agent0_attention_min
[-48.81  -0.05]
agent1_energy_min, agent1_attention_min
[-43.8   -4.22]
18300 50
steps: 914950, episodes: 18300, mean episode reward: -48.6701659792812, time: 24.964
agent0_energy_min, agent0_attention_min
[-48.58  -0.34]
agent1_energy_min, agent1_attention_min
[-42.48  -5.47]
18400 50
steps: 919950, episodes: 18400, mean episode reward: -45.336717923291665, time: 24.672
agent0_energy_min, agent0_attention_min
[-48.94  -0.25]
agent1_energy_min, agent1_attention_min
[-45.61  -3.23]
18500 50
steps: 924950, episodes: 18500, mean episode reward: -48.52349226239818, time: 24.913
agent0_energy_min, agent0_attention_min
[-49.26  -0.29]
agent1_energy_min, agent1_attention_min
[-45.98  -2.09]
18600 50
steps: 929950, episodes: 18600, mean episode reward: -43.355467213113315, time: 25.094
agent0_energy_min, agent0_attention_min
[-49.38  -0.12]
agent1_energy_min, agent1_attention_min
[-46.72  -1.91]
18700 50
steps: 934950, episodes: 18700, mean episode reward: -38.73421645721779, time: 24.988
agent0_energy_min, agent0_attention_min
[-48.16  -0.08]
agent1_energy_min, agent1_attention_min
[-48.17  -1.04]
18800 50
steps: 939950, episodes: 18800, mean episode reward: -52.605100185891054, time: 25.012
agent0_energy_min, agent0_attention_min
[-48.1   -0.07]
agent1_energy_min, agent1_attention_min
[-41.61  -6.97]
18900 50
steps: 944950, episodes: 18900, mean episode reward: -52.004875632951645, time: 24.77
agent0_energy_min, agent0_attention_min
[-48.71  -0.36]
agent1_energy_min, agent1_attention_min
[-43.79  -4.97]
19000 50
steps: 949950, episodes: 19000, mean episode reward: -48.62165380378785, time: 24.518
agent0_energy_min, agent0_attention_min
[-4.942e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-43.67  -4.06]
19100 50
steps: 954950, episodes: 19100, mean episode reward: -47.54417307540816, time: 25.032
agent0_energy_min, agent0_attention_min
[-49.32  -0.05]
agent1_energy_min, agent1_attention_min
[-45.27  -3.34]
19200 50
steps: 959950, episodes: 19200, mean episode reward: -63.30363533681416, time: 24.811
agent0_energy_min, agent0_attention_min
[-4.911e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-42.67  -5.68]
19300 50
steps: 964950, episodes: 19300, mean episode reward: -52.12372889204357, time: 24.755
agent0_energy_min, agent0_attention_min
[-4.919e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-42.62  -5.63]
19400 50
steps: 969950, episodes: 19400, mean episode reward: -45.11773041931509, time: 25.151
agent0_energy_min, agent0_attention_min
[-49.14  -0.05]
agent1_energy_min, agent1_attention_min
[-43.73  -3.32]
19500 50
steps: 974950, episodes: 19500, mean episode reward: -47.42113532892078, time: 24.584
agent0_energy_min, agent0_attention_min
[-49.02  -0.15]
agent1_energy_min, agent1_attention_min
[-46.5   -1.83]
19600 50
steps: 979950, episodes: 19600, mean episode reward: -48.297371555564204, time: 25.577
agent0_energy_min, agent0_attention_min
[-48.98  -0.08]
agent1_energy_min, agent1_attention_min
[-41.51  -2.92]
19700 50
steps: 984950, episodes: 19700, mean episode reward: -37.59468634805798, time: 24.491 50
steps: 799950, episodes: 16000, mean episode reward: -48.05960501503422, time: 24.547
agent0_energy_min, agent0_attention_min
[-49.19  -0.45]
agent1_energy_min, agent1_attention_min
[-48.8  -0.6]
16100 50
steps: 804950, episodes: 16100, mean episode reward: -50.827246130054284, time: 24.844
agent0_energy_min, agent0_attention_min
[-49.27  -0.53]
agent1_energy_min, agent1_attention_min
[-48.36  -0.97]
16200 50
steps: 809950, episodes: 16200, mean episode reward: -51.16610382878499, time: 24.632
agent0_energy_min, agent0_attention_min
[-49.17  -0.57]
agent1_energy_min, agent1_attention_min
[-48.08  -1.41]
16300 50
steps: 814950, episodes: 16300, mean episode reward: -49.953993151488575, time: 24.224
agent0_energy_min, agent0_attention_min
[-49.09  -0.27]
agent1_energy_min, agent1_attention_min
[-48.87  -0.87]
16400 50
steps: 819950, episodes: 16400, mean episode reward: -44.12756054098487, time: 23.85
agent0_energy_min, agent0_attention_min
[-49.16  -0.82]
agent1_energy_min, agent1_attention_min
[-48.44  -1.2 ]
16500 50
steps: 824950, episodes: 16500, mean episode reward: -51.94473424757061, time: 24.92
agent0_energy_min, agent0_attention_min
[-49.67  -0.06]
agent1_energy_min, agent1_attention_min
[-48.21  -1.35]
16600 50
steps: 829950, episodes: 16600, mean episode reward: -50.32380100494963, time: 24.829
agent0_energy_min, agent0_attention_min
[-49.6   -0.15]
agent1_energy_min, agent1_attention_min
[-47.73  -1.21]
16700 50
steps: 834950, episodes: 16700, mean episode reward: -56.43335247440462, time: 24.519
agent0_energy_min, agent0_attention_min
[-49.85  -0.12]
agent1_energy_min, agent1_attention_min
[-47.85  -1.69]
16800 50
steps: 839950, episodes: 16800, mean episode reward: -52.71066443190943, time: 24.022
agent0_energy_min, agent0_attention_min
[-49.79  -0.19]
agent1_energy_min, agent1_attention_min
[-48.36  -1.02]
16900 50
steps: 844950, episodes: 16900, mean episode reward: -43.637091276243574, time: 24.116
agent0_energy_min, agent0_attention_min
[-49.24  -0.74]
agent1_energy_min, agent1_attention_min
[-48.6   -0.92]
17000 50
steps: 849950, episodes: 17000, mean episode reward: -54.998958980256255, time: 24.313
agent0_energy_min, agent0_attention_min
[-49.21  -0.79]
agent1_energy_min, agent1_attention_min
[-47.62  -1.28]
17100 50
steps: 854950, episodes: 17100, mean episode reward: -57.17554038510817, time: 24.41
agent0_energy_min, agent0_attention_min
[-49.82  -0.17]
agent1_energy_min, agent1_attention_min
[-48.06  -1.28]
17200 50
steps: 859950, episodes: 17200, mean episode reward: -43.7594600994203, time: 24.292
agent0_energy_min, agent0_attention_min
[-49.63  -0.24]
agent1_energy_min, agent1_attention_min
[-47.92  -1.54]
17300 50
steps: 864950, episodes: 17300, mean episode reward: -58.22176788088184, time: 24.677
agent0_energy_min, agent0_attention_min
[-49.26  -0.73]
agent1_energy_min, agent1_attention_min
[-47.5  -1.9]
17400 50
steps: 869950, episodes: 17400, mean episode reward: -54.26737236602838, time: 24.719
agent0_energy_min, agent0_attention_min
[-49.3   -0.49]
agent1_energy_min, agent1_attention_min
[-47.81  -1.68]
17500 50
steps: 874950, episodes: 17500, mean episode reward: -47.42743284847838, time: 25.227
agent0_energy_min, agent0_attention_min
[-49.32  -0.33]
agent1_energy_min, agent1_attention_min
[-47.55  -1.84]
17600 50
steps: 879950, episodes: 17600, mean episode reward: -37.06552356188525, time: 25.587
agent0_energy_min, agent0_attention_min
[-49.12  -0.71]
agent1_energy_min, agent1_attention_min
[-48.54  -1.18]
17700 50
steps: 884950, episodes: 17700, mean episode reward: -47.538119954159555, time: 23.854
agent0_energy_min, agent0_attention_min
[-48.97  -0.57]
agent1_energy_min, agent1_attention_min
[-48.83  -0.82]
17800 50
steps: 889950, episodes: 17800, mean episode reward: -46.90962687127165, time: 24.634
agent0_energy_min, agent0_attention_min
[-49.03  -0.89]
agent1_energy_min, agent1_attention_min
[-48.4   -1.23]
17900 50
steps: 894950, episodes: 17900, mean episode reward: -51.86484094231271, time: 24.064
agent0_energy_min, agent0_attention_min
[-48.43  -1.29]
agent1_energy_min, agent1_attention_min
[-47.91  -1.34]
18000 50
steps: 899950, episodes: 18000, mean episode reward: -70.20600532437476, time: 24.123
agent0_energy_min, agent0_attention_min
[-49.03  -0.87]
agent1_energy_min, agent1_attention_min
[-47.06  -1.46]
18100 50
steps: 904950, episodes: 18100, mean episode reward: -42.910013000039584, time: 26.753
agent0_energy_min, agent0_attention_min
[-49.32  -0.64]
agent1_energy_min, agent1_attention_min
[-48.64  -1.07]
18200 50
steps: 909950, episodes: 18200, mean episode reward: -48.50696946338358, time: 24.421
agent0_energy_min, agent0_attention_min
[-48.66  -0.95]
agent1_energy_min, agent1_attention_min
[-48.66  -0.79]
18300 50
steps: 914950, episodes: 18300, mean episode reward: -44.08229869803488, time: 24.191
agent0_energy_min, agent0_attention_min
[-48.19  -1.74]
agent1_energy_min, agent1_attention_min
[-48.55  -0.8 ]
18400 50
steps: 919950, episodes: 18400, mean episode reward: -56.324459118499014, time: 24.186
agent0_energy_min, agent0_attention_min
[-48.46  -1.32]
agent1_energy_min, agent1_attention_min
[-48.59  -0.96]
18500 50
steps: 924950, episodes: 18500, mean episode reward: -54.621195473058506, time: 24.578
agent0_energy_min, agent0_attention_min
[-47.5   -2.43]
agent1_energy_min, agent1_attention_min
[-48.63  -0.78]
18600 50
steps: 929950, episodes: 18600, mean episode reward: -128.7803988856682, time: 25.127
agent0_energy_min, agent0_attention_min
[-47.22  -2.32]
agent1_energy_min, agent1_attention_min
[-48.51  -1.15]
18700 50
steps: 934950, episodes: 18700, mean episode reward: -52.45155617252999, time: 23.601
agent0_energy_min, agent0_attention_min
[-46.78  -3.21]
agent1_energy_min, agent1_attention_min
[-48.52  -1.25]
18800 50
steps: 939950, episodes: 18800, mean episode reward: -58.624506442949034, time: 24.169
agent0_energy_min, agent0_attention_min
[-47.16  -2.74]
agent1_energy_min, agent1_attention_min
[-48.44  -1.13]
18900 50
steps: 944950, episodes: 18900, mean episode reward: -50.487864076889444, time: 25.152
agent0_energy_min, agent0_attention_min
[-47.41  -2.52]
agent1_energy_min, agent1_attention_min
[-48.44  -1.16]
19000 50
steps: 949950, episodes: 19000, mean episode reward: -51.45798684170114, time: 24.673
agent0_energy_min, agent0_attention_min
[-48.07  -1.25]
agent1_energy_min, agent1_attention_min
[-48.29  -1.13]
19100 50
steps: 954950, episodes: 19100, mean episode reward: -47.7542733783034, time: 25.016
agent0_energy_min, agent0_attention_min
[-48.18  -1.67]
agent1_energy_min, agent1_attention_min
[-48.61  -0.93]
19200 50
steps: 959950, episodes: 19200, mean episode reward: -56.15992961663154, time: 24.241
agent0_energy_min, agent0_attention_min
[-47.95  -1.53]
agent1_energy_min, agent1_attention_min
[-48.99  -0.79]
19300 50
steps: 964950, episodes: 19300, mean episode reward: -74.43068688366098, time: 24.337
agent0_energy_min, agent0_attention_min
[-45.69  -4.24]
agent1_energy_min, agent1_attention_min
[-48.    -1.16]
19400 50
steps: 969950, episodes: 19400, mean episode reward: -60.75662392371367, time: 24.073
agent0_energy_min, agent0_attention_min
[-46.48  -3.4 ]
agent1_energy_min, agent1_attention_min
[-48.58  -1.11]
19500 50
steps: 974950, episodes: 19500, mean episode reward: -49.57095132320985, time: 24.158
agent0_energy_min, agent0_attention_min
[-48.6   -1.21]
agent1_energy_min, agent1_attention_min
[-48.64  -0.9 ]
19600 50
steps: 979950, episodes: 19600, mean episode reward: -64.17346197326043, time: 24.812
agent0_energy_min, agent0_attention_min
[-49.11  -0.74]
agent1_energy_min, agent1_attention_min
[-48.41  -0.8 ]
19700 50
steps: 984950, episodes: 19700, mean episode reward: -87.19732673169008, time: 24.186
agent0_energy_min, agent0_attention_min
[-47.39  -2.25]
agent1_energy_min, agent1_attention_min
[-48.64  -0.52]
19800 50
steps: 989950, episodes: 19800, mean episode reward: -67.20764655316746, time: 24.68
agent0_energy_min, agent0_attention_min
[-48.39  -0.92]
agent1_energy_min, agent1_attention_min
[-47.68  -1.03]
19900 50
steps: 994950, episodes: 19900, mean episode reward: -51.34587263595372, time: 24.181
agent0_energy_min, agent0_attention_min
[-4.745e+01 -4.000e-02]
16000 50
steps: 799950, episodes: 16000, mean episode reward: -52.27063199953091, time: 24.514
agent0_energy_min, agent0_attention_min
[-35.06 -14.13]
agent1_energy_min, agent1_attention_min
[-4.784e+01 -1.000e-02]
16100 50
steps: 804950, episodes: 16100, mean episode reward: -76.16245799112149, time: 25.512
agent0_energy_min, agent0_attention_min
[-37.93 -11.14]
agent1_energy_min, agent1_attention_min
[-44.82  -0.27]
16200 50
steps: 809950, episodes: 16200, mean episode reward: -49.308761958086826, time: 24.611
agent0_energy_min, agent0_attention_min
[-36.34  -9.52]
agent1_energy_min, agent1_attention_min
[-46.51  -0.12]
16300 50
steps: 814950, episodes: 16300, mean episode reward: -63.508347480165554, time: 23.903
agent0_energy_min, agent0_attention_min
[-47.43  -1.19]
agent1_energy_min, agent1_attention_min
[-46.73  -0.2 ]
16400 50
steps: 819950, episodes: 16400, mean episode reward: -64.25668738911843, time: 24.757
agent0_energy_min, agent0_attention_min
[-46.84  -1.23]
agent1_energy_min, agent1_attention_min
[-47.1  -0.2]
16500 50
steps: 824950, episodes: 16500, mean episode reward: -43.21235496643649, time: 24.31
agent0_energy_min, agent0_attention_min
[-39.93  -7.75]
agent1_energy_min, agent1_attention_min
[-48.53  -0.08]
16600 50
steps: 829950, episodes: 16600, mean episode reward: -52.66020173594644, time: 24.803
agent0_energy_min, agent0_attention_min
[-37.61  -9.68]
agent1_energy_min, agent1_attention_min
[-48.72  -0.11]
16700 50
steps: 834950, episodes: 16700, mean episode reward: -44.14044099335638, time: 24.429
agent0_energy_min, agent0_attention_min
[-45.93  -2.36]
agent1_energy_min, agent1_attention_min
[-47.96  -0.16]
16800 50
steps: 839950, episodes: 16800, mean episode reward: -53.67833413807485, time: 24.582
agent0_energy_min, agent0_attention_min
[-47.39  -2.46]
agent1_energy_min, agent1_attention_min
[-4.793e+01 -3.000e-02]
16900 50
steps: 844950, episodes: 16900, mean episode reward: -43.1226244530801, time: 24.212
agent0_energy_min, agent0_attention_min
[-47.94  -1.24]
agent1_energy_min, agent1_attention_min
[-47.99  -0.13]
17000 50
steps: 849950, episodes: 17000, mean episode reward: -52.2397965941599, time: 26.038
agent0_energy_min, agent0_attention_min
[-47.    -2.15]
agent1_energy_min, agent1_attention_min
[-48.12  -0.09]
17100 50
steps: 854950, episodes: 17100, mean episode reward: -64.58575929543348, time: 25.392
agent0_energy_min, agent0_attention_min
[-47.14  -1.83]
agent1_energy_min, agent1_attention_min
[-48.11  -0.2 ]
17200 50
steps: 859950, episodes: 17200, mean episode reward: -55.37286906543561, time: 24.905
agent0_energy_min, agent0_attention_min
[-47.88  -1.48]
agent1_energy_min, agent1_attention_min
[-47.72  -0.2 ]
17300 50
steps: 864950, episodes: 17300, mean episode reward: -42.916518016454276, time: 25.077
agent0_energy_min, agent0_attention_min
[-47.23  -0.95]
agent1_energy_min, agent1_attention_min
[-4.845e+01 -3.000e-02]
17400 50
steps: 869950, episodes: 17400, mean episode reward: -44.35272092641815, time: 24.854
agent0_energy_min, agent0_attention_min
[-47.24  -2.  ]
agent1_energy_min, agent1_attention_min
[-48.34   0.  ]
17500 50
steps: 874950, episodes: 17500, mean episode reward: -43.559176776894354, time: 24.54
agent0_energy_min, agent0_attention_min
[-47.95  -1.18]
agent1_energy_min, agent1_attention_min
[-48.64   0.  ]
17600 50
steps: 879950, episodes: 17600, mean episode reward: -43.04732585023551, time: 24.794
agent0_energy_min, agent0_attention_min
[-48.79  -0.63]
agent1_energy_min, agent1_attention_min
[-48.43   0.  ]
17700 50
steps: 884950, episodes: 17700, mean episode reward: -42.13522402952474, time: 24.864
agent0_energy_min, agent0_attention_min
[-48.42  -0.87]
agent1_energy_min, agent1_attention_min
[-49.18   0.  ]
17800 50
steps: 889950, episodes: 17800, mean episode reward: -46.84726234631037, time: 24.1
agent0_energy_min, agent0_attention_min
[-47.41  -1.29]
agent1_energy_min, agent1_attention_min
[-4.808e+01 -2.000e-02]
17900 50
steps: 894950, episodes: 17900, mean episode reward: -60.187342416688104, time: 24.547
agent0_energy_min, agent0_attention_min
[-47.38  -1.17]
agent1_energy_min, agent1_attention_min
[-4.833e+01 -3.000e-02]
18000 50
steps: 899950, episodes: 18000, mean episode reward: -38.97591956853056, time: 26.814
agent0_energy_min, agent0_attention_min
[-47.75  -0.59]
agent1_energy_min, agent1_attention_min
[-4.913e+01 -1.000e-02]
18100 50
steps: 904950, episodes: 18100, mean episode reward: -53.39616453678325, time: 25.208
agent0_energy_min, agent0_attention_min
[-48.31  -1.24]
agent1_energy_min, agent1_attention_min
[-4.892e+01 -1.000e-02]
18200 50
steps: 909950, episodes: 18200, mean episode reward: -42.572787182248696, time: 24.072
agent0_energy_min, agent0_attention_min
[-47.23  -1.12]
agent1_energy_min, agent1_attention_min
[-48.35   0.  ]
18300 50
steps: 914950, episodes: 18300, mean episode reward: -54.222567489495766, time: 24.359
agent0_energy_min, agent0_attention_min
[-47.31  -1.11]
agent1_energy_min, agent1_attention_min
[-4.865e+01 -2.000e-02]
18400 50
steps: 919950, episodes: 18400, mean episode reward: -45.120141299348504, time: 24.294
agent0_energy_min, agent0_attention_min
[-48.64  -0.95]
agent1_energy_min, agent1_attention_min
[-4.885e+01 -2.000e-02]
18500 50
steps: 924950, episodes: 18500, mean episode reward: -141.10029627885461, time: 24.601
agent0_energy_min, agent0_attention_min
[-49.14  -0.4 ]
agent1_energy_min, agent1_attention_min
[-4.879e+01 -1.000e-02]
18600 50
steps: 929950, episodes: 18600, mean episode reward: -45.065523312218566, time: 24.896
agent0_energy_min, agent0_attention_min
[-48.96  -0.91]
agent1_energy_min, agent1_attention_min
[-4.799e+01 -1.000e-02]
18700 50
steps: 934950, episodes: 18700, mean episode reward: -45.01999768365773, time: 24.134
agent0_energy_min, agent0_attention_min
[-48.46  -0.84]
agent1_energy_min, agent1_attention_min
[-48.74   0.  ]
18800 50
steps: 939950, episodes: 18800, mean episode reward: -45.604900948127096, time: 24.71
agent0_energy_min, agent0_attention_min
[-48.41  -0.31]
agent1_energy_min, agent1_attention_min
[-4.84e+01 -3.00e-02]
18900 50
steps: 944950, episodes: 18900, mean episode reward: -42.238974707231755, time: 24.404
agent0_energy_min, agent0_attention_min
[-48.48  -0.7 ]
agent1_energy_min, agent1_attention_min
[-4.873e+01 -2.000e-02]
19000 50
steps: 949950, episodes: 19000, mean episode reward: -51.525298610639055, time: 24.696
agent0_energy_min, agent0_attention_min
[-47.17  -1.6 ]
agent1_energy_min, agent1_attention_min
[-4.843e+01 -3.000e-02]
19100 50
steps: 954950, episodes: 19100, mean episode reward: -46.0900182859937, time: 24.817
agent0_energy_min, agent0_attention_min
[-46.37  -1.3 ]
agent1_energy_min, agent1_attention_min
[-4.828e+01 -1.000e-02]
19200 50
steps: 959950, episodes: 19200, mean episode reward: -42.58076172979436, time: 24.596
agent0_energy_min, agent0_attention_min
[-45.17  -1.37]
agent1_energy_min, agent1_attention_min
[-48.69   0.  ]
19300 50
steps: 964950, episodes: 19300, mean episode reward: -40.98632257814454, time: 24.4
agent0_energy_min, agent0_attention_min
[-47.07  -1.09]
agent1_energy_min, agent1_attention_min
[-4.866e+01 -1.000e-02]
19400 50
steps: 969950, episodes: 19400, mean episode reward: -64.84423789874464, time: 24.616
agent0_energy_min, agent0_attention_min
[-44.97  -1.5 ]
agent1_energy_min, agent1_attention_min
[-4.84e+01 -1.00e-02]
19500 50
steps: 974950, episodes: 19500, mean episode reward: -59.86672523780062, time: 24.465
agent0_energy_min, agent0_attention_min
[-46.49  -1.46]
agent1_energy_min, agent1_attention_min
[-48.37   0.  ]
19600 50
steps: 979950, episodes: 19600, mean episode reward: -64.32159579523336, time: 24.858
agent0_energy_min, agent0_attention_min
[-45.62  -1.61]
agent1_energy_min, agent1_attention_min
[-48.44   0.  ]
19700 50
steps: 984950, episodes: 19700, mean episode reward: -66.56212162661807, time: 24.675
agent0_energy_min, agent0_attention_min
[-46.46  -0.92]
agent1_energy_min, agent1_attention_min
[-4.823e+01 -3.000e-02]
19800 50
steps: 989950, episodes: 19800, mean episode reward: -53.76259256806841, time: 24.812
agent0_energy_min, agent0_attention_min
[-47.21  -0.82]
agent1_energy_min, agent1_attention_min
agent0_energy_min, agent0_attention_min
[-42.34  -7.61]
agent1_energy_min, agent1_attention_min
[-48.12  -1.27]
16100 50
steps: 804950, episodes: 16100, mean episode reward: -75.92997405634243, time: 24.647
agent0_energy_min, agent0_attention_min
[-41.92  -7.95]
agent1_energy_min, agent1_attention_min
[-47.7   -1.47]
16200 50
steps: 809950, episodes: 16200, mean episode reward: -67.24788518585675, time: 24.852
agent0_energy_min, agent0_attention_min
[-40.91  -9.03]
agent1_energy_min, agent1_attention_min
[-47.37  -1.73]
16300 50
steps: 814950, episodes: 16300, mean episode reward: -81.23081063719299, time: 23.598
agent0_energy_min, agent0_attention_min
[-39.84  -9.3 ]
agent1_energy_min, agent1_attention_min
[-47.61  -1.73]
16400 50
steps: 819950, episodes: 16400, mean episode reward: -73.91755016229565, time: 24.391
agent0_energy_min, agent0_attention_min
[-43.66  -6.05]
agent1_energy_min, agent1_attention_min
[-47.83  -1.41]
16500 50
steps: 824950, episodes: 16500, mean episode reward: -89.90390289233767, time: 24.529
agent0_energy_min, agent0_attention_min
[-43.68  -5.53]
agent1_energy_min, agent1_attention_min
[-48.38  -0.88]
16600 50
steps: 829950, episodes: 16600, mean episode reward: -73.62707799518118, time: 24.394
agent0_energy_min, agent0_attention_min
[-44.18  -5.63]
agent1_energy_min, agent1_attention_min
[-48.29  -1.22]
16700 50
steps: 834950, episodes: 16700, mean episode reward: -65.9085102105029, time: 24.372
agent0_energy_min, agent0_attention_min
[-42.24  -7.65]
agent1_energy_min, agent1_attention_min
[-46.09  -3.62]
16800 50
steps: 839950, episodes: 16800, mean episode reward: -73.9256583739299, time: 24.643
agent0_energy_min, agent0_attention_min
[-43.78  -6.11]
agent1_energy_min, agent1_attention_min
[-46.66  -3.01]
16900 50
steps: 844950, episodes: 16900, mean episode reward: -62.99981364794632, time: 23.878
agent0_energy_min, agent0_attention_min
[-41.02  -8.86]
agent1_energy_min, agent1_attention_min
[-47.94  -1.87]
17000 50
steps: 849950, episodes: 17000, mean episode reward: -64.77295706089744, time: 24.437
agent0_energy_min, agent0_attention_min
[-40.    -9.77]
agent1_energy_min, agent1_attention_min
[-45.55  -4.33]
17100 50
steps: 854950, episodes: 17100, mean episode reward: -64.6162715907673, time: 23.778
agent0_energy_min, agent0_attention_min
[-40.89  -9.01]
agent1_energy_min, agent1_attention_min
[-44.43  -5.19]
17200 50
steps: 859950, episodes: 17200, mean episode reward: -72.71577948809089, time: 24.617
agent0_energy_min, agent0_attention_min
[-41.42  -8.44]
agent1_energy_min, agent1_attention_min
[-45.47  -4.24]
17300 50
steps: 864950, episodes: 17300, mean episode reward: -70.76922854105005, time: 24.986
agent0_energy_min, agent0_attention_min
[-41.49  -8.35]
agent1_energy_min, agent1_attention_min
[-44.28  -5.39]
17400 50
steps: 869950, episodes: 17400, mean episode reward: -72.82479384456762, time: 24.052
agent0_energy_min, agent0_attention_min
[-42.95  -6.92]
agent1_energy_min, agent1_attention_min
[-46.78  -3.15]
17500 50
steps: 874950, episodes: 17500, mean episode reward: -70.40009231875584, time: 24.605
agent0_energy_min, agent0_attention_min
[-41.75  -8.23]
agent1_energy_min, agent1_attention_min
[-48.46  -1.39]
17600 50
steps: 879950, episodes: 17600, mean episode reward: -67.19716170021233, time: 25.156
agent0_energy_min, agent0_attention_min
[-40.17  -9.79]
agent1_energy_min, agent1_attention_min
[-47.84  -1.66]
17700 50
steps: 884950, episodes: 17700, mean episode reward: -73.17385921595184, time: 24.602
agent0_energy_min, agent0_attention_min
[-40.17  -9.76]
agent1_energy_min, agent1_attention_min
[-46.8   -2.66]
17800 50
steps: 889950, episodes: 17800, mean episode reward: -63.48165260324388, time: 24.368
agent0_energy_min, agent0_attention_min
[-40.38  -9.34]
agent1_energy_min, agent1_attention_min
[-47.71  -2.06]
17900 50
steps: 894950, episodes: 17900, mean episode reward: -64.17706013832107, time: 24.184
agent0_energy_min, agent0_attention_min
[-40.32  -9.42]
agent1_energy_min, agent1_attention_min
[-47.49  -2.1 ]
18000 50
steps: 899950, episodes: 18000, mean episode reward: -59.1594354339707, time: 23.984
agent0_energy_min, agent0_attention_min
[-36.7  -13.22]
agent1_energy_min, agent1_attention_min
[-47.77  -1.78]
18100 50
steps: 904950, episodes: 18100, mean episode reward: -63.239049243788784, time: 24.196
agent0_energy_min, agent0_attention_min
[-38.36 -11.57]
agent1_energy_min, agent1_attention_min
[-47.8   -1.79]
18200 50
steps: 909950, episodes: 18200, mean episode reward: -67.11513007897042, time: 24.611
agent0_energy_min, agent0_attention_min
[-34.78 -15.14]
agent1_energy_min, agent1_attention_min
[-48.16  -1.11]
18300 50
steps: 914950, episodes: 18300, mean episode reward: -77.83973564136348, time: 23.85
agent0_energy_min, agent0_attention_min
[-39.05 -10.83]
agent1_energy_min, agent1_attention_min
[-49.    -0.91]
18400 50
steps: 919950, episodes: 18400, mean episode reward: -67.60087342595953, time: 24.221
agent0_energy_min, agent0_attention_min
[-32.07 -17.76]
agent1_energy_min, agent1_attention_min
[-49.15  -0.72]
18500 50
steps: 924950, episodes: 18500, mean episode reward: -66.45220830581037, time: 24.568
agent0_energy_min, agent0_attention_min
[-35.22 -14.71]
agent1_energy_min, agent1_attention_min
[-48.56  -1.09]
18600 50
steps: 929950, episodes: 18600, mean episode reward: -61.422383474530534, time: 24.393
agent0_energy_min, agent0_attention_min
[-37.32 -12.63]
agent1_energy_min, agent1_attention_min
[-47.13  -2.45]
18700 50
steps: 934950, episodes: 18700, mean episode reward: -70.50160351627423, time: 24.332
agent0_energy_min, agent0_attention_min
[-33.08 -16.87]
agent1_energy_min, agent1_attention_min
[-45.21  -4.71]
18800 50
steps: 939950, episodes: 18800, mean episode reward: -62.75928163624198, time: 24.015
agent0_energy_min, agent0_attention_min
[-35.5  -14.39]
agent1_energy_min, agent1_attention_min
[-45.34  -4.45]
18900 50
steps: 944950, episodes: 18900, mean episode reward: -60.46075475172951, time: 24.697
agent0_energy_min, agent0_attention_min
[-37.28 -12.58]
agent1_energy_min, agent1_attention_min
[-42.7   -7.11]
19000 50
steps: 949950, episodes: 19000, mean episode reward: -62.91833278463752, time: 23.934
agent0_energy_min, agent0_attention_min
[-36.55 -13.36]
agent1_energy_min, agent1_attention_min
[-44.23  -5.35]
19100 50
steps: 954950, episodes: 19100, mean episode reward: -74.11773709087119, time: 24.936
agent0_energy_min, agent0_attention_min
[-32.95 -17.01]
agent1_energy_min, agent1_attention_min
[-45.07  -3.9 ]
19200 50
steps: 959950, episodes: 19200, mean episode reward: -65.21389647373952, time: 24.125
agent0_energy_min, agent0_attention_min
[-34.87 -15.04]
agent1_energy_min, agent1_attention_min
[-46.96  -2.44]
19300 50
steps: 964950, episodes: 19300, mean episode reward: -62.669670976439384, time: 24.46
agent0_energy_min, agent0_attention_min
[-29.96 -19.97]
agent1_energy_min, agent1_attention_min
[-47.04  -2.72]
19400 50
steps: 969950, episodes: 19400, mean episode reward: -57.655797447317454, time: 24.066
agent0_energy_min, agent0_attention_min
[-27.05 -22.89]
agent1_energy_min, agent1_attention_min
[-48.1  -1.7]
19500 50
steps: 974950, episodes: 19500, mean episode reward: -59.13758056239214, time: 24.187
agent0_energy_min, agent0_attention_min
[-28.25 -21.64]
agent1_energy_min, agent1_attention_min
[-47.42  -2.39]
19600 50
steps: 979950, episodes: 19600, mean episode reward: -64.64146480608363, time: 24.782
agent0_energy_min, agent0_attention_min
[-25.07 -24.79]
agent1_energy_min, agent1_attention_min
[-45.23  -3.87]
19700 50
steps: 984950, episodes: 19700, mean episode reward: -66.23206930702887, time: 24.39
agent0_energy_min, agent0_attention_min
[-24.75 -25.13]
agent1_energy_min, agent1_attention_min
[-47.99  -1.51]
19800 50
steps: 989950, episodes: 19800, mean episode reward: -71.66837347141201, time: 24.031
agent0_energy_min, agent0_attention_min
[-24.34 -25.62]
agent1_energy_min, agent1_attention_min
[-46.54  -3.16]
19900 50
steps: 994950, episodes: 19900, mean episode reward: -71.17285896270303, time: 24.455
agent0_energy_min, agent0_attention_min
[-29.54 -20.36]
agent1_energy_min, agent1_attention_min
[-45.62  -3.82]
20000 50
steps: 999950, episodes: 20000, mean episode reward: -68.05108441884988, time: 24.032
agent0_energy_min, agent0_attention_min
[-48.8   -0.22]
agent1_energy_min, agent1_attention_min
[-21.17 -25.5 ]
16100 50
steps: 804950, episodes: 16100, mean episode reward: -75.592718560803, time: 24.921
agent0_energy_min, agent0_attention_min
[-49.26  -0.26]
agent1_energy_min, agent1_attention_min
[-16.15 -29.14]
16200 50
steps: 809950, episodes: 16200, mean episode reward: -82.05516248094644, time: 23.782
agent0_energy_min, agent0_attention_min
[-49.22  -0.41]
agent1_energy_min, agent1_attention_min
[-13.81 -31.35]
16300 50
steps: 814950, episodes: 16300, mean episode reward: -78.65861602407207, time: 24.161
agent0_energy_min, agent0_attention_min
[-49.12  -0.29]
agent1_energy_min, agent1_attention_min
[-18.7 -28.2]
16400 50
steps: 819950, episodes: 16400, mean episode reward: -71.32015751096748, time: 24.352
agent0_energy_min, agent0_attention_min
[-49.19  -0.15]
agent1_energy_min, agent1_attention_min
[-19.55 -26.52]
16500 50
steps: 824950, episodes: 16500, mean episode reward: -85.1500501964012, time: 24.502
agent0_energy_min, agent0_attention_min
[-49.38  -0.22]
agent1_energy_min, agent1_attention_min
[-22.82 -24.98]
16600 50
steps: 829950, episodes: 16600, mean episode reward: -85.67220267120483, time: 24.498
agent0_energy_min, agent0_attention_min
[-49.34  -0.41]
agent1_energy_min, agent1_attention_min
[-22.75 -25.03]
16700 50
steps: 834950, episodes: 16700, mean episode reward: -77.5043938480539, time: 23.781
agent0_energy_min, agent0_attention_min
[-48.63  -0.89]
agent1_energy_min, agent1_attention_min
[-13.19 -34.37]
16800 50
steps: 839950, episodes: 16800, mean episode reward: -82.59078804524641, time: 24.46
agent0_energy_min, agent0_attention_min
[-48.91  -0.75]
agent1_energy_min, agent1_attention_min
[-16.   -31.51]
16900 50
steps: 844950, episodes: 16900, mean episode reward: -73.7494399041374, time: 26.184
agent0_energy_min, agent0_attention_min
[-47.13  -1.05]
agent1_energy_min, agent1_attention_min
[-17.93 -28.63]
17000 50
steps: 849950, episodes: 17000, mean episode reward: -85.95727513811555, time: 24.461
agent0_energy_min, agent0_attention_min
[-48.19  -0.2 ]
agent1_energy_min, agent1_attention_min
[-20.1 -27.1]
17100 50
steps: 854950, episodes: 17100, mean episode reward: -78.78577437215537, time: 25.342
agent0_energy_min, agent0_attention_min
[-48.47  -0.39]
agent1_energy_min, agent1_attention_min
[-18.5  -30.12]
17200 50
steps: 859950, episodes: 17200, mean episode reward: -69.8336726688605, time: 24.809
agent0_energy_min, agent0_attention_min
[-48.51  -0.62]
agent1_energy_min, agent1_attention_min
[-14.13 -32.59]
17300 50
steps: 864950, episodes: 17300, mean episode reward: -80.83707658967712, time: 24.775
agent0_energy_min, agent0_attention_min
[-49.2   -0.63]
agent1_energy_min, agent1_attention_min
[-16.51 -31.51]
17400 50
steps: 869950, episodes: 17400, mean episode reward: -101.49545891337293, time: 24.67
agent0_energy_min, agent0_attention_min
[-48.71  -0.4 ]
agent1_energy_min, agent1_attention_min
[-16.58 -30.53]
17500 50
steps: 874950, episodes: 17500, mean episode reward: -80.89295144004694, time: 24.674
agent0_energy_min, agent0_attention_min
[-45.76  -3.13]
agent1_energy_min, agent1_attention_min
[-15.96 -31.69]
17600 50
steps: 879950, episodes: 17600, mean episode reward: -99.28049429687766, time: 25.049
agent0_energy_min, agent0_attention_min
[-43.56  -5.76]
agent1_energy_min, agent1_attention_min
[-23.82 -24.11]
17700 50
steps: 884950, episodes: 17700, mean episode reward: -76.57167716076607, time: 23.645
agent0_energy_min, agent0_attention_min
[-40.62  -7.78]
agent1_energy_min, agent1_attention_min
[-16.97 -31.45]
17800 50
steps: 889950, episodes: 17800, mean episode reward: -71.83006768656725, time: 24.152
agent0_energy_min, agent0_attention_min
[-39.91  -8.73]
agent1_energy_min, agent1_attention_min
[-16.31 -32.29]
17900 50
steps: 894950, episodes: 17900, mean episode reward: -84.35905546322502, time: 26.614
agent0_energy_min, agent0_attention_min
[-39.17  -9.1 ]
agent1_energy_min, agent1_attention_min
[-17.89 -29.69]
18000 50
steps: 899950, episodes: 18000, mean episode reward: -82.99449773686806, time: 23.699
agent0_energy_min, agent0_attention_min
[-43.4   -4.85]
agent1_energy_min, agent1_attention_min
[-16.87 -31.34]
18100 50
steps: 904950, episodes: 18100, mean episode reward: -77.7040001953084, time: 24.554
agent0_energy_min, agent0_attention_min
[-42.06  -5.93]
agent1_energy_min, agent1_attention_min
[-10.74 -33.87]
18200 50
steps: 909950, episodes: 18200, mean episode reward: -68.83437325157485, time: 24.354
agent0_energy_min, agent0_attention_min
[-40.95  -6.24]
agent1_energy_min, agent1_attention_min
[-14.72 -32.51]
18300 50
steps: 914950, episodes: 18300, mean episode reward: -71.89721803106787, time: 24.585
agent0_energy_min, agent0_attention_min
[-44.27  -5.41]
agent1_energy_min, agent1_attention_min
[-18.92 -28.55]
18400 50
steps: 919950, episodes: 18400, mean episode reward: -112.4418775170984, time: 24.276
agent0_energy_min, agent0_attention_min
[-36.73 -11.73]
agent1_energy_min, agent1_attention_min
[-16.62 -29.01]
18500 50
steps: 924950, episodes: 18500, mean episode reward: -81.0226236204772, time: 24.329
agent0_energy_min, agent0_attention_min
[-41.02  -8.45]
agent1_energy_min, agent1_attention_min
[-16.35 -28.61]
18600 50
steps: 929950, episodes: 18600, mean episode reward: -72.7272300648727, time: 24.488
agent0_energy_min, agent0_attention_min
[-40.16  -7.1 ]
agent1_energy_min, agent1_attention_min
[-16.02 -29.63]
18700 50
steps: 934950, episodes: 18700, mean episode reward: -74.40202323266806, time: 24.719
agent0_energy_min, agent0_attention_min
[-40.61  -7.45]
agent1_energy_min, agent1_attention_min
[-17.02 -30.06]
18800 50
steps: 939950, episodes: 18800, mean episode reward: -80.33384378353858, time: 24.133
agent0_energy_min, agent0_attention_min
[-36.18  -9.61]
agent1_energy_min, agent1_attention_min
[-15.8  -32.43]
18900 50
steps: 944950, episodes: 18900, mean episode reward: -76.25317791651783, time: 24.436
agent0_energy_min, agent0_attention_min
[-37.28  -8.82]
agent1_energy_min, agent1_attention_min
[ -8.81 -39.04]
19000 50
steps: 949950, episodes: 19000, mean episode reward: -62.30890198117397, time: 23.725
agent0_energy_min, agent0_attention_min
[-34.78 -12.56]
agent1_energy_min, agent1_attention_min
[-15.48 -32.6 ]
19100 50
steps: 954950, episodes: 19100, mean episode reward: -73.58186177525891, time: 24.571
agent0_energy_min, agent0_attention_min
[-39.37  -8.62]
agent1_energy_min, agent1_attention_min
[-20.59 -27.98]
19200 50
steps: 959950, episodes: 19200, mean episode reward: -84.92144492092774, time: 23.91
agent0_energy_min, agent0_attention_min
[-37.42  -6.28]
agent1_energy_min, agent1_attention_min
[-19.33 -27.  ]
19300 50
steps: 964950, episodes: 19300, mean episode reward: -67.53238402358865, time: 24.546
agent0_energy_min, agent0_attention_min
[-37.61 -11.89]
agent1_energy_min, agent1_attention_min
[-21.09 -25.13]
19400 50
steps: 969950, episodes: 19400, mean episode reward: -79.24895721289556, time: 23.605
agent0_energy_min, agent0_attention_min
[-36.52  -9.24]
agent1_energy_min, agent1_attention_min
[-16.39 -29.56]
19500 50
steps: 974950, episodes: 19500, mean episode reward: -78.19842216634575, time: 25.042
agent0_energy_min, agent0_attention_min
[-41.68  -5.25]
agent1_energy_min, agent1_attention_min
[-26.47 -21.9 ]
19600 50
steps: 979950, episodes: 19600, mean episode reward: -68.76219455372444, time: 24.962
agent0_energy_min, agent0_attention_min
[-42.24  -5.52]
agent1_energy_min, agent1_attention_min
[-26.93 -21.41]
19700 50
steps: 984950, episodes: 19700, mean episode reward: -76.00927163426637, time: 24.095
agent0_energy_min, agent0_attention_min
[-43.73  -5.2 ]
agent1_energy_min, agent1_attention_min
[-24.43 -24.17]
19800 50
steps: 989950, episodes: 19800, mean episode reward: -76.2558101970227, time: 24.168
agent0_energy_min, agent0_attention_min
[-43.58  -3.46]
agent1_energy_min, agent1_attention_min
[-28.86 -20.3 ]
19900 50
steps: 994950, episodes: 19900, mean episode reward: -74.38261296408068, time: 23.642
agent0_energy_min, agent0_attention_min
[-40.31  -7.89]
agent1_energy_min, agent1_attention_min
[-18.95 -29.45]
20000 50
steps: 999950, episodes: 20000, mean episode reward: -73.26102957335799, time: 24.257
15900 50
steps: 794950, episodes: 15900, mean episode reward: -116.79593270294843, time: 24.235
agent0_energy_min, agent0_attention_min
[-3.347e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.07]
16000 50
steps: 799950, episodes: 16000, mean episode reward: -113.95470399746888, time: 24.242
agent0_energy_min, agent0_attention_min
[-3.192e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.05]
16100 50
steps: 804950, episodes: 16100, mean episode reward: -104.66432537472382, time: 25.08
agent0_energy_min, agent0_attention_min
[-3.381e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.04]
16200 50
steps: 809950, episodes: 16200, mean episode reward: -98.49585531419753, time: 24.417
agent0_energy_min, agent0_attention_min
[-3.647e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
16300 50
steps: 814950, episodes: 16300, mean episode reward: -103.57464675380417, time: 24.483
agent0_energy_min, agent0_attention_min
[-3.469e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.03]
16400 50
steps: 819950, episodes: 16400, mean episode reward: -101.69897340189283, time: 24.659
agent0_energy_min, agent0_attention_min
[-3.764e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.18 -0.02]
16500 50
steps: 824950, episodes: 16500, mean episode reward: -106.4709046800096, time: 23.554
agent0_energy_min, agent0_attention_min
[-26.68   0.  ]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
16600 50
steps: 829950, episodes: 16600, mean episode reward: -127.69557283567053, time: 25.093
agent0_energy_min, agent0_attention_min
[-3.5e+01 -2.0e-02]
agent1_energy_min, agent1_attention_min
[0. 0.]
16700 50
steps: 834950, episodes: 16700, mean episode reward: -107.35140994942309, time: 23.85
agent0_energy_min, agent0_attention_min
[-36.76  -0.06]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
16800 50
steps: 839950, episodes: 16800, mean episode reward: -106.24247851440576, time: 24.478
agent0_energy_min, agent0_attention_min
[-33.71   0.  ]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
16900 50
steps: 844950, episodes: 16900, mean episode reward: -114.52847418877305, time: 24.871
agent0_energy_min, agent0_attention_min
[-31.14  -0.06]
agent1_energy_min, agent1_attention_min
[0. 0.]
17000 50
steps: 849950, episodes: 17000, mean episode reward: -100.99554791428768, time: 24.791
agent0_energy_min, agent0_attention_min
[-40.92  -0.15]
agent1_energy_min, agent1_attention_min
[-0.03 -0.01]
17100 50
steps: 854950, episodes: 17100, mean episode reward: -115.47286527468513, time: 24.736
agent0_energy_min, agent0_attention_min
[-37.12  -0.04]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
17200 50
steps: 859950, episodes: 17200, mean episode reward: -100.04693288608001, time: 24.592
agent0_energy_min, agent0_attention_min
[-37.65  -0.04]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
17300 50
steps: 864950, episodes: 17300, mean episode reward: -89.48470870295192, time: 24.307
agent0_energy_min, agent0_attention_min
[-31.76  -0.19]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
17400 50
steps: 869950, episodes: 17400, mean episode reward: -115.42093476138217, time: 24.59
agent0_energy_min, agent0_attention_min
[-30.4  -0.1]
agent1_energy_min, agent1_attention_min
[0. 0.]
17500 50
steps: 874950, episodes: 17500, mean episode reward: -115.03289319227673, time: 24.358
agent0_energy_min, agent0_attention_min
[-33.56  -0.07]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
17600 50
steps: 879950, episodes: 17600, mean episode reward: -110.28743466964917, time: 24.745
agent0_energy_min, agent0_attention_min
[-33.27  -0.06]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
17700 50
steps: 884950, episodes: 17700, mean episode reward: -110.19274789790978, time: 24.099
agent0_energy_min, agent0_attention_min
[-32.01  -0.05]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
17800 50
steps: 889950, episodes: 17800, mean episode reward: -103.43474336193589, time: 24.295
agent0_energy_min, agent0_attention_min
[-29.39  -0.03]
agent1_energy_min, agent1_attention_min
[-0.01 -0.03]
17900 50
steps: 894950, episodes: 17900, mean episode reward: -96.87896091815786, time: 24.153
agent0_energy_min, agent0_attention_min
[-32.   -0.1]
agent1_energy_min, agent1_attention_min
[ 0.   -0.02]
18000 50
steps: 899950, episodes: 18000, mean episode reward: -93.61718879137763, time: 24.381
agent0_energy_min, agent0_attention_min
[-2.938e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.02]
18100 50
steps: 904950, episodes: 18100, mean episode reward: -105.13420590075638, time: 25.534
agent0_energy_min, agent0_attention_min
[-30.5   -0.11]
agent1_energy_min, agent1_attention_min
[-0.03 -0.03]
18200 50
steps: 909950, episodes: 18200, mean episode reward: -105.0928138173433, time: 24.116
agent0_energy_min, agent0_attention_min
[-2.988e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
18300 50
steps: 914950, episodes: 18300, mean episode reward: -99.23015560518603, time: 24.128
agent0_energy_min, agent0_attention_min
[-3.313e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
18400 50
steps: 919950, episodes: 18400, mean episode reward: -108.16228930045828, time: 24.086
agent0_energy_min, agent0_attention_min
[-3.016e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.04]
18500 50
steps: 924950, episodes: 18500, mean episode reward: -109.7784364279973, time: 24.717
agent0_energy_min, agent0_attention_min
[-2.964e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.08]
18600 50
steps: 929950, episodes: 18600, mean episode reward: -111.61042611936979, time: 25.101
agent0_energy_min, agent0_attention_min
[-3.035e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.02 -0.01]
18700 50
steps: 934950, episodes: 18700, mean episode reward: -100.14809630870596, time: 24.331
agent0_energy_min, agent0_attention_min
[-3.087e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.02 -0.05]
18800 50
steps: 939950, episodes: 18800, mean episode reward: -105.52828493975846, time: 24.252
agent0_energy_min, agent0_attention_min
[-31.65  -0.07]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
18900 50
steps: 944950, episodes: 18900, mean episode reward: -111.58928086022772, time: 24.232
agent0_energy_min, agent0_attention_min
[-32.39  -0.04]
agent1_energy_min, agent1_attention_min
[0. 0.]
19000 50
steps: 949950, episodes: 19000, mean episode reward: -99.67736252241035, time: 24.206
agent0_energy_min, agent0_attention_min
[-3.213e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
19100 50
steps: 954950, episodes: 19100, mean episode reward: -82.98535549953385, time: 24.593
agent0_energy_min, agent0_attention_min
[-31.86  -0.04]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
19200 50
steps: 959950, episodes: 19200, mean episode reward: -96.01396672640452, time: 24.246
agent0_energy_min, agent0_attention_min
[-27.53  -0.08]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
19300 50
steps: 964950, episodes: 19300, mean episode reward: -110.38340268737427, time: 24.293
agent0_energy_min, agent0_attention_min
[-3.018e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
19400 50
steps: 969950, episodes: 19400, mean episode reward: -96.10294054880853, time: 24.672
agent0_energy_min, agent0_attention_min
[-2.969e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
19500 50
steps: 974950, episodes: 19500, mean episode reward: -94.01659701320726, time: 24.7
agent0_energy_min, agent0_attention_min
[-27.99  -0.05]
agent1_energy_min, agent1_attention_min
[ 0.   -0.02]
19600 50
steps: 979950, episodes: 19600, mean episode reward: -100.28441063614662, time: 24.663
agent0_energy_min, agent0_attention_min
[-33.06  -0.06]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
19700 50
steps: 984950, episodes: 19700, mean episode reward: -101.63068143201383, time: 24.755
agent0_energy_min, agent0_attention_min
[-30.55  -0.05]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
19800 50
steps: 989950, episodes: 19800, mean episode reward: -101.77920936166676, time: 24.427
agent0_energy_min, agent0_attention_min
[-30.39  -0.68]
agent1_energy_min, agent1_attention_min
[ -6.58 -43.21]
16100 50
steps: 804950, episodes: 16100, mean episode reward: -69.8592237828262, time: 24.948
agent0_energy_min, agent0_attention_min
[-31.16  -1.09]
agent1_energy_min, agent1_attention_min
[-10.   -39.73]
16200 50
steps: 809950, episodes: 16200, mean episode reward: -68.26652118571242, time: 29.023
agent0_energy_min, agent0_attention_min
[-27.57  -0.9 ]
agent1_energy_min, agent1_attention_min
[ -6.31 -43.29]
16300 50
steps: 814950, episodes: 16300, mean episode reward: -60.74879284661201, time: 24.862
agent0_energy_min, agent0_attention_min
[-36.35  -1.07]
agent1_energy_min, agent1_attention_min
[ -8.17 -41.66]
16400 50
steps: 819950, episodes: 16400, mean episode reward: -71.60058253912302, time: 24.395
agent0_energy_min, agent0_attention_min
[-33.57  -1.03]
agent1_energy_min, agent1_attention_min
[ -4.12 -45.46]
16500 50
steps: 824950, episodes: 16500, mean episode reward: -62.110730121692285, time: 24.132
agent0_energy_min, agent0_attention_min
[-34.35  -1.55]
agent1_energy_min, agent1_attention_min
[ -6.02 -43.75]
16600 50
steps: 829950, episodes: 16600, mean episode reward: -65.36678586248361, time: 25.1
agent0_energy_min, agent0_attention_min
[-32.66  -1.74]
agent1_energy_min, agent1_attention_min
[ -5.92 -43.78]
16700 50
steps: 834950, episodes: 16700, mean episode reward: -90.31319193399779, time: 24.153
agent0_energy_min, agent0_attention_min
[-31.61  -1.67]
agent1_energy_min, agent1_attention_min
[ -6.21 -43.69]
16800 50
steps: 839950, episodes: 16800, mean episode reward: -74.47215364262091, time: 24.568
agent0_energy_min, agent0_attention_min
[-32.09  -1.01]
agent1_energy_min, agent1_attention_min
[ -7.64 -42.21]
16900 50
steps: 844950, episodes: 16900, mean episode reward: -65.3873113063102, time: 23.987
agent0_energy_min, agent0_attention_min
[-28.89  -1.97]
agent1_energy_min, agent1_attention_min
[ -5.45 -44.22]
17000 50
steps: 849950, episodes: 17000, mean episode reward: -89.914172886479, time: 24.371
agent0_energy_min, agent0_attention_min
[-34.72  -1.11]
agent1_energy_min, agent1_attention_min
[ -8.95 -40.84]
17100 50
steps: 854950, episodes: 17100, mean episode reward: -60.36631996063319, time: 24.958
agent0_energy_min, agent0_attention_min
[-32.3   -1.39]
agent1_energy_min, agent1_attention_min
[ -6.19 -43.68]
17200 50
steps: 859950, episodes: 17200, mean episode reward: -55.59566681572883, time: 24.79
agent0_energy_min, agent0_attention_min
[-25.23  -0.79]
agent1_energy_min, agent1_attention_min
[ -8.52 -41.17]
17300 50
steps: 864950, episodes: 17300, mean episode reward: -72.63597044398162, time: 24.477
agent0_energy_min, agent0_attention_min
[-26.59  -1.36]
agent1_energy_min, agent1_attention_min
[ -8.81 -40.87]
17400 50
steps: 869950, episodes: 17400, mean episode reward: -61.95271203593887, time: 24.673
agent0_energy_min, agent0_attention_min
[-28.22  -1.5 ]
agent1_energy_min, agent1_attention_min
[ -8.56 -41.08]
17500 50
steps: 874950, episodes: 17500, mean episode reward: -68.91170931693652, time: 24.917
agent0_energy_min, agent0_attention_min
[-27.23  -0.91]
agent1_energy_min, agent1_attention_min
[ -4.69 -44.92]
17600 50
steps: 879950, episodes: 17600, mean episode reward: -66.97727938339331, time: 25.152
agent0_energy_min, agent0_attention_min
[-28.23  -0.99]
agent1_energy_min, agent1_attention_min
[ -6.41 -43.3 ]
17700 50
steps: 884950, episodes: 17700, mean episode reward: -66.62655676004631, time: 24.466
agent0_energy_min, agent0_attention_min
[-27.58  -0.97]
agent1_energy_min, agent1_attention_min
[ -4.45 -45.48]
17800 50
steps: 889950, episodes: 17800, mean episode reward: -54.37996041319849, time: 23.963
agent0_energy_min, agent0_attention_min
[-28.21  -5.71]
agent1_energy_min, agent1_attention_min
[ -9.56 -40.32]
17900 50
steps: 894950, episodes: 17900, mean episode reward: -69.45343094856352, time: 23.674
agent0_energy_min, agent0_attention_min
[-27.25  -3.09]
agent1_energy_min, agent1_attention_min
[ -7.58 -42.32]
18000 50
steps: 899950, episodes: 18000, mean episode reward: -64.99435387182379, time: 24.736
agent0_energy_min, agent0_attention_min
[-33.75  -0.82]
agent1_energy_min, agent1_attention_min
[ -5.95 -43.87]
18100 50
steps: 904950, episodes: 18100, mean episode reward: -60.51611618674305, time: 25.032
agent0_energy_min, agent0_attention_min
[-27.33  -0.8 ]
agent1_energy_min, agent1_attention_min
[ -7.66 -42.1 ]
18200 50
steps: 909950, episodes: 18200, mean episode reward: -59.27622905676394, time: 24.439
agent0_energy_min, agent0_attention_min
[-25.94  -1.23]
agent1_energy_min, agent1_attention_min
[ -7.87 -42.1 ]
18300 50
steps: 914950, episodes: 18300, mean episode reward: -60.171334221668324, time: 24.595
agent0_energy_min, agent0_attention_min
[-28.36  -0.77]
agent1_energy_min, agent1_attention_min
[ -9.95 -39.92]
18400 50
steps: 919950, episodes: 18400, mean episode reward: -75.06413406259567, time: 24.412
agent0_energy_min, agent0_attention_min
[-24.29  -1.53]
agent1_energy_min, agent1_attention_min
[ -6.72 -43.25]
18500 50
steps: 924950, episodes: 18500, mean episode reward: -69.03060533198136, time: 24.427
agent0_energy_min, agent0_attention_min
[-30.07  -2.88]
agent1_energy_min, agent1_attention_min
[ -7.23 -42.74]
18600 50
steps: 929950, episodes: 18600, mean episode reward: -69.00262897548298, time: 24.651
agent0_energy_min, agent0_attention_min
[-26.63  -8.19]
agent1_energy_min, agent1_attention_min
[ -6.58 -43.32]
18700 50
steps: 934950, episodes: 18700, mean episode reward: -62.37188547670578, time: 24.591
agent0_energy_min, agent0_attention_min
[-32.47  -1.96]
agent1_energy_min, agent1_attention_min
[ -7.33 -42.61]
18800 50
steps: 939950, episodes: 18800, mean episode reward: -55.13134414339623, time: 24.219
agent0_energy_min, agent0_attention_min
[-23.63  -1.84]
agent1_energy_min, agent1_attention_min
[ -6.23 -43.74]
18900 50
steps: 944950, episodes: 18900, mean episode reward: -74.12652159066154, time: 24.531
agent0_energy_min, agent0_attention_min
[-25.02  -0.84]
agent1_energy_min, agent1_attention_min
[ -6.65 -43.3 ]
19000 50
steps: 949950, episodes: 19000, mean episode reward: -77.20254823520827, time: 23.898
agent0_energy_min, agent0_attention_min
[-29.08  -1.91]
agent1_energy_min, agent1_attention_min
[ -7.38 -42.6 ]
19100 50
steps: 954950, episodes: 19100, mean episode reward: -81.37068508842717, time: 24.505
agent0_energy_min, agent0_attention_min
[-27.6   -1.93]
agent1_energy_min, agent1_attention_min
[ -7.05 -42.93]
19200 50
steps: 959950, episodes: 19200, mean episode reward: -66.86400883694716, time: 24.606
agent0_energy_min, agent0_attention_min
[-25.33  -1.29]
agent1_energy_min, agent1_attention_min
[ -8.12 -41.84]
19300 50
steps: 964950, episodes: 19300, mean episode reward: -62.84738561458735, time: 24.377
agent0_energy_min, agent0_attention_min
[-28.12  -1.62]
agent1_energy_min, agent1_attention_min
[-12.1  -37.87]
19400 50
steps: 969950, episodes: 19400, mean episode reward: -65.76276328786884, time: 24.513
agent0_energy_min, agent0_attention_min
[-29.45  -2.05]
agent1_energy_min, agent1_attention_min
[-11.36 -38.58]
19500 50
steps: 974950, episodes: 19500, mean episode reward: -65.12772091417492, time: 24.114
agent0_energy_min, agent0_attention_min
[-26.58  -0.92]
agent1_energy_min, agent1_attention_min
[ -4.38 -45.58]
19600 50
steps: 979950, episodes: 19600, mean episode reward: -55.89355040466146, time: 25.268
agent0_energy_min, agent0_attention_min
[-20.47  -0.85]
agent1_energy_min, agent1_attention_min
[ -6.88 -43.09]
19700 50
steps: 984950, episodes: 19700, mean episode reward: -78.75510529320154, time: 25.037
agent0_energy_min, agent0_attention_min
[-24.27  -1.68]
agent1_energy_min, agent1_attention_min
[ -6.96 -43.01]
19800 50
steps: 989950, episodes: 19800, mean episode reward: -65.0387744618436, time: 25.716
agent0_energy_min, agent0_attention_min
[-25.05  -1.01]
agent1_energy_min, agent1_attention_min
[-11.46 -38.51]
19900 50
steps: 994950, episodes: 19900, mean episode reward: -73.88188998385577, time: 23.904
agent0_energy_min, agent0_attention_min
[-22.58  -0.97]
agent1_energy_min, agent1_attention_min
[ -7.61 -42.36]
20000 50
steps: 999950, episodes: 20000, mean episode reward: -61.39207722453611, time: 24.354
agent0_energy_min, agent0_attention_min
[-46.1   -1.82]
agent1_energy_min, agent1_attention_min
[-3.611e+01 -1.000e-02]
15900 50
steps: 794950, episodes: 15900, mean episode reward: -90.82036289993297, time: 24.593
agent0_energy_min, agent0_attention_min
[-45.09  -1.92]
agent1_energy_min, agent1_attention_min
[-3.895e+01 -2.000e-02]
16000 50
steps: 799950, episodes: 16000, mean episode reward: -87.80899433407959, time: 25.077
agent0_energy_min, agent0_attention_min
[-47.5   -0.73]
agent1_energy_min, agent1_attention_min
[-3.56e+01 -1.00e-02]
16100 50
steps: 804950, episodes: 16100, mean episode reward: -78.74939360547037, time: 25.168
agent0_energy_min, agent0_attention_min
[-42.39  -1.54]
agent1_energy_min, agent1_attention_min
[-3.953e+01 -1.000e-02]
16200 50
steps: 809950, episodes: 16200, mean episode reward: -80.98739380835917, time: 24.692
agent0_energy_min, agent0_attention_min
[-42.51  -1.15]
agent1_energy_min, agent1_attention_min
[-3.651e+01 -1.000e-02]
16300 50
steps: 814950, episodes: 16300, mean episode reward: -86.74750598050247, time: 24.924
agent0_energy_min, agent0_attention_min
[-44.48  -1.51]
agent1_energy_min, agent1_attention_min
[-3.594e+01 -2.000e-02]
16400 50
steps: 819950, episodes: 16400, mean episode reward: -85.23537526739959, time: 25.285
agent0_energy_min, agent0_attention_min
[-44.42  -1.69]
agent1_energy_min, agent1_attention_min
[-3.67e+01 -3.00e-02]
16500 50
steps: 824950, episodes: 16500, mean episode reward: -89.75613808673546, time: 24.586
agent0_energy_min, agent0_attention_min
[-46.33  -1.58]
agent1_energy_min, agent1_attention_min
[-4.56e+01 -1.00e-02]
16600 50
steps: 829950, episodes: 16600, mean episode reward: -85.0005222256502, time: 24.864
agent0_energy_min, agent0_attention_min
[-46.09  -1.41]
agent1_energy_min, agent1_attention_min
[-3.772e+01 -3.000e-02]
16700 50
steps: 834950, episodes: 16700, mean episode reward: -114.50337954750731, time: 24.462
agent0_energy_min, agent0_attention_min
[-40.52  -2.13]
agent1_energy_min, agent1_attention_min
[-39.42   0.  ]
16800 50
steps: 839950, episodes: 16800, mean episode reward: -120.16658544440493, time: 25.346
agent0_energy_min, agent0_attention_min
[-37.91  -3.7 ]
agent1_energy_min, agent1_attention_min
[-3.682e+01 -1.000e-02]
16900 50
steps: 844950, episodes: 16900, mean episode reward: -104.68797904359397, time: 25.515
agent0_energy_min, agent0_attention_min
[-40.42  -2.62]
agent1_energy_min, agent1_attention_min
[-35.85   0.  ]
17000 50
steps: 849950, episodes: 17000, mean episode reward: -112.14094947540246, time: 25.407
agent0_energy_min, agent0_attention_min
[-44.85  -3.45]
agent1_energy_min, agent1_attention_min
[-35.53   0.  ]
17100 50
steps: 854950, episodes: 17100, mean episode reward: -93.59528056719175, time: 25.281
agent0_energy_min, agent0_attention_min
[-48.21  -1.3 ]
agent1_energy_min, agent1_attention_min
[-38.96   0.  ]
17200 50
steps: 859950, episodes: 17200, mean episode reward: -86.60415865279752, time: 24.872
agent0_energy_min, agent0_attention_min
[-48.2  -1.2]
agent1_energy_min, agent1_attention_min
[-35.53  -0.04]
17300 50
steps: 864950, episodes: 17300, mean episode reward: -85.22732394772596, time: 25.174
agent0_energy_min, agent0_attention_min
[-49.13  -0.48]
agent1_energy_min, agent1_attention_min
[-3.846e+01 -1.000e-02]
17400 50
steps: 869950, episodes: 17400, mean episode reward: -83.59584376654298, time: 24.64
agent0_energy_min, agent0_attention_min
[-47.35  -1.09]
agent1_energy_min, agent1_attention_min
[-39.7   0. ]
17500 50
steps: 874950, episodes: 17500, mean episode reward: -83.03150772446672, time: 25.242
agent0_energy_min, agent0_attention_min
[-48.21  -0.93]
agent1_energy_min, agent1_attention_min
[-38.36   0.  ]
17600 50
steps: 879950, episodes: 17600, mean episode reward: -95.40798490363683, time: 24.697
agent0_energy_min, agent0_attention_min
[-48.53  -0.91]
agent1_energy_min, agent1_attention_min
[-3.933e+01 -1.000e-02]
17700 50
steps: 884950, episodes: 17700, mean episode reward: -97.66810201114053, time: 24.547
agent0_energy_min, agent0_attention_min
[-48.93  -0.59]
agent1_energy_min, agent1_attention_min
[-3.722e+01 -3.000e-02]
17800 50
steps: 889950, episodes: 17800, mean episode reward: -104.37116814438451, time: 25.04
agent0_energy_min, agent0_attention_min
[-49.01  -0.65]
agent1_energy_min, agent1_attention_min
[-35.01  -0.05]
17900 50
steps: 894950, episodes: 17900, mean episode reward: -87.4118772100349, time: 24.78
agent0_energy_min, agent0_attention_min
[-49.29  -0.49]
agent1_energy_min, agent1_attention_min
[-39.94   0.  ]
18000 50
steps: 899950, episodes: 18000, mean episode reward: -75.30675197660503, time: 24.746
agent0_energy_min, agent0_attention_min
[-49.14  -0.57]
agent1_energy_min, agent1_attention_min
[-40.09   0.  ]
18100 50
steps: 904950, episodes: 18100, mean episode reward: -81.06804604013989, time: 24.933
agent0_energy_min, agent0_attention_min
[-48.86  -0.72]
agent1_energy_min, agent1_attention_min
[-3.634e+01 -2.000e-02]
18200 50
steps: 909950, episodes: 18200, mean episode reward: -85.99470633149036, time: 24.449
agent0_energy_min, agent0_attention_min
[-49.44  -0.22]
agent1_energy_min, agent1_attention_min
[-34.73  -0.04]
18300 50
steps: 914950, episodes: 18300, mean episode reward: -87.64639814719476, time: 24.982
agent0_energy_min, agent0_attention_min
[-48.91  -0.82]
agent1_energy_min, agent1_attention_min
[-3.805e+01 -1.000e-02]
18400 50
steps: 919950, episodes: 18400, mean episode reward: -112.14608633019041, time: 25.188
agent0_energy_min, agent0_attention_min
[-49.14  -0.72]
agent1_energy_min, agent1_attention_min
[-37.82  -0.04]
18500 50
steps: 924950, episodes: 18500, mean episode reward: -119.02050567032809, time: 25.338
agent0_energy_min, agent0_attention_min
[-48.12  -1.68]
agent1_energy_min, agent1_attention_min
[-44.33  -0.07]
18600 50
steps: 929950, episodes: 18600, mean episode reward: -111.02069478927044, time: 25.315
agent0_energy_min, agent0_attention_min
[-48.68  -1.16]
agent1_energy_min, agent1_attention_min
[-37.99  -0.05]
18700 50
steps: 934950, episodes: 18700, mean episode reward: -80.02145996412736, time: 24.418
agent0_energy_min, agent0_attention_min
[-49.03  -0.7 ]
agent1_energy_min, agent1_attention_min
[-33.08   0.  ]
18800 50
steps: 939950, episodes: 18800, mean episode reward: -78.75508023284522, time: 24.69
agent0_energy_min, agent0_attention_min
[-49.1   -0.62]
agent1_energy_min, agent1_attention_min
[-36.54  -0.05]
18900 50
steps: 944950, episodes: 18900, mean episode reward: -85.07427995340187, time: 24.71
agent0_energy_min, agent0_attention_min
[-49.32  -0.5 ]
agent1_energy_min, agent1_attention_min
[-32.14   0.  ]
19000 50
steps: 949950, episodes: 19000, mean episode reward: -86.87278038887375, time: 24.709
agent0_energy_min, agent0_attention_min
[-49.16  -0.69]
agent1_energy_min, agent1_attention_min
[-34.61  -0.05]
19100 50
steps: 954950, episodes: 19100, mean episode reward: -76.67542999326967, time: 24.768
agent0_energy_min, agent0_attention_min
[-49.11  -0.51]
agent1_energy_min, agent1_attention_min
[-38.23  -0.34]
19200 50
steps: 959950, episodes: 19200, mean episode reward: -81.68177624742123, time: 25.27
agent0_energy_min, agent0_attention_min
[-44.77  -0.67]
agent1_energy_min, agent1_attention_min
[-39.09  -0.18]
19300 50
steps: 964950, episodes: 19300, mean episode reward: -71.76038789799021, time: 25.281
agent0_energy_min, agent0_attention_min
[-46.08  -0.95]
agent1_energy_min, agent1_attention_min
[-35.34   0.  ]
19400 50
steps: 969950, episodes: 19400, mean episode reward: -82.37057584435235, time: 25.096
agent0_energy_min, agent0_attention_min
[-47.9   -0.65]
agent1_energy_min, agent1_attention_min
[-3.872e+01 -2.000e-02]
19500 50
steps: 974950, episodes: 19500, mean episode reward: -79.01566768401017, time: 26.774
agent0_energy_min, agent0_attention_min
[-45.85  -1.76]
agent1_energy_min, agent1_attention_min
[-3.466e+01 -1.000e-02]
19600 50
steps: 979950, episodes: 19600, mean episode reward: -82.53336795800418, time: 25.896
agent0_energy_min, agent0_attention_min
[-49.15  -0.52]
agent1_energy_min, agent1_attention_min
[-4.052e+01 -1.000e-02]
19700 50
steps: 984950, episodes: 19700, mean episode reward: -85.72564144337267, time: 24.321
[-13.6   -0.02]
16100 50
steps: 804950, episodes: 16100, mean episode reward: -102.42378126751657, time: 24.405
agent0_energy_min, agent0_attention_min
[-48.11  -0.13]
agent1_energy_min, agent1_attention_min
[-40.18  -0.07]
16200 50
steps: 809950, episodes: 16200, mean episode reward: -153.27990656939505, time: 24.4
agent0_energy_min, agent0_attention_min
[-38.68  -0.06]
agent1_energy_min, agent1_attention_min
[-34.63   0.  ]
16300 50
steps: 814950, episodes: 16300, mean episode reward: -107.4031521116811, time: 24.769
agent0_energy_min, agent0_attention_min
[-3.098e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-2.852e+01 -2.000e-02]
16400 50
steps: 819950, episodes: 16400, mean episode reward: -161.16818278241843, time: 24.016
agent0_energy_min, agent0_attention_min
[-48.89  -0.06]
agent1_energy_min, agent1_attention_min
[-2.658e+01 -1.000e-02]
16500 50
steps: 824950, episodes: 16500, mean episode reward: -171.15824749326126, time: 24.199
agent0_energy_min, agent0_attention_min
[-46.56  -0.31]
agent1_energy_min, agent1_attention_min
[-20.62   0.  ]
16600 50
steps: 829950, episodes: 16600, mean episode reward: -116.93097527321814, time: 24.581
agent0_energy_min, agent0_attention_min
[-42.39  -0.48]
agent1_energy_min, agent1_attention_min
[-15.27  -0.02]
16700 50
steps: 834950, episodes: 16700, mean episode reward: -120.98976117274702, time: 24.509
agent0_energy_min, agent0_attention_min
[-48.25   0.  ]
agent1_energy_min, agent1_attention_min
[-48.92  -0.16]
16800 50
steps: 839950, episodes: 16800, mean episode reward: -126.48159718764072, time: 24.775
agent0_energy_min, agent0_attention_min
[-4.914e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-27.49  -0.26]
16900 50
steps: 844950, episodes: 16900, mean episode reward: -110.97950338692883, time: 24.491
agent0_energy_min, agent0_attention_min
[-4.893e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-32.95  -0.05]
17000 50
steps: 849950, episodes: 17000, mean episode reward: -145.8551281730173, time: 24.418
agent0_energy_min, agent0_attention_min
[-47.92  -0.05]
agent1_energy_min, agent1_attention_min
[-33.06  -0.33]
17100 50
steps: 854950, episodes: 17100, mean episode reward: -132.34122568776343, time: 24.783
agent0_energy_min, agent0_attention_min
[-46.63  -0.19]
agent1_energy_min, agent1_attention_min
[-27.49  -0.08]
17200 50
steps: 859950, episodes: 17200, mean episode reward: -124.70164937004924, time: 24.035
agent0_energy_min, agent0_attention_min
[-43.05  -0.05]
agent1_energy_min, agent1_attention_min
[-9.65 -0.05]
17300 50
steps: 864950, episodes: 17300, mean episode reward: -118.34831165122456, time: 24.238
agent0_energy_min, agent0_attention_min
[-4.71e+01 -1.00e-02]
agent1_energy_min, agent1_attention_min
[-0.06 -0.06]
17400 50
steps: 869950, episodes: 17400, mean episode reward: -112.28634371639204, time: 23.535
agent0_energy_min, agent0_attention_min
[-4.747e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-6.21 -0.02]
17500 50
steps: 874950, episodes: 17500, mean episode reward: -108.47883140559853, time: 24.676
agent0_energy_min, agent0_attention_min
[-4.793e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-3.027e+01 -1.000e-02]
17600 50
steps: 879950, episodes: 17600, mean episode reward: -106.32420975470562, time: 24.264
agent0_energy_min, agent0_attention_min
[-4.811e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-22.87  -0.05]
17700 50
steps: 884950, episodes: 17700, mean episode reward: -109.30326612324284, time: 24.405
agent0_energy_min, agent0_attention_min
[-4.796e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-1.88 -0.02]
17800 50
steps: 889950, episodes: 17800, mean episode reward: -109.61470725422832, time: 24.076
agent0_energy_min, agent0_attention_min
[-48.15   0.  ]
agent1_energy_min, agent1_attention_min
[-2.15 -0.04]
17900 50
steps: 894950, episodes: 17900, mean episode reward: -110.25639683196744, time: 23.742
agent0_energy_min, agent0_attention_min
[-4.716e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-14.4   -0.03]
18000 50
steps: 899950, episodes: 18000, mean episode reward: -100.5667612120202, time: 23.953
agent0_energy_min, agent0_attention_min
[-4.833e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-4.417e+01 -3.000e-02]
18100 50
steps: 904950, episodes: 18100, mean episode reward: -109.35260498958074, time: 24.54
agent0_energy_min, agent0_attention_min
[-48.86  -0.05]
agent1_energy_min, agent1_attention_min
[-47.38   0.  ]
18200 50
steps: 909950, episodes: 18200, mean episode reward: -119.3248778887363, time: 23.373
agent0_energy_min, agent0_attention_min
[-47.24   0.  ]
agent1_energy_min, agent1_attention_min
[-4.435e+01 -1.000e-02]
18300 50
steps: 914950, episodes: 18300, mean episode reward: -114.11155915520526, time: 23.571
agent0_energy_min, agent0_attention_min
[-4.64e+01 -1.00e-02]
agent1_energy_min, agent1_attention_min
[-4.721e+01 -1.000e-02]
18400 50
steps: 919950, episodes: 18400, mean episode reward: -121.93347176918634, time: 24.579
agent0_energy_min, agent0_attention_min
[-4.767e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-1.811e+01 -1.000e-02]
18500 50
steps: 924950, episodes: 18500, mean episode reward: -103.87907933050961, time: 24.139
agent0_energy_min, agent0_attention_min
[-48.9   0. ]
agent1_energy_min, agent1_attention_min
[-4.02 -0.02]
18600 50
steps: 929950, episodes: 18600, mean episode reward: -104.6913306767898, time: 24.505
agent0_energy_min, agent0_attention_min
[-49.58   0.  ]
agent1_energy_min, agent1_attention_min
[-3.714e+01 -3.000e-02]
18700 50
steps: 934950, episodes: 18700, mean episode reward: -122.02470400626608, time: 24.056
agent0_energy_min, agent0_attention_min
[-4.947e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-41.13   0.  ]
18800 50
steps: 939950, episodes: 18800, mean episode reward: -137.47963145910404, time: 24.106
agent0_energy_min, agent0_attention_min
[-4.876e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-13.79  -0.03]
18900 50
steps: 944950, episodes: 18900, mean episode reward: -106.6323972459411, time: 24.05
agent0_energy_min, agent0_attention_min
[-49.41   0.  ]
agent1_energy_min, agent1_attention_min
[-8.17 -0.01]
19000 50
steps: 949950, episodes: 19000, mean episode reward: -98.756904677258, time: 23.923
agent0_energy_min, agent0_attention_min
[-4.986e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-4.32  0.  ]
19100 50
steps: 954950, episodes: 19100, mean episode reward: -103.33620233730446, time: 24.059
agent0_energy_min, agent0_attention_min
[-4.989e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-3.71  0.  ]
19200 50
steps: 959950, episodes: 19200, mean episode reward: -97.97413881122421, time: 23.917
agent0_energy_min, agent0_attention_min
[-49.7  -0.1]
agent1_energy_min, agent1_attention_min
[-3.39 -0.01]
19300 50
steps: 964950, episodes: 19300, mean episode reward: -158.5680171761529, time: 24.734
agent0_energy_min, agent0_attention_min
[-48.98  -0.05]
agent1_energy_min, agent1_attention_min
[-29.52  -0.04]
19400 50
steps: 969950, episodes: 19400, mean episode reward: -94.69183579125344, time: 24.308
agent0_energy_min, agent0_attention_min
[-46.78  -0.07]
agent1_energy_min, agent1_attention_min
[-3.922e+01 -2.000e-02]
19500 50
steps: 974950, episodes: 19500, mean episode reward: -103.8607405617815, time: 23.666
agent0_energy_min, agent0_attention_min
[-4.981e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-2.572e+01 -1.000e-02]
19600 50
steps: 979950, episodes: 19600, mean episode reward: -101.48145588949711, time: 24.554
agent0_energy_min, agent0_attention_min
[-4.99e+01 -4.00e-02]
agent1_energy_min, agent1_attention_min
[-9.1  0. ]
19700 50
steps: 984950, episodes: 19700, mean episode reward: -89.92858489442933, time: 23.772
agent0_energy_min, agent0_attention_min
[-4.987e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-9.7  -0.04]
19800 50
steps: 989950, episodes: 19800, mean episode reward: -101.98836077469565, time: 23.734
agent0_energy_min, agent0_attention_min
[-49.81  -0.07]
agent1_energy_min, agent1_attention_min
[-3.22 -0.04]
19900 50
steps: 994950, episodes: 19900, mean episode reward: -101.40959705007639, time: 23.789

agent0_energy_min, agent0_attention_min
[-49.49   0.  ]
agent1_energy_min, agent1_attention_min
[-43.68  -2.9 ]
19800 50
steps: 989950, episodes: 19800, mean episode reward: -53.88128530005685, time: 26.475
agent0_energy_min, agent0_attention_min
[-4.89e+01 -2.00e-02]
agent1_energy_min, agent1_attention_min
[-43.34  -2.98]
19900 50
steps: 994950, episodes: 19900, mean episode reward: -73.70216904745395, time: 24.589
agent0_energy_min, agent0_attention_min
[-4.886e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-42.94  -3.74]
20000 50
steps: 999950, episodes: 20000, mean episode reward: -50.26515248901147, time: 24.8
agent0_energy_min, agent0_attention_min
[-4.77e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-43.72  -3.97]
20100 50
steps: 1004950, episodes: 20100, mean episode reward: -49.969761976420806, time: 25.123
agent0_energy_min, agent0_attention_min
[-4.853e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-43.41  -3.87]
20200 50
steps: 1009950, episodes: 20200, mean episode reward: -46.36822677150859, time: 24.596
agent0_energy_min, agent0_attention_min
[-4.936e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-40.31  -4.97]
20300 50
steps: 1014950, episodes: 20300, mean episode reward: -60.78555242710673, time: 24.32
agent0_energy_min, agent0_attention_min
[-4.898e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-36.9   -9.46]
20400 50
steps: 1019950, episodes: 20400, mean episode reward: -44.398966173167835, time: 26.853
agent0_energy_min, agent0_attention_min
[-49.   0.]
agent1_energy_min, agent1_attention_min
[-37.96  -6.97]
20500 50
steps: 1024950, episodes: 20500, mean episode reward: -56.75280093253894, time: 24.651
agent0_energy_min, agent0_attention_min
[-4.904e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-41.56  -4.88]
20600 50
steps: 1029950, episodes: 20600, mean episode reward: -48.8760576492084, time: 24.894
agent0_energy_min, agent0_attention_min
[-4.716e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-39.9   -5.56]
20700 50
steps: 1034950, episodes: 20700, mean episode reward: -50.87739571239564, time: 24.213
agent0_energy_min, agent0_attention_min
[-4.828e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-39.9   -5.06]
20800 50
steps: 1039950, episodes: 20800, mean episode reward: -56.150270789007, time: 24.264
agent0_energy_min, agent0_attention_min
[-4.934e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-37.22  -9.37]
20900 50
steps: 1044950, episodes: 20900, mean episode reward: -72.18979955577822, time: 24.463
agent0_energy_min, agent0_attention_min
[-4.822e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-32.15 -15.91]
21000 50
steps: 1049950, episodes: 21000, mean episode reward: -50.00219834402411, time: 24.743
agent0_energy_min, agent0_attention_min
[-48.33  -0.06]
agent1_energy_min, agent1_attention_min
[-44.04  -4.78]
21100 50
steps: 1054950, episodes: 21100, mean episode reward: -63.19003453563067, time: 25.146
agent0_energy_min, agent0_attention_min
[-4.827e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-45.36  -3.2 ]
21200 50
steps: 1059950, episodes: 21200, mean episode reward: -42.89681537118642, time: 24.777
agent0_energy_min, agent0_attention_min
[-4.395e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-45.84  -2.25]
21300 50
steps: 1064950, episodes: 21300, mean episode reward: -46.59571734742928, time: 24.785
agent0_energy_min, agent0_attention_min
[-46.31  -0.67]
agent1_energy_min, agent1_attention_min
[-45.15  -2.56]
21400 50
steps: 1069950, episodes: 21400, mean episode reward: -56.83045203090851, time: 25.296
agent0_energy_min, agent0_attention_min
[-4.756e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-43.51  -5.15]
21500 50
steps: 1074950, episodes: 21500, mean episode reward: -65.5129422302906, time: 25.188
agent0_energy_min, agent0_attention_min
[-48.95  -0.05]
agent1_energy_min, agent1_attention_min
[-45.63  -3.07]
21600 50
steps: 1079950, episodes: 21600, mean episode reward: -43.352715298442675, time: 25.486
agent0_energy_min, agent0_attention_min
[-4.801e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-43.49  -4.53]
21700 50
steps: 1084950, episodes: 21700, mean episode reward: -102.84702241611377, time: 24.566
agent0_energy_min, agent0_attention_min
[-30.82  -0.05]
agent1_energy_min, agent1_attention_min
[-44.13  -3.95]
21800 50
steps: 1089950, episodes: 21800, mean episode reward: -65.95612882507035, time: 24.289
agent0_energy_min, agent0_attention_min
[-48.49  -0.06]
agent1_energy_min, agent1_attention_min
[-39.25  -4.51]
21900 50
steps: 1094950, episodes: 21900, mean episode reward: -109.58652075337943, time: 24.324
agent0_energy_min, agent0_attention_min
[-4.89e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-39.65  -6.39]
22000 50
steps: 1099950, episodes: 22000, mean episode reward: -54.289553259774685, time: 24.967
agent0_energy_min, agent0_attention_min
[-47.25  -1.46]
agent1_energy_min, agent1_attention_min
[-38.68  -6.57]
22100 50
steps: 1104950, episodes: 22100, mean episode reward: -95.55160842902025, time: 24.846
agent0_energy_min, agent0_attention_min
[-46.57  -2.02]
agent1_energy_min, agent1_attention_min
[-39.33  -5.25]
22200 50
steps: 1109950, episodes: 22200, mean episode reward: -73.29241329498541, time: 25.023
agent0_energy_min, agent0_attention_min
[-45.9   -1.74]
agent1_energy_min, agent1_attention_min
[-39.58  -4.04]
22300 50
steps: 1114950, episodes: 22300, mean episode reward: -58.34125113222068, time: 24.866
agent0_energy_min, agent0_attention_min
[-47.63  -0.25]
agent1_energy_min, agent1_attention_min
[-43.91  -3.22]
22400 50
steps: 1119950, episodes: 22400, mean episode reward: -45.407735659869815, time: 24.559
agent0_energy_min, agent0_attention_min
[-47.95  -0.66]
agent1_energy_min, agent1_attention_min
[-42.99  -4.61]
22500 50
steps: 1124950, episodes: 22500, mean episode reward: -53.27492894738266, time: 24.211
agent0_energy_min, agent0_attention_min
[-49.33  -0.26]
agent1_energy_min, agent1_attention_min
[-40.88  -7.24]
22600 50
steps: 1129950, episodes: 22600, mean episode reward: -325.13027209493686, time: 25.17
agent0_energy_min, agent0_attention_min
[-38.84  -0.72]
agent1_energy_min, agent1_attention_min
[-46.31  -2.47]
22700 50
steps: 1134950, episodes: 22700, mean episode reward: -437.4880196357244, time: 24.584
agent0_energy_min, agent0_attention_min
[-35.52  -0.82]
agent1_energy_min, agent1_attention_min
[-41.11  -6.3 ]
22800 50
steps: 1139950, episodes: 22800, mean episode reward: -67.10026797476422, time: 24.505
agent0_energy_min, agent0_attention_min
[-49.4   -0.17]
agent1_energy_min, agent1_attention_min
[-46.15  -1.73]
22900 50
steps: 1144950, episodes: 22900, mean episode reward: -68.90691527572018, time: 25.045
agent0_energy_min, agent0_attention_min
[-48.33  -0.06]
agent1_energy_min, agent1_attention_min
[-43.11  -2.17]
23000 50
steps: 1149950, episodes: 23000, mean episode reward: -53.687460922048665, time: 24.837
agent0_energy_min, agent0_attention_min
[-49.22  -0.25]
agent1_energy_min, agent1_attention_min
[-41.45  -3.46]
23100 50
steps: 1154950, episodes: 23100, mean episode reward: -67.69877928668167, time: 24.799
agent0_energy_min, agent0_attention_min
[-48.15  -0.63]
agent1_energy_min, agent1_attention_min
[-45.53  -2.26]
23200 50
steps: 1159950, episodes: 23200, mean episode reward: -46.85718647077951, time: 25.014
agent0_energy_min, agent0_attention_min
[-49.26  -0.22]
agent1_energy_min, agent1_attention_min
[-42.41  -3.02]
23300 50
steps: 1164950, episodes: 23300, mean episode reward: -38.56888003177353, time: 24.938
agent0_energy_min, agent0_attention_min
[-49.45  -0.13]
agent1_energy_min, agent1_attention_min
[-42.43  -2.56]
23400 50
steps: 1169950, episodes: 23400, mean episode reward: -47.71769884485886, time: 24.416
agent0_energy_min, agent0_attention_min
[-49.05  -0.05]
agent1_energy_min, agent1_attention_min
[-39.61  -5.4 ]
23500 50
steps: 1174950, episodes: 23500, mean episode reward: -50.12912140281787, time: 24.524
agent0_energy_min, agent0_attention_min
[-47.02  -2.66]
agent1_energy_min, agent1_attention_min
[-40.31  -3.  ]
23600 50
steps: 1179950, episodes: 23600, mean episode reward: -62.57206308490693, time: 25.234
[-4.908e+01 -1.000e-02]
19900 50
steps: 994950, episodes: 19900, mean episode reward: -41.11977629983747, time: 24.222
agent0_energy_min, agent0_attention_min
[-47.37  -0.82]
agent1_energy_min, agent1_attention_min
[-4.928e+01 -2.000e-02]
20000 50
steps: 999950, episodes: 20000, mean episode reward: -51.55947338776747, time: 24.535
agent0_energy_min, agent0_attention_min
[-48.35  -1.48]
agent1_energy_min, agent1_attention_min
[-49.06   0.  ]
20100 50
steps: 1004950, episodes: 20100, mean episode reward: -75.59804872621422, time: 24.74
agent0_energy_min, agent0_attention_min
[-48.12  -1.58]
agent1_energy_min, agent1_attention_min
[-4.935e+01 -3.000e-02]
20200 50
steps: 1009950, episodes: 20200, mean episode reward: -56.202364591446276, time: 24.212
agent0_energy_min, agent0_attention_min
[-48.61  -1.19]
agent1_energy_min, agent1_attention_min
[-4.886e+01 -1.000e-02]
20300 50
steps: 1014950, episodes: 20300, mean episode reward: -56.23970370947632, time: 24.134
agent0_energy_min, agent0_attention_min
[-48.15  -0.72]
agent1_energy_min, agent1_attention_min
[-48.48   0.  ]
20400 50
steps: 1019950, episodes: 20400, mean episode reward: -50.74829087578365, time: 24.423
agent0_energy_min, agent0_attention_min
[-48.17  -0.85]
agent1_energy_min, agent1_attention_min
[-4.802e+01 -1.000e-02]
20500 50
steps: 1024950, episodes: 20500, mean episode reward: -43.83253928314752, time: 26.051
agent0_energy_min, agent0_attention_min
[-47.82  -0.76]
agent1_energy_min, agent1_attention_min
[-4.886e+01 -2.000e-02]
20600 50
steps: 1029950, episodes: 20600, mean episode reward: -44.3468325408448, time: 24.666
agent0_energy_min, agent0_attention_min
[-48.74  -0.69]
agent1_energy_min, agent1_attention_min
[-4.833e+01 -2.000e-02]
20700 50
steps: 1034950, episodes: 20700, mean episode reward: -51.533223307531635, time: 24.456
agent0_energy_min, agent0_attention_min
[-48.62  -1.  ]
agent1_energy_min, agent1_attention_min
[-4.876e+01 -3.000e-02]
20800 50
steps: 1039950, episodes: 20800, mean episode reward: -58.05825042937547, time: 24.427
agent0_energy_min, agent0_attention_min
[-49.37  -0.52]
agent1_energy_min, agent1_attention_min
[-4.87e+01 -2.00e-02]
20900 50
steps: 1044950, episodes: 20900, mean episode reward: -58.6123019220996, time: 23.943
agent0_energy_min, agent0_attention_min
[-47.77  -1.29]
agent1_energy_min, agent1_attention_min
[-49.27   0.  ]
21000 50
steps: 1049950, episodes: 21000, mean episode reward: -47.11344606146077, time: 24.484
agent0_energy_min, agent0_attention_min
[-47.48  -1.87]
agent1_energy_min, agent1_attention_min
[-4.915e+01 -2.000e-02]
21100 50
steps: 1054950, episodes: 21100, mean episode reward: -45.354229607216695, time: 24.873
agent0_energy_min, agent0_attention_min
[-45.33  -4.22]
agent1_energy_min, agent1_attention_min
[-48.26  -0.18]
21200 50
steps: 1059950, episodes: 21200, mean episode reward: -51.60223820633152, time: 24.41
agent0_energy_min, agent0_attention_min
[-47.91  -1.22]
agent1_energy_min, agent1_attention_min
[-4.88e+01 -3.00e-02]
21300 50
steps: 1064950, episodes: 21300, mean episode reward: -71.69336143342342, time: 24.305
agent0_energy_min, agent0_attention_min
[-44.3   -3.46]
agent1_energy_min, agent1_attention_min
[-48.53  -0.16]
21400 50
steps: 1069950, episodes: 21400, mean episode reward: -67.60438861218863, time: 24.957
agent0_energy_min, agent0_attention_min
[-47.21  -2.44]
agent1_energy_min, agent1_attention_min
[-48.32  -0.5 ]
21500 50
steps: 1074950, episodes: 21500, mean episode reward: -51.025496601880874, time: 24.292
agent0_energy_min, agent0_attention_min
[-48.37  -1.4 ]
agent1_energy_min, agent1_attention_min
[-48.74  -0.3 ]
21600 50
steps: 1079950, episodes: 21600, mean episode reward: -49.77266412120727, time: 25.039
agent0_energy_min, agent0_attention_min
[-47.42  -2.23]
agent1_energy_min, agent1_attention_min
[-48.91  -0.25]
21700 50
steps: 1084950, episodes: 21700, mean episode reward: -46.8369075387338, time: 25.122
agent0_energy_min, agent0_attention_min
[-45.4   -4.34]
agent1_energy_min, agent1_attention_min
[-48.84  -0.25]
21800 50
steps: 1089950, episodes: 21800, mean episode reward: -64.50691695453035, time: 24.066
agent0_energy_min, agent0_attention_min
[-42.98  -4.38]
agent1_energy_min, agent1_attention_min
[-48.19  -0.13]
21900 50
steps: 1094950, episodes: 21900, mean episode reward: -59.96228437857586, time: 24.767
agent0_energy_min, agent0_attention_min
[-43.88  -4.01]
agent1_energy_min, agent1_attention_min
[-49.11  -0.07]
22000 50
steps: 1099950, episodes: 22000, mean episode reward: -52.440275831236214, time: 24.799
agent0_energy_min, agent0_attention_min
[-43.83  -0.71]
agent1_energy_min, agent1_attention_min
[-48.57   0.  ]
22100 50
steps: 1104950, episodes: 22100, mean episode reward: -59.00469584156647, time: 25.043
agent0_energy_min, agent0_attention_min
[-48.21  -1.31]
agent1_energy_min, agent1_attention_min
[-4.823e+01 -3.000e-02]
22200 50
steps: 1109950, episodes: 22200, mean episode reward: -43.57849006402781, time: 24.322
agent0_energy_min, agent0_attention_min
[-47.38  -0.96]
agent1_energy_min, agent1_attention_min
[-48.79  -0.6 ]
22300 50
steps: 1114950, episodes: 22300, mean episode reward: -50.47797364416397, time: 24.553
agent0_energy_min, agent0_attention_min
[-49.67  -0.13]
agent1_energy_min, agent1_attention_min
[-48.27  -0.88]
22400 50
steps: 1119950, episodes: 22400, mean episode reward: -51.14295223335427, time: 24.61
agent0_energy_min, agent0_attention_min
[-49.19  -0.54]
agent1_energy_min, agent1_attention_min
[-49.1   -0.41]
22500 50
steps: 1124950, episodes: 22500, mean episode reward: -43.72489692404646, time: 24.894
agent0_energy_min, agent0_attention_min
[-49.72  -0.08]
agent1_energy_min, agent1_attention_min
[-48.86  -0.5 ]
22600 50
steps: 1129950, episodes: 22600, mean episode reward: -46.26594260824636, time: 24.937
agent0_energy_min, agent0_attention_min
[-48.74  -0.05]
agent1_energy_min, agent1_attention_min
[-48.93  -0.53]
22700 50
steps: 1134950, episodes: 22700, mean episode reward: -48.83462393306428, time: 24.402
agent0_energy_min, agent0_attention_min
[-47.09  -0.09]
agent1_energy_min, agent1_attention_min
[-48.71  -0.7 ]
22800 50
steps: 1139950, episodes: 22800, mean episode reward: -246.51675415680515, time: 24.268
agent0_energy_min, agent0_attention_min
[-21.52  -3.62]
agent1_energy_min, agent1_attention_min
[-48.14  -0.9 ]
22900 50
steps: 1144950, episodes: 22900, mean episode reward: -45.477973828293926, time: 24.838
agent0_energy_min, agent0_attention_min
[-44.8   -4.98]
agent1_energy_min, agent1_attention_min
[-48.83  -0.46]
23000 50
steps: 1149950, episodes: 23000, mean episode reward: -41.47231662324816, time: 24.901
agent0_energy_min, agent0_attention_min
[-46.43  -3.5 ]
agent1_energy_min, agent1_attention_min
[-48.66  -0.71]
23100 50
steps: 1154950, episodes: 23100, mean episode reward: -44.525178155813, time: 24.489
agent0_energy_min, agent0_attention_min
[-49.12  -0.86]
agent1_energy_min, agent1_attention_min
[-49.1   -0.37]
23200 50
steps: 1159950, episodes: 23200, mean episode reward: -40.59653070350757, time: 25.056
agent0_energy_min, agent0_attention_min
[-44.83  -5.16]
agent1_energy_min, agent1_attention_min
[-49.07  -0.19]
23300 50
steps: 1164950, episodes: 23300, mean episode reward: -46.91232983577125, time: 24.659
agent0_energy_min, agent0_attention_min
[-44.86  -4.98]
agent1_energy_min, agent1_attention_min
[-49.15  -0.14]
23400 50
steps: 1169950, episodes: 23400, mean episode reward: -48.005267006333064, time: 24.715
agent0_energy_min, agent0_attention_min
[-42.55  -7.01]
agent1_energy_min, agent1_attention_min
[-48.98  -0.41]
23500 50
steps: 1174950, episodes: 23500, mean episode reward: -57.5259840630353, time: 25.087
agent0_energy_min, agent0_attention_min
[-44.89  -4.94]
agent1_energy_min, agent1_attention_min
[-47.28  -0.6 ]
23600 50
steps: 1179950, episodes: 23600, mean episode reward: -48.74215974333004, time: 25.282
agent0_energy_min, agent0_attention_min
[-46.01  -3.89]
agent1_energy_min, agent1_attention_min
[-47.51  -1.76]
23700 50
steps: 1184950, episodes: 23700, mean episode reward: -59.63799381093773, time: 25.086
agent0_energy_min, agent0_attention_min
[-47.9   -1.72]
agent1_energy_min, agent1_attention_min
[-48.9   -0.81]
agent1_energy_min, agent1_attention_min
[-47.75  -1.17]
20000 50
steps: 999950, episodes: 20000, mean episode reward: -47.871211239257924, time: 24.731
agent0_energy_min, agent0_attention_min
[-49.48  -0.39]
agent1_energy_min, agent1_attention_min
[-48.71  -0.81]
20100 50
steps: 1004950, episodes: 20100, mean episode reward: -47.22335512281617, time: 24.764
agent0_energy_min, agent0_attention_min
[-49.79  -0.16]
agent1_energy_min, agent1_attention_min
[-48.64  -1.06]
20200 50
steps: 1009950, episodes: 20200, mean episode reward: -46.3033124553615, time: 24.315
agent0_energy_min, agent0_attention_min
[-49.5   -0.39]
agent1_energy_min, agent1_attention_min
[-48.53  -1.04]
20300 50
steps: 1014950, episodes: 20300, mean episode reward: -62.100120074349185, time: 24.202
agent0_energy_min, agent0_attention_min
[-49.04  -0.23]
agent1_energy_min, agent1_attention_min
[-48.64  -0.94]
20400 50
steps: 1019950, episodes: 20400, mean episode reward: -53.48613180413622, time: 24.516
agent0_energy_min, agent0_attention_min
[-48.82  -0.82]
agent1_energy_min, agent1_attention_min
[-48.64  -0.76]
20500 50
steps: 1024950, episodes: 20500, mean episode reward: -48.8555270785061, time: 24.355
agent0_energy_min, agent0_attention_min
[-49.26  -0.7 ]
agent1_energy_min, agent1_attention_min
[-48.63  -0.57]
20600 50
steps: 1029950, episodes: 20600, mean episode reward: -48.03547786207175, time: 24.515
agent0_energy_min, agent0_attention_min
[-49.24  -0.61]
agent1_energy_min, agent1_attention_min
[-48.74  -0.96]
20700 50
steps: 1034950, episodes: 20700, mean episode reward: -39.11781042957589, time: 24.956
agent0_energy_min, agent0_attention_min
[-49.29  -0.7 ]
agent1_energy_min, agent1_attention_min
[-48.77  -0.91]
20800 50
steps: 1039950, episodes: 20800, mean episode reward: -46.379116204616466, time: 24.432
agent0_energy_min, agent0_attention_min
[-48.64  -0.89]
agent1_energy_min, agent1_attention_min
[-48.76  -0.79]
20900 50
steps: 1044950, episodes: 20900, mean episode reward: -49.89442304400309, time: 24.282
agent0_energy_min, agent0_attention_min
[-47.42  -1.29]
agent1_energy_min, agent1_attention_min
[-48.31  -1.26]
21000 50
steps: 1049950, episodes: 21000, mean episode reward: -52.32780629397902, time: 24.751
agent0_energy_min, agent0_attention_min
[-48.03  -0.89]
agent1_energy_min, agent1_attention_min
[-47.99  -1.18]
21100 50
steps: 1054950, episodes: 21100, mean episode reward: -48.06454515051901, time: 25.154
agent0_energy_min, agent0_attention_min
[-49.6   -0.22]
agent1_energy_min, agent1_attention_min
[-48.96  -0.7 ]
21200 50
steps: 1059950, episodes: 21200, mean episode reward: -47.945752134143646, time: 24.422
agent0_energy_min, agent0_attention_min
[-48.73  -1.04]
agent1_energy_min, agent1_attention_min
[-48.68  -0.92]
21300 50
steps: 1064950, episodes: 21300, mean episode reward: -42.977875532612096, time: 24.482
agent0_energy_min, agent0_attention_min
[-46.04  -3.13]
agent1_energy_min, agent1_attention_min
[-48.9   -0.72]
21400 50
steps: 1069950, episodes: 21400, mean episode reward: -48.65075810062928, time: 24.33
agent0_energy_min, agent0_attention_min
[-28.16  -7.18]
agent1_energy_min, agent1_attention_min
[-49.13  -0.76]
21500 50
steps: 1074950, episodes: 21500, mean episode reward: -45.25424190557974, time: 24.808
agent0_energy_min, agent0_attention_min
[-25.08  -0.42]
agent1_energy_min, agent1_attention_min
[-48.34  -0.77]
21600 50
steps: 1079950, episodes: 21600, mean episode reward: -48.30420508167902, time: 24.659
agent0_energy_min, agent0_attention_min
[-23.48  -0.73]
agent1_energy_min, agent1_attention_min
[-48.7   -0.66]
21700 50
steps: 1084950, episodes: 21700, mean episode reward: -44.29418656425403, time: 24.829
agent0_energy_min, agent0_attention_min
[-22.15  -1.18]
agent1_energy_min, agent1_attention_min
[-48.89  -0.66]
21800 50
steps: 1089950, episodes: 21800, mean episode reward: -59.17706364725831, time: 24.881
agent0_energy_min, agent0_attention_min
[-41.65  -0.83]
agent1_energy_min, agent1_attention_min
[-48.88  -0.6 ]
21900 50
steps: 1094950, episodes: 21900, mean episode reward: -59.32230597639123, time: 24.695
agent0_energy_min, agent0_attention_min
[-23.51  -1.25]
agent1_energy_min, agent1_attention_min
[-48.7   -0.66]
22000 50
steps: 1099950, episodes: 22000, mean episode reward: -44.584961126204625, time: 24.601
agent0_energy_min, agent0_attention_min
[-31.93  -0.65]
agent1_energy_min, agent1_attention_min
[-48.91  -0.61]
22100 50
steps: 1104950, episodes: 22100, mean episode reward: -63.14961177677726, time: 25.394
agent0_energy_min, agent0_attention_min
[-28.72  -0.22]
agent1_energy_min, agent1_attention_min
[-48.41  -0.62]
22200 50
steps: 1109950, episodes: 22200, mean episode reward: -101.10700916801352, time: 24.481
agent0_energy_min, agent0_attention_min
[-39.75  -0.36]
agent1_energy_min, agent1_attention_min
[-48.22  -0.13]
22300 50
steps: 1114950, episodes: 22300, mean episode reward: -65.74940764349931, time: 24.38
agent0_energy_min, agent0_attention_min
[-47.36  -1.18]
agent1_energy_min, agent1_attention_min
[-49.47  -0.21]
22400 50
steps: 1119950, episodes: 22400, mean episode reward: -75.5600993409358, time: 24.407
agent0_energy_min, agent0_attention_min
[-46.35  -1.25]
agent1_energy_min, agent1_attention_min
[-49.56  -0.28]
22500 50
steps: 1124950, episodes: 22500, mean episode reward: -83.26806079293766, time: 24.898
agent0_energy_min, agent0_attention_min
[-34.07  -0.57]
agent1_energy_min, agent1_attention_min
[-49.23  -0.38]
22600 50
steps: 1129950, episodes: 22600, mean episode reward: -93.12888674603163, time: 25.094
agent0_energy_min, agent0_attention_min
[-43.76  -0.14]
agent1_energy_min, agent1_attention_min
[-48.89  -0.82]
22700 50
steps: 1134950, episodes: 22700, mean episode reward: -234.72582948526983, time: 24.581
agent0_energy_min, agent0_attention_min
[-27.25  -0.14]
agent1_energy_min, agent1_attention_min
[-46.81  -2.85]
22800 50
steps: 1139950, episodes: 22800, mean episode reward: -47.22126464564813, time: 24.332
agent0_energy_min, agent0_attention_min
[-49.08  -0.2 ]
agent1_energy_min, agent1_attention_min
[-48.95  -0.82]
22900 50
steps: 1144950, episodes: 22900, mean episode reward: -53.64071199376059, time: 24.022
agent0_energy_min, agent0_attention_min
[-49.59  -0.19]
agent1_energy_min, agent1_attention_min
[-47.31  -0.93]
23000 50
steps: 1149950, episodes: 23000, mean episode reward: -46.334057519355405, time: 24.063
agent0_energy_min, agent0_attention_min
[-49.32  -0.55]
agent1_energy_min, agent1_attention_min
[-48.33  -0.62]
23100 50
steps: 1154950, episodes: 23100, mean episode reward: -47.62370959502609, time: 25.089
agent0_energy_min, agent0_attention_min
[-39.19  -7.36]
agent1_energy_min, agent1_attention_min
[-48.77  -0.42]
23200 50
steps: 1159950, episodes: 23200, mean episode reward: -48.295715564392225, time: 24.673
agent0_energy_min, agent0_attention_min
[-40.65  -0.78]
agent1_energy_min, agent1_attention_min
[-48.1   -0.46]
23300 50
steps: 1164950, episodes: 23300, mean episode reward: -43.937451286648404, time: 23.895
agent0_energy_min, agent0_attention_min
[-37.85  -0.59]
agent1_energy_min, agent1_attention_min
[-48.1   -1.06]
23400 50
steps: 1169950, episodes: 23400, mean episode reward: -43.50877744445078, time: 24.506
agent0_energy_min, agent0_attention_min
[-43.83  -0.5 ]
agent1_energy_min, agent1_attention_min
[-47.86  -0.81]
23500 50
steps: 1174950, episodes: 23500, mean episode reward: -88.73564413616924, time: 24.668
agent0_energy_min, agent0_attention_min
[-35.03  -2.72]
agent1_energy_min, agent1_attention_min
[-47.64  -0.63]
23600 50
steps: 1179950, episodes: 23600, mean episode reward: -106.24390535291215, time: 25.507
agent0_energy_min, agent0_attention_min
[-40.57  -2.02]
agent1_energy_min, agent1_attention_min
[-47.22  -0.92]
23700 50
steps: 1184950, episodes: 23700, mean episode reward: -93.23640122281678, time: 24.184
agent0_energy_min, agent0_attention_min
[-36.28  -1.62]
agent1_energy_min, agent1_attention_min
[-41.85  -5.07]
23800 50
steps: 1189950, episodes: 23800, mean episode reward: -152.12091280097044, time: 24.738
agent0_energy_min, agent0_attention_min
[-45.33  -2.08]
agent1_energy_min, agent1_attention_min
[-32.79  -7.96]
23900
agent0_energy_min, agent0_attention_min
[-24.58 -25.16]
agent1_energy_min, agent1_attention_min
[-45.51  -4.01]
20100 50
steps: 1004950, episodes: 20100, mean episode reward: -80.35551522140537, time: 24.38
agent0_energy_min, agent0_attention_min
[-33.09 -16.6 ]
agent1_energy_min, agent1_attention_min
[-45.58  -3.54]
20200 50
steps: 1009950, episodes: 20200, mean episode reward: -63.405211853300386, time: 24.025
agent0_energy_min, agent0_attention_min
[-28.99 -20.6 ]
agent1_energy_min, agent1_attention_min
[-45.78  -3.88]
20300 50
steps: 1014950, episodes: 20300, mean episode reward: -73.02031014577643, time: 24.342
agent0_energy_min, agent0_attention_min
[-26.52 -23.37]
agent1_energy_min, agent1_attention_min
[-47.47  -2.32]
20400 50
steps: 1019950, episodes: 20400, mean episode reward: -83.87325421213042, time: 24.002
agent0_energy_min, agent0_attention_min
[-30.08 -19.38]
agent1_energy_min, agent1_attention_min
[-47.45  -2.4 ]
20500 50
steps: 1024950, episodes: 20500, mean episode reward: -76.94268569413515, time: 24.401
agent0_energy_min, agent0_attention_min
[-29.64 -19.96]
agent1_energy_min, agent1_attention_min
[-46.17  -3.44]
20600 50
steps: 1029950, episodes: 20600, mean episode reward: -68.89267553440926, time: 23.955
agent0_energy_min, agent0_attention_min
[-27.22 -22.57]
agent1_energy_min, agent1_attention_min
[-45.85  -3.74]
20700 50
steps: 1034950, episodes: 20700, mean episode reward: -77.23447201629574, time: 24.213
agent0_energy_min, agent0_attention_min
[-30.04 -19.81]
agent1_energy_min, agent1_attention_min
[-46.19  -3.35]
20800 50
steps: 1039950, episodes: 20800, mean episode reward: -64.54879063398555, time: 23.986
agent0_energy_min, agent0_attention_min
[-28.49 -21.33]
agent1_energy_min, agent1_attention_min
[-45.3   -4.33]
20900 50
steps: 1044950, episodes: 20900, mean episode reward: -122.46126362202966, time: 24.278
agent0_energy_min, agent0_attention_min
[-29.47 -20.37]
agent1_energy_min, agent1_attention_min
[-45.36  -4.41]
21000 50
steps: 1049950, episodes: 21000, mean episode reward: -83.07824886435293, time: 24.152
agent0_energy_min, agent0_attention_min
[-23.88 -25.82]
agent1_energy_min, agent1_attention_min
[-47.16  -2.4 ]
21100 50
steps: 1054950, episodes: 21100, mean episode reward: -71.8315697519242, time: 25.205
agent0_energy_min, agent0_attention_min
[-20.95 -28.67]
agent1_energy_min, agent1_attention_min
[-45.91  -3.51]
21200 50
steps: 1059950, episodes: 21200, mean episode reward: -62.437403405957966, time: 24.072
agent0_energy_min, agent0_attention_min
[-20.85 -29.07]
agent1_energy_min, agent1_attention_min
[-47.09  -2.46]
21300 50
steps: 1064950, episodes: 21300, mean episode reward: -66.56382648387162, time: 24.92
agent0_energy_min, agent0_attention_min
[-17.53 -32.38]
agent1_energy_min, agent1_attention_min
[-45.6  -3.9]
21400 50
steps: 1069950, episodes: 21400, mean episode reward: -65.68637003705634, time: 24.255
agent0_energy_min, agent0_attention_min
[-22.75 -27.19]
agent1_energy_min, agent1_attention_min
[-46.22  -3.31]
21500 50
steps: 1074950, episodes: 21500, mean episode reward: -61.929016838251684, time: 24.369
agent0_energy_min, agent0_attention_min
[-24.86 -24.75]
agent1_energy_min, agent1_attention_min
[-39.38  -9.97]
21600 50
steps: 1079950, episodes: 21600, mean episode reward: -95.24400969285931, time: 25.417
agent0_energy_min, agent0_attention_min
[-20.35 -28.53]
agent1_energy_min, agent1_attention_min
[-41.85  -7.68]
21700 50
steps: 1084950, episodes: 21700, mean episode reward: -64.94673318643041, time: 24.494
agent0_energy_min, agent0_attention_min
[-17.34 -30.15]
agent1_energy_min, agent1_attention_min
[-45.27  -4.28]
21800 50
steps: 1089950, episodes: 21800, mean episode reward: -93.65822636811068, time: 24.966
agent0_energy_min, agent0_attention_min
[-13.33 -30.81]
agent1_energy_min, agent1_attention_min
[-43.35  -5.99]
21900 50
steps: 1094950, episodes: 21900, mean episode reward: -56.899364542356324, time: 24.822
agent0_energy_min, agent0_attention_min
[-17.75 -31.69]
agent1_energy_min, agent1_attention_min
[-42.11  -7.8 ]
22000 50
steps: 1099950, episodes: 22000, mean episode reward: -85.17852014955142, time: 24.123
agent0_energy_min, agent0_attention_min
[-22.03 -27.54]
agent1_energy_min, agent1_attention_min
[-40.96  -8.75]
22100 50
steps: 1104950, episodes: 22100, mean episode reward: -63.495919262993546, time: 24.56
agent0_energy_min, agent0_attention_min
[-25.16 -24.03]
agent1_energy_min, agent1_attention_min
[-40.41  -9.2 ]
22200 50
steps: 1109950, episodes: 22200, mean episode reward: -60.12289062105606, time: 24.424
agent0_energy_min, agent0_attention_min
[-20.08 -28.59]
agent1_energy_min, agent1_attention_min
[-37.5  -12.26]
22300 50
steps: 1114950, episodes: 22300, mean episode reward: -79.61169283760978, time: 23.836
agent0_energy_min, agent0_attention_min
[-23.68 -25.17]
agent1_energy_min, agent1_attention_min
[-27.13 -21.7 ]
22400 50
steps: 1119950, episodes: 22400, mean episode reward: -77.5755493645343, time: 24.124
agent0_energy_min, agent0_attention_min
[-19.65 -29.98]
agent1_energy_min, agent1_attention_min
[-30.38 -17.62]
22500 50
steps: 1124950, episodes: 22500, mean episode reward: -72.48410877083566, time: 24.654
agent0_energy_min, agent0_attention_min
[-28.44 -21.36]
agent1_energy_min, agent1_attention_min
[-31.1  -18.22]
22600 50
steps: 1129950, episodes: 22600, mean episode reward: -80.1658416616974, time: 24.515
agent0_energy_min, agent0_attention_min
[-27.4  -22.51]
agent1_energy_min, agent1_attention_min
[-33.98 -14.83]
22700 50
steps: 1134950, episodes: 22700, mean episode reward: -87.33149727115101, time: 24.25
agent0_energy_min, agent0_attention_min
[-23.06 -26.4 ]
agent1_energy_min, agent1_attention_min
[-34.93 -13.75]
22800 50
steps: 1139950, episodes: 22800, mean episode reward: -86.2079575839253, time: 24.391
agent0_energy_min, agent0_attention_min
[-25.42 -21.39]
agent1_energy_min, agent1_attention_min
[-38.64 -10.2 ]
22900 50
steps: 1144950, episodes: 22900, mean episode reward: -67.4038287721329, time: 24.588
agent0_energy_min, agent0_attention_min
[-17.26 -30.17]
agent1_energy_min, agent1_attention_min
[-34.02 -14.13]
23000 50
steps: 1149950, episodes: 23000, mean episode reward: -73.82247314634023, time: 24.383
agent0_energy_min, agent0_attention_min
[-21.44 -27.42]
agent1_energy_min, agent1_attention_min
[-34.68 -12.5 ]
23100 50
steps: 1154950, episodes: 23100, mean episode reward: -71.29642326418593, time: 25.824
agent0_energy_min, agent0_attention_min
[-12.06 -29.  ]
agent1_energy_min, agent1_attention_min
[-32.23 -14.57]
23200 50
steps: 1159950, episodes: 23200, mean episode reward: -59.404834227436226, time: 24.784
agent0_energy_min, agent0_attention_min
[ -8.91 -35.58]
agent1_energy_min, agent1_attention_min
[-28.03 -21.66]
23300 50
steps: 1164950, episodes: 23300, mean episode reward: -67.76493851410588, time: 24.139
agent0_energy_min, agent0_attention_min
[-15.94 -29.98]
agent1_energy_min, agent1_attention_min
[-23.54 -25.92]
23400 50
steps: 1169950, episodes: 23400, mean episode reward: -53.67869631250056, time: 24.451
agent0_energy_min, agent0_attention_min
[-14.43 -33.75]
agent1_energy_min, agent1_attention_min
[-25.88 -23.8 ]
23500 50
steps: 1174950, episodes: 23500, mean episode reward: -60.60614384551092, time: 24.119
agent0_energy_min, agent0_attention_min
[-15.03 -33.7 ]
agent1_energy_min, agent1_attention_min
[-25.1  -24.35]
23600 50
steps: 1179950, episodes: 23600, mean episode reward: -57.86192103039878, time: 24.76
agent0_energy_min, agent0_attention_min
[-15.97 -33.35]
agent1_energy_min, agent1_attention_min
[-24.39 -25.32]
23700 50
steps: 1184950, episodes: 23700, mean episode reward: -57.37682224528699, time: 24.241
agent0_energy_min, agent0_attention_min
[ -9.67 -39.92]
agent1_energy_min, agent1_attention_min
[-27.15 -22.03]
23800 50
steps: 1189950, episodes: 23800, mean episode reward: -64.20983613186714, time: 24.348
agent0_energy_min, agent0_attention_min
[-14.29 -35.42]
agent1_energy_min, agent1_attention_min
[-27.43 -21.24]
23900 50
steps: 1194950, episodes: 23900, mean episode reward: -56.641113231424406, time: 25.583
agent0_energy_min, agent0_attention_min
[-14.88 -35.01]
agent1_energy_min, agent1_attention_min
agent0_energy_min, agent0_attention_min
[-34.88 -14.99]
agent1_energy_min, agent1_attention_min
[-20.93 -27.88]
20100 50
steps: 1004950, episodes: 20100, mean episode reward: -65.37218952731044, time: 24.384
agent0_energy_min, agent0_attention_min
[-35.06 -14.89]
agent1_energy_min, agent1_attention_min
[-23.73 -24.56]
20200 50
steps: 1009950, episodes: 20200, mean episode reward: -71.43724006819414, time: 23.945
agent0_energy_min, agent0_attention_min
[-35.41 -14.52]
agent1_energy_min, agent1_attention_min
[-25.31 -23.79]
20300 50
steps: 1014950, episodes: 20300, mean episode reward: -74.78848830046077, time: 24.126
agent0_energy_min, agent0_attention_min
[-34.8  -14.06]
agent1_energy_min, agent1_attention_min
[-24.08 -25.02]
20400 50
steps: 1019950, episodes: 20400, mean episode reward: -76.51447561399056, time: 23.584
agent0_energy_min, agent0_attention_min
[-37.36 -11.84]
agent1_energy_min, agent1_attention_min
[-28.28 -20.72]
20500 50
steps: 1024950, episodes: 20500, mean episode reward: -74.24102541597834, time: 24.214
agent0_energy_min, agent0_attention_min
[-38.45 -11.16]
agent1_energy_min, agent1_attention_min
[-25.34 -23.3 ]
20600 50
steps: 1029950, episodes: 20600, mean episode reward: -73.84368105683502, time: 24.392
agent0_energy_min, agent0_attention_min
[-33.62 -14.04]
agent1_energy_min, agent1_attention_min
[-23.66 -25.44]
20700 50
steps: 1034950, episodes: 20700, mean episode reward: -75.94360810112826, time: 23.911
agent0_energy_min, agent0_attention_min
[-33.74 -15.18]
agent1_energy_min, agent1_attention_min
[-24.25 -24.38]
20800 50
steps: 1039950, episodes: 20800, mean episode reward: -67.0671563387595, time: 23.994
agent0_energy_min, agent0_attention_min
[-35.13 -14.83]
agent1_energy_min, agent1_attention_min
[-26.25 -22.4 ]
20900 50
steps: 1044950, episodes: 20900, mean episode reward: -81.17414322311676, time: 24.206
agent0_energy_min, agent0_attention_min
[-36.92 -12.95]
agent1_energy_min, agent1_attention_min
[-20.51 -26.98]
21000 50
steps: 1049950, episodes: 21000, mean episode reward: -85.39549426070491, time: 23.856
agent0_energy_min, agent0_attention_min
[-40.36  -9.49]
agent1_energy_min, agent1_attention_min
[-24.26 -24.56]
21100 50
steps: 1054950, episodes: 21100, mean episode reward: -66.49467679492032, time: 24.707
agent0_energy_min, agent0_attention_min
[-33.89 -15.62]
agent1_energy_min, agent1_attention_min
[-22.86 -26.14]
21200 50
steps: 1059950, episodes: 21200, mean episode reward: -77.60033535206236, time: 24.062
agent0_energy_min, agent0_attention_min
[-41.36  -8.11]
agent1_energy_min, agent1_attention_min
[-19.62 -29.57]
21300 50
steps: 1064950, episodes: 21300, mean episode reward: -70.10914270456375, time: 24.67
agent0_energy_min, agent0_attention_min
[-34.06 -15.72]
agent1_energy_min, agent1_attention_min
[-23.97 -25.5 ]
21400 50
steps: 1069950, episodes: 21400, mean episode reward: -96.06647625935243, time: 24.628
agent0_energy_min, agent0_attention_min
[-35.96 -13.69]
agent1_energy_min, agent1_attention_min
[-21.98 -27.45]
21500 50
steps: 1074950, episodes: 21500, mean episode reward: -96.787396921849, time: 24.414
agent0_energy_min, agent0_attention_min
[-30.51 -15.64]
agent1_energy_min, agent1_attention_min
[-26.01 -23.26]
21600 50
steps: 1079950, episodes: 21600, mean episode reward: -67.56208420823134, time: 25.164
agent0_energy_min, agent0_attention_min
[-31.06 -17.62]
agent1_energy_min, agent1_attention_min
[-27.51 -21.07]
21700 50
steps: 1084950, episodes: 21700, mean episode reward: -72.35198538067576, time: 24.429
agent0_energy_min, agent0_attention_min
[-33.35 -16.41]
agent1_energy_min, agent1_attention_min
[-24.74 -24.4 ]
21800 50
steps: 1089950, episodes: 21800, mean episode reward: -79.74218396403609, time: 23.327
agent0_energy_min, agent0_attention_min
[-41.94  -7.89]
agent1_energy_min, agent1_attention_min
[-26.89 -21.97]
21900 50
steps: 1094950, episodes: 21900, mean episode reward: -75.73391068050107, time: 24.213
agent0_energy_min, agent0_attention_min
[-29.17 -20.51]
agent1_energy_min, agent1_attention_min
[-30.68 -18.39]
22000 50
steps: 1099950, episodes: 22000, mean episode reward: -67.61005846269664, time: 24.142
agent0_energy_min, agent0_attention_min
[-33.03 -16.42]
agent1_energy_min, agent1_attention_min
[-25.8  -23.49]
22100 50
steps: 1104950, episodes: 22100, mean episode reward: -71.58417913670952, time: 24.704
agent0_energy_min, agent0_attention_min
[-31.31 -18.61]
agent1_energy_min, agent1_attention_min
[-29.07 -20.18]
22200 50
steps: 1109950, episodes: 22200, mean episode reward: -67.21437142519552, time: 24.213
agent0_energy_min, agent0_attention_min
[-31.36 -18.59]
agent1_energy_min, agent1_attention_min
[-29.57 -19.43]
22300 50
steps: 1114950, episodes: 22300, mean episode reward: -64.77119634258288, time: 25.22
agent0_energy_min, agent0_attention_min
[-31.98 -17.9 ]
agent1_energy_min, agent1_attention_min
[-26.09 -23.18]
22400 50
steps: 1119950, episodes: 22400, mean episode reward: -61.90787538054471, time: 24.509
agent0_energy_min, agent0_attention_min
[-36.59 -13.16]
agent1_energy_min, agent1_attention_min
[-27.34 -21.67]
22500 50
steps: 1124950, episodes: 22500, mean episode reward: -64.70788656748164, time: 24.723
agent0_energy_min, agent0_attention_min
[-34.23 -15.47]
agent1_energy_min, agent1_attention_min
[-23.34 -24.7 ]
22600 50
steps: 1129950, episodes: 22600, mean episode reward: -71.1814918358748, time: 24.468
agent0_energy_min, agent0_attention_min
[-38.56 -10.15]
agent1_energy_min, agent1_attention_min
[-29.91 -19.04]
22700 50
steps: 1134950, episodes: 22700, mean episode reward: -102.53042195524951, time: 24.097
agent0_energy_min, agent0_attention_min
[-32.11 -14.58]
agent1_energy_min, agent1_attention_min
[-35.17 -12.95]
22800 50
steps: 1139950, episodes: 22800, mean episode reward: -78.93209288686589, time: 24.31
agent0_energy_min, agent0_attention_min
[-34.99 -13.39]
agent1_energy_min, agent1_attention_min
[-36.87 -10.51]
22900 50
steps: 1144950, episodes: 22900, mean episode reward: -106.24506681024667, time: 25.043
agent0_energy_min, agent0_attention_min
[-32.94  -5.65]
agent1_energy_min, agent1_attention_min
[-33.87 -13.5 ]
23000 50
steps: 1149950, episodes: 23000, mean episode reward: -70.33805286757624, time: 24.96
agent0_energy_min, agent0_attention_min
[-35.22 -11.9 ]
agent1_energy_min, agent1_attention_min
[-39.03  -9.52]
23100 50
steps: 1154950, episodes: 23100, mean episode reward: -68.88977661979851, time: 24.531
agent0_energy_min, agent0_attention_min
[-39.1   -9.43]
agent1_energy_min, agent1_attention_min
[-32.48 -15.97]
23200 50
steps: 1159950, episodes: 23200, mean episode reward: -71.83526780434413, time: 24.333
agent0_energy_min, agent0_attention_min
[-36.88 -12.95]
agent1_energy_min, agent1_attention_min
[-22.94 -22.44]
23300 50
steps: 1164950, episodes: 23300, mean episode reward: -94.72853255204393, time: 24.137
agent0_energy_min, agent0_attention_min
[-38.76 -11.14]
agent1_energy_min, agent1_attention_min
[-34.44 -14.37]
23400 50
steps: 1169950, episodes: 23400, mean episode reward: -96.49182125702534, time: 24.34
agent0_energy_min, agent0_attention_min
[-40.51  -8.55]
agent1_energy_min, agent1_attention_min
[-28.67 -16.02]
23500 50
steps: 1174950, episodes: 23500, mean episode reward: -76.28326930095392, time: 24.016
agent0_energy_min, agent0_attention_min
[-36.9 -11.7]
agent1_energy_min, agent1_attention_min
[-29.7  -16.17]
23600 50
steps: 1179950, episodes: 23600, mean episode reward: -137.82682502303223, time: 25.154
agent0_energy_min, agent0_attention_min
[-37.   -12.14]
agent1_energy_min, agent1_attention_min
[-33.75 -14.28]
23700 50
steps: 1184950, episodes: 23700, mean episode reward: -92.81244898620666, time: 24.626
agent0_energy_min, agent0_attention_min
[-38.18 -10.62]
agent1_energy_min, agent1_attention_min
[-37.65 -10.22]
23800 50
steps: 1189950, episodes: 23800, mean episode reward: -61.76762812676332, time: 24.989
agent0_energy_min, agent0_attention_min
[-33.49 -16.32]
agent1_energy_min, agent1_attention_min
[-37.61 -10.76]
23900 50
steps: 1194950, episodes: 23900, mean episode reward: -79.36987520816932, time: 23.903
agent0_energy_min, agent0_attention_min
[-37.49 -12.45]
agent1_energy_min, agent1_attention_minagent0_energy_min, agent0_attention_min
[-4.992e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-1.73 -0.11]
20000 50
steps: 999950, episodes: 20000, mean episode reward: -93.36341142339975, time: 23.898
agent0_energy_min, agent0_attention_min
[-49.79  -0.16]
agent1_energy_min, agent1_attention_min
[-4.21 -0.63]
20100 50
steps: 1004950, episodes: 20100, mean episode reward: -126.0918060148585, time: 23.584
agent0_energy_min, agent0_attention_min
[-4.988e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-16.37 -20.28]
20200 50
steps: 1009950, episodes: 20200, mean episode reward: -110.74226392332208, time: 24.143
agent0_energy_min, agent0_attention_min
[-49.91   0.  ]
agent1_energy_min, agent1_attention_min
[-29.06  -0.79]
20300 50
steps: 1014950, episodes: 20300, mean episode reward: -108.29210165936145, time: 24.402
agent0_energy_min, agent0_attention_min
[-4.994e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-1.297e+01 -1.000e-02]
20400 50
steps: 1019950, episodes: 20400, mean episode reward: -91.50163098781132, time: 23.33
agent0_energy_min, agent0_attention_min
[-4.995e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-24.02   0.  ]
20500 50
steps: 1024950, episodes: 20500, mean episode reward: -105.93355401738964, time: 23.792
agent0_energy_min, agent0_attention_min
[-4.996e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-2.717e+01 -1.000e-02]
20600 50
steps: 1029950, episodes: 20600, mean episode reward: -112.24398142948928, time: 24.214
agent0_energy_min, agent0_attention_min
[-4.995e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-20.75  -0.04]
20700 50
steps: 1034950, episodes: 20700, mean episode reward: -109.51915161647722, time: 23.456
agent0_energy_min, agent0_attention_min
[-4.993e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-1.486e+01 -1.000e-02]
20800 50
steps: 1039950, episodes: 20800, mean episode reward: -106.75280369006887, time: 23.983
agent0_energy_min, agent0_attention_min
[-4.99e+01 -1.00e-02]
agent1_energy_min, agent1_attention_min
[-11.26   0.  ]
20900 50
steps: 1044950, episodes: 20900, mean episode reward: -108.30632077332073, time: 23.776
agent0_energy_min, agent0_attention_min
[-4.99e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-10.02  -0.02]
21000 50
steps: 1049950, episodes: 21000, mean episode reward: -92.84181578806825, time: 24.032
agent0_energy_min, agent0_attention_min
[-4.992e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-14.16  -0.02]
21100 50
steps: 1054950, episodes: 21100, mean episode reward: -96.83293721993442, time: 24.302
agent0_energy_min, agent0_attention_min
[-4.995e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-3.046e+01 -1.000e-02]
21200 50
steps: 1059950, episodes: 21200, mean episode reward: -98.85615686028795, time: 24.012
agent0_energy_min, agent0_attention_min
[-4.995e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-5.59  0.  ]
21300 50
steps: 1064950, episodes: 21300, mean episode reward: -103.6990822445455, time: 24.226
agent0_energy_min, agent0_attention_min
[-4.993e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-11.44  -0.03]
21400 50
steps: 1069950, episodes: 21400, mean episode reward: -92.47165231086561, time: 24.393
agent0_energy_min, agent0_attention_min
[-4.996e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-2.192e+01 -1.000e-02]
21500 50
steps: 1074950, episodes: 21500, mean episode reward: -107.84299194326681, time: 23.814
agent0_energy_min, agent0_attention_min
[-4.978e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-26.66  -0.33]
21600 50
steps: 1079950, episodes: 21600, mean episode reward: -144.84765174358247, time: 24.153
agent0_energy_min, agent0_attention_min
[-49.66   0.  ]
agent1_energy_min, agent1_attention_min
[-22.28  -1.21]
21700 50
steps: 1084950, episodes: 21700, mean episode reward: -101.39457837549575, time: 24.101
agent0_energy_min, agent0_attention_min
[-4.954e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-2.096e+01 -1.000e-02]
21800 50
steps: 1089950, episodes: 21800, mean episode reward: -85.31079658039057, time: 24.326
agent0_energy_min, agent0_attention_min
[-49.63  -0.05]
agent1_energy_min, agent1_attention_min
[-24.94  -0.04]
21900 50
steps: 1094950, episodes: 21900, mean episode reward: -101.21764322621719, time: 23.701
agent0_energy_min, agent0_attention_min
[-49.75   0.  ]
agent1_energy_min, agent1_attention_min
[-17.84  -0.03]
22000 50
steps: 1099950, episodes: 22000, mean episode reward: -122.86425341915702, time: 23.941
agent0_energy_min, agent0_attention_min
[-4.987e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-16.11   0.  ]
22100 50
steps: 1104950, episodes: 22100, mean episode reward: -104.24894037019038, time: 24.785
agent0_energy_min, agent0_attention_min
[-4.977e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-4.4  -0.09]
22200 50
steps: 1109950, episodes: 22200, mean episode reward: -754.5783469169779, time: 23.726
agent0_energy_min, agent0_attention_min
[-49.7   -0.22]
agent1_energy_min, agent1_attention_min
[-1.96 -0.01]
22300 50
steps: 1114950, episodes: 22300, mean episode reward: -97.46486786430474, time: 23.796
agent0_energy_min, agent0_attention_min
[-49.46  -0.35]
agent1_energy_min, agent1_attention_min
[-19.98  -0.05]
22400 50
steps: 1119950, episodes: 22400, mean episode reward: -102.21136656717526, time: 23.871
agent0_energy_min, agent0_attention_min
[-49.67  -0.09]
agent1_energy_min, agent1_attention_min
[-11.    -0.09]
22500 50
steps: 1124950, episodes: 22500, mean episode reward: -113.8518450238235, time: 24.276
agent0_energy_min, agent0_attention_min
[-49.83  -0.05]
agent1_energy_min, agent1_attention_min
[-9.67  0.  ]
22600 50
steps: 1129950, episodes: 22600, mean episode reward: -104.97810059812954, time: 24.245
agent0_energy_min, agent0_attention_min
[-4.98e+01 -2.00e-02]
agent1_energy_min, agent1_attention_min
[-1.05e+01 -1.00e-02]
22700 50
steps: 1134950, episodes: 22700, mean episode reward: -108.5355082327952, time: 24.243
agent0_energy_min, agent0_attention_min
[-4.968e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-8.35 -0.03]
22800 50
steps: 1139950, episodes: 22800, mean episode reward: -113.56363560951303, time: 24.077
agent0_energy_min, agent0_attention_min
[-49.77  -0.08]
agent1_energy_min, agent1_attention_min
[-3.  0.]
22900 50
steps: 1144950, episodes: 22900, mean episode reward: -158.12408065592663, time: 23.809
agent0_energy_min, agent0_attention_min
[-48.79  -0.05]
agent1_energy_min, agent1_attention_min
[-5.37 -0.01]
23000 50
steps: 1149950, episodes: 23000, mean episode reward: -157.7219072005638, time: 23.975
agent0_energy_min, agent0_attention_min
[-46.81  -0.11]
agent1_energy_min, agent1_attention_min
[-1.57 -0.01]
23100 50
steps: 1154950, episodes: 23100, mean episode reward: -129.41326108783107, time: 24.406
agent0_energy_min, agent0_attention_min
[-49.83  -0.08]
agent1_energy_min, agent1_attention_min
[-27.88  -0.11]
23200 50
steps: 1159950, episodes: 23200, mean episode reward: -98.30722527581304, time: 23.463
agent0_energy_min, agent0_attention_min
[-4.993e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-37.34  -0.04]
23300 50
steps: 1164950, episodes: 23300, mean episode reward: -82.65773628663291, time: 23.495
agent0_energy_min, agent0_attention_min
[-49.9   0. ]
agent1_energy_min, agent1_attention_min
[-43.08  -0.05]
23400 50
steps: 1169950, episodes: 23400, mean episode reward: -90.88601654811777, time: 23.845
agent0_energy_min, agent0_attention_min
[-49.89   0.  ]
agent1_energy_min, agent1_attention_min
[-4.246e+01 -1.000e-02]
23500 50
steps: 1174950, episodes: 23500, mean episode reward: -102.85330224091109, time: 24.47
agent0_energy_min, agent0_attention_min
[-4.987e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-47.16  -0.05]
23600 50
steps: 1179950, episodes: 23600, mean episode reward: -105.50041809534643, time: 23.892
agent0_energy_min, agent0_attention_min
[-4.993e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-42.28   0.  ]
23700 50
steps: 1184950, episodes: 23700, mean episode reward: -108.73757474042253, time: 24.127
agent0_energy_min, agent0_attention_min
[-49.92   0.  ]
agent1_energy_min, agent1_attention_min
agent0_energy_min, agent0_attention_min
[-22.02  -1.39]
agent1_energy_min, agent1_attention_min
[ -9.61 -40.36]
20100 50
steps: 1004950, episodes: 20100, mean episode reward: -59.112127019569726, time: 24.937
agent0_energy_min, agent0_attention_min
[-19.94  -0.89]
agent1_energy_min, agent1_attention_min
[-10.25 -39.7 ]
20200 50
steps: 1009950, episodes: 20200, mean episode reward: -56.21229160698564, time: 24.575
agent0_energy_min, agent0_attention_min
[-26.47  -1.9 ]
agent1_energy_min, agent1_attention_min
[ -9.9  -40.08]
20300 50
steps: 1014950, episodes: 20300, mean episode reward: -63.29397267041638, time: 24.244
agent0_energy_min, agent0_attention_min
[-25.63  -1.5 ]
agent1_energy_min, agent1_attention_min
[ -8.73 -41.2 ]
20400 50
steps: 1019950, episodes: 20400, mean episode reward: -63.020790489759236, time: 23.973
agent0_energy_min, agent0_attention_min
[-23.81  -1.15]
agent1_energy_min, agent1_attention_min
[-10.36 -39.62]
20500 50
steps: 1024950, episodes: 20500, mean episode reward: -72.52323863942127, time: 24.683
agent0_energy_min, agent0_attention_min
[-22.73  -0.84]
agent1_energy_min, agent1_attention_min
[-10.09 -39.86]
20600 50
steps: 1029950, episodes: 20600, mean episode reward: -69.64771124611761, time: 23.64
agent0_energy_min, agent0_attention_min
[-26.44  -1.45]
agent1_energy_min, agent1_attention_min
[ -9.86 -40.13]
20700 50
steps: 1034950, episodes: 20700, mean episode reward: -77.56365026642612, time: 24.064
agent0_energy_min, agent0_attention_min
[-22.21  -0.83]
agent1_energy_min, agent1_attention_min
[ -6.41 -43.55]
20800 50
steps: 1039950, episodes: 20800, mean episode reward: -63.73674253690826, time: 23.986
agent0_energy_min, agent0_attention_min
[-23.15  -0.92]
agent1_energy_min, agent1_attention_min
[ -7.29 -42.68]
20900 50
steps: 1044950, episodes: 20900, mean episode reward: -68.98079327177567, time: 24.326
agent0_energy_min, agent0_attention_min
[-28.54  -0.81]
agent1_energy_min, agent1_attention_min
[ -4.8  -45.19]
21000 50
steps: 1049950, episodes: 21000, mean episode reward: -93.94282773766379, time: 24.383
agent0_energy_min, agent0_attention_min
[-24.7   -1.02]
agent1_energy_min, agent1_attention_min
[ -6.64 -43.34]
21100 50
steps: 1054950, episodes: 21100, mean episode reward: -58.45182677507396, time: 24.922
agent0_energy_min, agent0_attention_min
[-21.66  -0.85]
agent1_energy_min, agent1_attention_min
[ -7.1  -42.44]
21200 50
steps: 1059950, episodes: 21200, mean episode reward: -68.53852241284314, time: 24.558
agent0_energy_min, agent0_attention_min
[-23.03  -1.51]
agent1_energy_min, agent1_attention_min
[ -5.77 -42.57]
21300 50
steps: 1064950, episodes: 21300, mean episode reward: -86.94392449257425, time: 24.536
agent0_energy_min, agent0_attention_min
[-23.97  -1.1 ]
agent1_energy_min, agent1_attention_min
[ -6.72 -42.5 ]
21400 50
steps: 1069950, episodes: 21400, mean episode reward: -73.01951198055595, time: 24.47
agent0_energy_min, agent0_attention_min
[-24.35  -0.97]
agent1_energy_min, agent1_attention_min
[ -7.59 -42.27]
21500 50
steps: 1074950, episodes: 21500, mean episode reward: -69.92129965182116, time: 24.618
agent0_energy_min, agent0_attention_min
[-25.07  -0.83]
agent1_energy_min, agent1_attention_min
[ -6.03 -43.87]
21600 50
steps: 1079950, episodes: 21600, mean episode reward: -68.56872385571698, time: 25.354
agent0_energy_min, agent0_attention_min
[-25.26  -0.6 ]
agent1_energy_min, agent1_attention_min
[ -6.14 -43.81]
21700 50
steps: 1084950, episodes: 21700, mean episode reward: -62.88476089732489, time: 24.334
agent0_energy_min, agent0_attention_min
[-20.38  -2.12]
agent1_energy_min, agent1_attention_min
[ -8.18 -41.7 ]
21800 50
steps: 1089950, episodes: 21800, mean episode reward: -64.37183923072521, time: 24.93
agent0_energy_min, agent0_attention_min
[-23.87  -1.33]
agent1_energy_min, agent1_attention_min
[-11.66 -38.23]
21900 50
steps: 1094950, episodes: 21900, mean episode reward: -81.38610213160543, time: 24.47
agent0_energy_min, agent0_attention_min
[-26.95  -1.58]
agent1_energy_min, agent1_attention_min
[-11.3  -37.65]
22000 50
steps: 1099950, episodes: 22000, mean episode reward: -79.29703309018495, time: 24.927
agent0_energy_min, agent0_attention_min
[-24.15  -1.05]
agent1_energy_min, agent1_attention_min
[-14.32 -34.38]
22100 50
steps: 1104950, episodes: 22100, mean episode reward: -66.69565619602156, time: 24.419
agent0_energy_min, agent0_attention_min
[-24.68  -2.24]
agent1_energy_min, agent1_attention_min
[-13.25 -35.87]
22200 50
steps: 1109950, episodes: 22200, mean episode reward: -74.0668756788836, time: 24.539
agent0_energy_min, agent0_attention_min
[-24.17  -1.1 ]
agent1_energy_min, agent1_attention_min
[-17.5  -32.43]
22300 50
steps: 1114950, episodes: 22300, mean episode reward: -77.56042084584483, time: 25.026
agent0_energy_min, agent0_attention_min
[-21.13  -0.75]
agent1_energy_min, agent1_attention_min
[-22.23 -27.53]
22400 50
steps: 1119950, episodes: 22400, mean episode reward: -77.87557904803367, time: 24.68
agent0_energy_min, agent0_attention_min
[-25.85  -1.07]
agent1_energy_min, agent1_attention_min
[-25.04 -24.72]
22500 50
steps: 1124950, episodes: 22500, mean episode reward: -94.88757201489679, time: 24.825
agent0_energy_min, agent0_attention_min
[-28.98  -1.73]
agent1_energy_min, agent1_attention_min
[-17.88 -31.93]
22600 50
steps: 1129950, episodes: 22600, mean episode reward: -73.43487637893149, time: 24.398
agent0_energy_min, agent0_attention_min
[-22.74  -1.8 ]
agent1_energy_min, agent1_attention_min
[-16.44 -31.51]
22700 50
steps: 1134950, episodes: 22700, mean episode reward: -68.22651818094286, time: 24.254
agent0_energy_min, agent0_attention_min
[-22.74  -1.6 ]
agent1_energy_min, agent1_attention_min
[-14.7  -32.31]
22800 50
steps: 1139950, episodes: 22800, mean episode reward: -60.387494889772114, time: 24.39
agent0_energy_min, agent0_attention_min
[-22.78  -2.03]
agent1_energy_min, agent1_attention_min
[-17.66 -30.74]
22900 50
steps: 1144950, episodes: 22900, mean episode reward: -76.43390978441485, time: 25.005
agent0_energy_min, agent0_attention_min
[-25.05  -4.19]
agent1_energy_min, agent1_attention_min
[-20.72 -28.83]
23000 50
steps: 1149950, episodes: 23000, mean episode reward: -68.77966045134396, time: 24.57
agent0_energy_min, agent0_attention_min
[-22.3   -4.54]
agent1_energy_min, agent1_attention_min
[-14.72 -34.85]
23100 50
steps: 1154950, episodes: 23100, mean episode reward: -79.50188686165573, time: 24.405
agent0_energy_min, agent0_attention_min
[-22.31  -2.74]
agent1_energy_min, agent1_attention_min
[-16.29 -33.28]
23200 50
steps: 1159950, episodes: 23200, mean episode reward: -94.36551694184746, time: 24.508
agent0_energy_min, agent0_attention_min
[-22.78  -3.4 ]
agent1_energy_min, agent1_attention_min
[-13.38 -36.54]
23300 50
steps: 1164950, episodes: 23300, mean episode reward: -118.01639653739048, time: 24.906
agent0_energy_min, agent0_attention_min
[-21.93  -4.52]
agent1_energy_min, agent1_attention_min
[-19.92 -29.79]
23400 50
steps: 1169950, episodes: 23400, mean episode reward: -93.30097787264869, time: 24.094
agent0_energy_min, agent0_attention_min
[-21.53  -3.41]
agent1_energy_min, agent1_attention_min
[-21.96 -27.97]
23500 50
steps: 1174950, episodes: 23500, mean episode reward: -139.12173700601036, time: 24.269
agent0_energy_min, agent0_attention_min
[-22.27  -4.43]
agent1_energy_min, agent1_attention_min
[ -7.51 -42.36]
23600 50
steps: 1179950, episodes: 23600, mean episode reward: -93.1447118592987, time: 24.788
agent0_energy_min, agent0_attention_min
[-25.05  -5.83]
agent1_energy_min, agent1_attention_min
[ -8.87 -41.07]
23700 50
steps: 1184950, episodes: 23700, mean episode reward: -57.00848524999213, time: 24.397
agent0_energy_min, agent0_attention_min
[-21.79  -4.06]
agent1_energy_min, agent1_attention_min
[ -4.34 -45.56]
23800 50
steps: 1189950, episodes: 23800, mean episode reward: -68.84364287843201, time: 23.886
agent0_energy_min, agent0_attention_min
[-22.31  -2.91]
agent1_energy_min, agent1_attention_min
[ -4.82 -45.1 ]
23900 50
steps: 1194950, episodes: 23900, mean episode reward: -70.494172626564, time: 24.423
agent0_energy_min, agent0_attention_min
[-23.83  -2.32]
agent1_energy_min, agent1_attention_min
agent0_energy_min, agent0_attention_min
[-49.28  -0.48]
agent1_energy_min, agent1_attention_min
[-4.348e+01 -2.000e-02]
19800 50
steps: 989950, episodes: 19800, mean episode reward: -83.51132453409778, time: 24.72
agent0_energy_min, agent0_attention_min
[-49.27  -0.59]
agent1_energy_min, agent1_attention_min
[-3.991e+01 -1.000e-02]
19900 50
steps: 994950, episodes: 19900, mean episode reward: -87.89642151689858, time: 24.372
agent0_energy_min, agent0_attention_min
[-48.22  -1.53]
agent1_energy_min, agent1_attention_min
[-4.302e+01 -1.000e-02]
20000 50
steps: 999950, episodes: 20000, mean episode reward: -75.84098147410995, time: 24.637
agent0_energy_min, agent0_attention_min
[-49.35  -0.41]
agent1_energy_min, agent1_attention_min
[-39.67   0.  ]
20100 50
steps: 1004950, episodes: 20100, mean episode reward: -78.68790735822876, time: 24.403
agent0_energy_min, agent0_attention_min
[-48.62  -1.01]
agent1_energy_min, agent1_attention_min
[-39.07   0.  ]
20200 50
steps: 1009950, episodes: 20200, mean episode reward: -85.31217202736738, time: 25.468
agent0_energy_min, agent0_attention_min
[-49.41  -0.36]
agent1_energy_min, agent1_attention_min
[-36.97  -0.04]
20300 50
steps: 1014950, episodes: 20300, mean episode reward: -88.54002388900855, time: 27.481
agent0_energy_min, agent0_attention_min
[-49.5  -0.2]
agent1_energy_min, agent1_attention_min
[-37.72   0.  ]
20400 50
steps: 1019950, episodes: 20400, mean episode reward: -73.51724778613804, time: 24.235
agent0_energy_min, agent0_attention_min
[-49.54  -0.26]
agent1_energy_min, agent1_attention_min
[-3.679e+01 -1.000e-02]
20500 50
steps: 1024950, episodes: 20500, mean episode reward: -74.90231802329951, time: 24.701
agent0_energy_min, agent0_attention_min
[-48.95  -0.64]
agent1_energy_min, agent1_attention_min
[-3.836e+01 -3.000e-02]
20600 50
steps: 1029950, episodes: 20600, mean episode reward: -81.64391503284666, time: 25.238
agent0_energy_min, agent0_attention_min
[-49.06  -0.65]
agent1_energy_min, agent1_attention_min
[-38.58  -0.04]
20700 50
steps: 1034950, episodes: 20700, mean episode reward: -86.91994750352453, time: 24.12
agent0_energy_min, agent0_attention_min
[-49.44  -0.46]
agent1_energy_min, agent1_attention_min
[-4.365e+01 -4.000e-02]
20800 50
steps: 1039950, episodes: 20800, mean episode reward: -71.92071246399732, time: 24.496
agent0_energy_min, agent0_attention_min
[-49.68  -0.23]
agent1_energy_min, agent1_attention_min
[-3.749e+01 -1.000e-02]
20900 50
steps: 1044950, episodes: 20900, mean episode reward: -91.6148502123286, time: 24.639
agent0_energy_min, agent0_attention_min
[-47.08  -0.83]
agent1_energy_min, agent1_attention_min
[-43.48  -0.16]
21000 50
steps: 1049950, episodes: 21000, mean episode reward: -82.95762896791038, time: 24.695
agent0_energy_min, agent0_attention_min
[-47.03  -0.48]
agent1_energy_min, agent1_attention_min
[-40.27  -0.31]
21100 50
steps: 1054950, episodes: 21100, mean episode reward: -89.43632830170641, time: 25.08
agent0_energy_min, agent0_attention_min
[-45.17  -0.25]
agent1_energy_min, agent1_attention_min
[-39.33  -0.46]
21200 50
steps: 1059950, episodes: 21200, mean episode reward: -85.03335603100628, time: 24.573
agent0_energy_min, agent0_attention_min
[-45.37  -0.58]
agent1_energy_min, agent1_attention_min
[-36.87  -1.38]
21300 50
steps: 1064950, episodes: 21300, mean episode reward: -75.29104803343007, time: 24.65
agent0_energy_min, agent0_attention_min
[-47.87  -0.17]
agent1_energy_min, agent1_attention_min
[-41.96  -0.72]
21400 50
steps: 1069950, episodes: 21400, mean episode reward: -76.80680345443768, time: 24.245
agent0_energy_min, agent0_attention_min
[-48.21  -0.56]
agent1_energy_min, agent1_attention_min
[-38.33  -0.2 ]
21500 50
steps: 1074950, episodes: 21500, mean episode reward: -101.12039420019761, time: 24.245
agent0_energy_min, agent0_attention_min
[-43.03  -0.97]
agent1_energy_min, agent1_attention_min
[-36.92  -0.98]
21600 50
steps: 1079950, episodes: 21600, mean episode reward: -74.75901251510909, time: 25.216
agent0_energy_min, agent0_attention_min
[-44.71  -0.99]
agent1_energy_min, agent1_attention_min
[-36.36  -0.66]
21700 50
steps: 1084950, episodes: 21700, mean episode reward: -94.5997707207873, time: 24.316
agent0_energy_min, agent0_attention_min
[-45.6   -1.15]
agent1_energy_min, agent1_attention_min
[-39.63  -0.22]
21800 50
steps: 1089950, episodes: 21800, mean episode reward: -87.78713782309734, time: 24.289
agent0_energy_min, agent0_attention_min
[-47.39  -0.31]
agent1_energy_min, agent1_attention_min
[-35.4   -0.31]
21900 50
steps: 1094950, episodes: 21900, mean episode reward: -83.17835006409442, time: 24.608
agent0_energy_min, agent0_attention_min
[-48.78  -0.4 ]
agent1_energy_min, agent1_attention_min
[-39.11  -0.07]
22000 50
steps: 1099950, episodes: 22000, mean episode reward: -73.15565454713682, time: 24.673
agent0_energy_min, agent0_attention_min
[-4.829e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-32.35   0.  ]
22100 50
steps: 1104950, episodes: 22100, mean episode reward: -85.95165336405026, time: 24.748
agent0_energy_min, agent0_attention_min
[-49.84   0.  ]
agent1_energy_min, agent1_attention_min
[-3.784e+01 -2.000e-02]
22200 50
steps: 1109950, episodes: 22200, mean episode reward: -73.33604455042914, time: 24.196
agent0_energy_min, agent0_attention_min
[-49.21   0.  ]
agent1_energy_min, agent1_attention_min
[-34.55  -0.09]
22300 50
steps: 1114950, episodes: 22300, mean episode reward: -136.61530013496045, time: 24.121
agent0_energy_min, agent0_attention_min
[-4.621e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-29.25  -0.19]
22400 50
steps: 1119950, episodes: 22400, mean episode reward: -76.67186239129688, time: 23.884
agent0_energy_min, agent0_attention_min
[-48.58   0.  ]
agent1_energy_min, agent1_attention_min
[-37.07  -0.08]
22500 50
steps: 1124950, episodes: 22500, mean episode reward: -76.04396879444174, time: 24.399
agent0_energy_min, agent0_attention_min
[-4.947e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-36.5   -1.22]
22600 50
steps: 1129950, episodes: 22600, mean episode reward: -72.22946186465951, time: 24.77
agent0_energy_min, agent0_attention_min
[-48.9   -0.08]
agent1_energy_min, agent1_attention_min
[-35.67  -0.25]
22700 50
steps: 1134950, episodes: 22700, mean episode reward: -96.44106798790499, time: 24.08
agent0_energy_min, agent0_attention_min
[-48.51  -0.12]
agent1_energy_min, agent1_attention_min
[-37.17  -0.53]
22800 50
steps: 1139950, episodes: 22800, mean episode reward: -83.2508304872241, time: 24.053
agent0_energy_min, agent0_attention_min
[-49.67  -0.11]
agent1_energy_min, agent1_attention_min
[-30.33  -0.26]
22900 50
steps: 1144950, episodes: 22900, mean episode reward: -74.06251859660475, time: 24.448
agent0_energy_min, agent0_attention_min
[-48.56  -0.25]
agent1_energy_min, agent1_attention_min
[-31.16  -0.12]
23000 50
steps: 1149950, episodes: 23000, mean episode reward: -147.50329205174302, time: 24.191
agent0_energy_min, agent0_attention_min
[-45.47  -3.17]
agent1_energy_min, agent1_attention_min
[-34.25  -0.61]
23100 50
steps: 1154950, episodes: 23100, mean episode reward: -110.66985313461075, time: 24.117
agent0_energy_min, agent0_attention_min
[-48.65  -1.09]
agent1_energy_min, agent1_attention_min
[-37.48  -2.27]
23200 50
steps: 1159950, episodes: 23200, mean episode reward: -145.02623476099433, time: 24.015
agent0_energy_min, agent0_attention_min
[-45.59  -0.13]
agent1_energy_min, agent1_attention_min
[-26.17  -3.7 ]
23300 50
steps: 1164950, episodes: 23300, mean episode reward: -168.8588340328905, time: 24.378
agent0_energy_min, agent0_attention_min
[-2.088e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-26.52  -1.42]
23400 50
steps: 1169950, episodes: 23400, mean episode reward: -66.84661553230661, time: 24.468
agent0_energy_min, agent0_attention_min
[-4.206e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-31.1   -0.16]
23500 50
steps: 1174950, episodes: 23500, mean episode reward: -79.65901184405882, time: 23.866
agent0_energy_min, agent0_attention_min
[-47.94  -0.35]
agent1_energy_min, agent1_attention_min
[-33.71  -0.27]
23600 50
steps: 1179950, episodes: 23600, mean episode reward: -71.34522877593882, time: 23.932
agent0_energy_min, agent0_attention_min
[-29.47  -0.05]
agent1_energy_min, agent1_attention_min
[-0.02 -0.04]
19900 50
steps: 994950, episodes: 19900, mean episode reward: -102.36077831801722, time: 24.143
agent0_energy_min, agent0_attention_min
[-30.11  -0.05]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
20000 50
steps: 999950, episodes: 20000, mean episode reward: -100.40550499159762, time: 24.484
agent0_energy_min, agent0_attention_min
[-30.12  -0.1 ]
agent1_energy_min, agent1_attention_min
[-0.01  0.  ]
20100 50
steps: 1004950, episodes: 20100, mean episode reward: -113.81721464832584, time: 25.075
agent0_energy_min, agent0_attention_min
[-32.6   -0.04]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
20200 50
steps: 1009950, episodes: 20200, mean episode reward: -88.57751937209156, time: 23.986
agent0_energy_min, agent0_attention_min
[-29.58  -0.07]
agent1_energy_min, agent1_attention_min
[-0.01 -0.05]
20300 50
steps: 1014950, episodes: 20300, mean episode reward: -108.44241857339082, time: 24.516
agent0_energy_min, agent0_attention_min
[-31.16  -0.12]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
20400 50
steps: 1019950, episodes: 20400, mean episode reward: -102.92031506499796, time: 24.254
agent0_energy_min, agent0_attention_min
[-2.8e+01 -1.0e-02]
agent1_energy_min, agent1_attention_min
[-0.02 -0.06]
20500 50
steps: 1024950, episodes: 20500, mean episode reward: -95.60940146789264, time: 23.742
agent0_energy_min, agent0_attention_min
[-26.12  -0.04]
agent1_energy_min, agent1_attention_min
[-0.01 -0.01]
20600 50
steps: 1029950, episodes: 20600, mean episode reward: -94.11599332521547, time: 24.926
agent0_energy_min, agent0_attention_min
[-27.57  -0.03]
agent1_energy_min, agent1_attention_min
[-0.02 -0.04]
20700 50
steps: 1034950, episodes: 20700, mean episode reward: -116.76963165507296, time: 24.405
agent0_energy_min, agent0_attention_min
[-27.62  -0.05]
agent1_energy_min, agent1_attention_min
[ 0.   -0.02]
20800 50
steps: 1039950, episodes: 20800, mean episode reward: -97.50278666934732, time: 23.575
agent0_energy_min, agent0_attention_min
[-3.06e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-0.03 -0.05]
20900 50
steps: 1044950, episodes: 20900, mean episode reward: -129.14866982820925, time: 24.523
agent0_energy_min, agent0_attention_min
[-20.78  -0.06]
agent1_energy_min, agent1_attention_min
[-0.04 -0.03]
21000 50
steps: 1049950, episodes: 21000, mean episode reward: -102.37175792211903, time: 23.973
agent0_energy_min, agent0_attention_min
[-33.23  -0.06]
agent1_energy_min, agent1_attention_min
[-0.02  0.  ]
21100 50
steps: 1054950, episodes: 21100, mean episode reward: -102.91326133730684, time: 24.887
agent0_energy_min, agent0_attention_min
[-32.34  -0.05]
agent1_energy_min, agent1_attention_min
[-0.02 -0.02]
21200 50
steps: 1059950, episodes: 21200, mean episode reward: -123.68459649950859, time: 25.057
agent0_energy_min, agent0_attention_min
[-29.41  -0.1 ]
agent1_energy_min, agent1_attention_min
[ 0.   -0.04]
21300 50
steps: 1064950, episodes: 21300, mean episode reward: -140.11687097634976, time: 24.898
agent0_energy_min, agent0_attention_min
[-34.2   -0.14]
agent1_energy_min, agent1_attention_min
[-0.04 -0.01]
21400 50
steps: 1069950, episodes: 21400, mean episode reward: -132.23806220309848, time: 24.996
agent0_energy_min, agent0_attention_min
[-33.23  -0.21]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
21500 50
steps: 1074950, episodes: 21500, mean episode reward: -86.38781291692968, time: 24.395
agent0_energy_min, agent0_attention_min
[-28.59  -0.12]
agent1_energy_min, agent1_attention_min
[ 0.   -0.02]
21600 50
steps: 1079950, episodes: 21600, mean episode reward: -106.43084207887432, time: 24.619
agent0_energy_min, agent0_attention_min
[-30.36  -0.18]
agent1_energy_min, agent1_attention_min
[-0.21 -0.06]
21700 50
steps: 1084950, episodes: 21700, mean episode reward: -94.3810909083916, time: 24.542
agent0_energy_min, agent0_attention_min
[-32.16  -0.28]
agent1_energy_min, agent1_attention_min
[-0.3  -0.03]
21800 50
steps: 1089950, episodes: 21800, mean episode reward: -156.50673070432137, time: 24.881
agent0_energy_min, agent0_attention_min
[-35.61  -0.3 ]
agent1_energy_min, agent1_attention_min
[-9.6  -0.58]
21900 50
steps: 1094950, episodes: 21900, mean episode reward: -339.5764574887666, time: 24.418
agent0_energy_min, agent0_attention_min
[-35.41  -0.32]
agent1_energy_min, agent1_attention_min
[-26.61  -1.46]
22000 50
steps: 1099950, episodes: 22000, mean episode reward: -137.98858886555436, time: 24.63
agent0_energy_min, agent0_attention_min
[-24.09 -11.67]
agent1_energy_min, agent1_attention_min
[-0.72 -0.04]
22100 50
steps: 1104950, episodes: 22100, mean episode reward: -147.35411967459072, time: 25.528
agent0_energy_min, agent0_attention_min
[-21.88  -9.81]
agent1_energy_min, agent1_attention_min
[-0.02 -0.02]
22200 50
steps: 1109950, episodes: 22200, mean episode reward: -137.02882186008392, time: 23.968
agent0_energy_min, agent0_attention_min
[-25.05  -5.35]
agent1_energy_min, agent1_attention_min
[-0.01 -0.15]
22300 50
steps: 1114950, episodes: 22300, mean episode reward: -99.12101979977655, time: 24.245
agent0_energy_min, agent0_attention_min
[-27.77  -0.47]
agent1_energy_min, agent1_attention_min
[-0.04 -0.34]
22400 50
steps: 1119950, episodes: 22400, mean episode reward: -226.16263215158145, time: 24.151
agent0_energy_min, agent0_attention_min
[-30.64  -0.25]
agent1_energy_min, agent1_attention_min
[-0.04 -3.29]
22500 50
steps: 1124950, episodes: 22500, mean episode reward: -108.86215970798587, time: 24.314
agent0_energy_min, agent0_attention_min
[-26.21  -0.73]
agent1_energy_min, agent1_attention_min
[-0.02 -0.82]
22600 50
steps: 1129950, episodes: 22600, mean episode reward: -95.54703019593182, time: 24.549
agent0_energy_min, agent0_attention_min
[-28.75  -0.96]
agent1_energy_min, agent1_attention_min
[-0.01 -0.03]
22700 50
steps: 1134950, episodes: 22700, mean episode reward: -105.27524388645097, time: 25.181
agent0_energy_min, agent0_attention_min
[-32.3  -1.7]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
22800 50
steps: 1139950, episodes: 22800, mean episode reward: -123.30041694588495, time: 24.313
agent0_energy_min, agent0_attention_min
[-29.37  -5.14]
agent1_energy_min, agent1_attention_min
[-0.03 -0.05]
22900 50
steps: 1144950, episodes: 22900, mean episode reward: -99.56564110081749, time: 24.229
agent0_energy_min, agent0_attention_min
[-29.41  -2.17]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
23000 50
steps: 1149950, episodes: 23000, mean episode reward: -278.8663316194234, time: 24.919
agent0_energy_min, agent0_attention_min
[-27.12  -2.24]
agent1_energy_min, agent1_attention_min
[-0.03 -0.18]
23100 50
steps: 1154950, episodes: 23100, mean episode reward: -103.93521355132593, time: 25.082
agent0_energy_min, agent0_attention_min
[-22.51  -0.47]
agent1_energy_min, agent1_attention_min
[-0.05 -0.03]
23200 50
steps: 1159950, episodes: 23200, mean episode reward: -123.1284984266418, time: 24.235
agent0_energy_min, agent0_attention_min
[-29.78  -4.6 ]
agent1_energy_min, agent1_attention_min
[ 0.   -0.02]
23300 50
steps: 1164950, episodes: 23300, mean episode reward: -104.80501448720497, time: 24.149
agent0_energy_min, agent0_attention_min
[-26.04  -1.8 ]
agent1_energy_min, agent1_attention_min
[-0.04 -0.01]
23400 50
steps: 1169950, episodes: 23400, mean episode reward: -103.25271856602018, time: 24.923
agent0_energy_min, agent0_attention_min
[-24.01  -0.61]
agent1_energy_min, agent1_attention_min
[-0.04 -0.06]
23500 50
steps: 1174950, episodes: 23500, mean episode reward: -96.15990021082031, time: 24.832
agent0_energy_min, agent0_attention_min
[-24.23  -0.47]
agent1_energy_min, agent1_attention_min
[-0.03 -0.64]
23600 50
steps: 1179950, episodes: 23600, mean episode reward: -108.43338963750185, time: 24.925
agent0_energy_min, agent0_attention_min
[-25.24  -0.33]
agent1_energy_min, agent1_attention_min
[-0.05 -0.26]
23700 50
steps: 1184950, episodes: 23700, mean episode reward: -108.8247479237138, time: 24.57
agent0_energy_min, agent0_attention_min
[-24.2   -0.09]
agent1_energy_min, agent1_attention_min
[-0.07 -0.58]
23800 50
steps: 1189950, episodes: 23800, mean episode reward: -105.53490683988825, time: 24.674
agent0_energy_min, agent0_attention_min
[-35.38 -14.51]
agent1_energy_min, agent1_attention_min
[-39.22  -3.96]
23700 50
steps: 1184950, episodes: 23700, mean episode reward: -37.73348394134371, time: 24.821
agent0_energy_min, agent0_attention_min
[-49.87   0.  ]
agent1_energy_min, agent1_attention_min
[-38.57  -4.83]
23800 50
steps: 1189950, episodes: 23800, mean episode reward: -63.62847051237087, time: 24.953
agent0_energy_min, agent0_attention_min
[-4.968e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-20.61  -2.53]
23900 50
steps: 1194950, episodes: 23900, mean episode reward: -40.833038766463304, time: 24.197
agent0_energy_min, agent0_attention_min
[-49.38  -0.1 ]
agent1_energy_min, agent1_attention_min
[-41.12  -3.11]
24000 50
steps: 1199950, episodes: 24000, mean episode reward: -48.171644867365536, time: 24.832
agent0_energy_min, agent0_attention_min
[-4.975e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-25.52 -18.44]
24100 50
steps: 1204950, episodes: 24100, mean episode reward: -40.373289908327514, time: 25.181
agent0_energy_min, agent0_attention_min
[-49.95   0.  ]
agent1_energy_min, agent1_attention_min
[-42.93  -2.84]
24200 50
steps: 1209950, episodes: 24200, mean episode reward: -37.724284272493776, time: 24.825
agent0_energy_min, agent0_attention_min
[-4.982e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-42.99  -3.23]
24300 50
steps: 1214950, episodes: 24300, mean episode reward: -41.02717152609214, time: 24.938
agent0_energy_min, agent0_attention_min
[-4.97e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-40.8   -2.68]
24400 50
steps: 1219950, episodes: 24400, mean episode reward: -40.94832457090877, time: 24.175
agent0_energy_min, agent0_attention_min
[-4.974e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-44.13  -3.47]
24500 50
steps: 1224950, episodes: 24500, mean episode reward: -46.787022376289734, time: 24.425
agent0_energy_min, agent0_attention_min
[-49.56  -0.17]
agent1_energy_min, agent1_attention_min
[-40.73  -6.44]
24600 50
steps: 1229950, episodes: 24600, mean episode reward: -50.36906516611283, time: 25.051
agent0_energy_min, agent0_attention_min
[-49.46  -0.27]
agent1_energy_min, agent1_attention_min
[-31.3 -17.9]
24700 50
steps: 1234950, episodes: 24700, mean episode reward: -49.02877558385662, time: 24.691
agent0_energy_min, agent0_attention_min
[-49.46  -0.18]
agent1_energy_min, agent1_attention_min
[-33.12 -16.18]
24800 50
steps: 1239950, episodes: 24800, mean episode reward: -52.63602139214303, time: 24.783
agent0_energy_min, agent0_attention_min
[-49.29  -0.27]
agent1_energy_min, agent1_attention_min
[-33.21 -15.8 ]
24900 50
steps: 1244950, episodes: 24900, mean episode reward: -76.3494966286115, time: 25.035
agent0_energy_min, agent0_attention_min
[-48.96  -0.48]
agent1_energy_min, agent1_attention_min
[-34.64 -13.55]
25000 50
steps: 1249950, episodes: 25000, mean episode reward: -45.50800367671335, time: 24.855
agent0_energy_min, agent0_attention_min
[-49.54  -0.22]
agent1_energy_min, agent1_attention_min
[-33.63 -14.33]
25100 50
steps: 1254950, episodes: 25100, mean episode reward: -60.41423051190336, time: 26.35
agent0_energy_min, agent0_attention_min
[-49.71  -0.1 ]
agent1_energy_min, agent1_attention_min
[-42.98  -4.55]
25200 50
steps: 1259950, episodes: 25200, mean episode reward: -52.94207660478345, time: 24.634
agent0_energy_min, agent0_attention_min
[-48.85  -0.24]
agent1_energy_min, agent1_attention_min
[-46.35  -2.06]
25300 50
steps: 1264950, episodes: 25300, mean episode reward: -69.22305072172144, time: 24.685
agent0_energy_min, agent0_attention_min
[-48.47  -0.32]
agent1_energy_min, agent1_attention_min
[-45.19  -1.79]
25400 50
steps: 1269950, episodes: 25400, mean episode reward: -51.1844604988718, time: 24.757
agent0_energy_min, agent0_attention_min
[-49.16  -0.12]
agent1_energy_min, agent1_attention_min
[-40.4   -0.77]
25500 50
steps: 1274950, episodes: 25500, mean episode reward: -66.55398653775087, time: 24.866
agent0_energy_min, agent0_attention_min
[-49.53  -0.13]
agent1_energy_min, agent1_attention_min
[-45.51  -0.61]
25600 50
steps: 1279950, episodes: 25600, mean episode reward: -56.26068037935154, time: 25.208
agent0_energy_min, agent0_attention_min
[-49.04  -0.12]
agent1_energy_min, agent1_attention_min
[-45.27  -0.38]
25700 50
steps: 1284950, episodes: 25700, mean episode reward: -74.29912473383797, time: 25.018
agent0_energy_min, agent0_attention_min
[-49.31  -0.07]
agent1_energy_min, agent1_attention_min
[-44.5   -4.28]
25800 50
steps: 1289950, episodes: 25800, mean episode reward: -133.23022028609049, time: 24.56
agent0_energy_min, agent0_attention_min
[-48.57  -0.06]
agent1_energy_min, agent1_attention_min
[-32.6  -13.99]
25900 50
steps: 1294950, episodes: 25900, mean episode reward: -78.17392931988236, time: 24.339
agent0_energy_min, agent0_attention_min
[-48.98  -0.07]
agent1_energy_min, agent1_attention_min
[-34.37  -2.2 ]
26000 50
steps: 1299950, episodes: 26000, mean episode reward: -61.78905100796282, time: 24.374
agent0_energy_min, agent0_attention_min
[-48.48  -0.2 ]
agent1_energy_min, agent1_attention_min
[-31.88 -11.32]
26100 50
steps: 1304950, episodes: 26100, mean episode reward: -80.1259369342215, time: 24.848
agent0_energy_min, agent0_attention_min
[-45.    -3.52]
agent1_energy_min, agent1_attention_min
[-45.27  -3.23]
26200 50
steps: 1309950, episodes: 26200, mean episode reward: -65.38377189009847, time: 25.392
agent0_energy_min, agent0_attention_min
[-42.5   -5.96]
agent1_energy_min, agent1_attention_min
[-43.16  -1.65]
26300 50
steps: 1314950, episodes: 26300, mean episode reward: -65.77659477648672, time: 24.847
agent0_energy_min, agent0_attention_min
[-41.72  -7.2 ]
agent1_energy_min, agent1_attention_min
[-38.89  -1.99]
26400 50
steps: 1319950, episodes: 26400, mean episode reward: -78.25663019358292, time: 24.591
agent0_energy_min, agent0_attention_min
[-43.25  -5.67]
agent1_energy_min, agent1_attention_min
[-40.51  -6.17]
26500 50
steps: 1324950, episodes: 26500, mean episode reward: -48.68251926036767, time: 24.584
agent0_energy_min, agent0_attention_min
[-48.9   -0.35]
agent1_energy_min, agent1_attention_min
[-40.9  -6.3]
26600 50
steps: 1329950, episodes: 26600, mean episode reward: -43.57973530145816, time: 24.93
agent0_energy_min, agent0_attention_min
[-49.46  -0.06]
agent1_energy_min, agent1_attention_min
[-36.37  -9.73]
26700 50
steps: 1334950, episodes: 26700, mean episode reward: -46.42979521166808, time: 24.679
agent0_energy_min, agent0_attention_min
[-48.74  -0.05]
agent1_energy_min, agent1_attention_min
[-40.2   -4.64]
26800 50
steps: 1339950, episodes: 26800, mean episode reward: -52.59219121864569, time: 24.973
agent0_energy_min, agent0_attention_min
[-4.793e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-38.3   -3.44]
26900 50
steps: 1344950, episodes: 26900, mean episode reward: -49.01726177032937, time: 24.552
agent0_energy_min, agent0_attention_min
[-47.62  -0.06]
agent1_energy_min, agent1_attention_min
[-38.    -0.64]
27000 50
steps: 1349950, episodes: 27000, mean episode reward: -57.44204527288307, time: 25.007
agent0_energy_min, agent0_attention_min
[-4.822e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-39.9   -1.59]
27100 50
steps: 1354950, episodes: 27100, mean episode reward: -43.39987021734607, time: 25.046
agent0_energy_min, agent0_attention_min
[-48.15  -0.18]
agent1_energy_min, agent1_attention_min
[-46.53  -0.85]
27200 50
steps: 1359950, episodes: 27200, mean episode reward: -71.16144958565785, time: 24.716
agent0_energy_min, agent0_attention_min
[-47.37  -0.71]
agent1_energy_min, agent1_attention_min
[-46.87  -0.84]
27300 50
steps: 1364950, episodes: 27300, mean episode reward: -120.87181454118931, time: 24.223
agent0_energy_min, agent0_attention_min
[-47.82  -1.  ]
agent1_energy_min, agent1_attention_min
[-46.54  -0.48]
27400 50
steps: 1369950, episodes: 27400, mean episode reward: -54.04300706171055, time: 24.865
agent0_energy_min, agent0_attention_min
[-48.38  -0.95]
agent1_energy_min, agent1_attention_min
[-43.4   -0.93]
27500 50
steps: 1374950, episodes: 27500, mean episode reward: -46.16352069331112, time: 24.7
agent0_energy_min, agent0_attention_min
[-4.19e+01 -3.00e-02]
23800 50
steps: 1189950, episodes: 23800, mean episode reward: -142.28428841012496, time: 23.877
agent0_energy_min, agent0_attention_min
[-4.99e+01 -2.00e-02]
agent1_energy_min, agent1_attention_min
[-4.277e+01 -3.000e-02]
23900 50
steps: 1194950, episodes: 23900, mean episode reward: -107.04406021653632, time: 23.883
agent0_energy_min, agent0_attention_min
[-49.92   0.  ]
agent1_energy_min, agent1_attention_min
[-4.672e+01 -2.000e-02]
24000 50
steps: 1199950, episodes: 24000, mean episode reward: -105.99797042177184, time: 23.705
agent0_energy_min, agent0_attention_min
[-49.9   0. ]
agent1_energy_min, agent1_attention_min
[-4.379e+01 -1.000e-02]
24100 50
steps: 1204950, episodes: 24100, mean episode reward: -108.88492673119505, time: 24.738
agent0_energy_min, agent0_attention_min
[-49.87   0.  ]
agent1_energy_min, agent1_attention_min
[-3.294e+01 -3.000e-02]
24200 50
steps: 1209950, episodes: 24200, mean episode reward: -116.47259153940819, time: 23.948
agent0_energy_min, agent0_attention_min
[-4.986e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-13.98  -0.02]
24300 50
steps: 1214950, episodes: 24300, mean episode reward: -107.072650859883, time: 24.09
agent0_energy_min, agent0_attention_min
[-49.93   0.  ]
agent1_energy_min, agent1_attention_min
[-7.77 -0.03]
24400 50
steps: 1219950, episodes: 24400, mean episode reward: -113.91781996993814, time: 24.124
agent0_energy_min, agent0_attention_min
[-49.96   0.  ]
agent1_energy_min, agent1_attention_min
[-6.67 -0.02]
24500 50
steps: 1224950, episodes: 24500, mean episode reward: -107.95574938114396, time: 23.838
agent0_energy_min, agent0_attention_min
[-4.994e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-14.88  -0.02]
24600 50
steps: 1229950, episodes: 24600, mean episode reward: -94.00764850030399, time: 23.653
agent0_energy_min, agent0_attention_min
[-4.993e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-44.01   0.  ]
24700 50
steps: 1234950, episodes: 24700, mean episode reward: -108.3969712977973, time: 23.981
agent0_energy_min, agent0_attention_min
[-49.93   0.  ]
agent1_energy_min, agent1_attention_min
[-4.455e+01 -1.000e-02]
24800 50
steps: 1239950, episodes: 24800, mean episode reward: -106.54924717387374, time: 24.302
agent0_energy_min, agent0_attention_min
[-49.97   0.  ]
agent1_energy_min, agent1_attention_min
[-4.63e+01 -2.00e-02]
24900 50
steps: 1244950, episodes: 24900, mean episode reward: -109.57257804130057, time: 23.956
agent0_energy_min, agent0_attention_min
[-4.995e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-45.55   0.  ]
25000 50
steps: 1249950, episodes: 25000, mean episode reward: -109.49568735435359, time: 23.643
agent0_energy_min, agent0_attention_min
[-49.98   0.  ]
agent1_energy_min, agent1_attention_min
[-4.262e+01 -2.000e-02]
25100 50
steps: 1254950, episodes: 25100, mean episode reward: -98.8085125242528, time: 24.951
agent0_energy_min, agent0_attention_min
[-4.997e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-43.43   0.  ]
25200 50
steps: 1259950, episodes: 25200, mean episode reward: -102.94905682897581, time: 24.415
agent0_energy_min, agent0_attention_min
[-49.97   0.  ]
agent1_energy_min, agent1_attention_min
[-4.328e+01 -1.000e-02]
25300 50
steps: 1264950, episodes: 25300, mean episode reward: -103.54091608720715, time: 23.78
agent0_energy_min, agent0_attention_min
[-49.97   0.  ]
agent1_energy_min, agent1_attention_min
[-4.063e+01 -3.000e-02]
25400 50
steps: 1269950, episodes: 25400, mean episode reward: -100.58400507185665, time: 23.868
agent0_energy_min, agent0_attention_min
[-4.998e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-4.222e+01 -3.000e-02]
25500 50
steps: 1274950, episodes: 25500, mean episode reward: -89.61714457964659, time: 23.993
agent0_energy_min, agent0_attention_min
[-4.996e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-4.481e+01 -1.000e-02]
25600 50
steps: 1279950, episodes: 25600, mean episode reward: -98.32053957392887, time: 24.813
agent0_energy_min, agent0_attention_min
[-4.995e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-4.53e+01 -3.00e-02]
25700 50
steps: 1284950, episodes: 25700, mean episode reward: -100.65042665365239, time: 23.647
agent0_energy_min, agent0_attention_min
[-49.97   0.  ]
agent1_energy_min, agent1_attention_min
[-4.236e+01 -1.000e-02]
25800 50
steps: 1289950, episodes: 25800, mean episode reward: -94.5589953497261, time: 23.836
agent0_energy_min, agent0_attention_min
[-4.996e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-4.005e+01 -1.000e-02]
25900 50
steps: 1294950, episodes: 25900, mean episode reward: -89.96678728432114, time: 23.689
agent0_energy_min, agent0_attention_min
[-4.995e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-27.85  -0.03]
26000 50
steps: 1299950, episodes: 26000, mean episode reward: -265.8504128039733, time: 24.656
agent0_energy_min, agent0_attention_min
[-4.995e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-9.64 -0.06]
26100 50
steps: 1304950, episodes: 26100, mean episode reward: -243.11857761012703, time: 24.542
agent0_energy_min, agent0_attention_min
[-48.9   -0.05]
agent1_energy_min, agent1_attention_min
[-40.56  -0.23]
26200 50
steps: 1309950, episodes: 26200, mean episode reward: -183.57392733235326, time: 24.428
agent0_energy_min, agent0_attention_min
[-48.21  -0.11]
agent1_energy_min, agent1_attention_min
[-37.66  -1.22]
26300 50
steps: 1314950, episodes: 26300, mean episode reward: -116.5596607511669, time: 23.525
agent0_energy_min, agent0_attention_min
[-49.89  -0.09]
agent1_energy_min, agent1_attention_min
[-32.2   -0.09]
26400 50
steps: 1319950, episodes: 26400, mean episode reward: -120.53946827414956, time: 24.265
agent0_energy_min, agent0_attention_min
[-49.89  -0.08]
agent1_energy_min, agent1_attention_min
[-33.58  -0.57]
26500 50
steps: 1324950, episodes: 26500, mean episode reward: -206.13154082020577, time: 23.864
agent0_energy_min, agent0_attention_min
[-49.86  -0.11]
agent1_energy_min, agent1_attention_min
[-31.65  -0.08]
26600 50
steps: 1329950, episodes: 26600, mean episode reward: -170.01334418953033, time: 24.922
agent0_energy_min, agent0_attention_min
[-49.8   -0.15]
agent1_energy_min, agent1_attention_min
[-36.65  -0.29]
26700 50
steps: 1334950, episodes: 26700, mean episode reward: -112.70680636674393, time: 23.634
agent0_energy_min, agent0_attention_min
[-4.994e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-38.93  -0.63]
26800 50
steps: 1339950, episodes: 26800, mean episode reward: -103.37461379028369, time: 23.72
agent0_energy_min, agent0_attention_min
[-4.993e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-3.839e+01 -2.000e-02]
26900 50
steps: 1344950, episodes: 26900, mean episode reward: -118.50988545474237, time: 23.867
agent0_energy_min, agent0_attention_min
[-4.996e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-3.603e+01 -1.000e-02]
27000 50
steps: 1349950, episodes: 27000, mean episode reward: -146.15225911844087, time: 24.282
agent0_energy_min, agent0_attention_min
[-4.994e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-35.4   0. ]
27100 50
steps: 1354950, episodes: 27100, mean episode reward: -120.78468996062256, time: 24.551
agent0_energy_min, agent0_attention_min
[-49.98   0.  ]
agent1_energy_min, agent1_attention_min
[-40.49   0.  ]
27200 50
steps: 1359950, episodes: 27200, mean episode reward: -125.59815627239624, time: 23.761
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-32.73   0.  ]
27300 50
steps: 1364950, episodes: 27300, mean episode reward: -117.08802965769621, time: 24.291
agent0_energy_min, agent0_attention_min
[-50.   0.]
agent1_energy_min, agent1_attention_min
[-3.275e+01 -3.000e-02]
27400 50
steps: 1369950, episodes: 27400, mean episode reward: -108.84198359060298, time: 23.85
agent0_energy_min, agent0_attention_min
[-4.995e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-35.44  -0.04]
27500 50
steps: 1374950, episodes: 27500, mean episode reward: -109.46111331067301, time: 23.961
agent0_energy_min, agent0_attention_min
[-4.999e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-4.181e+01 -1.000e-02] 50
steps: 1194950, episodes: 23900, mean episode reward: -88.31419707768076, time: 24.938
agent0_energy_min, agent0_attention_min
[-39.96  -6.04]
agent1_energy_min, agent1_attention_min
[-46.71  -1.  ]
24000 50
steps: 1199950, episodes: 24000, mean episode reward: -78.75517091345863, time: 24.508
agent0_energy_min, agent0_attention_min
[-47.8   -0.91]
agent1_energy_min, agent1_attention_min
[-19.42  -0.15]
24100 50
steps: 1204950, episodes: 24100, mean episode reward: -52.370149916678855, time: 24.803
agent0_energy_min, agent0_attention_min
[-46.7   -0.72]
agent1_energy_min, agent1_attention_min
[-37.38  -1.12]
24200 50
steps: 1209950, episodes: 24200, mean episode reward: -61.34217400176763, time: 24.589
agent0_energy_min, agent0_attention_min
[-34.81  -1.82]
agent1_energy_min, agent1_attention_min
[-44.45  -0.45]
24300 50
steps: 1214950, episodes: 24300, mean episode reward: -103.9153848976809, time: 24.566
agent0_energy_min, agent0_attention_min
[-38.9   -1.53]
agent1_energy_min, agent1_attention_min
[-47.28  -0.58]
24400 50
steps: 1219950, episodes: 24400, mean episode reward: -59.90953710649495, time: 24.151
agent0_energy_min, agent0_attention_min
[-39.7   -0.31]
agent1_energy_min, agent1_attention_min
[-48.95  -0.66]
24500 50
steps: 1224950, episodes: 24500, mean episode reward: -61.85004810830635, time: 24.388
agent0_energy_min, agent0_attention_min
[-45.89  -3.32]
agent1_energy_min, agent1_attention_min
[-48.05  -0.43]
24600 50
steps: 1229950, episodes: 24600, mean episode reward: -69.05505745630721, time: 24.855
agent0_energy_min, agent0_attention_min
[-44.67  -3.6 ]
agent1_energy_min, agent1_attention_min
[-48.9   -0.44]
24700 50
steps: 1234950, episodes: 24700, mean episode reward: -53.31745476647131, time: 23.97
agent0_energy_min, agent0_attention_min
[-42.85  -2.55]
agent1_energy_min, agent1_attention_min
[-48.89  -0.33]
24800 50
steps: 1239950, episodes: 24800, mean episode reward: -38.86177078632897, time: 24.69
agent0_energy_min, agent0_attention_min
[-39.16  -0.52]
agent1_energy_min, agent1_attention_min
[-49.27  -0.23]
24900 50
steps: 1244950, episodes: 24900, mean episode reward: -46.45505672060406, time: 23.741
agent0_energy_min, agent0_attention_min
[-37.46  -0.4 ]
agent1_energy_min, agent1_attention_min
[-47.03  -0.4 ]
25000 50
steps: 1249950, episodes: 25000, mean episode reward: -40.831479971962914, time: 24.76
agent0_energy_min, agent0_attention_min
[-46.79  -0.4 ]
agent1_energy_min, agent1_attention_min
[-44.38  -0.19]
25100 50
steps: 1254950, episodes: 25100, mean episode reward: -41.49395037858516, time: 25.73
agent0_energy_min, agent0_attention_min
[-48.03  -1.76]
agent1_energy_min, agent1_attention_min
[-43.88  -0.09]
25200 50
steps: 1259950, episodes: 25200, mean episode reward: -40.838956964330286, time: 24.638
agent0_energy_min, agent0_attention_min
[-49.13  -0.68]
agent1_energy_min, agent1_attention_min
[-48.    -0.33]
25300 50
steps: 1264950, episodes: 25300, mean episode reward: -47.2277344510898, time: 25.147
agent0_energy_min, agent0_attention_min
[-49.52  -0.28]
agent1_energy_min, agent1_attention_min
[-41.74  -2.32]
25400 50
steps: 1269950, episodes: 25400, mean episode reward: -42.130156394089994, time: 24.393
agent0_energy_min, agent0_attention_min
[-49.57  -0.24]
agent1_energy_min, agent1_attention_min
[-45.25  -2.12]
25500 50
steps: 1274950, episodes: 25500, mean episode reward: -41.370416130310765, time: 24.496
agent0_energy_min, agent0_attention_min
[-49.54  -0.38]
agent1_energy_min, agent1_attention_min
[-45.48  -3.51]
25600 50
steps: 1279950, episodes: 25600, mean episode reward: -41.90443676492149, time: 24.676
agent0_energy_min, agent0_attention_min
[-46.08  -0.37]
agent1_energy_min, agent1_attention_min
[-40.89  -6.19]
25700 50
steps: 1284950, episodes: 25700, mean episode reward: -54.0987486667556, time: 24.98
agent0_energy_min, agent0_attention_min
[-44.04  -0.44]
agent1_energy_min, agent1_attention_min
[-33.09 -12.49]
25800 50
steps: 1289950, episodes: 25800, mean episode reward: -39.49252706986348, time: 24.866
agent0_energy_min, agent0_attention_min
[-49.48  -0.19]
agent1_energy_min, agent1_attention_min
[-40.5   -8.17]
25900 50
steps: 1294950, episodes: 25900, mean episode reward: -43.82740974258818, time: 24.23
agent0_energy_min, agent0_attention_min
[-39.53 -10.19]
agent1_energy_min, agent1_attention_min
[-42.55  -7.13]
26000 50
steps: 1299950, episodes: 26000, mean episode reward: -42.36520093506451, time: 24.734
agent0_energy_min, agent0_attention_min
[-47.62  -2.11]
agent1_energy_min, agent1_attention_min
[-47.26  -2.61]
26100 50
steps: 1304950, episodes: 26100, mean episode reward: -43.53143479044652, time: 25.095
agent0_energy_min, agent0_attention_min
[-40.29  -9.5 ]
agent1_energy_min, agent1_attention_min
[-39.55 -10.34]
26200 50
steps: 1309950, episodes: 26200, mean episode reward: -43.81230386516816, time: 24.532
agent0_energy_min, agent0_attention_min
[-47.35  -2.56]
agent1_energy_min, agent1_attention_min
[-47.43  -2.5 ]
26300 50
steps: 1314950, episodes: 26300, mean episode reward: -39.451471406678344, time: 24.261
agent0_energy_min, agent0_attention_min
[-47.55  -2.34]
agent1_energy_min, agent1_attention_min
[-44.9   -5.07]
26400 50
steps: 1319950, episodes: 26400, mean episode reward: -42.636531220510484, time: 24.391
agent0_energy_min, agent0_attention_min
[-47.75  -1.73]
agent1_energy_min, agent1_attention_min
[-38.55 -11.16]
26500 50
steps: 1324950, episodes: 26500, mean episode reward: -54.906983178594395, time: 24.759
agent0_energy_min, agent0_attention_min
[-27.08 -19.35]
agent1_energy_min, agent1_attention_min
[-37.46 -12.38]
26600 50
steps: 1329950, episodes: 26600, mean episode reward: -38.604091323006934, time: 25.139
agent0_energy_min, agent0_attention_min
[-40.88  -6.25]
agent1_energy_min, agent1_attention_min
[-38.13 -11.65]
26700 50
steps: 1334950, episodes: 26700, mean episode reward: -43.3550734731713, time: 24.418
agent0_energy_min, agent0_attention_min
[-38.05  -5.33]
agent1_energy_min, agent1_attention_min
[-38.48 -11.35]
26800 50
steps: 1339950, episodes: 26800, mean episode reward: -49.69288862723667, time: 24.41
agent0_energy_min, agent0_attention_min
[-45.1   -1.41]
agent1_energy_min, agent1_attention_min
[-43.19  -6.49]
26900 50
steps: 1344950, episodes: 26900, mean episode reward: -35.91495712714849, time: 24.691
agent0_energy_min, agent0_attention_min
[-45.99  -0.37]
agent1_energy_min, agent1_attention_min
[-44.74  -4.86]
27000 50
steps: 1349950, episodes: 27000, mean episode reward: -44.70713970547877, time: 24.437
agent0_energy_min, agent0_attention_min
[-33.3   -2.65]
agent1_energy_min, agent1_attention_min
[-45.    -4.93]
27100 50
steps: 1354950, episodes: 27100, mean episode reward: -48.26393404371821, time: 24.384
agent0_energy_min, agent0_attention_min
[-48.66  -0.42]
agent1_energy_min, agent1_attention_min
[-43.25  -6.56]
27200 50
steps: 1359950, episodes: 27200, mean episode reward: -49.14918909177131, time: 24.763
agent0_energy_min, agent0_attention_min
[-47.96  -0.47]
agent1_energy_min, agent1_attention_min
[-41.83  -8.04]
27300 50
steps: 1364950, episodes: 27300, mean episode reward: -40.71109985537418, time: 24.882
agent0_energy_min, agent0_attention_min
[-45.32  -0.33]
agent1_energy_min, agent1_attention_min
[-41.92  -8.03]
27400 50
steps: 1369950, episodes: 27400, mean episode reward: -42.67906597289665, time: 24.545
agent0_energy_min, agent0_attention_min
[-38.9   -0.42]
agent1_energy_min, agent1_attention_min
[-43.74  -6.15]
27500 50
steps: 1374950, episodes: 27500, mean episode reward: -41.95982472192507, time: 24.18
agent0_energy_min, agent0_attention_min
[-42.59  -3.  ]
agent1_energy_min, agent1_attention_min
[-36.59 -13.18]
27600 50
steps: 1379950, episodes: 27600, mean episode reward: -42.244540952557, time: 25.121
agent0_energy_min, agent0_attention_min
[-47.54  -1.  ]
agent1_energy_min, agent1_attention_min
[-32.27 -17.51]
27700 50
steps: 1384950, episodes: 27700, mean episode reward: -42.77886525927075, time: 24.498
agent0_energy_min, agent0_attention_min
[-43.8   -4.65]
agent1_energy_min, agent1_attention_min
[-29.28 -20.68]
27800 50
steps: 1389950, episodes: 27800, mean episode reward: -41.4661838644023, time: 24.729
agent0_energy_min, agent0_attention_min
[-45.77  -0.88]
agent1_energy_min, agent1_attention_min
[-30.    -0.26]
23700 50
steps: 1184950, episodes: 23700, mean episode reward: -97.02837707202082, time: 23.659
agent0_energy_min, agent0_attention_min
[-46.86  -0.59]
agent1_energy_min, agent1_attention_min
[-33.91  -0.08]
23800 50
steps: 1189950, episodes: 23800, mean episode reward: -83.40666833928982, time: 23.757
agent0_energy_min, agent0_attention_min
[-44.69  -0.79]
agent1_energy_min, agent1_attention_min
[-27.22  -0.87]
23900 50
steps: 1194950, episodes: 23900, mean episode reward: -109.54111575711914, time: 24.241
agent0_energy_min, agent0_attention_min
[-43.16  -4.13]
agent1_energy_min, agent1_attention_min
[-34.38  -4.29]
24000 50
steps: 1199950, episodes: 24000, mean episode reward: -80.05301517651522, time: 24.054
agent0_energy_min, agent0_attention_min
[-46.19  -0.71]
agent1_energy_min, agent1_attention_min
[-3.577e+01 -1.000e-02]
24100 50
steps: 1204950, episodes: 24100, mean episode reward: -62.749889012312785, time: 23.865
agent0_energy_min, agent0_attention_min
[-4.663e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-31.84  -0.12]
24200 50
steps: 1209950, episodes: 24200, mean episode reward: -62.004942108811, time: 23.996
agent0_energy_min, agent0_attention_min
[-47.5   0. ]
agent1_energy_min, agent1_attention_min
[-29.31  -0.07]
24300 50
steps: 1214950, episodes: 24300, mean episode reward: -78.88733816891767, time: 24.083
agent0_energy_min, agent0_attention_min
[-4.804e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-30.62  -0.05]
24400 50
steps: 1219950, episodes: 24400, mean episode reward: -61.92191605102818, time: 23.853
agent0_energy_min, agent0_attention_min
[-4.57e+01 -3.00e-02]
agent1_energy_min, agent1_attention_min
[-28.7   -0.07]
24500 50
steps: 1224950, episodes: 24500, mean episode reward: -59.753677742276686, time: 23.753
agent0_energy_min, agent0_attention_min
[-4.497e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-27.45  -0.11]
24600 50
steps: 1229950, episodes: 24600, mean episode reward: -62.735462343949365, time: 24.475
agent0_energy_min, agent0_attention_min
[-4.123e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-25.96  -0.67]
24700 50
steps: 1234950, episodes: 24700, mean episode reward: -94.5642777402534, time: 24.299
agent0_energy_min, agent0_attention_min
[-3.719e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-25.1   -4.64]
24800 50
steps: 1239950, episodes: 24800, mean episode reward: -87.57162582881202, time: 23.643
agent0_energy_min, agent0_attention_min
[-38.88   0.  ]
agent1_energy_min, agent1_attention_min
[-25.83  -3.29]
24900 50
steps: 1244950, episodes: 24900, mean episode reward: -96.20789052055444, time: 23.612
agent0_energy_min, agent0_attention_min
[-4.322e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-26.16  -8.14]
25000 50
steps: 1249950, episodes: 25000, mean episode reward: -92.76846538331094, time: 23.969
agent0_energy_min, agent0_attention_min
[-4.728e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-28.    -7.04]
25100 50
steps: 1254950, episodes: 25100, mean episode reward: -97.63475714141254, time: 24.829
agent0_energy_min, agent0_attention_min
[-4.218e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-27.98  -0.67]
25200 50
steps: 1259950, episodes: 25200, mean episode reward: -93.28855126541163, time: 24.309
agent0_energy_min, agent0_attention_min
[-4.572e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-33.99  -0.34]
25300 50
steps: 1264950, episodes: 25300, mean episode reward: -88.90822229648698, time: 23.922
agent0_energy_min, agent0_attention_min
[-4.505e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-25.63  -1.37]
25400 50
steps: 1269950, episodes: 25400, mean episode reward: -78.87053413002964, time: 24.215
agent0_energy_min, agent0_attention_min
[-4.426e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-20.67  -6.02]
25500 50
steps: 1274950, episodes: 25500, mean episode reward: -73.20600381661018, time: 23.388
agent0_energy_min, agent0_attention_min
[-4.026e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-26.03  -0.7 ]
25600 50
steps: 1279950, episodes: 25600, mean episode reward: -93.50267338001066, time: 24.073
agent0_energy_min, agent0_attention_min
[-4.681e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-22.3   -3.98]
25700 50
steps: 1284950, episodes: 25700, mean episode reward: -82.74021559861752, time: 23.881
agent0_energy_min, agent0_attention_min
[-45.56   0.  ]
agent1_energy_min, agent1_attention_min
[-22.75  -7.16]
25800 50
steps: 1289950, episodes: 25800, mean episode reward: -77.62414968409328, time: 23.206
agent0_energy_min, agent0_attention_min
[-4.362e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-20.87  -1.1 ]
25900 50
steps: 1294950, episodes: 25900, mean episode reward: -92.41548229286789, time: 23.529
agent0_energy_min, agent0_attention_min
[-4.759e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-24.72  -0.43]
26000 50
steps: 1299950, episodes: 26000, mean episode reward: -62.81081545809579, time: 23.749
agent0_energy_min, agent0_attention_min
[-4.708e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-19.47  -3.43]
26100 50
steps: 1304950, episodes: 26100, mean episode reward: -69.48061677324044, time: 24.031
agent0_energy_min, agent0_attention_min
[-45.87  -0.05]
agent1_energy_min, agent1_attention_min
[-22.86  -2.7 ]
26200 50
steps: 1309950, episodes: 26200, mean episode reward: -64.73665640535171, time: 23.634
agent0_energy_min, agent0_attention_min
[-4.841e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-23.38  -1.  ]
26300 50
steps: 1314950, episodes: 26300, mean episode reward: -74.48920204083987, time: 23.984
agent0_energy_min, agent0_attention_min
[-48.55   0.  ]
agent1_energy_min, agent1_attention_min
[-25.39  -1.14]
26400 50
steps: 1319950, episodes: 26400, mean episode reward: -79.90132158382745, time: 23.397
agent0_energy_min, agent0_attention_min
[-40.45   0.  ]
agent1_energy_min, agent1_attention_min
[-25.09  -1.86]
26500 50
steps: 1324950, episodes: 26500, mean episode reward: -75.57900924925825, time: 23.628
agent0_energy_min, agent0_attention_min
[-4.383e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-28.01  -1.65]
26600 50
steps: 1329950, episodes: 26600, mean episode reward: -71.16089183470125, time: 24.578
agent0_energy_min, agent0_attention_min
[-47.32   0.  ]
agent1_energy_min, agent1_attention_min
[-23.66  -1.35]
26700 50
steps: 1334950, episodes: 26700, mean episode reward: -82.00152389760906, time: 24.019
agent0_energy_min, agent0_attention_min
[-46.68   0.  ]
agent1_energy_min, agent1_attention_min
[-29.96  -1.38]
26800 50
steps: 1339950, episodes: 26800, mean episode reward: -65.02279272515985, time: 24.169
agent0_energy_min, agent0_attention_min
[-38.61   0.  ]
agent1_energy_min, agent1_attention_min
[-29.89  -0.4 ]
26900 50
steps: 1344950, episodes: 26900, mean episode reward: -69.17463750882314, time: 24.291
agent0_energy_min, agent0_attention_min
[-4.311e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-27.05  -1.65]
27000 50
steps: 1349950, episodes: 27000, mean episode reward: -83.18852127053354, time: 23.722
agent0_energy_min, agent0_attention_min
[-44.71  -0.53]
agent1_energy_min, agent1_attention_min
[-23.14  -0.5 ]
27100 50
steps: 1354950, episodes: 27100, mean episode reward: -106.56839360920937, time: 24.247
agent0_energy_min, agent0_attention_min
[-41.79  -1.22]
agent1_energy_min, agent1_attention_min
[-23.91  -1.37]
27200 50
steps: 1359950, episodes: 27200, mean episode reward: -73.41328947982794, time: 23.959
agent0_energy_min, agent0_attention_min
[-41.09  -1.04]
agent1_energy_min, agent1_attention_min
[-22.93  -1.34]
27300 50
steps: 1364950, episodes: 27300, mean episode reward: -87.95790242379161, time: 23.531
agent0_energy_min, agent0_attention_min
[-4.53e+01 -2.00e-02]
agent1_energy_min, agent1_attention_min
[-23.95  -1.37]
27400 50
steps: 1369950, episodes: 27400, mean episode reward: -78.98594986288636, time: 24.307
agent0_energy_min, agent0_attention_min
[-4.713e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-25.77  -0.44]
[-46.8   -2.11]
23800 50
steps: 1189950, episodes: 23800, mean episode reward: -68.84320752714682, time: 24.664
agent0_energy_min, agent0_attention_min
[-47.38  -1.25]
agent1_energy_min, agent1_attention_min
[-48.25  -0.6 ]
23900 50
steps: 1194950, episodes: 23900, mean episode reward: -62.41685911303703, time: 24.439
agent0_energy_min, agent0_attention_min
[-45.37  -0.66]
agent1_energy_min, agent1_attention_min
[-48.72  -0.6 ]
24000 50
steps: 1199950, episodes: 24000, mean episode reward: -46.13420385177132, time: 24.344
agent0_energy_min, agent0_attention_min
[-48.35  -0.98]
agent1_energy_min, agent1_attention_min
[-48.48  -0.62]
24100 50
steps: 1204950, episodes: 24100, mean episode reward: -55.64025616288219, time: 24.92
agent0_energy_min, agent0_attention_min
[-47.89  -1.51]
agent1_energy_min, agent1_attention_min
[-47.78  -1.25]
24200 50
steps: 1209950, episodes: 24200, mean episode reward: -59.5844576149137, time: 24.56
agent0_energy_min, agent0_attention_min
[-46.69  -1.15]
agent1_energy_min, agent1_attention_min
[-47.93  -1.08]
24300 50
steps: 1214950, episodes: 24300, mean episode reward: -49.710398425671634, time: 24.522
agent0_energy_min, agent0_attention_min
[-41.35  -0.84]
agent1_energy_min, agent1_attention_min
[-48.87  -0.56]
24400 50
steps: 1219950, episodes: 24400, mean episode reward: -75.38120491396563, time: 24.229
agent0_energy_min, agent0_attention_min
[-41.39  -1.11]
agent1_energy_min, agent1_attention_min
[-47.83  -1.21]
24500 50
steps: 1224950, episodes: 24500, mean episode reward: -63.469919089676125, time: 24.21
agent0_energy_min, agent0_attention_min
[-44.43  -2.06]
agent1_energy_min, agent1_attention_min
[-48.78  -0.46]
24600 50
steps: 1229950, episodes: 24600, mean episode reward: -60.31312894750239, time: 24.842
agent0_energy_min, agent0_attention_min
[-43.37  -4.62]
agent1_energy_min, agent1_attention_min
[-48.45  -0.63]
24700 50
steps: 1234950, episodes: 24700, mean episode reward: -44.679237382320586, time: 24.501
agent0_energy_min, agent0_attention_min
[-48.4   -1.53]
agent1_energy_min, agent1_attention_min
[-48.52  -0.86]
24800 50
steps: 1239950, episodes: 24800, mean episode reward: -47.40209772765134, time: 24.138
agent0_energy_min, agent0_attention_min
[-48.71  -1.24]
agent1_energy_min, agent1_attention_min
[-48.22  -0.79]
24900 50
steps: 1244950, episodes: 24900, mean episode reward: -52.952481792334, time: 24.641
agent0_energy_min, agent0_attention_min
[-47.    -0.75]
agent1_energy_min, agent1_attention_min
[-47.76  -0.83]
25000 50
steps: 1249950, episodes: 25000, mean episode reward: -56.65885631503775, time: 25.023
agent0_energy_min, agent0_attention_min
[-44.44  -5.53]
agent1_energy_min, agent1_attention_min
[-47.88  -0.77]
25100 50
steps: 1254950, episodes: 25100, mean episode reward: -50.58328239788181, time: 25.845
agent0_energy_min, agent0_attention_min
[-45.56  -4.41]
agent1_energy_min, agent1_attention_min
[-48.1   -0.76]
25200 50
steps: 1259950, episodes: 25200, mean episode reward: -54.64503746225357, time: 24.868
agent0_energy_min, agent0_attention_min
[-48.52  -1.47]
agent1_energy_min, agent1_attention_min
[-47.62  -0.58]
25300 50
steps: 1264950, episodes: 25300, mean episode reward: -49.334174345920204, time: 24.488
agent0_energy_min, agent0_attention_min
[-47.14  -2.7 ]
agent1_energy_min, agent1_attention_min
[-48.4   -0.56]
25400 50
steps: 1269950, episodes: 25400, mean episode reward: -56.70677328344778, time: 24.201
agent0_energy_min, agent0_attention_min
[-40.59  -0.99]
agent1_energy_min, agent1_attention_min
[-48.09  -1.08]
25500 50
steps: 1274950, episodes: 25500, mean episode reward: -46.763152361698495, time: 23.89
agent0_energy_min, agent0_attention_min
[-45.32  -4.68]
agent1_energy_min, agent1_attention_min
[-48.26  -0.94]
25600 50
steps: 1279950, episodes: 25600, mean episode reward: -48.66564254485164, time: 25.523
agent0_energy_min, agent0_attention_min
[-41.49  -8.46]
agent1_energy_min, agent1_attention_min
[-47.96  -0.79]
25700 50
steps: 1284950, episodes: 25700, mean episode reward: -47.46634060268681, time: 24.694
agent0_energy_min, agent0_attention_min
[-41.06  -8.92]
agent1_energy_min, agent1_attention_min
[-48.16  -0.91]
25800 50
steps: 1289950, episodes: 25800, mean episode reward: -43.27119187581818, time: 24.325
agent0_energy_min, agent0_attention_min
[-36.5  -13.04]
agent1_energy_min, agent1_attention_min
[-47.59  -1.29]
25900 50
steps: 1294950, episodes: 25900, mean episode reward: -55.87176196128173, time: 24.224
agent0_energy_min, agent0_attention_min
[-41.1   -8.82]
agent1_energy_min, agent1_attention_min
[-48.27  -0.88]
26000 50
steps: 1299950, episodes: 26000, mean episode reward: -95.18224310421563, time: 24.743
agent0_energy_min, agent0_attention_min
[-36.7  -9. ]
agent1_energy_min, agent1_attention_min
[-46.38  -0.65]
26100 50
steps: 1304950, episodes: 26100, mean episode reward: -99.73249792708454, time: 25.104
agent0_energy_min, agent0_attention_min
[-27.62 -10.98]
agent1_energy_min, agent1_attention_min
[-45.94  -0.93]
26200 50
steps: 1309950, episodes: 26200, mean episode reward: -60.17053111963638, time: 24.186
agent0_energy_min, agent0_attention_min
[-19.25 -11.81]
agent1_energy_min, agent1_attention_min
[-47.74  -1.22]
26300 50
steps: 1314950, episodes: 26300, mean episode reward: -50.009471207716906, time: 24.503
agent0_energy_min, agent0_attention_min
[-22.49  -9.82]
agent1_energy_min, agent1_attention_min
[-48.65  -0.75]
26400 50
steps: 1319950, episodes: 26400, mean episode reward: -57.95656895895952, time: 24.594
agent0_energy_min, agent0_attention_min
[-30.85  -9.48]
agent1_energy_min, agent1_attention_min
[-48.07  -1.03]
26500 50
steps: 1324950, episodes: 26500, mean episode reward: -41.61251058232054, time: 24.341
agent0_energy_min, agent0_attention_min
[-42.85  -5.89]
agent1_energy_min, agent1_attention_min
[-48.48  -0.63]
26600 50
steps: 1329950, episodes: 26600, mean episode reward: -54.19390161819379, time: 24.882
agent0_energy_min, agent0_attention_min
[-39.11  -9.29]
agent1_energy_min, agent1_attention_min
[-47.05  -1.06]
26700 50
steps: 1334950, episodes: 26700, mean episode reward: -89.74973879801635, time: 24.457
agent0_energy_min, agent0_attention_min
[-43.07  -5.85]
agent1_energy_min, agent1_attention_min
[-39.44  -1.41]
26800 50
steps: 1339950, episodes: 26800, mean episode reward: -75.29400922842115, time: 24.791
agent0_energy_min, agent0_attention_min
[-41.93  -6.27]
agent1_energy_min, agent1_attention_min
[-44.37  -0.88]
26900 50
steps: 1344950, episodes: 26900, mean episode reward: -72.30788648190105, time: 24.46
agent0_energy_min, agent0_attention_min
[-38.14 -11.33]
agent1_energy_min, agent1_attention_min
[-48.1   -0.29]
27000 50
steps: 1349950, episodes: 27000, mean episode reward: -68.63259496889741, time: 24.551
agent0_energy_min, agent0_attention_min
[-43.41  -6.06]
agent1_energy_min, agent1_attention_min
[-4.941e+01 -2.000e-02]
27100 50
steps: 1354950, episodes: 27100, mean episode reward: -39.21526385757284, time: 25.158
agent0_energy_min, agent0_attention_min
[-40.08  -9.56]
agent1_energy_min, agent1_attention_min
[-4.918e+01 -4.000e-02]
27200 50
steps: 1359950, episodes: 27200, mean episode reward: -51.508729792826124, time: 24.273
agent0_energy_min, agent0_attention_min
[-43.29  -6.56]
agent1_energy_min, agent1_attention_min
[-49.24  -0.3 ]
27300 50
steps: 1364950, episodes: 27300, mean episode reward: -51.03177851158489, time: 24.649
agent0_energy_min, agent0_attention_min
[-42.81  -6.41]
agent1_energy_min, agent1_attention_min
[-48.96  -0.69]
27400 50
steps: 1369950, episodes: 27400, mean episode reward: -64.20356991434984, time: 24.313
agent0_energy_min, agent0_attention_min
[-43.76  -5.81]
agent1_energy_min, agent1_attention_min
[-48.38  -1.1 ]
27500 50
steps: 1374950, episodes: 27500, mean episode reward: -48.959396524121566, time: 24.838
agent0_energy_min, agent0_attention_min
[-48.36  -1.51]
agent1_energy_min, agent1_attention_min
[-48.34  -0.99]
27600 50
steps: 1379950, episodes: 27600, mean episode reward: -43.16332707259779, time: 24.66
agent0_energy_min, agent0_attention_min
[-45.55  -4.35]
agent1_energy_min, agent1_attention_min
[-48.88  -0.07]
27700 50
steps: 1384950, episodes: 27700, mean episode reward: -67.21503567732644, time: 24.373
[-26.16 -23.63]
24000 50
steps: 1199950, episodes: 24000, mean episode reward: -71.29650862298148, time: 24.773
agent0_energy_min, agent0_attention_min
[-17.5  -32.38]
agent1_energy_min, agent1_attention_min
[-26.26 -23.17]
24100 50
steps: 1204950, episodes: 24100, mean episode reward: -84.8334918364302, time: 24.869
agent0_energy_min, agent0_attention_min
[-17.15 -32.78]
agent1_energy_min, agent1_attention_min
[-25.84 -22.56]
24200 50
steps: 1209950, episodes: 24200, mean episode reward: -55.95262723475863, time: 24.227
agent0_energy_min, agent0_attention_min
[-19.86 -30.12]
agent1_energy_min, agent1_attention_min
[-19.79 -29.58]
24300 50
steps: 1214950, episodes: 24300, mean episode reward: -290.6582619460545, time: 24.17
agent0_energy_min, agent0_attention_min
[-24.   -25.98]
agent1_energy_min, agent1_attention_min
[-4.58 -7.49]
24400 50
steps: 1219950, episodes: 24400, mean episode reward: -88.55913997077565, time: 24.361
agent0_energy_min, agent0_attention_min
[ -7.16 -42.8 ]
agent1_energy_min, agent1_attention_min
[-29.32 -20.35]
24500 50
steps: 1224950, episodes: 24500, mean episode reward: -80.37768166156825, time: 24.32
agent0_energy_min, agent0_attention_min
[ -7.88 -42.1 ]
agent1_energy_min, agent1_attention_min
[-28.95 -20.8 ]
24600 50
steps: 1229950, episodes: 24600, mean episode reward: -83.2254266320123, time: 24.99
agent0_energy_min, agent0_attention_min
[-11.66 -38.29]
agent1_energy_min, agent1_attention_min
[-25.46 -23.25]
24700 50
steps: 1234950, episodes: 24700, mean episode reward: -63.174617453880884, time: 23.997
agent0_energy_min, agent0_attention_min
[-11.78 -38.18]
agent1_energy_min, agent1_attention_min
[-22.36 -26.31]
24800 50
steps: 1239950, episodes: 24800, mean episode reward: -56.24610898599228, time: 24.485
agent0_energy_min, agent0_attention_min
[-15.15 -34.8 ]
agent1_energy_min, agent1_attention_min
[-22.45 -25.6 ]
24900 50
steps: 1244950, episodes: 24900, mean episode reward: -92.16178644010462, time: 24.004
agent0_energy_min, agent0_attention_min
[-15.11 -34.83]
agent1_energy_min, agent1_attention_min
[-22.77 -25.45]
25000 50
steps: 1249950, episodes: 25000, mean episode reward: -69.27990019804412, time: 24.567
agent0_energy_min, agent0_attention_min
[-14.09 -35.81]
agent1_energy_min, agent1_attention_min
[-23.55 -25.8 ]
25100 50
steps: 1254950, episodes: 25100, mean episode reward: -59.224734185129364, time: 25.545
agent0_energy_min, agent0_attention_min
[-13.04 -36.88]
agent1_energy_min, agent1_attention_min
[-22.7  -26.95]
25200 50
steps: 1259950, episodes: 25200, mean episode reward: -54.49102596875534, time: 24.352
agent0_energy_min, agent0_attention_min
[-13.43 -36.48]
agent1_energy_min, agent1_attention_min
[-24.69 -24.93]
25300 50
steps: 1264950, episodes: 25300, mean episode reward: -98.61769321617429, time: 24.497
agent0_energy_min, agent0_attention_min
[-18.48 -31.4 ]
agent1_energy_min, agent1_attention_min
[-23.94 -25.49]
25400 50
steps: 1269950, episodes: 25400, mean episode reward: -73.64080867565163, time: 24.656
agent0_energy_min, agent0_attention_min
[-16.57 -33.24]
agent1_energy_min, agent1_attention_min
[-21.37 -27.96]
25500 50
steps: 1274950, episodes: 25500, mean episode reward: -103.70904055825218, time: 23.963
agent0_energy_min, agent0_attention_min
[-23.85 -25.79]
agent1_energy_min, agent1_attention_min
[-25.26 -24.28]
25600 50
steps: 1279950, episodes: 25600, mean episode reward: -89.52100385998781, time: 25.236
agent0_energy_min, agent0_attention_min
[-21.63 -28.13]
agent1_energy_min, agent1_attention_min
[-23.62 -26.24]
25700 50
steps: 1284950, episodes: 25700, mean episode reward: -87.05358094493502, time: 24.215
agent0_energy_min, agent0_attention_min
[-24.95 -24.56]
agent1_energy_min, agent1_attention_min
[-23.84 -25.64]
25800 50
steps: 1289950, episodes: 25800, mean episode reward: -89.04192376665542, time: 24.072
agent0_energy_min, agent0_attention_min
[-19.95 -28.96]
agent1_energy_min, agent1_attention_min
[-26.27 -23.18]
25900 50
steps: 1294950, episodes: 25900, mean episode reward: -129.25240227159128, time: 24.955
agent0_energy_min, agent0_attention_min
[-23.26 -25.69]
agent1_energy_min, agent1_attention_min
[-23.66 -26.05]
26000 50
steps: 1299950, episodes: 26000, mean episode reward: -87.67029716122795, time: 24.593
agent0_energy_min, agent0_attention_min
[-20.63 -28.75]
agent1_energy_min, agent1_attention_min
[-24.8  -24.73]
26100 50
steps: 1304950, episodes: 26100, mean episode reward: -74.59634629717843, time: 24.402
agent0_energy_min, agent0_attention_min
[-18.72 -30.97]
agent1_energy_min, agent1_attention_min
[-26.64 -20.83]
26200 50
steps: 1309950, episodes: 26200, mean episode reward: -83.68865063563283, time: 24.648
agent0_energy_min, agent0_attention_min
[-18.27 -31.33]
agent1_energy_min, agent1_attention_min
[-27.45 -20.75]
26300 50
steps: 1314950, episodes: 26300, mean episode reward: -104.66602755531456, time: 24.863
agent0_energy_min, agent0_attention_min
[-17.47 -31.61]
agent1_energy_min, agent1_attention_min
[-30.05 -18.74]
26400 50
steps: 1319950, episodes: 26400, mean episode reward: -63.42814811967851, time: 24.134
agent0_energy_min, agent0_attention_min
[-13.31 -35.99]
agent1_energy_min, agent1_attention_min
[-31.94 -17.03]
26500 50
steps: 1324950, episodes: 26500, mean episode reward: -86.30759489181264, time: 24.137
agent0_energy_min, agent0_attention_min
[-18.86 -30.92]
agent1_energy_min, agent1_attention_min
[-31.19 -18.16]
26600 50
steps: 1329950, episodes: 26600, mean episode reward: -68.72952786844233, time: 24.93
agent0_energy_min, agent0_attention_min
[-23.53 -25.83]
agent1_energy_min, agent1_attention_min
[-31.48 -17.67]
26700 50
steps: 1334950, episodes: 26700, mean episode reward: -79.04766523496201, time: 24.16
agent0_energy_min, agent0_attention_min
[-24.34 -24.95]
agent1_energy_min, agent1_attention_min
[-33.08 -13.38]
26800 50
steps: 1339950, episodes: 26800, mean episode reward: -83.64378408275351, time: 24.567
agent0_energy_min, agent0_attention_min
[-17.5  -28.59]
agent1_energy_min, agent1_attention_min
[-32.3  -13.81]
26900 50
steps: 1344950, episodes: 26900, mean episode reward: -126.85875995144802, time: 24.67
agent0_energy_min, agent0_attention_min
[-31.42 -17.23]
agent1_energy_min, agent1_attention_min
[-31.58 -12.84]
27000 50
steps: 1349950, episodes: 27000, mean episode reward: -76.2023696628933, time: 24.532
agent0_energy_min, agent0_attention_min
[-31.35 -18.46]
agent1_energy_min, agent1_attention_min
[-32.01 -14.28]
27100 50
steps: 1354950, episodes: 27100, mean episode reward: -86.36123393424513, time: 25.081
agent0_energy_min, agent0_attention_min
[-25.45 -24.3 ]
agent1_energy_min, agent1_attention_min
[-29.69 -15.94]
27200 50
steps: 1359950, episodes: 27200, mean episode reward: -93.1460724515925, time: 24.428
agent0_energy_min, agent0_attention_min
[-29.2  -20.43]
agent1_energy_min, agent1_attention_min
[-25.22 -19.57]
27300 50
steps: 1364950, episodes: 27300, mean episode reward: -75.71895886815786, time: 24.135
agent0_energy_min, agent0_attention_min
[-23.71 -26.12]
agent1_energy_min, agent1_attention_min
[-32.44 -14.4 ]
27400 50
steps: 1369950, episodes: 27400, mean episode reward: -129.61427537723503, time: 24.736
agent0_energy_min, agent0_attention_min
[-27.03 -22.89]
agent1_energy_min, agent1_attention_min
[-33.72 -11.79]
27500 50
steps: 1374950, episodes: 27500, mean episode reward: -91.12956432349463, time: 23.944
agent0_energy_min, agent0_attention_min
[-22.81 -26.88]
agent1_energy_min, agent1_attention_min
[-29.99 -15.63]
27600 50
steps: 1379950, episodes: 27600, mean episode reward: -75.14842969936397, time: 24.412
agent0_energy_min, agent0_attention_min
[-22.14 -27.15]
agent1_energy_min, agent1_attention_min
[-34.39 -13.26]
27700 50
steps: 1384950, episodes: 27700, mean episode reward: -79.41919813890252, time: 24.617
agent0_energy_min, agent0_attention_min
[-21.12 -28.62]
agent1_energy_min, agent1_attention_min
[-35.31 -13.16]
27800 50
steps: 1389950, episodes: 27800, mean episode reward: -85.5438098277354, time: 24.519
agent0_energy_min, agent0_attention_min
[-25.98 -23.93]
agent1_energy_min, agent1_attention_min
[-34.04 -13.02]
27900 50
steps: 1394950, episodes: 27900, mean episode reward: -72.92197222603359, time: 24.924
[-36.73 -11.72]
24000 50
steps: 1199950, episodes: 24000, mean episode reward: -70.94451814751409, time: 24.061
agent0_energy_min, agent0_attention_min
[-35.21 -14.69]
agent1_energy_min, agent1_attention_min
[-35.28 -10.76]
24100 50
steps: 1204950, episodes: 24100, mean episode reward: -75.33864485926136, time: 25.28
agent0_energy_min, agent0_attention_min
[-36.21 -13.51]
agent1_energy_min, agent1_attention_min
[-31.2   -4.72]
24200 50
steps: 1209950, episodes: 24200, mean episode reward: -85.29877398490407, time: 24.794
agent0_energy_min, agent0_attention_min
[-32.78 -13.29]
agent1_energy_min, agent1_attention_min
[-36.64 -11.34]
24300 50
steps: 1214950, episodes: 24300, mean episode reward: -68.9587808386444, time: 24.025
agent0_energy_min, agent0_attention_min
[-32.14  -9.62]
agent1_energy_min, agent1_attention_min
[-41.69  -7.99]
24400 50
steps: 1219950, episodes: 24400, mean episode reward: -67.03512210743008, time: 24.097
agent0_energy_min, agent0_attention_min
[-37.39  -9.09]
agent1_energy_min, agent1_attention_min
[-35.43 -14.12]
24500 50
steps: 1224950, episodes: 24500, mean episode reward: -59.286436297484926, time: 24.211
agent0_energy_min, agent0_attention_min
[-38.24  -8.12]
agent1_energy_min, agent1_attention_min
[-39.14 -10.69]
24600 50
steps: 1229950, episodes: 24600, mean episode reward: -67.38107257847551, time: 24.912
agent0_energy_min, agent0_attention_min
[-37.8  -10.09]
agent1_energy_min, agent1_attention_min
[-46.63  -3.07]
24700 50
steps: 1234950, episodes: 24700, mean episode reward: -68.04455672794086, time: 24.493
agent0_energy_min, agent0_attention_min
[-38.13 -11.59]
agent1_energy_min, agent1_attention_min
[-42.52  -6.91]
24800 50
steps: 1239950, episodes: 24800, mean episode reward: -88.30525235077235, time: 24.651
agent0_energy_min, agent0_attention_min
[-31.6  -18.24]
agent1_energy_min, agent1_attention_min
[-44.73  -4.9 ]
24900 50
steps: 1244950, episodes: 24900, mean episode reward: -81.64521289714921, time: 24.67
agent0_energy_min, agent0_attention_min
[-34.95 -14.87]
agent1_energy_min, agent1_attention_min
[-44.91  -4.75]
25000 50
steps: 1249950, episodes: 25000, mean episode reward: -67.76172651601706, time: 24.428
agent0_energy_min, agent0_attention_min
[-34.55 -15.22]
agent1_energy_min, agent1_attention_min
[-37.39 -12.17]
25100 50
steps: 1254950, episodes: 25100, mean episode reward: -83.17785286462255, time: 25.318
agent0_energy_min, agent0_attention_min
[-22.7  -11.77]
agent1_energy_min, agent1_attention_min
[-44.11  -5.65]
25200 50
steps: 1259950, episodes: 25200, mean episode reward: -84.06327960814822, time: 24.351
agent0_energy_min, agent0_attention_min
[-26.02  -9.22]
agent1_energy_min, agent1_attention_min
[-42.34  -7.23]
25300 50
steps: 1264950, episodes: 25300, mean episode reward: -57.39579117993645, time: 24.259
agent0_energy_min, agent0_attention_min
[-32.15 -17.66]
agent1_energy_min, agent1_attention_min
[-37.39 -12.24]
25400 50
steps: 1269950, episodes: 25400, mean episode reward: -58.62553224953197, time: 24.079
agent0_energy_min, agent0_attention_min
[-35.01 -14.86]
agent1_energy_min, agent1_attention_min
[-33.01 -16.4 ]
25500 50
steps: 1274950, episodes: 25500, mean episode reward: -60.76028488906644, time: 24.792
agent0_energy_min, agent0_attention_min
[-38.62 -10.99]
agent1_energy_min, agent1_attention_min
[-40.34  -8.84]
25600 50
steps: 1279950, episodes: 25600, mean episode reward: -57.644867238736886, time: 24.207
agent0_energy_min, agent0_attention_min
[-33.39 -16.05]
agent1_energy_min, agent1_attention_min
[-37.7  -10.75]
25700 50
steps: 1284950, episodes: 25700, mean episode reward: -86.39961627422217, time: 24.698
agent0_energy_min, agent0_attention_min
[-35.3  -14.35]
agent1_energy_min, agent1_attention_min
[-33.65 -15.2 ]
25800 50
steps: 1289950, episodes: 25800, mean episode reward: -75.2078198659558, time: 24.621
agent0_energy_min, agent0_attention_min
[-40.43  -9.05]
agent1_energy_min, agent1_attention_min
[-30.99 -18.23]
25900 50
steps: 1294950, episodes: 25900, mean episode reward: -62.25553243160822, time: 24.381
agent0_energy_min, agent0_attention_min
[-38.76 -11.08]
agent1_energy_min, agent1_attention_min
[-38.82 -10.88]
26000 50
steps: 1299950, episodes: 26000, mean episode reward: -60.48316445162173, time: 24.051
agent0_energy_min, agent0_attention_min
[-39.26 -10.53]
agent1_energy_min, agent1_attention_min
[-28.36 -21.12]
26100 50
steps: 1304950, episodes: 26100, mean episode reward: -74.96530718490371, time: 24.642
agent0_energy_min, agent0_attention_min
[-35.14 -14.38]
agent1_energy_min, agent1_attention_min
[-36.03 -13.55]
26200 50
steps: 1309950, episodes: 26200, mean episode reward: -145.43458191615025, time: 23.756
agent0_energy_min, agent0_attention_min
[-38.68 -10.93]
agent1_energy_min, agent1_attention_min
[-33.71 -15.84]
26300 50
steps: 1314950, episodes: 26300, mean episode reward: -106.03646283919834, time: 24.242
agent0_energy_min, agent0_attention_min
[-36.8  -12.73]
agent1_energy_min, agent1_attention_min
[-37.14 -12.11]
26400 50
steps: 1319950, episodes: 26400, mean episode reward: -66.52159105526776, time: 24.507
agent0_energy_min, agent0_attention_min
[-36.3  -13.08]
agent1_energy_min, agent1_attention_min
[-33.73 -15.7 ]
26500 50
steps: 1324950, episodes: 26500, mean episode reward: -68.10531608648745, time: 23.733
agent0_energy_min, agent0_attention_min
[-28.13 -14.94]
agent1_energy_min, agent1_attention_min
[-31.42 -17.39]
26600 50
steps: 1329950, episodes: 26600, mean episode reward: -65.31810020143597, time: 24.54
agent0_energy_min, agent0_attention_min
[-32.7  -14.99]
agent1_energy_min, agent1_attention_min
[-28.24 -14.79]
26700 50
steps: 1334950, episodes: 26700, mean episode reward: -59.2812346145969, time: 24.076
agent0_energy_min, agent0_attention_min
[-29.06 -17.67]
agent1_energy_min, agent1_attention_min
[-26.65 -21.  ]
26800 50
steps: 1339950, episodes: 26800, mean episode reward: -72.66302227667515, time: 24.348
agent0_energy_min, agent0_attention_min
[-30.57 -16.51]
agent1_energy_min, agent1_attention_min
[-28.12 -20.65]
26900 50
steps: 1344950, episodes: 26900, mean episode reward: -60.14194662309397, time: 24.001
agent0_energy_min, agent0_attention_min
[-34.61 -12.28]
agent1_energy_min, agent1_attention_min
[-32.97 -15.12]
27000 50
steps: 1349950, episodes: 27000, mean episode reward: -55.70333396686469, time: 24.308
agent0_energy_min, agent0_attention_min
[-27.26 -12.92]
agent1_energy_min, agent1_attention_min
[-27.01 -21.57]
27100 50
steps: 1354950, episodes: 27100, mean episode reward: -59.77034192895374, time: 24.86
agent0_energy_min, agent0_attention_min
[-27.86 -20.42]
agent1_energy_min, agent1_attention_min
[-31.22 -17.66]
27200 50
steps: 1359950, episodes: 27200, mean episode reward: -55.94913134927561, time: 24.124
agent0_energy_min, agent0_attention_min
[-23.7  -18.51]
agent1_energy_min, agent1_attention_min
[-17.76 -30.92]
27300 50
steps: 1364950, episodes: 27300, mean episode reward: -57.445666725185156, time: 24.108
agent0_energy_min, agent0_attention_min
[-30.02 -15.51]
agent1_energy_min, agent1_attention_min
[-16.7  -28.49]
27400 50
steps: 1369950, episodes: 27400, mean episode reward: -73.02095188091864, time: 24.495
agent0_energy_min, agent0_attention_min
[-27.67 -20.88]
agent1_energy_min, agent1_attention_min
[-21.26 -21.29]
27500 50
steps: 1374950, episodes: 27500, mean episode reward: -81.1584857237807, time: 23.957
agent0_energy_min, agent0_attention_min
[-15.31 -29.06]
agent1_energy_min, agent1_attention_min
[-18.79 -26.42]
27600 50
steps: 1379950, episodes: 27600, mean episode reward: -87.91342217517261, time: 24.852
agent0_energy_min, agent0_attention_min
[-19.54 -25.88]
agent1_energy_min, agent1_attention_min
[-20.94 -22.35]
27700 50
steps: 1384950, episodes: 27700, mean episode reward: -72.21298502273828, time: 24.631
agent0_energy_min, agent0_attention_min
[-28.17 -12.12]
agent1_energy_min, agent1_attention_min
[-24.3  -22.17]
27800 50
steps: 1389950, episodes: 27800, mean episode reward: -76.27304451700755, time: 24.514
agent0_energy_min, agent0_attention_min
[-26.09 -14.05]
agent1_energy_min, agent1_attention_min
[-20.45 -21.56]
27900 50
steps: 1394950, episodes: 27900, mean episode reward: -62.93194954093782, time: 24.757
agent0_energy_min, agent0_attention_min
[-24.86  -0.12]
agent1_energy_min, agent1_attention_min
[-0.08 -0.11]
23900 50
steps: 1194950, episodes: 23900, mean episode reward: -93.32999434516314, time: 24.227
agent0_energy_min, agent0_attention_min
[-21.    -0.08]
agent1_energy_min, agent1_attention_min
[-0.06 -0.03]
24000 50
steps: 1199950, episodes: 24000, mean episode reward: -92.47092882488259, time: 24.758
agent0_energy_min, agent0_attention_min
[-25.43  -0.03]
agent1_energy_min, agent1_attention_min
[-0.04 -0.1 ]
24100 50
steps: 1204950, episodes: 24100, mean episode reward: -100.88967788819602, time: 24.889
agent0_energy_min, agent0_attention_min
[-22.6   -0.04]
agent1_energy_min, agent1_attention_min
[-0.01 -0.03]
24200 50
steps: 1209950, episodes: 24200, mean episode reward: -92.06648375540391, time: 24.433
agent0_energy_min, agent0_attention_min
[-22.77  -0.04]
agent1_energy_min, agent1_attention_min
[-0.34 -0.11]
24300 50
steps: 1214950, episodes: 24300, mean episode reward: -97.98239134230089, time: 24.104
agent0_energy_min, agent0_attention_min
[-26.67  -0.04]
agent1_energy_min, agent1_attention_min
[-0.02 -0.18]
24400 50
steps: 1219950, episodes: 24400, mean episode reward: -109.3727244936696, time: 24.789
agent0_energy_min, agent0_attention_min
[-22.52  -0.06]
agent1_energy_min, agent1_attention_min
[-0.03 -0.04]
24500 50
steps: 1224950, episodes: 24500, mean episode reward: -94.84535268393853, time: 24.066
agent0_energy_min, agent0_attention_min
[-25.15  -0.23]
agent1_energy_min, agent1_attention_min
[-0.15 -0.03]
24600 50
steps: 1229950, episodes: 24600, mean episode reward: -97.5770083644929, time: 24.573
agent0_energy_min, agent0_attention_min
[-23.39  -0.25]
agent1_energy_min, agent1_attention_min
[-0.67 -0.06]
24700 50
steps: 1234950, episodes: 24700, mean episode reward: -114.70953789465759, time: 24.635
agent0_energy_min, agent0_attention_min
[-31.44  -0.47]
agent1_energy_min, agent1_attention_min
[-0.01 -0.02]
24800 50
steps: 1239950, episodes: 24800, mean episode reward: -106.09126561931485, time: 24.718
agent0_energy_min, agent0_attention_min
[-24.6   -0.19]
agent1_energy_min, agent1_attention_min
[-0.03 -0.05]
24900 50
steps: 1244950, episodes: 24900, mean episode reward: -97.6129405768225, time: 24.552
agent0_energy_min, agent0_attention_min
[-27.18  -0.23]
agent1_energy_min, agent1_attention_min
[-0.03 -0.01]
25000 50
steps: 1249950, episodes: 25000, mean episode reward: -132.7057000141948, time: 24.694
agent0_energy_min, agent0_attention_min
[-27.43  -0.42]
agent1_energy_min, agent1_attention_min
[-0.02 -0.07]
25100 50
steps: 1254950, episodes: 25100, mean episode reward: -106.62120785815752, time: 25.205
agent0_energy_min, agent0_attention_min
[-24.14  -1.49]
agent1_energy_min, agent1_attention_min
[-0.21 -0.07]
25200 50
steps: 1259950, episodes: 25200, mean episode reward: -100.19802734997215, time: 24.715
agent0_energy_min, agent0_attention_min
[-23.09  -0.66]
agent1_energy_min, agent1_attention_min
[-0.36 -0.06]
25300 50
steps: 1264950, episodes: 25300, mean episode reward: -92.54626366131477, time: 24.168
agent0_energy_min, agent0_attention_min
[-19.05  -0.18]
agent1_energy_min, agent1_attention_min
[ 0.   -0.04]
25400 50
steps: 1269950, episodes: 25400, mean episode reward: -95.98167423187593, time: 25.06
agent0_energy_min, agent0_attention_min
[-27.35  -0.09]
agent1_energy_min, agent1_attention_min
[-0.3  -0.04]
25500 50
steps: 1274950, episodes: 25500, mean episode reward: -107.22333843042708, time: 24.813
agent0_energy_min, agent0_attention_min
[-20.29  -0.19]
agent1_energy_min, agent1_attention_min
[ 0.   -0.04]
25600 50
steps: 1279950, episodes: 25600, mean episode reward: -106.56799791633743, time: 24.626
agent0_energy_min, agent0_attention_min
[-20.92  -0.22]
agent1_energy_min, agent1_attention_min
[ -0.03 -11.79]
25700 50
steps: 1284950, episodes: 25700, mean episode reward: -128.87642424395779, time: 24.444
agent0_energy_min, agent0_attention_min
[-27.55  -0.58]
agent1_energy_min, agent1_attention_min
[ -0.03 -17.09]
25800 50
steps: 1289950, episodes: 25800, mean episode reward: -99.81729543300052, time: 24.416
agent0_energy_min, agent0_attention_min
[-25.61  -0.2 ]
agent1_energy_min, agent1_attention_min
[-0.4  -0.69]
25900 50
steps: 1294950, episodes: 25900, mean episode reward: -121.1421383192534, time: 24.103
agent0_energy_min, agent0_attention_min
[-25.02  -0.08]
agent1_energy_min, agent1_attention_min
[-0.05 -0.26]
26000 50
steps: 1299950, episodes: 26000, mean episode reward: -122.6017484286012, time: 24.451
agent0_energy_min, agent0_attention_min
[-21.31  -0.14]
agent1_energy_min, agent1_attention_min
[-0.01 -0.44]
26100 50
steps: 1304950, episodes: 26100, mean episode reward: -105.92010075625778, time: 24.89
agent0_energy_min, agent0_attention_min
[-21.31  -0.04]
agent1_energy_min, agent1_attention_min
[-0.35 -0.31]
26200 50
steps: 1309950, episodes: 26200, mean episode reward: -97.94107096391768, time: 24.133
agent0_energy_min, agent0_attention_min
[-2.259e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.05 -0.24]
26300 50
steps: 1314950, episodes: 26300, mean episode reward: -108.97132582583143, time: 24.711
agent0_energy_min, agent0_attention_min
[-2.367e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.03 -0.4 ]
26400 50
steps: 1319950, episodes: 26400, mean episode reward: -100.10144934903099, time: 24.971
agent0_energy_min, agent0_attention_min
[-23.39  -0.05]
agent1_energy_min, agent1_attention_min
[-0.02 -0.3 ]
26500 50
steps: 1324950, episodes: 26500, mean episode reward: -108.93614591050112, time: 24.777
agent0_energy_min, agent0_attention_min
[-23.88  -0.15]
agent1_energy_min, agent1_attention_min
[-0.02 -0.15]
26600 50
steps: 1329950, episodes: 26600, mean episode reward: -97.60920663673042, time: 24.596
agent0_energy_min, agent0_attention_min
[-28.81  -1.22]
agent1_energy_min, agent1_attention_min
[-0.02 -0.11]
26700 50
steps: 1334950, episodes: 26700, mean episode reward: -92.06241649023669, time: 24.283
agent0_energy_min, agent0_attention_min
[-25.36  -0.06]
agent1_energy_min, agent1_attention_min
[-0.01 -0.09]
26800 50
steps: 1339950, episodes: 26800, mean episode reward: -101.86299857376252, time: 24.278
agent0_energy_min, agent0_attention_min
[-22.73  -0.03]
agent1_energy_min, agent1_attention_min
[ 0.   -0.08]
26900 50
steps: 1344950, episodes: 26900, mean episode reward: -107.16581602783812, time: 24.19
agent0_energy_min, agent0_attention_min
[-21.93   0.  ]
agent1_energy_min, agent1_attention_min
[ 0.   -0.37]
27000 50
steps: 1349950, episodes: 27000, mean episode reward: -135.21648987107667, time: 24.571
agent0_energy_min, agent0_attention_min
[-2.436e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.02 -0.27]
27100 50
steps: 1354950, episodes: 27100, mean episode reward: -111.89392051893421, time: 24.605
agent0_energy_min, agent0_attention_min
[-2.163e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.05]
27200 50
steps: 1359950, episodes: 27200, mean episode reward: -124.87976985124467, time: 25.081
agent0_energy_min, agent0_attention_min
[-24.05   0.  ]
agent1_energy_min, agent1_attention_min
[ 0.   -0.04]
27300 50
steps: 1364950, episodes: 27300, mean episode reward: -105.52886946254277, time: 24.51
agent0_energy_min, agent0_attention_min
[-23.11  -0.03]
agent1_energy_min, agent1_attention_min
[-0.03 -0.05]
27400 50
steps: 1369950, episodes: 27400, mean episode reward: -106.40070086721256, time: 24.612
agent0_energy_min, agent0_attention_min
[-2.081e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.06]
27500 50
steps: 1374950, episodes: 27500, mean episode reward: -94.04836923906876, time: 25.027
agent0_energy_min, agent0_attention_min
[-2.239e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.14 -0.03]
27600 50
steps: 1379950, episodes: 27600, mean episode reward: -103.99151825434775, time: 25.184
agent0_energy_min, agent0_attention_min
[-2.233e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-13.97  -0.03]
27700 50
steps: 1384950, episodes: 27700, mean episode reward: -867.5932104812039, time: 24.624
agent0_energy_min, agent0_attention_min
[-2.162e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-12.42 -37.32]
24000 50
steps: 1199950, episodes: 24000, mean episode reward: -56.63725127452597, time: 24.239
agent0_energy_min, agent0_attention_min
[-22.26  -2.75]
agent1_energy_min, agent1_attention_min
[ -7.39 -41.93]
24100 50
steps: 1204950, episodes: 24100, mean episode reward: -66.92415401608508, time: 24.963
agent0_energy_min, agent0_attention_min
[-28.57  -0.57]
agent1_energy_min, agent1_attention_min
[ -4.05 -45.62]
24200 50
steps: 1209950, episodes: 24200, mean episode reward: -78.60551923551523, time: 24.721
agent0_energy_min, agent0_attention_min
[-28.63  -1.55]
agent1_energy_min, agent1_attention_min
[ -4.84 -44.85]
24300 50
steps: 1214950, episodes: 24300, mean episode reward: -62.83332111134294, time: 24.086
agent0_energy_min, agent0_attention_min
[-23.61  -1.38]
agent1_energy_min, agent1_attention_min
[ -4.57 -45.26]
24400 50
steps: 1219950, episodes: 24400, mean episode reward: -87.62039772521207, time: 24.473
agent0_energy_min, agent0_attention_min
[-28.85  -2.65]
agent1_energy_min, agent1_attention_min
[ -6.48 -43.17]
24500 50
steps: 1224950, episodes: 24500, mean episode reward: -79.6612941611416, time: 24.646
agent0_energy_min, agent0_attention_min
[-25.73  -1.7 ]
agent1_energy_min, agent1_attention_min
[ -4.58 -45.07]
24600 50
steps: 1229950, episodes: 24600, mean episode reward: -67.60175316576824, time: 25.072
agent0_energy_min, agent0_attention_min
[-26.76  -0.95]
agent1_energy_min, agent1_attention_min
[ -5.34 -44.35]
24700 50
steps: 1234950, episodes: 24700, mean episode reward: -70.81531404670605, time: 24.322
agent0_energy_min, agent0_attention_min
[-23.73  -1.61]
agent1_energy_min, agent1_attention_min
[ -4.56 -44.99]
24800 50
steps: 1239950, episodes: 24800, mean episode reward: -77.64500761794201, time: 24.29
agent0_energy_min, agent0_attention_min
[-22.84  -4.03]
agent1_energy_min, agent1_attention_min
[ -3.62 -46.33]
24900 50
steps: 1244950, episodes: 24900, mean episode reward: -61.61709004694619, time: 24.971
agent0_energy_min, agent0_attention_min
[-24.51  -2.54]
agent1_energy_min, agent1_attention_min
[ -7.39 -42.42]
25000 50
steps: 1249950, episodes: 25000, mean episode reward: -78.02057937359673, time: 24.198
agent0_energy_min, agent0_attention_min
[-26.9   -2.74]
agent1_energy_min, agent1_attention_min
[ -6.45 -43.26]
25100 50
steps: 1254950, episodes: 25100, mean episode reward: -65.40942617742152, time: 25.864
agent0_energy_min, agent0_attention_min
[-21.27  -3.35]
agent1_energy_min, agent1_attention_min
[ -3.79 -46.  ]
25200 50
steps: 1259950, episodes: 25200, mean episode reward: -95.26671742771474, time: 24.583
agent0_energy_min, agent0_attention_min
[-21.2   -3.75]
agent1_energy_min, agent1_attention_min
[ -4.99 -45.01]
25300 50
steps: 1264950, episodes: 25300, mean episode reward: -86.87147414365398, time: 24.158
agent0_energy_min, agent0_attention_min
[-23.95  -6.33]
agent1_energy_min, agent1_attention_min
[ -5.31 -44.64]
25400 50
steps: 1269950, episodes: 25400, mean episode reward: -64.00263739014072, time: 24.953
agent0_energy_min, agent0_attention_min
[-19.27  -9.62]
agent1_energy_min, agent1_attention_min
[ -7.86 -42.07]
25500 50
steps: 1274950, episodes: 25500, mean episode reward: -64.84080122019583, time: 24.849
agent0_energy_min, agent0_attention_min
[-22.19  -7.04]
agent1_energy_min, agent1_attention_min
[ -5.92 -44.04]
25600 50
steps: 1279950, episodes: 25600, mean episode reward: -78.91434856355868, time: 25.008
agent0_energy_min, agent0_attention_min
[-34.67  -2.59]
agent1_energy_min, agent1_attention_min
[ -5.56 -44.29]
25700 50
steps: 1284950, episodes: 25700, mean episode reward: -67.57044089835567, time: 24.42
agent0_energy_min, agent0_attention_min
[-28.07  -3.72]
agent1_energy_min, agent1_attention_min
[ -7.28 -42.38]
25800 50
steps: 1289950, episodes: 25800, mean episode reward: -57.62055862641857, time: 24.581
agent0_energy_min, agent0_attention_min
[-20.36  -3.01]
agent1_energy_min, agent1_attention_min
[ -2.75 -46.45]
25900 50
steps: 1294950, episodes: 25900, mean episode reward: -56.672420414743485, time: 24.047
agent0_energy_min, agent0_attention_min
[-19.69  -2.91]
agent1_energy_min, agent1_attention_min
[ -2.81 -46.87]
26000 50
steps: 1299950, episodes: 26000, mean episode reward: -59.37723763680415, time: 24.75
agent0_energy_min, agent0_attention_min
[-20.51  -7.65]
agent1_energy_min, agent1_attention_min
[ -3.15 -46.72]
26100 50
steps: 1304950, episodes: 26100, mean episode reward: -54.27893308107167, time: 24.797
agent0_energy_min, agent0_attention_min
[-18.36 -10.65]
agent1_energy_min, agent1_attention_min
[ -4.54 -45.41]
26200 50
steps: 1309950, episodes: 26200, mean episode reward: -59.98073805679385, time: 24.71
agent0_energy_min, agent0_attention_min
[-21.21 -11.04]
agent1_energy_min, agent1_attention_min
[ -2.44 -47.44]
26300 50
steps: 1314950, episodes: 26300, mean episode reward: -59.88738886685078, time: 24.563
agent0_energy_min, agent0_attention_min
[-18.04 -10.31]
agent1_energy_min, agent1_attention_min
[ -3.29 -46.67]
26400 50
steps: 1319950, episodes: 26400, mean episode reward: -64.28805597874909, time: 24.669
agent0_energy_min, agent0_attention_min
[-19.65  -8.  ]
agent1_energy_min, agent1_attention_min
[ -2.94 -47.05]
26500 50
steps: 1324950, episodes: 26500, mean episode reward: -74.53036743135186, time: 24.361
agent0_energy_min, agent0_attention_min
[-18.86  -7.05]
agent1_energy_min, agent1_attention_min
[ -3.37 -46.6 ]
26600 50
steps: 1329950, episodes: 26600, mean episode reward: -67.95333129694991, time: 25.391
agent0_energy_min, agent0_attention_min
[-19.85 -11.55]
agent1_energy_min, agent1_attention_min
[ -3.47 -46.5 ]
26700 50
steps: 1334950, episodes: 26700, mean episode reward: -53.03740888776701, time: 24.752
agent0_energy_min, agent0_attention_min
[-18.73 -11.62]
agent1_energy_min, agent1_attention_min
[ -2.3  -47.58]
26800 50
steps: 1339950, episodes: 26800, mean episode reward: -76.59848688280114, time: 24.239
agent0_energy_min, agent0_attention_min
[-23.46  -2.6 ]
agent1_energy_min, agent1_attention_min
[ -2.61 -47.32]
26900 50
steps: 1344950, episodes: 26900, mean episode reward: -51.30249856583574, time: 24.272
agent0_energy_min, agent0_attention_min
[-21.85  -4.1 ]
agent1_energy_min, agent1_attention_min
[ -3.6  -46.32]
27000 50
steps: 1349950, episodes: 27000, mean episode reward: -51.1918638388846, time: 24.403
agent0_energy_min, agent0_attention_min
[-22.98  -4.42]
agent1_energy_min, agent1_attention_min
[ -2.41 -47.53]
27100 50
steps: 1354950, episodes: 27100, mean episode reward: -61.654438664552885, time: 25.387
agent0_energy_min, agent0_attention_min
[-22.86  -9.  ]
agent1_energy_min, agent1_attention_min
[ -3.05 -46.88]
27200 50
steps: 1359950, episodes: 27200, mean episode reward: -69.12485026042482, time: 24.385
agent0_energy_min, agent0_attention_min
[-23.99  -5.69]
agent1_energy_min, agent1_attention_min
[ -3.35 -46.6 ]
27300 50
steps: 1364950, episodes: 27300, mean episode reward: -91.66181805015445, time: 24.94
agent0_energy_min, agent0_attention_min
[-26.06  -7.59]
agent1_energy_min, agent1_attention_min
[ -3.14 -46.82]
27400 50
steps: 1369950, episodes: 27400, mean episode reward: -79.26524384984693, time: 25.24
agent0_energy_min, agent0_attention_min
[-19.48  -6.15]
agent1_energy_min, agent1_attention_min
[ -2.19 -47.78]
27500 50
steps: 1374950, episodes: 27500, mean episode reward: -74.22107376123886, time: 24.336
agent0_energy_min, agent0_attention_min
[-16.08  -8.2 ]
agent1_energy_min, agent1_attention_min
[ -1.99 -48.  ]
27600 50
steps: 1379950, episodes: 27600, mean episode reward: -101.97178867331273, time: 25.665
agent0_energy_min, agent0_attention_min
[-16.36  -4.77]
agent1_energy_min, agent1_attention_min
[ -4.17 -45.83]
27700 50
steps: 1384950, episodes: 27700, mean episode reward: -178.5106700705423, time: 24.701
agent0_energy_min, agent0_attention_min
[-20.72  -2.13]
agent1_energy_min, agent1_attention_min
[ -4.4  -45.56]
27800 50
steps: 1389950, episodes: 27800, mean episode reward: -135.13823271668457, time: 25.479
agent0_energy_min, agent0_attention_min
[-18.71  -5.94]
agent1_energy_min, agent1_attention_min
[ -2.3  -47.66]
27900 50
steps: 1394950, episodes: 27900, mean episode reward: -81.78942032872875, time: 24.023
27600 50
steps: 1379950, episodes: 27600, mean episode reward: -169.0669919072239, time: 24.501
agent0_energy_min, agent0_attention_min
[-4.997e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-3.691e+01 -2.000e-02]
27700 50
steps: 1384950, episodes: 27700, mean episode reward: -113.76339767991432, time: 24.221
agent0_energy_min, agent0_attention_min
[-4.999e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-41.42   0.  ]
27800 50
steps: 1389950, episodes: 27800, mean episode reward: -106.91787250762123, time: 23.86
agent0_energy_min, agent0_attention_min
[-4.997e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-41.08  -0.06]
27900 50
steps: 1394950, episodes: 27900, mean episode reward: -91.57579369559285, time: 23.765
agent0_energy_min, agent0_attention_min
[-50.   0.]
agent1_energy_min, agent1_attention_min
[-4.168e+01 -1.000e-02]
28000 50
steps: 1399950, episodes: 28000, mean episode reward: -97.12808214674038, time: 24.473
agent0_energy_min, agent0_attention_min
[-4.998e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-41.49   0.  ]
28100 50
steps: 1404950, episodes: 28100, mean episode reward: -107.92892841138811, time: 24.717
agent0_energy_min, agent0_attention_min
[-50.   0.]
agent1_energy_min, agent1_attention_min
[-40.07   0.  ]
28200 50
steps: 1409950, episodes: 28200, mean episode reward: -106.22398392822387, time: 24.701
agent0_energy_min, agent0_attention_min
[-4.994e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-3.896e+01 -1.000e-02]
28300 50
steps: 1414950, episodes: 28300, mean episode reward: -83.46443503348316, time: 23.755
agent0_energy_min, agent0_attention_min
[-4.959e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-3.88e+01 -2.00e-02]
28400 50
steps: 1419950, episodes: 28400, mean episode reward: -85.32907886269463, time: 23.777
agent0_energy_min, agent0_attention_min
[-49.98   0.  ]
agent1_energy_min, agent1_attention_min
[-3.924e+01 -1.000e-02]
28500 50
steps: 1424950, episodes: 28500, mean episode reward: -79.41961046344895, time: 24.257
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-3.899e+01 -1.000e-02]
28600 50
steps: 1429950, episodes: 28600, mean episode reward: -79.04750291965289, time: 24.414
agent0_energy_min, agent0_attention_min
[-4.997e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-4.281e+01 -1.000e-02]
28700 50
steps: 1434950, episodes: 28700, mean episode reward: -89.1438070940628, time: 23.862
agent0_energy_min, agent0_attention_min
[-4.997e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-43.9   0. ]
28800 50
steps: 1439950, episodes: 28800, mean episode reward: -100.6328750616013, time: 23.497
agent0_energy_min, agent0_attention_min
[-40.61  -9.32]
agent1_energy_min, agent1_attention_min
[-44.04   0.  ]
28900 50
steps: 1444950, episodes: 28900, mean episode reward: -82.88217211186533, time: 24.316
agent0_energy_min, agent0_attention_min
[-48.68  -1.32]
agent1_energy_min, agent1_attention_min
[-4.388e+01 -2.000e-02]
29000 50
steps: 1449950, episodes: 29000, mean episode reward: -95.01383618687501, time: 24.17
agent0_energy_min, agent0_attention_min
[-45.13  -4.81]
agent1_energy_min, agent1_attention_min
[-39.58  -1.95]
29100 50
steps: 1454950, episodes: 29100, mean episode reward: -88.9062215620529, time: 24.987
agent0_energy_min, agent0_attention_min
[-45.93  -4.04]
agent1_energy_min, agent1_attention_min
[-40.9  -2.3]
29200 50
steps: 1459950, episodes: 29200, mean episode reward: -66.39434091580814, time: 23.414
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-45.82  -0.52]
29300 50
steps: 1464950, episodes: 29300, mean episode reward: -69.629969165336, time: 24.227
agent0_energy_min, agent0_attention_min
[-50.   0.]
agent1_energy_min, agent1_attention_min
[-46.42  -0.07]
29400 50
steps: 1469950, episodes: 29400, mean episode reward: -66.02282915486965, time: 23.727
agent0_energy_min, agent0_attention_min
[-4.996e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-48.71  -0.07]
29500 50
steps: 1474950, episodes: 29500, mean episode reward: -283.37032646997505, time: 23.936
agent0_energy_min, agent0_attention_min
[-50.   0.]
agent1_energy_min, agent1_attention_min
[-34.45  -8.99]
29600 50
steps: 1479950, episodes: 29600, mean episode reward: -140.5025807821862, time: 24.926
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-33.01  -1.68]
29700 50
steps: 1484950, episodes: 29700, mean episode reward: -72.99381210745508, time: 23.829
agent0_energy_min, agent0_attention_min
[-49.97   0.  ]
agent1_energy_min, agent1_attention_min
[-44.28  -0.99]
29800 50
steps: 1489950, episodes: 29800, mean episode reward: -102.17405164488582, time: 23.868
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-45.65  -1.32]
29900 50
steps: 1494950, episodes: 29900, mean episode reward: -87.08932018525306, time: 24.377
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-45.12  -0.82]
30000 50
steps: 1499950, episodes: 30000, mean episode reward: -84.62340872004408, time: 24.206
agent0_energy_min, agent0_attention_min
[-50.   0.]
agent1_energy_min, agent1_attention_min
[-43.75  -2.11]
30100 50
steps: 1504950, episodes: 30100, mean episode reward: -73.34632230191359, time: 24.554
agent0_energy_min, agent0_attention_min
[-4.998e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-47.08  -0.06]
30200 50
steps: 1509950, episodes: 30200, mean episode reward: -82.9612484679728, time: 24.203
agent0_energy_min, agent0_attention_min
[-4.999e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-47.44  -0.17]
30300 50
steps: 1514950, episodes: 30300, mean episode reward: -65.19737652604738, time: 23.805
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-48.44  -0.22]
30400 50
steps: 1519950, episodes: 30400, mean episode reward: -71.08364201308727, time: 24.037
agent0_energy_min, agent0_attention_min
[-49.98   0.  ]
agent1_energy_min, agent1_attention_min
[-48.01  -1.01]
30500 50
steps: 1524950, episodes: 30500, mean episode reward: -82.1333621886123, time: 24.176
agent0_energy_min, agent0_attention_min
[-4.999e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-47.97  -0.86]
30600 50
steps: 1529950, episodes: 30600, mean episode reward: -78.92242308822034, time: 24.615
agent0_energy_min, agent0_attention_min
[-4.997e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-46.97  -1.03]
30700 50
steps: 1534950, episodes: 30700, mean episode reward: -79.68968536316315, time: 23.781
agent0_energy_min, agent0_attention_min
[-49.98   0.  ]
agent1_energy_min, agent1_attention_min
[-47.    -1.14]
30800 50
steps: 1539950, episodes: 30800, mean episode reward: -66.47047171547374, time: 24.077
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-48.41  -0.55]
30900 50
steps: 1544950, episodes: 30900, mean episode reward: -71.4693673731545, time: 24.038
agent0_energy_min, agent0_attention_min
[-4.996e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-47.76  -1.08]
31000 50
steps: 1549950, episodes: 31000, mean episode reward: -82.99087130938467, time: 23.132
agent0_energy_min, agent0_attention_min
[-4.996e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-47.08  -1.19]
31100 50
steps: 1554950, episodes: 31100, mean episode reward: -90.22969923075343, time: 24.694
agent0_energy_min, agent0_attention_min
[-49.88   0.  ]
agent1_energy_min, agent1_attention_min
[-31.79  -0.05]
31200 50
steps: 1559950, episodes: 31200, mean episode reward: -111.37128507901816, time: 24.265
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-21.33  -0.11]
31300 50
steps: 1564950, episodes: 31300, mean episode reward: -75.88583703397018, time: 24.199
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-48.4  -0.2]
31400 50
steps: 1569950, episodes: 31400, mean episode reward: -75.21936834207966, time: 23.697
agent0_energy_min, agent0_attention_min
27500 50
steps: 1374950, episodes: 27500, mean episode reward: -85.57004520809464, time: 23.889
agent0_energy_min, agent0_attention_min
[-46.6   0. ]
agent1_energy_min, agent1_attention_min
[-24.72  -0.19]
27600 50
steps: 1379950, episodes: 27600, mean episode reward: -70.91989675580675, time: 24.36
agent0_energy_min, agent0_attention_min
[-4.444e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-24.14  -0.64]
27700 50
steps: 1384950, episodes: 27700, mean episode reward: -80.62155928477226, time: 23.668
agent0_energy_min, agent0_attention_min
[-4.482e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-22.41  -0.19]
27800 50
steps: 1389950, episodes: 27800, mean episode reward: -87.73085976296176, time: 24.172
agent0_energy_min, agent0_attention_min
[-4.5e+01 -1.0e-02]
agent1_energy_min, agent1_attention_min
[-21.67  -0.13]
27900 50
steps: 1394950, episodes: 27900, mean episode reward: -94.73233072970001, time: 23.868
agent0_energy_min, agent0_attention_min
[-46.52   0.  ]
agent1_energy_min, agent1_attention_min
[-22.41  -0.2 ]
28000 50
steps: 1399950, episodes: 28000, mean episode reward: -89.11117987888463, time: 23.612
agent0_energy_min, agent0_attention_min
[-49.15   0.  ]
agent1_energy_min, agent1_attention_min
[-24.62  -0.11]
28100 50
steps: 1404950, episodes: 28100, mean episode reward: -90.41045981326656, time: 24.528
agent0_energy_min, agent0_attention_min
[-4.826e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-22.43  -0.19]
28200 50
steps: 1409950, episodes: 28200, mean episode reward: -106.06149644656566, time: 23.891
agent0_energy_min, agent0_attention_min
[-49.37   0.  ]
agent1_energy_min, agent1_attention_min
[-21.16  -0.52]
28300 50
steps: 1414950, episodes: 28300, mean episode reward: -65.97195216256632, time: 23.694
agent0_energy_min, agent0_attention_min
[-45.74   0.  ]
agent1_energy_min, agent1_attention_min
[-21.54  -0.75]
28400 50
steps: 1419950, episodes: 28400, mean episode reward: -62.07691209891654, time: 23.493
agent0_energy_min, agent0_attention_min
[-4.243e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-20.18  -0.22]
28500 50
steps: 1424950, episodes: 28500, mean episode reward: -85.57352339173393, time: 23.722
agent0_energy_min, agent0_attention_min
[-44.12  -0.05]
agent1_energy_min, agent1_attention_min
[-21.12  -0.03]
28600 50
steps: 1429950, episodes: 28600, mean episode reward: -107.90350538370848, time: 24.668
agent0_energy_min, agent0_attention_min
[-4.808e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-20.77  -0.08]
28700 50
steps: 1434950, episodes: 28700, mean episode reward: -81.11458392415618, time: 24.181
agent0_energy_min, agent0_attention_min
[-43.12   0.  ]
agent1_energy_min, agent1_attention_min
[-18.92  -0.03]
28800 50
steps: 1439950, episodes: 28800, mean episode reward: -88.50803836223555, time: 23.828
agent0_energy_min, agent0_attention_min
[-3.422e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-2.46e+01 -2.00e-02]
28900 50
steps: 1444950, episodes: 28900, mean episode reward: -73.02577301520716, time: 23.825
agent0_energy_min, agent0_attention_min
[-45.19  -0.06]
agent1_energy_min, agent1_attention_min
[-25.78  -0.03]
29000 50
steps: 1449950, episodes: 29000, mean episode reward: -70.94256653676425, time: 23.464
agent0_energy_min, agent0_attention_min
[-4.309e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-19.59  -0.11]
29100 50
steps: 1454950, episodes: 29100, mean episode reward: -63.10123201354696, time: 24.078
agent0_energy_min, agent0_attention_min
[-3.768e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-20.91  -0.17]
29200 50
steps: 1459950, episodes: 29200, mean episode reward: -76.41679974326478, time: 23.844
agent0_energy_min, agent0_attention_min
[-37.29   0.  ]
agent1_energy_min, agent1_attention_min
[-20.6   -0.23]
29300 50
steps: 1464950, episodes: 29300, mean episode reward: -57.33253211346904, time: 23.479
agent0_energy_min, agent0_attention_min
[-40.88   0.  ]
agent1_energy_min, agent1_attention_min
[-17.7   -0.25]
29400 50
steps: 1469950, episodes: 29400, mean episode reward: -115.85139521567146, time: 23.679
agent0_energy_min, agent0_attention_min
[-45.66  -0.21]
agent1_energy_min, agent1_attention_min
[-11.26  -0.06]
29500 50
steps: 1474950, episodes: 29500, mean episode reward: -122.9459497175275, time: 23.729
agent0_energy_min, agent0_attention_min
[-45.24   0.  ]
agent1_energy_min, agent1_attention_min
[-13.87  -0.09]
29600 50
steps: 1479950, episodes: 29600, mean episode reward: -71.13152705150306, time: 23.864
agent0_energy_min, agent0_attention_min
[-4.291e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-20.32  -0.06]
29700 50
steps: 1484950, episodes: 29700, mean episode reward: -66.87934281128346, time: 23.833
agent0_energy_min, agent0_attention_min
[-4.707e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-18.89  -0.03]
29800 50
steps: 1489950, episodes: 29800, mean episode reward: -66.65541692860131, time: 24.42
agent0_energy_min, agent0_attention_min
[-4.315e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-21.63   0.  ]
29900 50
steps: 1494950, episodes: 29900, mean episode reward: -72.47238737472989, time: 24.294
agent0_energy_min, agent0_attention_min
[-45.88   0.  ]
agent1_energy_min, agent1_attention_min
[-2.109e+01 -2.000e-02]
30000 50
steps: 1499950, episodes: 30000, mean episode reward: -59.91397267466865, time: 24.089
agent0_energy_min, agent0_attention_min
[-42.3   -0.05]
agent1_energy_min, agent1_attention_min
[-22.03  -0.04]
30100 50
steps: 1504950, episodes: 30100, mean episode reward: -62.54077114382789, time: 23.903
agent0_energy_min, agent0_attention_min
[-41.68  -0.47]
agent1_energy_min, agent1_attention_min
[-1.922e+01 -1.000e-02]
30200 50
steps: 1509950, episodes: 30200, mean episode reward: -57.76153019562929, time: 23.695
agent0_energy_min, agent0_attention_min
[-44.93  -0.23]
agent1_energy_min, agent1_attention_min
[-21.33  -0.03]
30300 50
steps: 1514950, episodes: 30300, mean episode reward: -63.764921741082006, time: 23.691
agent0_energy_min, agent0_attention_min
[-4.754e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-2.313e+01 -1.000e-02]
30400 50
steps: 1519950, episodes: 30400, mean episode reward: -64.04321079391154, time: 23.929
agent0_energy_min, agent0_attention_min
[-41.55  -0.21]
agent1_energy_min, agent1_attention_min
[-21.17  -1.14]
30500 50
steps: 1524950, episodes: 30500, mean episode reward: -70.26325324742554, time: 23.964
agent0_energy_min, agent0_attention_min
[-4.349e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-24.76  -1.56]
30600 50
steps: 1529950, episodes: 30600, mean episode reward: -61.35563833574943, time: 24.461
agent0_energy_min, agent0_attention_min
[-44.14  -0.1 ]
agent1_energy_min, agent1_attention_min
[-24.11  -1.03]
30700 50
steps: 1534950, episodes: 30700, mean episode reward: -64.82073406361268, time: 23.56
agent0_energy_min, agent0_attention_min
[-40.58  -0.58]
agent1_energy_min, agent1_attention_min
[-22.51  -0.44]
30800 50
steps: 1539950, episodes: 30800, mean episode reward: -64.65072796584046, time: 27.559
agent0_energy_min, agent0_attention_min
[-41.06  -0.52]
agent1_energy_min, agent1_attention_min
[-17.48  -0.57]
30900 50
steps: 1544950, episodes: 30900, mean episode reward: -65.89410655477464, time: 23.465
agent0_energy_min, agent0_attention_min
[-41.2   -0.77]
agent1_energy_min, agent1_attention_min
[-18.73  -0.03]
31000 50
steps: 1549950, episodes: 31000, mean episode reward: -65.88924017381463, time: 23.718
agent0_energy_min, agent0_attention_min
[-40.16  -0.59]
agent1_energy_min, agent1_attention_min
[-1.834e+01 -1.000e-02]
31100 50
steps: 1554950, episodes: 31100, mean episode reward: -58.552579002804926, time: 24.651
agent0_energy_min, agent0_attention_min
[-43.31  -0.19]
agent1_energy_min, agent1_attention_min
[-15.44  -0.02]
31200 50
steps: 1559950, episodes: 31200, mean episode reward: -66.49003531803595, time: 23.987
agent0_energy_min, agent0_attention_min
[-46.51  -1.04]
agent1_energy_min, agent1_attention_min
[-18.46  -0.08]
31300 50
steps: 1564950, episodes: 31300, mean episode reward: -69.18343824911268, time: 23.893
agent0_energy_min, agent0_attention_min
[-39.82  -0.23]
agent0_energy_min, agent0_attention_min
[-48.63  -0.94]
agent1_energy_min, agent1_attention_min
[-47.8   0. ]
27800 50
steps: 1389950, episodes: 27800, mean episode reward: -62.06506129933031, time: 24.429
agent0_energy_min, agent0_attention_min
[-49.68  -0.15]
agent1_energy_min, agent1_attention_min
[-48.39  -0.07]
27900 50
steps: 1394950, episodes: 27900, mean episode reward: -93.68094772200456, time: 24.818
agent0_energy_min, agent0_attention_min
[-49.22  -0.05]
agent1_energy_min, agent1_attention_min
[-4.838e+01 -1.000e-02]
28000 50
steps: 1399950, episodes: 28000, mean episode reward: -147.31585319103783, time: 24.3
agent0_energy_min, agent0_attention_min
[-48.66  -0.27]
agent1_energy_min, agent1_attention_min
[-4.868e+01 -2.000e-02]
28100 50
steps: 1404950, episodes: 28100, mean episode reward: -72.16880768647238, time: 25.632
agent0_energy_min, agent0_attention_min
[-49.03  -0.54]
agent1_energy_min, agent1_attention_min
[-48.94   0.  ]
28200 50
steps: 1409950, episodes: 28200, mean episode reward: -46.652466476375906, time: 24.899
agent0_energy_min, agent0_attention_min
[-43.26  -1.45]
agent1_energy_min, agent1_attention_min
[-49.56   0.  ]
28300 50
steps: 1414950, episodes: 28300, mean episode reward: -48.832589211013854, time: 24.444
agent0_energy_min, agent0_attention_min
[-48.63  -1.21]
agent1_energy_min, agent1_attention_min
[-4.936e+01 -2.000e-02]
28400 50
steps: 1419950, episodes: 28400, mean episode reward: -46.08879635982988, time: 24.362
agent0_energy_min, agent0_attention_min
[-48.64  -1.09]
agent1_energy_min, agent1_attention_min
[-4.919e+01 -1.000e-02]
28500 50
steps: 1424950, episodes: 28500, mean episode reward: -43.32132658106144, time: 24.344
agent0_energy_min, agent0_attention_min
[-48.37  -1.4 ]
agent1_energy_min, agent1_attention_min
[-4.891e+01 -1.000e-02]
28600 50
steps: 1429950, episodes: 28600, mean episode reward: -52.245504710313, time: 24.752
agent0_energy_min, agent0_attention_min
[-48.66  -1.23]
agent1_energy_min, agent1_attention_min
[-4.867e+01 -2.000e-02]
28700 50
steps: 1434950, episodes: 28700, mean episode reward: -55.3532143634476, time: 24.782
agent0_energy_min, agent0_attention_min
[-40.94  -4.72]
agent1_energy_min, agent1_attention_min
[-4.885e+01 -1.000e-02]
28800 50
steps: 1439950, episodes: 28800, mean episode reward: -44.84565992222055, time: 24.082
agent0_energy_min, agent0_attention_min
[-41.96  -6.  ]
agent1_energy_min, agent1_attention_min
[-4.934e+01 -2.000e-02]
28900 50
steps: 1444950, episodes: 28900, mean episode reward: -53.15227713575188, time: 24.612
agent0_energy_min, agent0_attention_min
[-40.19  -8.57]
agent1_energy_min, agent1_attention_min
[-4.914e+01 -2.000e-02]
29000 50
steps: 1449950, episodes: 29000, mean episode reward: -46.560702831406154, time: 24.64
agent0_energy_min, agent0_attention_min
[-34.47  -4.75]
agent1_energy_min, agent1_attention_min
[-4.942e+01 -1.000e-02]
29100 50
steps: 1454950, episodes: 29100, mean episode reward: -52.839470128842116, time: 25.0
agent0_energy_min, agent0_attention_min
[-40.34  -6.75]
agent1_energy_min, agent1_attention_min
[-4.929e+01 -1.000e-02]
29200 50
steps: 1459950, episodes: 29200, mean episode reward: -61.67523103574868, time: 24.141
agent0_energy_min, agent0_attention_min
[-42.17  -7.63]
agent1_energy_min, agent1_attention_min
[-49.46   0.  ]
29300 50
steps: 1464950, episodes: 29300, mean episode reward: -52.55490285764918, time: 24.588
agent0_energy_min, agent0_attention_min
[-43.18  -6.78]
agent1_energy_min, agent1_attention_min
[-4.943e+01 -2.000e-02]
29400 50
steps: 1469950, episodes: 29400, mean episode reward: -64.86304356792151, time: 24.539
agent0_energy_min, agent0_attention_min
[-45.49  -4.44]
agent1_energy_min, agent1_attention_min
[-48.8   0. ]
29500 50
steps: 1474950, episodes: 29500, mean episode reward: -59.06887764438456, time: 24.471
agent0_energy_min, agent0_attention_min
[-45.25  -4.7 ]
agent1_energy_min, agent1_attention_min
[-4.892e+01 -2.000e-02]
29600 50
steps: 1479950, episodes: 29600, mean episode reward: -50.00524036697776, time: 25.201
agent0_energy_min, agent0_attention_min
[-47.61  -2.33]
agent1_energy_min, agent1_attention_min
[-4.655e+01 -1.000e-02]
29700 50
steps: 1484950, episodes: 29700, mean episode reward: -42.97954593744543, time: 24.604
agent0_energy_min, agent0_attention_min
[-46.2   -3.66]
agent1_energy_min, agent1_attention_min
[-4.524e+01 -1.000e-02]
29800 50
steps: 1489950, episodes: 29800, mean episode reward: -73.73368591763543, time: 24.093
agent0_energy_min, agent0_attention_min
[-46.33  -3.41]
agent1_energy_min, agent1_attention_min
[-3.871e+01 -2.000e-02]
29900 50
steps: 1494950, episodes: 29900, mean episode reward: -51.55053581672132, time: 24.696
agent0_energy_min, agent0_attention_min
[-46.68  -3.18]
agent1_energy_min, agent1_attention_min
[-41.99   0.  ]
30000 50
steps: 1499950, episodes: 30000, mean episode reward: -128.20119822353666, time: 24.788
agent0_energy_min, agent0_attention_min
[-45.55  -4.04]
agent1_energy_min, agent1_attention_min
[-4.421e+01 -1.000e-02]
30100 50
steps: 1504950, episodes: 30100, mean episode reward: -189.42699069816223, time: 25.295
agent0_energy_min, agent0_attention_min
[-48.04  -1.76]
agent1_energy_min, agent1_attention_min
[-48.96   0.  ]
30200 50
steps: 1509950, episodes: 30200, mean episode reward: -54.141388652639186, time: 24.646
agent0_energy_min, agent0_attention_min
[-46.33  -2.8 ]
agent1_energy_min, agent1_attention_min
[-4.835e+01 -1.000e-02]
30300 50
steps: 1514950, episodes: 30300, mean episode reward: -63.309568873869566, time: 24.681
agent0_energy_min, agent0_attention_min
[-49.08  -0.67]
agent1_energy_min, agent1_attention_min
[-4.389e+01 -2.000e-02]
30400 50
steps: 1519950, episodes: 30400, mean episode reward: -66.16811683264575, time: 24.497
agent0_energy_min, agent0_attention_min
[-49.5   -0.35]
agent1_energy_min, agent1_attention_min
[-4.061e+01 -2.000e-02]
30500 50
steps: 1524950, episodes: 30500, mean episode reward: -50.37809817646999, time: 24.171
agent0_energy_min, agent0_attention_min
[-49.63  -0.27]
agent1_energy_min, agent1_attention_min
[-4.115e+01 -1.000e-02]
30600 50
steps: 1529950, episodes: 30600, mean episode reward: -43.24029412924196, time: 24.457
agent0_energy_min, agent0_attention_min
[-49.42  -0.5 ]
agent1_energy_min, agent1_attention_min
[-3.968e+01 -2.000e-02]
30700 50
steps: 1534950, episodes: 30700, mean episode reward: -50.35937388200486, time: 24.093
agent0_energy_min, agent0_attention_min
[-49.71  -0.16]
agent1_energy_min, agent1_attention_min
[-4.204e+01 -4.000e-02]
30800 50
steps: 1539950, episodes: 30800, mean episode reward: -61.90242625380648, time: 24.933
agent0_energy_min, agent0_attention_min
[-49.54  -0.41]
agent1_energy_min, agent1_attention_min
[-4.093e+01 -1.000e-02]
30900 50
steps: 1544950, episodes: 30900, mean episode reward: -47.56429929687216, time: 24.286
agent0_energy_min, agent0_attention_min
[-49.42  -0.24]
agent1_energy_min, agent1_attention_min
[-4.148e+01 -2.000e-02]
31000 50
steps: 1549950, episodes: 31000, mean episode reward: -105.109217924624, time: 23.52
agent0_energy_min, agent0_attention_min
[-49.61  -0.27]
agent1_energy_min, agent1_attention_min
[-3.587e+01 -1.000e-02]
31100 50
steps: 1554950, episodes: 31100, mean episode reward: -135.9908988050425, time: 24.693
agent0_energy_min, agent0_attention_min
[-49.76  -0.19]
agent1_energy_min, agent1_attention_min
[-3.638e+01 -2.000e-02]
31200 50
steps: 1559950, episodes: 31200, mean episode reward: -55.920379363784534, time: 24.989
agent0_energy_min, agent0_attention_min
[-49.32  -0.59]
agent1_energy_min, agent1_attention_min
[-38.48  -0.07]
31300 50
steps: 1564950, episodes: 31300, mean episode reward: -56.90189800273875, time: 24.611
agent0_energy_min, agent0_attention_min
[-47.95  -1.91]
agent1_energy_min, agent1_attention_min
[-4.297e+01 -4.000e-02]
31400 50
steps: 1569950, episodes: 31400, mean episode reward: -56.172335518591645, time: 24.408
agent0_energy_min, agent0_attention_min
[-48.56  -1.35]
agent1_energy_min, agent1_attention_min
[-46.24  -0.42]
31500 50
steps: 1574950, episodes: 31500, mean episode reward: -70.52308052840831, time: 24.535
agent0_energy_min, agent0_attention_min
[-43.76  -5.95]
agent1_energy_min, agent1_attention_min
agent0_energy_min, agent0_attention_min
[-48.76  -0.92]
agent1_energy_min, agent1_attention_min
[-30.57 -19.38]
27900 50
steps: 1394950, episodes: 27900, mean episode reward: -39.97686029212652, time: 24.689
agent0_energy_min, agent0_attention_min
[-30.53 -16.5 ]
agent1_energy_min, agent1_attention_min
[-28.33 -21.47]
28000 50
steps: 1399950, episodes: 28000, mean episode reward: -48.456659163366005, time: 25.275
agent0_energy_min, agent0_attention_min
[-21.43 -27.89]
agent1_energy_min, agent1_attention_min
[-24.45 -25.35]
28100 50
steps: 1404950, episodes: 28100, mean episode reward: -60.49131317723107, time: 24.64
agent0_energy_min, agent0_attention_min
[-29.12 -20.32]
agent1_energy_min, agent1_attention_min
[-29.97 -19.7 ]
28200 50
steps: 1409950, episodes: 28200, mean episode reward: -54.39009155093909, time: 24.766
agent0_energy_min, agent0_attention_min
[-43.54  -5.91]
agent1_energy_min, agent1_attention_min
[-31.82 -14.09]
28300 50
steps: 1414950, episodes: 28300, mean episode reward: -78.20182166597621, time: 24.812
agent0_energy_min, agent0_attention_min
[-44.54  -5.2 ]
agent1_energy_min, agent1_attention_min
[-27.87 -11.99]
28400 50
steps: 1419950, episodes: 28400, mean episode reward: -105.0765740755748, time: 24.431
agent0_energy_min, agent0_attention_min
[-31.35 -18.21]
agent1_energy_min, agent1_attention_min
[-38.03  -6.62]
28500 50
steps: 1424950, episodes: 28500, mean episode reward: -90.25845390980581, time: 24.613
agent0_energy_min, agent0_attention_min
[-36.08 -13.26]
agent1_energy_min, agent1_attention_min
[-32.25 -15.86]
28600 50
steps: 1429950, episodes: 28600, mean episode reward: -72.73357712255665, time: 25.06
agent0_energy_min, agent0_attention_min
[-44.55  -4.69]
agent1_energy_min, agent1_attention_min
[-39.38  -7.32]
28700 50
steps: 1434950, episodes: 28700, mean episode reward: -139.19252875371444, time: 24.437
agent0_energy_min, agent0_attention_min
[-42.29  -2.36]
agent1_energy_min, agent1_attention_min
[-45.33  -2.73]
28800 50
steps: 1439950, episodes: 28800, mean episode reward: -58.57108864234576, time: 24.644
agent0_energy_min, agent0_attention_min
[-45.02  -1.74]
agent1_energy_min, agent1_attention_min
[-44.28  -2.82]
28900 50
steps: 1444950, episodes: 28900, mean episode reward: -40.68902228844852, time: 24.765
agent0_energy_min, agent0_attention_min
[-36.96  -0.74]
agent1_energy_min, agent1_attention_min
[-44.48  -4.95]
29000 50
steps: 1449950, episodes: 29000, mean episode reward: -84.50208477317068, time: 24.659
agent0_energy_min, agent0_attention_min
[-45.11  -1.01]
agent1_energy_min, agent1_attention_min
[-45.92  -3.95]
29100 50
steps: 1454950, episodes: 29100, mean episode reward: -50.60148727984887, time: 24.793
agent0_energy_min, agent0_attention_min
[-45.72  -0.74]
agent1_energy_min, agent1_attention_min
[-45.58  -4.39]
29200 50
steps: 1459950, episodes: 29200, mean episode reward: -45.261616155030225, time: 24.443
agent0_energy_min, agent0_attention_min
[-42.18  -0.61]
agent1_energy_min, agent1_attention_min
[-46.45  -3.5 ]
29300 50
steps: 1464950, episodes: 29300, mean episode reward: -41.78729604780721, time: 24.774
agent0_energy_min, agent0_attention_min
[-46.76  -0.61]
agent1_energy_min, agent1_attention_min
[-47.92  -2.02]
29400 50
steps: 1469950, episodes: 29400, mean episode reward: -47.579868669683094, time: 24.416
agent0_energy_min, agent0_attention_min
[-47.81  -0.91]
agent1_energy_min, agent1_attention_min
[-47.15  -2.81]
29500 50
steps: 1474950, episodes: 29500, mean episode reward: -364.68537608253956, time: 24.46
agent0_energy_min, agent0_attention_min
[-42.18  -0.8 ]
agent1_energy_min, agent1_attention_min
[-28.57 -21.34]
29600 50
steps: 1479950, episodes: 29600, mean episode reward: -320.21904034473476, time: 25.255
agent0_energy_min, agent0_attention_min
[-48.36  -0.6 ]
agent1_energy_min, agent1_attention_min
[-20.02 -29.79]
29700 50
steps: 1484950, episodes: 29700, mean episode reward: -105.31012663614106, time: 24.181
agent0_energy_min, agent0_attention_min
[-43.07  -1.27]
agent1_energy_min, agent1_attention_min
[-42.18  -7.36]
29800 50
steps: 1489950, episodes: 29800, mean episode reward: -82.97652212917636, time: 24.61
agent0_energy_min, agent0_attention_min
[-44.81  -2.15]
agent1_energy_min, agent1_attention_min
[-47.73  -2.18]
29900 50
steps: 1494950, episodes: 29900, mean episode reward: -62.402410984452665, time: 24.779
agent0_energy_min, agent0_attention_min
[-48.39  -0.56]
agent1_energy_min, agent1_attention_min
[-48.28  -1.53]
30000 50
steps: 1499950, episodes: 30000, mean episode reward: -56.39125962204882, time: 24.077
agent0_energy_min, agent0_attention_min
[-48.    -1.29]
agent1_energy_min, agent1_attention_min
[-48.25  -1.56]
30100 50
steps: 1504950, episodes: 30100, mean episode reward: -80.19805299643875, time: 24.747
agent0_energy_min, agent0_attention_min
[-46.6  -1. ]
agent1_energy_min, agent1_attention_min
[-49.43  -0.4 ]
30200 50
steps: 1509950, episodes: 30200, mean episode reward: -70.58356211866266, time: 24.226
agent0_energy_min, agent0_attention_min
[-47.82  -1.44]
agent1_energy_min, agent1_attention_min
[-48.77  -1.1 ]
30300 50
steps: 1514950, episodes: 30300, mean episode reward: -70.42632682975052, time: 24.632
agent0_energy_min, agent0_attention_min
[-42.58  -4.92]
agent1_energy_min, agent1_attention_min
[-48.02  -1.61]
30400 50
steps: 1519950, episodes: 30400, mean episode reward: -61.82543200056983, time: 24.406
agent0_energy_min, agent0_attention_min
[-32.36 -11.57]
agent1_energy_min, agent1_attention_min
[-46.95  -1.71]
30500 50
steps: 1524950, episodes: 30500, mean episode reward: -72.17767821392546, time: 24.814
agent0_energy_min, agent0_attention_min
[-37.84 -11.33]
agent1_energy_min, agent1_attention_min
[-35.45 -10.2 ]
30600 50
steps: 1529950, episodes: 30600, mean episode reward: -52.4690618429404, time: 25.34
agent0_energy_min, agent0_attention_min
[-43.42  -6.07]
agent1_energy_min, agent1_attention_min
[-28.46  -1.97]
30700 50
steps: 1534950, episodes: 30700, mean episode reward: -62.55846931099597, time: 24.607
agent0_energy_min, agent0_attention_min
[-42.   -7.5]
agent1_energy_min, agent1_attention_min
[-39.01  -1.25]
30800 50
steps: 1539950, episodes: 30800, mean episode reward: -65.74392359325297, time: 23.972
agent0_energy_min, agent0_attention_min
[-39.18 -10.49]
agent1_energy_min, agent1_attention_min
[-46.47  -2.64]
30900 50
steps: 1544950, episodes: 30900, mean episode reward: -46.623352049769736, time: 24.852
agent0_energy_min, agent0_attention_min
[-45.04  -2.48]
agent1_energy_min, agent1_attention_min
[-46.61  -0.28]
31000 50
steps: 1549950, episodes: 31000, mean episode reward: -54.9882678373889, time: 24.782
agent0_energy_min, agent0_attention_min
[-45.6   -1.96]
agent1_energy_min, agent1_attention_min
[-45.92  -1.16]
31100 50
steps: 1554950, episodes: 31100, mean episode reward: -52.698743946889564, time: 24.824
agent0_energy_min, agent0_attention_min
[-46.35  -1.96]
agent1_energy_min, agent1_attention_min
[-46.94  -2.37]
31200 50
steps: 1559950, episodes: 31200, mean episode reward: -48.424079439946354, time: 23.171
agent0_energy_min, agent0_attention_min
[-43.29  -1.42]
agent1_energy_min, agent1_attention_min
[-42.06  -2.23]
31300 50
steps: 1564950, episodes: 31300, mean episode reward: -83.8639502369231, time: 24.645
agent0_energy_min, agent0_attention_min
[-27.38  -3.51]
agent1_energy_min, agent1_attention_min
[-41.61  -6.71]
31400 50
steps: 1569950, episodes: 31400, mean episode reward: -117.86175643306996, time: 24.831
agent0_energy_min, agent0_attention_min
[-28.27  -4.11]
agent1_energy_min, agent1_attention_min
[-38.5   -8.58]
31500 50
steps: 1574950, episodes: 31500, mean episode reward: -75.90059874084791, time: 24.387
agent0_energy_min, agent0_attention_min
[-38.54  -3.93]
agent1_energy_min, agent1_attention_min
[-45.81  -2.32]
31600 50
steps: 1579950, episodes: 31600, mean episode reward: -43.91249916925163, time: 24.754
agent0_energy_min, agent0_attention_min
[-40.53  -6.99]
agent1_energy_min, agent1_attention_min
[-41.59  -0.43]
31700 50
steps: 1584950, episodes: 31700, mean episode reward: -61.30467267832594, time: 23.692
agent0_energy_min, agent0_attention_min
[-32.17  -8.28]
agent1_energy_min, agent1_attention_min
[-48.43  -0.95]
agent1_energy_min, agent1_attention_min
[-48.02  -0.45]
27600 50
steps: 1379950, episodes: 27600, mean episode reward: -67.1051320624014, time: 25.25
agent0_energy_min, agent0_attention_min
[-48.13  -1.06]
agent1_energy_min, agent1_attention_min
[-48.49  -0.66]
27700 50
steps: 1384950, episodes: 27700, mean episode reward: -91.46557243603844, time: 24.989
agent0_energy_min, agent0_attention_min
[-46.59  -2.25]
agent1_energy_min, agent1_attention_min
[-49.15  -0.37]
27800 50
steps: 1389950, episodes: 27800, mean episode reward: -55.9189775000526, time: 24.738
agent0_energy_min, agent0_attention_min
[-47.15  -2.17]
agent1_energy_min, agent1_attention_min
[-46.22  -1.02]
27900 50
steps: 1394950, episodes: 27900, mean episode reward: -69.80848555900329, time: 24.781
agent0_energy_min, agent0_attention_min
[-49.09  -0.42]
agent1_energy_min, agent1_attention_min
[-41.59  -0.72]
28000 50
steps: 1399950, episodes: 28000, mean episode reward: -57.98918792961148, time: 24.679
agent0_energy_min, agent0_attention_min
[-48.9   -0.42]
agent1_energy_min, agent1_attention_min
[-45.81  -1.67]
28100 50
steps: 1404950, episodes: 28100, mean episode reward: -77.92430343542333, time: 25.541
agent0_energy_min, agent0_attention_min
[-48.86  -0.59]
agent1_energy_min, agent1_attention_min
[-44.7   -1.72]
28200 50
steps: 1409950, episodes: 28200, mean episode reward: -55.390633381352984, time: 24.547
agent0_energy_min, agent0_attention_min
[-49.01  -0.49]
agent1_energy_min, agent1_attention_min
[-42.54  -1.08]
28300 50
steps: 1414950, episodes: 28300, mean episode reward: -54.89393649526569, time: 24.982
agent0_energy_min, agent0_attention_min
[-48.87  -0.48]
agent1_energy_min, agent1_attention_min
[-32.38  -0.93]
28400 50
steps: 1419950, episodes: 28400, mean episode reward: -69.93016693076065, time: 24.647
agent0_energy_min, agent0_attention_min
[-48.76  -0.81]
agent1_energy_min, agent1_attention_min
[-33.78  -1.51]
28500 50
steps: 1424950, episodes: 28500, mean episode reward: -51.41664599345621, time: 24.539
agent0_energy_min, agent0_attention_min
[-47.12  -0.84]
agent1_energy_min, agent1_attention_min
[-39.17  -2.63]
28600 50
steps: 1429950, episodes: 28600, mean episode reward: -46.319349084043445, time: 25.017
agent0_energy_min, agent0_attention_min
[-47.93  -0.92]
agent1_energy_min, agent1_attention_min
[-20.24 -17.89]
28700 50
steps: 1434950, episodes: 28700, mean episode reward: -91.38632477870334, time: 24.87
agent0_energy_min, agent0_attention_min
[-38.39 -10.62]
agent1_energy_min, agent1_attention_min
[-21.61 -23.53]
28800 50
steps: 1439950, episodes: 28800, mean episode reward: -89.12620884223385, time: 24.665
agent0_energy_min, agent0_attention_min
[-43.54  -5.75]
agent1_energy_min, agent1_attention_min
[-28.55 -19.31]
28900 50
steps: 1444950, episodes: 28900, mean episode reward: -75.65332166388258, time: 24.705
agent0_energy_min, agent0_attention_min
[-48.41  -0.51]
agent1_energy_min, agent1_attention_min
[-24.28 -23.4 ]
29000 50
steps: 1449950, episodes: 29000, mean episode reward: -129.3131218411343, time: 24.515
agent0_energy_min, agent0_attention_min
[-48.46  -0.31]
agent1_energy_min, agent1_attention_min
[-22.87 -22.25]
29100 50
steps: 1454950, episodes: 29100, mean episode reward: -65.76117837974716, time: 25.112
agent0_energy_min, agent0_attention_min
[-48.31  -0.36]
agent1_energy_min, agent1_attention_min
[-28.78 -19.29]
29200 50
steps: 1459950, episodes: 29200, mean episode reward: -56.82540337829691, time: 24.668
agent0_energy_min, agent0_attention_min
[-48.45  -0.5 ]
agent1_energy_min, agent1_attention_min
[-33.1  -13.67]
29300 50
steps: 1464950, episodes: 29300, mean episode reward: -79.88177909199766, time: 23.919
agent0_energy_min, agent0_attention_min
[-47.52  -0.31]
agent1_energy_min, agent1_attention_min
[-24.68 -22.35]
29400 50
steps: 1469950, episodes: 29400, mean episode reward: -48.85045049344049, time: 23.924
agent0_energy_min, agent0_attention_min
[-49.05  -0.26]
agent1_energy_min, agent1_attention_min
[-21.82 -24.66]
29500 50
steps: 1474950, episodes: 29500, mean episode reward: -65.19190695911935, time: 24.444
agent0_energy_min, agent0_attention_min
[-48.69  -0.41]
agent1_energy_min, agent1_attention_min
[-15.95 -28.31]
29600 50
steps: 1479950, episodes: 29600, mean episode reward: -66.0769183304826, time: 24.553
agent0_energy_min, agent0_attention_min
[-47.64  -0.44]
agent1_energy_min, agent1_attention_min
[-26.46 -21.06]
29700 50
steps: 1484950, episodes: 29700, mean episode reward: -77.13233474276686, time: 23.983
agent0_energy_min, agent0_attention_min
[-44.87  -0.81]
agent1_energy_min, agent1_attention_min
[-34.    -5.96]
29800 50
steps: 1489950, episodes: 29800, mean episode reward: -107.86486334290184, time: 24.166
agent0_energy_min, agent0_attention_min
[-41.5   -0.45]
agent1_energy_min, agent1_attention_min
[-30.14 -11.96]
29900 50
steps: 1494950, episodes: 29900, mean episode reward: -222.9776881554731, time: 24.847
agent0_energy_min, agent0_attention_min
[-36.15  -0.1 ]
agent1_energy_min, agent1_attention_min
[-11.32 -36.58]
30000 50
steps: 1499950, episodes: 30000, mean episode reward: -247.9969426062745, time: 24.53
agent0_energy_min, agent0_attention_min
[-36.41  -0.25]
agent1_energy_min, agent1_attention_min
[-17.01 -28.57]
30100 50
steps: 1504950, episodes: 30100, mean episode reward: -66.67969101180068, time: 24.643
agent0_energy_min, agent0_attention_min
[-47.27  -0.73]
agent1_energy_min, agent1_attention_min
[-27.76 -13.02]
30200 50
steps: 1509950, episodes: 30200, mean episode reward: -50.661172237064974, time: 24.136
agent0_energy_min, agent0_attention_min
[-49.41  -0.21]
agent1_energy_min, agent1_attention_min
[-31.04  -8.75]
30300 50
steps: 1514950, episodes: 30300, mean episode reward: -61.47126111547479, time: 24.011
agent0_energy_min, agent0_attention_min
[-49.44  -0.21]
agent1_energy_min, agent1_attention_min
[-38.19  -5.23]
30400 50
steps: 1519950, episodes: 30400, mean episode reward: -74.9609098369937, time: 24.262
agent0_energy_min, agent0_attention_min
[-49.63  -0.1 ]
agent1_energy_min, agent1_attention_min
[-35.74  -5.96]
30500 50
steps: 1524950, episodes: 30500, mean episode reward: -74.26333606966827, time: 25.912
agent0_energy_min, agent0_attention_min
[-49.53  -0.19]
agent1_energy_min, agent1_attention_min
[-40.25  -3.93]
30600 50
steps: 1529950, episodes: 30600, mean episode reward: -94.20488832019375, time: 25.175
agent0_energy_min, agent0_attention_min
[-49.12  -0.12]
agent1_energy_min, agent1_attention_min
[-47.7   -0.85]
30700 50
steps: 1534950, episodes: 30700, mean episode reward: -78.81629185462337, time: 24.427
agent0_energy_min, agent0_attention_min
[-48.44  -0.32]
agent1_energy_min, agent1_attention_min
[-48.99  -0.27]
30800 50
steps: 1539950, episodes: 30800, mean episode reward: -71.07429302349512, time: 23.821
agent0_energy_min, agent0_attention_min
[-49.46  -0.09]
agent1_energy_min, agent1_attention_min
[-40.49  -1.45]
30900 50
steps: 1544950, episodes: 30900, mean episode reward: -57.08418999785642, time: 27.981
agent0_energy_min, agent0_attention_min
[-48.74  -0.37]
agent1_energy_min, agent1_attention_min
[-41.33  -1.21]
31000 50
steps: 1549950, episodes: 31000, mean episode reward: -79.95925318054233, time: 23.447
agent0_energy_min, agent0_attention_min
[-49.04  -0.18]
agent1_energy_min, agent1_attention_min
[-40.19  -1.76]
31100 50
steps: 1554950, episodes: 31100, mean episode reward: -64.54684005133795, time: 24.879
agent0_energy_min, agent0_attention_min
[-48.28  -0.28]
agent1_energy_min, agent1_attention_min
[-36.52  -3.03]
31200 50
steps: 1559950, episodes: 31200, mean episode reward: -114.43502720097487, time: 24.024
agent0_energy_min, agent0_attention_min
[-47.76  -0.22]
agent1_energy_min, agent1_attention_min
[-31.7   -6.51]
31300 50
steps: 1564950, episodes: 31300, mean episode reward: -117.28609388051962, time: 24.201
agent0_energy_min, agent0_attention_min
[-4.811e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-22.22 -14.15]
31400 50
steps: 1569950, episodes: 31400, mean episode reward: -79.0181652116209, time: 24.571
agent0_energy_min, agent0_attention_min
[-48.82  -0.15]
agent1_energy_min, agent1_attention_min
[-37.43  -5.29]
31500
agent0_energy_min, agent0_attention_min
[-20.83 -29.13]
agent1_energy_min, agent1_attention_min
[-33.99 -14.25]
28000 50
steps: 1399950, episodes: 28000, mean episode reward: -52.898330419343466, time: 24.289
agent0_energy_min, agent0_attention_min
[-17.21 -32.75]
agent1_energy_min, agent1_attention_min
[-32.65 -15.28]
28100 50
steps: 1404950, episodes: 28100, mean episode reward: -74.98133084423588, time: 24.592
agent0_energy_min, agent0_attention_min
[-19.05 -30.92]
agent1_energy_min, agent1_attention_min
[-33.85 -12.2 ]
28200 50
steps: 1409950, episodes: 28200, mean episode reward: -59.294441524112706, time: 24.777
agent0_energy_min, agent0_attention_min
[-19.76 -30.18]
agent1_energy_min, agent1_attention_min
[-34.54 -12.51]
28300 50
steps: 1414950, episodes: 28300, mean episode reward: -66.02658330250117, time: 24.354
agent0_energy_min, agent0_attention_min
[-18.08 -31.71]
agent1_energy_min, agent1_attention_min
[-35.47 -13.89]
28400 50
steps: 1419950, episodes: 28400, mean episode reward: -66.32987058587389, time: 24.269
agent0_energy_min, agent0_attention_min
[-19.04 -30.91]
agent1_energy_min, agent1_attention_min
[-31.46 -17.94]
28500 50
steps: 1424950, episodes: 28500, mean episode reward: -70.78962502501359, time: 24.381
agent0_energy_min, agent0_attention_min
[-17.38 -32.53]
agent1_energy_min, agent1_attention_min
[-30.37 -19.39]
28600 50
steps: 1429950, episodes: 28600, mean episode reward: -61.66815786568895, time: 25.365
agent0_energy_min, agent0_attention_min
[-18.32 -31.63]
agent1_energy_min, agent1_attention_min
[-33.62 -15.7 ]
28700 50
steps: 1434950, episodes: 28700, mean episode reward: -75.18975090421816, time: 24.558
agent0_energy_min, agent0_attention_min
[-19.88 -30.08]
agent1_energy_min, agent1_attention_min
[-42.22  -7.2 ]
28800 50
steps: 1439950, episodes: 28800, mean episode reward: -65.63574859967318, time: 23.993
agent0_energy_min, agent0_attention_min
[-17.96 -31.98]
agent1_energy_min, agent1_attention_min
[-43.7   -5.95]
28900 50
steps: 1444950, episodes: 28900, mean episode reward: -76.31891552914152, time: 24.262
agent0_energy_min, agent0_attention_min
[-15.97 -34.  ]
agent1_energy_min, agent1_attention_min
[-42.7   -6.37]
29000 50
steps: 1449950, episodes: 29000, mean episode reward: -74.86187668058629, time: 24.148
agent0_energy_min, agent0_attention_min
[-16.17 -33.8 ]
agent1_energy_min, agent1_attention_min
[-43.41  -6.22]
29100 50
steps: 1454950, episodes: 29100, mean episode reward: -70.96717438704663, time: 24.808
agent0_energy_min, agent0_attention_min
[-15.37 -33.85]
agent1_energy_min, agent1_attention_min
[-37.65 -11.78]
29200 50
steps: 1459950, episodes: 29200, mean episode reward: -71.32112883734693, time: 24.492
agent0_energy_min, agent0_attention_min
[-13.99 -35.27]
agent1_energy_min, agent1_attention_min
[-36.7  -12.74]
29300 50
steps: 1464950, episodes: 29300, mean episode reward: -67.2947843930203, time: 24.459
agent0_energy_min, agent0_attention_min
[-13.52 -36.44]
agent1_energy_min, agent1_attention_min
[-36.85 -12.71]
29400 50
steps: 1469950, episodes: 29400, mean episode reward: -70.09490648960129, time: 24.419
agent0_energy_min, agent0_attention_min
[-15.38 -34.55]
agent1_energy_min, agent1_attention_min
[-35.47 -14.21]
29500 50
steps: 1474950, episodes: 29500, mean episode reward: -63.54746842819544, time: 24.096
agent0_energy_min, agent0_attention_min
[-11.58 -38.41]
agent1_energy_min, agent1_attention_min
[-41.41  -8.  ]
29600 50
steps: 1479950, episodes: 29600, mean episode reward: -71.55408370686591, time: 25.144
agent0_energy_min, agent0_attention_min
[-15.86 -34.09]
agent1_energy_min, agent1_attention_min
[-42.08  -7.13]
29700 50
steps: 1484950, episodes: 29700, mean episode reward: -67.05769005724459, time: 28.089
agent0_energy_min, agent0_attention_min
[-13.84 -36.09]
agent1_energy_min, agent1_attention_min
[-36.03 -12.9 ]
29800 50
steps: 1489950, episodes: 29800, mean episode reward: -139.57489933348126, time: 24.299
agent0_energy_min, agent0_attention_min
[-18.68 -31.22]
agent1_energy_min, agent1_attention_min
[-35.49 -11.45]
29900 50
steps: 1494950, episodes: 29900, mean episode reward: -78.57149403610046, time: 24.91
agent0_energy_min, agent0_attention_min
[-12.83 -35.85]
agent1_energy_min, agent1_attention_min
[-27.16 -21.5 ]
30000 50
steps: 1499950, episodes: 30000, mean episode reward: -107.4792557031425, time: 23.96
agent0_energy_min, agent0_attention_min
[ -9.97 -35.38]
agent1_energy_min, agent1_attention_min
[-34.73 -14.61]
30100 50
steps: 1504950, episodes: 30100, mean episode reward: -135.35205447076345, time: 25.255
agent0_energy_min, agent0_attention_min
[-10.06 -27.66]
agent1_energy_min, agent1_attention_min
[-37.36 -12.21]
30200 50
steps: 1509950, episodes: 30200, mean episode reward: -155.31900063564345, time: 24.622
agent0_energy_min, agent0_attention_min
[-13.11 -30.3 ]
agent1_energy_min, agent1_attention_min
[-37.23 -11.65]
30300 50
steps: 1514950, episodes: 30300, mean episode reward: -104.80311892891955, time: 25.13
agent0_energy_min, agent0_attention_min
[-16.35 -33.46]
agent1_energy_min, agent1_attention_min
[-33.09 -16.49]
30400 50
steps: 1519950, episodes: 30400, mean episode reward: -68.34572592929052, time: 24.558
agent0_energy_min, agent0_attention_min
[-15.71 -34.25]
agent1_energy_min, agent1_attention_min
[-35.3  -11.18]
30500 50
steps: 1524950, episodes: 30500, mean episode reward: -59.404410913878735, time: 24.009
agent0_energy_min, agent0_attention_min
[ -9.8  -40.13]
agent1_energy_min, agent1_attention_min
[-34.17 -10.34]
30600 50
steps: 1529950, episodes: 30600, mean episode reward: -122.98380806839164, time: 25.007
agent0_energy_min, agent0_attention_min
[-11.3  -38.64]
agent1_energy_min, agent1_attention_min
[-24.5  -18.38]
30700 50
steps: 1534950, episodes: 30700, mean episode reward: -92.44653648933408, time: 26.164
agent0_energy_min, agent0_attention_min
[-18.9 -31. ]
agent1_energy_min, agent1_attention_min
[-27.52 -18.69]
30800 50
steps: 1539950, episodes: 30800, mean episode reward: -72.28186218496715, time: 24.503
agent0_energy_min, agent0_attention_min
[-11.52 -38.43]
agent1_energy_min, agent1_attention_min
[-26.95 -19.79]
30900 50
steps: 1544950, episodes: 30900, mean episode reward: -62.62939050381712, time: 24.084
agent0_energy_min, agent0_attention_min
[-12.17 -37.77]
agent1_energy_min, agent1_attention_min
[-31.84 -17.28]
31000 50
steps: 1549950, episodes: 31000, mean episode reward: -61.74902715258307, time: 24.198
agent0_energy_min, agent0_attention_min
[ -8.42 -41.46]
agent1_energy_min, agent1_attention_min
[-30.32 -14.29]
31100 50
steps: 1554950, episodes: 31100, mean episode reward: -67.48071586726374, time: 25.831
agent0_energy_min, agent0_attention_min
[-12.08 -37.75]
agent1_energy_min, agent1_attention_min
[-26.12 -18.6 ]
31200 50
steps: 1559950, episodes: 31200, mean episode reward: -64.25691693874441, time: 23.257
agent0_energy_min, agent0_attention_min
[-13.57 -35.55]
agent1_energy_min, agent1_attention_min
[-31.38 -16.12]
31300 50
steps: 1564950, episodes: 31300, mean episode reward: -60.7099761520109, time: 24.808
agent0_energy_min, agent0_attention_min
[-12.4  -36.27]
agent1_energy_min, agent1_attention_min
[-29.04 -17.83]
31400 50
steps: 1569950, episodes: 31400, mean episode reward: -62.95766057594727, time: 24.397
agent0_energy_min, agent0_attention_min
[ -8.81 -40.22]
agent1_energy_min, agent1_attention_min
[-34.02 -13.59]
31500 50
steps: 1574950, episodes: 31500, mean episode reward: -67.27241275149237, time: 24.554
agent0_energy_min, agent0_attention_min
[-19.82 -29.67]
agent1_energy_min, agent1_attention_min
[-40.9  -5.7]
31600 50
steps: 1579950, episodes: 31600, mean episode reward: -64.88706648793269, time: 25.043
agent0_energy_min, agent0_attention_min
[-10.67 -38.7 ]
agent1_energy_min, agent1_attention_min
[-37.08  -7.75]
31700 50
steps: 1584950, episodes: 31700, mean episode reward: -69.7839045824417, time: 24.347
agent0_energy_min, agent0_attention_min
[ -9.73 -40.  ]
agent1_energy_min, agent1_attention_min
[-31.16 -13.51]
31800 50
steps: 1589950, episodes: 31800, mean episode reward: -67.1954265152153, time: 24.536
agent0_energy_min, agent0_attention_min
[-14.72 -34.95]
agent1_energy_min, agent1_attention_min
agent0_energy_min, agent0_attention_min
[-33.91 -13.19]
agent1_energy_min, agent1_attention_min
[-21.29 -22.99]
28000 50
steps: 1399950, episodes: 28000, mean episode reward: -65.82452599190908, time: 24.274
agent0_energy_min, agent0_attention_min
[-22.24 -17.05]
agent1_energy_min, agent1_attention_min
[-23.61 -20.54]
28100 50
steps: 1404950, episodes: 28100, mean episode reward: -59.198089421591284, time: 25.307
agent0_energy_min, agent0_attention_min
[-20.85 -21.2 ]
agent1_energy_min, agent1_attention_min
[-23.67 -18.52]
28200 50
steps: 1409950, episodes: 28200, mean episode reward: -96.59248286290092, time: 24.574
agent0_energy_min, agent0_attention_min
[-23.27 -14.63]
agent1_energy_min, agent1_attention_min
[-21.27 -27.27]
28300 50
steps: 1414950, episodes: 28300, mean episode reward: -103.65685135767977, time: 23.873
agent0_energy_min, agent0_attention_min
[-27.7   -8.67]
agent1_energy_min, agent1_attention_min
[-17.3  -26.74]
28400 50
steps: 1419950, episodes: 28400, mean episode reward: -76.17306740124303, time: 24.141
agent0_energy_min, agent0_attention_min
[-34.5   -9.37]
agent1_energy_min, agent1_attention_min
[-20.35 -27.49]
28500 50
steps: 1424950, episodes: 28500, mean episode reward: -75.019277911433, time: 24.399
agent0_energy_min, agent0_attention_min
[-35.25  -9.66]
agent1_energy_min, agent1_attention_min
[-20.93 -26.39]
28600 50
steps: 1429950, episodes: 28600, mean episode reward: -71.90739885491605, time: 24.895
agent0_energy_min, agent0_attention_min
[-27.71  -7.78]
agent1_energy_min, agent1_attention_min
[-18.19 -28.3 ]
28700 50
steps: 1434950, episodes: 28700, mean episode reward: -100.99361606846233, time: 24.759
agent0_energy_min, agent0_attention_min
[-32.68 -13.79]
agent1_energy_min, agent1_attention_min
[-19.57 -28.58]
28800 50
steps: 1439950, episodes: 28800, mean episode reward: -86.68459842607284, time: 24.396
agent0_energy_min, agent0_attention_min
[-35.19  -9.59]
agent1_energy_min, agent1_attention_min
[-23.09 -24.9 ]
28900 50
steps: 1444950, episodes: 28900, mean episode reward: -77.90773945544464, time: 24.55
agent0_energy_min, agent0_attention_min
[-28.24  -6.32]
agent1_energy_min, agent1_attention_min
[-21.11 -26.12]
29000 50
steps: 1449950, episodes: 29000, mean episode reward: -67.5665473598302, time: 24.543
agent0_energy_min, agent0_attention_min
[-29.69  -0.37]
agent1_energy_min, agent1_attention_min
[-23.3  -22.56]
29100 50
steps: 1454950, episodes: 29100, mean episode reward: -62.61048660226682, time: 25.402
agent0_energy_min, agent0_attention_min
[-30.07  -1.1 ]
agent1_energy_min, agent1_attention_min
[-22.89 -25.76]
29200 50
steps: 1459950, episodes: 29200, mean episode reward: -53.62597777350461, time: 24.671
agent0_energy_min, agent0_attention_min
[-34.55  -3.04]
agent1_energy_min, agent1_attention_min
[-18.08 -28.49]
29300 50
steps: 1464950, episodes: 29300, mean episode reward: -57.72125817722746, time: 24.417
agent0_energy_min, agent0_attention_min
[-28.72  -5.17]
agent1_energy_min, agent1_attention_min
[-21.36 -20.82]
29400 50
steps: 1469950, episodes: 29400, mean episode reward: -69.39003215747704, time: 24.333
agent0_energy_min, agent0_attention_min
[-31.05  -0.88]
agent1_energy_min, agent1_attention_min
[-20.09 -24.01]
29500 50
steps: 1474950, episodes: 29500, mean episode reward: -76.98446079953197, time: 23.717
agent0_energy_min, agent0_attention_min
[-23.46  -2.89]
agent1_energy_min, agent1_attention_min
[-23.87 -24.2 ]
29600 50
steps: 1479950, episodes: 29600, mean episode reward: -68.4836839522132, time: 24.639
agent0_energy_min, agent0_attention_min
[-24.86  -1.01]
agent1_energy_min, agent1_attention_min
[-27.35 -22.22]
29700 50
steps: 1484950, episodes: 29700, mean episode reward: -68.69701595718783, time: 24.557
agent0_energy_min, agent0_attention_min
[-39.63  -2.64]
agent1_energy_min, agent1_attention_min
[-22.2  -24.04]
29800 50
steps: 1489950, episodes: 29800, mean episode reward: -61.97607245613557, time: 24.603
agent0_energy_min, agent0_attention_min
[-35.51  -6.4 ]
agent1_energy_min, agent1_attention_min
[-20.14 -29.8 ]
29900 50
steps: 1494950, episodes: 29900, mean episode reward: -71.69403836213796, time: 24.026
agent0_energy_min, agent0_attention_min
[-32.06  -2.95]
agent1_energy_min, agent1_attention_min
[-25.47 -24.42]
30000 50
steps: 1499950, episodes: 30000, mean episode reward: -99.47084934316445, time: 24.585
agent0_energy_min, agent0_attention_min
[-29.46  -0.28]
agent1_energy_min, agent1_attention_min
[-24.79 -24.68]
30100 50
steps: 1504950, episodes: 30100, mean episode reward: -183.60841268492402, time: 25.31
agent0_energy_min, agent0_attention_min
[-28.05  -0.57]
agent1_energy_min, agent1_attention_min
[-23.6  -23.95]
30200 50
steps: 1509950, episodes: 30200, mean episode reward: -61.68425196658183, time: 25.11
agent0_energy_min, agent0_attention_min
[-29.59  -0.78]
agent1_energy_min, agent1_attention_min
[-22.08 -23.24]
30300 50
steps: 1514950, episodes: 30300, mean episode reward: -63.55490181500978, time: 24.349
agent0_energy_min, agent0_attention_min
[-26.62  -2.51]
agent1_energy_min, agent1_attention_min
[-28.12 -18.29]
30400 50
steps: 1519950, episodes: 30400, mean episode reward: -60.55833777709576, time: 24.606
agent0_energy_min, agent0_attention_min
[-25.18  -3.21]
agent1_energy_min, agent1_attention_min
[-29.66 -18.02]
30500 50
steps: 1524950, episodes: 30500, mean episode reward: -65.06561469014065, time: 24.052
agent0_energy_min, agent0_attention_min
[-27.33  -1.69]
agent1_energy_min, agent1_attention_min
[-27.61 -21.47]
30600 50
steps: 1529950, episodes: 30600, mean episode reward: -63.70929712261839, time: 25.027
agent0_energy_min, agent0_attention_min
[-28.27  -5.3 ]
agent1_energy_min, agent1_attention_min
[-31.71 -17.21]
30700 50
steps: 1534950, episodes: 30700, mean episode reward: -63.7706922124154, time: 24.571
agent0_energy_min, agent0_attention_min
[-25.01  -6.9 ]
agent1_energy_min, agent1_attention_min
[-23.92 -25.83]
30800 50
steps: 1539950, episodes: 30800, mean episode reward: -92.85611103745907, time: 24.231
agent0_energy_min, agent0_attention_min
[-34.31  -1.83]
agent1_energy_min, agent1_attention_min
[-26.08 -21.95]
30900 50
steps: 1544950, episodes: 30900, mean episode reward: -138.52731403408544, time: 24.385
agent0_energy_min, agent0_attention_min
[-23.43  -1.46]
agent1_energy_min, agent1_attention_min
[-24.14 -18.52]
31000 50
steps: 1549950, episodes: 31000, mean episode reward: -133.17081851831009, time: 24.8
agent0_energy_min, agent0_attention_min
[-29.63  -1.87]
agent1_energy_min, agent1_attention_min
[-29.03 -15.59]
31100 50
steps: 1554950, episodes: 31100, mean episode reward: -63.609915668669515, time: 24.031
agent0_energy_min, agent0_attention_min
[-22.55  -2.2 ]
agent1_energy_min, agent1_attention_min
[-26.69 -20.95]
31200 50
steps: 1559950, episodes: 31200, mean episode reward: -79.20558485478489, time: 24.353
agent0_energy_min, agent0_attention_min
[-18.27  -1.06]
agent1_energy_min, agent1_attention_min
[-27.76 -20.94]
31300 50
steps: 1564950, episodes: 31300, mean episode reward: -93.37614608240243, time: 24.59
agent0_energy_min, agent0_attention_min
[-22.28  -2.27]
agent1_energy_min, agent1_attention_min
[-22.63 -25.11]
31400 50
steps: 1569950, episodes: 31400, mean episode reward: -69.42452770562721, time: 24.617
agent0_energy_min, agent0_attention_min
[-27.    -4.94]
agent1_energy_min, agent1_attention_min
[-26.68 -21.12]
31500 50
steps: 1574950, episodes: 31500, mean episode reward: -97.17161699134458, time: 24.667
agent0_energy_min, agent0_attention_min
[-23.39  -5.09]
agent1_energy_min, agent1_attention_min
[-26.64 -20.61]
31600 50
steps: 1579950, episodes: 31600, mean episode reward: -128.55055773559016, time: 24.882
agent0_energy_min, agent0_attention_min
[-24.18  -6.84]
agent1_energy_min, agent1_attention_min
[-25.21 -22.54]
31700 50
steps: 1584950, episodes: 31700, mean episode reward: -99.658746505281, time: 24.4
agent0_energy_min, agent0_attention_min
[-23.64  -5.14]
agent1_energy_min, agent1_attention_min
[-25.34 -22.85]
31800 50
steps: 1589950, episodes: 31800, mean episode reward: -78.96531503982517, time: 24.944
agent0_energy_min, agent0_attention_min
[-22.97  -1.75]
agent1_energy_min, agent1_attention_min
[-35.65  -0.05]
27800 50
steps: 1389950, episodes: 27800, mean episode reward: -107.61890308136755, time: 24.545
agent0_energy_min, agent0_attention_min
[-1.746e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
27900 50
steps: 1394950, episodes: 27900, mean episode reward: -117.68571362280974, time: 24.982
agent0_energy_min, agent0_attention_min
[-17.55  -0.02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
28000 50
steps: 1399950, episodes: 28000, mean episode reward: -194.2755754242059, time: 24.199
agent0_energy_min, agent0_attention_min
[-17.81   0.  ]
agent1_energy_min, agent1_attention_min
[-0.02 -0.05]
28100 50
steps: 1404950, episodes: 28100, mean episode reward: -147.69847209111413, time: 25.178
agent0_energy_min, agent0_attention_min
[-1.791e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.05]
28200 50
steps: 1409950, episodes: 28200, mean episode reward: -110.68013656349747, time: 24.666
agent0_energy_min, agent0_attention_min
[-1.995e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.02 -0.04]
28300 50
steps: 1414950, episodes: 28300, mean episode reward: -97.761897256145, time: 24.776
agent0_energy_min, agent0_attention_min
[-2.285e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.04 -0.09]
28400 50
steps: 1419950, episodes: 28400, mean episode reward: -90.69244254574707, time: 24.512
agent0_energy_min, agent0_attention_min
[-22.9   -0.04]
agent1_energy_min, agent1_attention_min
[-0.03 -0.02]
28500 50
steps: 1424950, episodes: 28500, mean episode reward: -119.82634626733208, time: 24.7
agent0_energy_min, agent0_attention_min
[-2.316e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.01 -0.03]
28600 50
steps: 1429950, episodes: 28600, mean episode reward: -104.11727984156349, time: 25.582
agent0_energy_min, agent0_attention_min
[-20.9   -0.03]
agent1_energy_min, agent1_attention_min
[ 0.   -7.12]
28700 50
steps: 1434950, episodes: 28700, mean episode reward: -127.14638061239113, time: 24.505
agent0_energy_min, agent0_attention_min
[-16.88  -0.03]
agent1_energy_min, agent1_attention_min
[-3.000e-02 -3.082e+01]
28800 50
steps: 1439950, episodes: 28800, mean episode reward: -343.12012610505803, time: 24.898
agent0_energy_min, agent0_attention_min
[-2.206e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-1.000e-02 -1.759e+01]
28900 50
steps: 1444950, episodes: 28900, mean episode reward: -213.39161891006768, time: 25.1
agent0_energy_min, agent0_attention_min
[-19.43   0.  ]
agent1_energy_min, agent1_attention_min
[-0.08 -0.39]
29000 50
steps: 1449950, episodes: 29000, mean episode reward: -102.76049022617006, time: 24.435
agent0_energy_min, agent0_attention_min
[-21.25  -0.04]
agent1_energy_min, agent1_attention_min
[ 0.   -0.01]
29100 50
steps: 1454950, episodes: 29100, mean episode reward: -109.2245889777412, time: 24.987
agent0_energy_min, agent0_attention_min
[-19.22  -0.04]
agent1_energy_min, agent1_attention_min
[ 0.   -0.04]
29200 50
steps: 1459950, episodes: 29200, mean episode reward: -97.63017276099006, time: 24.324
agent0_energy_min, agent0_attention_min
[-2.108e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[ 0.   -0.06]
29300 50
steps: 1464950, episodes: 29300, mean episode reward: -107.42932371279193, time: 24.775
agent0_energy_min, agent0_attention_min
[-2.139e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.08 -0.03]
29400 50
steps: 1469950, episodes: 29400, mean episode reward: -89.25871689686961, time: 24.418
agent0_energy_min, agent0_attention_min
[-2.197e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.4  -0.02]
29500 50
steps: 1474950, episodes: 29500, mean episode reward: -92.41091352751867, time: 24.32
agent0_energy_min, agent0_attention_min
[-19.49  -0.04]
agent1_energy_min, agent1_attention_min
[-3.11 -0.07]
29600 50
steps: 1479950, episodes: 29600, mean episode reward: -151.1349814943991, time: 25.114
agent0_energy_min, agent0_attention_min
[-18.89  -0.03]
agent1_energy_min, agent1_attention_min
[-22.11  -0.1 ]
29700 50
steps: 1484950, episodes: 29700, mean episode reward: -198.50282791989, time: 24.254
agent0_energy_min, agent0_attention_min
[-1.979e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-36.22  -0.47]
29800 50
steps: 1489950, episodes: 29800, mean episode reward: -207.74401587140932, time: 25.024
agent0_energy_min, agent0_attention_min
[-22.96  -0.04]
agent1_energy_min, agent1_attention_min
[-27.96  -0.89]
29900 50
steps: 1494950, episodes: 29900, mean episode reward: -213.88692055039053, time: 24.532
agent0_energy_min, agent0_attention_min
[-22.75  -0.04]
agent1_energy_min, agent1_attention_min
[-20.14  -0.77]
30000 50
steps: 1499950, episodes: 30000, mean episode reward: -131.63419966902106, time: 24.515
agent0_energy_min, agent0_attention_min
[-18.96  -0.02]
agent1_energy_min, agent1_attention_min
[-8.92 -0.56]
30100 50
steps: 1504950, episodes: 30100, mean episode reward: -111.95205254907346, time: 24.406
agent0_energy_min, agent0_attention_min
[-17.74  -0.04]
agent1_energy_min, agent1_attention_min
[-2.7  -0.03]
30200 50
steps: 1509950, episodes: 30200, mean episode reward: -106.65241467642448, time: 24.516
agent0_energy_min, agent0_attention_min
[-17.57  -0.08]
agent1_energy_min, agent1_attention_min
[-1.72 -0.04]
30300 50
steps: 1514950, episodes: 30300, mean episode reward: -94.75052955442821, time: 24.749
agent0_energy_min, agent0_attention_min
[-18.18  -0.7 ]
agent1_energy_min, agent1_attention_min
[-0.4  -0.06]
30400 50
steps: 1519950, episodes: 30400, mean episode reward: -104.43948854023485, time: 24.659
agent0_energy_min, agent0_attention_min
[-20.26  -1.34]
agent1_energy_min, agent1_attention_min
[-0.21 -0.11]
30500 50
steps: 1524950, episodes: 30500, mean episode reward: -86.589180689429, time: 24.619
agent0_energy_min, agent0_attention_min
[-22.08  -0.78]
agent1_energy_min, agent1_attention_min
[-0.34 -0.47]
30600 50
steps: 1529950, episodes: 30600, mean episode reward: -101.81844284543781, time: 24.611
agent0_energy_min, agent0_attention_min
[-22.86  -0.26]
agent1_energy_min, agent1_attention_min
[-0.66 -0.1 ]
30700 50
steps: 1534950, episodes: 30700, mean episode reward: -83.35526211309997, time: 24.9
agent0_energy_min, agent0_attention_min
[-1.806e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.13 -0.18]
30800 50
steps: 1539950, episodes: 30800, mean episode reward: -92.18553754708928, time: 23.375
agent0_energy_min, agent0_attention_min
[-16.86  -0.04]
agent1_energy_min, agent1_attention_min
[-0.58 -0.49]
30900 50
steps: 1544950, episodes: 30900, mean episode reward: -109.18148629011142, time: 24.95
agent0_energy_min, agent0_attention_min
[-17.58  -0.03]
agent1_energy_min, agent1_attention_min
[-0.17 -0.11]
31000 50
steps: 1549950, episodes: 31000, mean episode reward: -113.76454610453573, time: 24.299
agent0_energy_min, agent0_attention_min
[-19.05  -0.06]
agent1_energy_min, agent1_attention_min
[-0.47 -0.78]
31100 50
steps: 1554950, episodes: 31100, mean episode reward: -155.17503494217746, time: 25.417
agent0_energy_min, agent0_attention_min
[-1.578e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.16 -0.68]
31200 50
steps: 1559950, episodes: 31200, mean episode reward: -106.22383901583126, time: 24.592
agent0_energy_min, agent0_attention_min
[-1.566e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.42 -1.87]
31300 50
steps: 1564950, episodes: 31300, mean episode reward: -121.58337332868685, time: 24.061
agent0_energy_min, agent0_attention_min
[-19.19  -0.02]
agent1_energy_min, agent1_attention_min
[-0.44 -0.66]
31400 50
steps: 1569950, episodes: 31400, mean episode reward: -134.8159929590814, time: 24.482
agent0_energy_min, agent0_attention_min
[-24.46  -0.03]
agent1_energy_min, agent1_attention_min
[-0.64 -0.41]
31500 50
steps: 1574950, episodes: 31500, mean episode reward: -157.37206888882736, time: 25.209
agent0_energy_min, agent0_attention_min
[-21.38  -0.53]
agent1_energy_min, agent1_attention_min
[-1.56 -2.07]
31600 50
steps: 1579950, episodes: 31600, mean episode reward: -114.66698996837268, time: 24.944
agent0_energy_min, agent0_attention_min
[-21.12  -1.85]
agent1_energy_min, agent1_attention_min
[-2.04 -1.54]
agent0_energy_min, agent0_attention_min
[-21.6   -4.97]
agent1_energy_min, agent1_attention_min
[ -2.33 -47.63]
28000 50
steps: 1399950, episodes: 28000, mean episode reward: -65.09577151628123, time: 24.833
agent0_energy_min, agent0_attention_min
[-19.8   -2.85]
agent1_energy_min, agent1_attention_min
[ -2.72 -47.26]
28100 50
steps: 1404950, episodes: 28100, mean episode reward: -62.98261301625757, time: 25.726
agent0_energy_min, agent0_attention_min
[-22.58  -3.75]
agent1_energy_min, agent1_attention_min
[ -3.33 -46.6 ]
28200 50
steps: 1409950, episodes: 28200, mean episode reward: -72.40487253672319, time: 24.315
agent0_energy_min, agent0_attention_min
[-22.27  -4.52]
agent1_energy_min, agent1_attention_min
[ -2.83 -47.17]
28300 50
steps: 1414950, episodes: 28300, mean episode reward: -51.77470136744407, time: 24.639
agent0_energy_min, agent0_attention_min
[-18.35  -4.62]
agent1_energy_min, agent1_attention_min
[ -4.46 -45.53]
28400 50
steps: 1419950, episodes: 28400, mean episode reward: -53.150121603355366, time: 24.585
agent0_energy_min, agent0_attention_min
[-20.84  -2.92]
agent1_energy_min, agent1_attention_min
[ -1.88 -48.11]
28500 50
steps: 1424950, episodes: 28500, mean episode reward: -59.197165646691744, time: 24.584
agent0_energy_min, agent0_attention_min
[-17.95  -5.56]
agent1_energy_min, agent1_attention_min
[ -2.04 -47.93]
28600 50
steps: 1429950, episodes: 28600, mean episode reward: -64.44815280655624, time: 25.085
agent0_energy_min, agent0_attention_min
[-21.33  -3.36]
agent1_energy_min, agent1_attention_min
[ -2.66 -47.31]
28700 50
steps: 1434950, episodes: 28700, mean episode reward: -46.894176456913385, time: 24.463
agent0_energy_min, agent0_attention_min
[-18.5   -2.96]
agent1_energy_min, agent1_attention_min
[ -3.55 -46.43]
28800 50
steps: 1439950, episodes: 28800, mean episode reward: -58.27414555810767, time: 25.002
agent0_energy_min, agent0_attention_min
[-18.21  -4.56]
agent1_energy_min, agent1_attention_min
[ -4.9  -45.06]
28900 50
steps: 1444950, episodes: 28900, mean episode reward: -54.05063021483596, time: 24.735
agent0_energy_min, agent0_attention_min
[-15.96  -7.27]
agent1_energy_min, agent1_attention_min
[ -3.18 -46.81]
29000 50
steps: 1449950, episodes: 29000, mean episode reward: -52.88021346880156, time: 24.718
agent0_energy_min, agent0_attention_min
[-18.58  -9.79]
agent1_energy_min, agent1_attention_min
[ -5.99 -43.98]
29100 50
steps: 1454950, episodes: 29100, mean episode reward: -60.82604100935159, time: 25.582
agent0_energy_min, agent0_attention_min
[-15.89  -8.81]
agent1_energy_min, agent1_attention_min
[ -3.28 -46.68]
29200 50
steps: 1459950, episodes: 29200, mean episode reward: -52.71088067808614, time: 24.738
agent0_energy_min, agent0_attention_min
[-15.83  -7.6 ]
agent1_energy_min, agent1_attention_min
[ -5.48 -44.37]
29300 50
steps: 1464950, episodes: 29300, mean episode reward: -58.90128641539652, time: 24.409
agent0_energy_min, agent0_attention_min
[-15.35  -9.54]
agent1_energy_min, agent1_attention_min
[ -4.71 -45.15]
29400 50
steps: 1469950, episodes: 29400, mean episode reward: -62.337540608545176, time: 24.323
agent0_energy_min, agent0_attention_min
[-14.38  -9.94]
agent1_energy_min, agent1_attention_min
[ -5.98 -43.89]
29500 50
steps: 1474950, episodes: 29500, mean episode reward: -57.867162492980626, time: 24.947
agent0_energy_min, agent0_attention_min
[-18.06  -7.52]
agent1_energy_min, agent1_attention_min
[ -6.58 -43.37]
29600 50
steps: 1479950, episodes: 29600, mean episode reward: -79.73602486704871, time: 25.201
agent0_energy_min, agent0_attention_min
[-12.46 -10.63]
agent1_energy_min, agent1_attention_min
[ -5.34 -44.64]
29700 50
steps: 1484950, episodes: 29700, mean episode reward: -68.64832922839793, time: 24.546
agent0_energy_min, agent0_attention_min
[-18.93  -7.21]
agent1_energy_min, agent1_attention_min
[ -6.4  -43.53]
29800 50
steps: 1489950, episodes: 29800, mean episode reward: -67.66179985235824, time: 24.827
agent0_energy_min, agent0_attention_min
[-18.45  -8.81]
agent1_energy_min, agent1_attention_min
[ -5.49 -44.46]
29900 50
steps: 1494950, episodes: 29900, mean episode reward: -50.66042658475077, time: 24.763
agent0_energy_min, agent0_attention_min
[-16.6   -6.83]
agent1_energy_min, agent1_attention_min
[ -6.62 -43.36]
30000 50
steps: 1499950, episodes: 30000, mean episode reward: -53.5693072130168, time: 24.499
agent0_energy_min, agent0_attention_min
[-18.31  -4.36]
agent1_energy_min, agent1_attention_min
[ -5.3  -44.68]
30100 50
steps: 1504950, episodes: 30100, mean episode reward: -52.53451558792968, time: 25.073
agent0_energy_min, agent0_attention_min
[-17.31  -4.1 ]
agent1_energy_min, agent1_attention_min
[ -6.23 -43.67]
30200 50
steps: 1509950, episodes: 30200, mean episode reward: -57.79652515338889, time: 24.817
agent0_energy_min, agent0_attention_min
[-17.8   -7.46]
agent1_energy_min, agent1_attention_min
[ -6.99 -42.97]
30300 50
steps: 1514950, episodes: 30300, mean episode reward: -67.173600518335, time: 24.089
agent0_energy_min, agent0_attention_min
[-17.89  -3.44]
agent1_energy_min, agent1_attention_min
[ -8.01 -41.84]
30400 50
steps: 1519950, episodes: 30400, mean episode reward: -62.10155706429401, time: 24.35
agent0_energy_min, agent0_attention_min
[-20.51  -2.6 ]
agent1_energy_min, agent1_attention_min
[ -7.57 -42.38]
30500 50
steps: 1524950, episodes: 30500, mean episode reward: -54.17175459830062, time: 24.846
agent0_energy_min, agent0_attention_min
[-18.76  -3.16]
agent1_energy_min, agent1_attention_min
[ -5.23 -44.71]
30600 50
steps: 1529950, episodes: 30600, mean episode reward: -59.223808413835535, time: 24.922
agent0_energy_min, agent0_attention_min
[-22.05  -3.18]
agent1_energy_min, agent1_attention_min
[ -8.53 -41.36]
30700 50
steps: 1534950, episodes: 30700, mean episode reward: -77.99613511789785, time: 24.796
agent0_energy_min, agent0_attention_min
[-17.42  -4.83]
agent1_energy_min, agent1_attention_min
[-10.62 -39.29]
30800 50
steps: 1539950, episodes: 30800, mean episode reward: -62.97745493492508, time: 24.691
agent0_energy_min, agent0_attention_min
[-17.91  -4.84]
agent1_energy_min, agent1_attention_min
[ -8.74 -41.04]
30900 50
steps: 1544950, episodes: 30900, mean episode reward: -66.64846423214952, time: 28.041
agent0_energy_min, agent0_attention_min
[-18.52  -3.2 ]
agent1_energy_min, agent1_attention_min
[-11.24 -38.36]
31000 50
steps: 1549950, episodes: 31000, mean episode reward: -57.458495088709725, time: 24.606
agent0_energy_min, agent0_attention_min
[-14.44  -3.23]
agent1_energy_min, agent1_attention_min
[ -8.58 -40.7 ]
31100 50
steps: 1554950, episodes: 31100, mean episode reward: -53.05208003003969, time: 25.006
agent0_energy_min, agent0_attention_min
[-16.97  -2.88]
agent1_energy_min, agent1_attention_min
[-11.86 -37.88]
31200 50
steps: 1559950, episodes: 31200, mean episode reward: -66.6015525816293, time: 24.648
agent0_energy_min, agent0_attention_min
[-18.03  -2.76]
agent1_energy_min, agent1_attention_min
[-11.62 -38.  ]
31300 50
steps: 1564950, episodes: 31300, mean episode reward: -60.54641937815064, time: 24.931
agent0_energy_min, agent0_attention_min
[-19.8   -1.57]
agent1_energy_min, agent1_attention_min
[ -8.9  -40.57]
31400 50
steps: 1569950, episodes: 31400, mean episode reward: -53.39125438754931, time: 24.719
agent0_energy_min, agent0_attention_min
[-19.57  -1.13]
agent1_energy_min, agent1_attention_min
[ -8.2  -41.66]
31500 50
steps: 1574950, episodes: 31500, mean episode reward: -57.32469818663642, time: 24.393
agent0_energy_min, agent0_attention_min
[-17.66  -1.63]
agent1_energy_min, agent1_attention_min
[ -8.09 -41.1 ]
31600 50
steps: 1579950, episodes: 31600, mean episode reward: -69.18184554196152, time: 25.291
agent0_energy_min, agent0_attention_min
[-17.85  -2.04]
agent1_energy_min, agent1_attention_min
[-10.82 -38.54]
31700 50
steps: 1584950, episodes: 31700, mean episode reward: -81.98638945793151, time: 24.524
agent0_energy_min, agent0_attention_min
[-17.35  -2.19]
agent1_energy_min, agent1_attention_min
[-10.37 -39.34]
31800 50
steps: 1589950, episodes: 31800, mean episode reward: -66.49807615006485, time: 24.713
agent0_energy_min, agent0_attention_min
[-17.69  -1.7 ]
agent1_energy_min, agent1_attention_min
[-4.997e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-48.17  -0.18]
31500 50
steps: 1574950, episodes: 31500, mean episode reward: -127.88243780947174, time: 23.846
agent0_energy_min, agent0_attention_min
[-46.47  -3.47]
agent1_energy_min, agent1_attention_min
[-28.7  -17.79]
31600 50
steps: 1579950, episodes: 31600, mean episode reward: -96.37544637702348, time: 23.833
agent0_energy_min, agent0_attention_min
[-49.    -0.99]
agent1_energy_min, agent1_attention_min
[-31.83 -14.41]
31700 50
steps: 1584950, episodes: 31700, mean episode reward: -87.3073626145426, time: 24.051
agent0_energy_min, agent0_attention_min
[-48.04  -1.94]
agent1_energy_min, agent1_attention_min
[-40.11  -6.17]
31800 50
steps: 1589950, episodes: 31800, mean episode reward: -82.79038076826599, time: 24.057
agent0_energy_min, agent0_attention_min
[-47.45  -2.48]
agent1_energy_min, agent1_attention_min
[-48.77  -0.2 ]
31900 50
steps: 1594950, episodes: 31900, mean episode reward: -72.90456885473073, time: 24.005
agent0_energy_min, agent0_attention_min
[-49.5   -0.49]
agent1_energy_min, agent1_attention_min
[-48.99  -0.2 ]
32000 50
steps: 1599950, episodes: 32000, mean episode reward: -64.10877375168852, time: 23.748
agent0_energy_min, agent0_attention_min
[-49.97   0.  ]
agent1_energy_min, agent1_attention_min
[-49.35  -0.08]
32100 50
steps: 1604950, episodes: 32100, mean episode reward: -73.875909479752, time: 24.367
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-49.38  -0.13]
32200 50
steps: 1609950, episodes: 32200, mean episode reward: -82.67223756955842, time: 23.674
agent0_energy_min, agent0_attention_min
[-4.998e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-48.11  -1.3 ]
32300 50
steps: 1614950, episodes: 32300, mean episode reward: -68.31967374173624, time: 23.609
agent0_energy_min, agent0_attention_min
[-4.995e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-48.34  -1.16]
32400 50
steps: 1619950, episodes: 32400, mean episode reward: -81.232713751991, time: 23.972
agent0_energy_min, agent0_attention_min
[-4.995e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-49.19  -0.39]
32500 50
steps: 1624950, episodes: 32500, mean episode reward: -61.702440827602295, time: 24.22
agent0_energy_min, agent0_attention_min
[-49.98   0.  ]
agent1_energy_min, agent1_attention_min
[-47.5   -1.47]
32600 50
steps: 1629950, episodes: 32600, mean episode reward: -61.40511739184153, time: 24.16
agent0_energy_min, agent0_attention_min
[-49.97   0.  ]
agent1_energy_min, agent1_attention_min
[-49.13  -0.46]
32700 50
steps: 1634950, episodes: 32700, mean episode reward: -70.259255653754, time: 24.239
agent0_energy_min, agent0_attention_min
[-4.996e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-49.41  -0.36]
32800 50
steps: 1639950, episodes: 32800, mean episode reward: -68.66782930995878, time: 23.877
agent0_energy_min, agent0_attention_min
[-49.98   0.  ]
agent1_energy_min, agent1_attention_min
[-49.03  -0.66]
32900 50
steps: 1644950, episodes: 32900, mean episode reward: -84.67995742483427, time: 23.943
agent0_energy_min, agent0_attention_min
[-4.998e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-49.34  -0.39]
33000 50
steps: 1649950, episodes: 33000, mean episode reward: -92.65949662650205, time: 24.01
agent0_energy_min, agent0_attention_min
[-4.951e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-48.65  -1.01]
33100 50
steps: 1654950, episodes: 33100, mean episode reward: -75.28135180629425, time: 24.706
agent0_energy_min, agent0_attention_min
[-49.16   0.  ]
agent1_energy_min, agent1_attention_min
[-49.67   0.  ]
33200 50
steps: 1659950, episodes: 33200, mean episode reward: -77.95690209412916, time: 24.118
agent0_energy_min, agent0_attention_min
[-4.975e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-4.98e+01 -1.00e-02]
33300 50
steps: 1664950, episodes: 33300, mean episode reward: -69.02214720552429, time: 24.083
agent0_energy_min, agent0_attention_min
[-4.971e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-49.48  -0.26]
33400 50
steps: 1669950, episodes: 33400, mean episode reward: -69.74556467694059, time: 24.355
agent0_energy_min, agent0_attention_min
[-4.996e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-49.48  -0.27]
33500 50
steps: 1674950, episodes: 33500, mean episode reward: -67.73935985025791, time: 24.13
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-4.968e+01 -2.000e-02]
33600 50
steps: 1679950, episodes: 33600, mean episode reward: -63.51153194855144, time: 24.722
agent0_energy_min, agent0_attention_min
[-4.998e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-4.992e+01 -1.000e-02]
33700 50
steps: 1684950, episodes: 33700, mean episode reward: -61.18778686882923, time: 23.75
agent0_energy_min, agent0_attention_min
[-4.998e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-4.988e+01 -1.000e-02]
33800 50
steps: 1689950, episodes: 33800, mean episode reward: -70.4129244580517, time: 23.788
agent0_energy_min, agent0_attention_min
[-4.998e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-4.983e+01 -1.000e-02]
33900 50
steps: 1694950, episodes: 33900, mean episode reward: -63.86804366724402, time: 24.36
agent0_energy_min, agent0_attention_min
[-4.997e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-49.79   0.  ]
34000 50
steps: 1699950, episodes: 34000, mean episode reward: -61.03702817862304, time: 24.066
agent0_energy_min, agent0_attention_min
[-4.996e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-49.81   0.  ]
34100 50
steps: 1704950, episodes: 34100, mean episode reward: -62.52518739998374, time: 24.593
agent0_energy_min, agent0_attention_min
[-4.997e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-4.973e+01 -3.000e-02]
34200 50
steps: 1709950, episodes: 34200, mean episode reward: -59.35965260004904, time: 23.83
agent0_energy_min, agent0_attention_min
[-49.96   0.  ]
agent1_energy_min, agent1_attention_min
[-4.98e+01 -1.00e-02]
34300 50
steps: 1714950, episodes: 34300, mean episode reward: -70.76925128089955, time: 24.143
agent0_energy_min, agent0_attention_min
[-4.998e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-4.963e+01 -3.000e-02]
34400 50
steps: 1719950, episodes: 34400, mean episode reward: -62.27707005546697, time: 24.272
agent0_energy_min, agent0_attention_min
[-4.995e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-4.969e+01 -2.000e-02]
34500 50
steps: 1724950, episodes: 34500, mean episode reward: -62.10720319100298, time: 24.296
agent0_energy_min, agent0_attention_min
[-4.995e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-4.922e+01 -1.000e-02]
34600 50
steps: 1729950, episodes: 34600, mean episode reward: -84.42829674052399, time: 25.388
agent0_energy_min, agent0_attention_min
[-4.996e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-49.08  -0.09]
34700 50
steps: 1734950, episodes: 34700, mean episode reward: -82.63864743046668, time: 23.728
agent0_energy_min, agent0_attention_min
[-4.999e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-49.27  -0.26]
34800 50
steps: 1739950, episodes: 34800, mean episode reward: -92.30178493204353, time: 24.27
agent0_energy_min, agent0_attention_min
[-4.998e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-49.44  -0.07]
34900 50
steps: 1744950, episodes: 34900, mean episode reward: -110.38365796754734, time: 24.395
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-49.12  -0.14]
35000 50
steps: 1749950, episodes: 35000, mean episode reward: -90.39544121989931, time: 24.343
agent0_energy_min, agent0_attention_min
[-50.   0.]
agent1_energy_min, agent1_attention_min
[-48.65  -0.84]
35100 50
steps: 1754950, episodes: 35100, mean episode reward: -93.8361577168311, time: 24.7
agent0_energy_min, agent0_attention_min
[-49.97   0.  ]
agent1_energy_min, agent1_attention_min
[-49.21  -0.38]
35200 50
steps: 1759950, episodes: 35200, mean episode reward: -73.66814501033949, time: 23.678
agent0_energy_min, agent0_attention_min
[-49.78  -0.22]
agent1_energy_min, agent1_attention_min

agent1_energy_min, agent1_attention_min
[-22.22  -0.67]
31400 50
steps: 1569950, episodes: 31400, mean episode reward: -59.9417765788856, time: 23.79
agent0_energy_min, agent0_attention_min
[-35.03  -0.14]
agent1_energy_min, agent1_attention_min
[-17.35  -0.47]
31500 50
steps: 1574950, episodes: 31500, mean episode reward: -57.90036925262043, time: 23.546
agent0_energy_min, agent0_attention_min
[-4.489e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-15.83  -0.04]
31600 50
steps: 1579950, episodes: 31600, mean episode reward: -73.40686684214882, time: 24.514
agent0_energy_min, agent0_attention_min
[-4.341e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-19.33  -0.03]
31700 50
steps: 1584950, episodes: 31700, mean episode reward: -62.935503759503646, time: 23.84
agent0_energy_min, agent0_attention_min
[-40.22  -0.13]
agent1_energy_min, agent1_attention_min
[-19.04   0.  ]
31800 50
steps: 1589950, episodes: 31800, mean episode reward: -67.44075599605162, time: 23.658
agent0_energy_min, agent0_attention_min
[-40.25  -0.85]
agent1_energy_min, agent1_attention_min
[-2.177e+01 -1.000e-02]
31900 50
steps: 1594950, episodes: 31900, mean episode reward: -73.1794987150163, time: 23.918
agent0_energy_min, agent0_attention_min
[-47.21  -0.27]
agent1_energy_min, agent1_attention_min
[-23.23  -0.03]
32000 50
steps: 1599950, episodes: 32000, mean episode reward: -67.3429584574296, time: 24.04
agent0_energy_min, agent0_attention_min
[-49.89  -0.05]
agent1_energy_min, agent1_attention_min
[-2.454e+01 -2.000e-02]
32100 50
steps: 1604950, episodes: 32100, mean episode reward: -70.5750766479578, time: 24.127
agent0_energy_min, agent0_attention_min
[-45.38  -0.54]
agent1_energy_min, agent1_attention_min
[-2.153e+01 -1.000e-02]
32200 50
steps: 1609950, episodes: 32200, mean episode reward: -76.3198313429727, time: 23.918
agent0_energy_min, agent0_attention_min
[-44.04  -0.56]
agent1_energy_min, agent1_attention_min
[-18.31  -0.03]
32300 50
steps: 1614950, episodes: 32300, mean episode reward: -98.02116601754224, time: 24.31
agent0_energy_min, agent0_attention_min
[-44.44  -0.09]
agent1_energy_min, agent1_attention_min
[-18.51  -0.02]
32400 50
steps: 1619950, episodes: 32400, mean episode reward: -113.71071941502491, time: 23.947
agent0_energy_min, agent0_attention_min
[-43.01  -0.05]
agent1_energy_min, agent1_attention_min
[-2.098e+01 -1.000e-02]
32500 50
steps: 1624950, episodes: 32500, mean episode reward: -103.47376971458937, time: 23.872
agent0_energy_min, agent0_attention_min
[-43.44  -0.09]
agent1_energy_min, agent1_attention_min
[-1.973e+01 -1.000e-02]
32600 50
steps: 1629950, episodes: 32600, mean episode reward: -77.80541555207301, time: 24.701
agent0_energy_min, agent0_attention_min
[-43.49  -0.27]
agent1_energy_min, agent1_attention_min
[-17.8   -0.02]
32700 50
steps: 1634950, episodes: 32700, mean episode reward: -73.34132450594012, time: 23.806
agent0_energy_min, agent0_attention_min
[-41.58  -0.13]
agent1_energy_min, agent1_attention_min
[-24.61  -0.03]
32800 50
steps: 1639950, episodes: 32800, mean episode reward: -65.74620920636302, time: 24.175
agent0_energy_min, agent0_attention_min
[-41.33  -0.24]
agent1_energy_min, agent1_attention_min
[-17.37  -0.02]
32900 50
steps: 1644950, episodes: 32900, mean episode reward: -60.35376206687128, time: 24.038
agent0_energy_min, agent0_attention_min
[-42.24  -0.18]
agent1_energy_min, agent1_attention_min
[-18.59  -0.08]
33000 50
steps: 1649950, episodes: 33000, mean episode reward: -69.08512780742666, time: 24.878
agent0_energy_min, agent0_attention_min
[-40.64  -0.92]
agent1_energy_min, agent1_attention_min
[-16.8   -0.58]
33100 50
steps: 1654950, episodes: 33100, mean episode reward: -74.23879816519482, time: 24.555
agent0_energy_min, agent0_attention_min
[-4.079e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-20.72  -0.42]
33200 50
steps: 1659950, episodes: 33200, mean episode reward: -65.1302421942246, time: 24.521
agent0_energy_min, agent0_attention_min
[-43.95  -0.15]
agent1_energy_min, agent1_attention_min
[-17.42  -0.23]
33300 50
steps: 1664950, episodes: 33300, mean episode reward: -67.93161421535928, time: 24.566
agent0_energy_min, agent0_attention_min
[-40.08  -0.52]
agent1_energy_min, agent1_attention_min
[-19.17   0.  ]
33400 50
steps: 1669950, episodes: 33400, mean episode reward: -69.30971771598024, time: 23.957
agent0_energy_min, agent0_attention_min
[-42.24  -0.32]
agent1_energy_min, agent1_attention_min
[-19.7   -0.07]
33500 50
steps: 1674950, episodes: 33500, mean episode reward: -74.07010875775195, time: 24.06
agent0_energy_min, agent0_attention_min
[-48.3   -0.15]
agent1_energy_min, agent1_attention_min
[-18.97  -0.52]
33600 50
steps: 1679950, episodes: 33600, mean episode reward: -62.29930820556644, time: 24.009
agent0_energy_min, agent0_attention_min
[-48.07  -0.37]
agent1_energy_min, agent1_attention_min
[-18.06  -0.27]
33700 50
steps: 1684950, episodes: 33700, mean episode reward: -75.8320193451314, time: 24.223
agent0_energy_min, agent0_attention_min
[-42.51  -6.17]
agent1_energy_min, agent1_attention_min
[-20.82  -0.2 ]
33800 50
steps: 1689950, episodes: 33800, mean episode reward: -67.00499197776216, time: 23.998
agent0_energy_min, agent0_attention_min
[-46.77  -0.77]
agent1_energy_min, agent1_attention_min
[-19.11  -0.26]
33900 50
steps: 1694950, episodes: 33900, mean episode reward: -71.57568322201182, time: 24.141
agent0_energy_min, agent0_attention_min
[-47.21  -0.47]
agent1_energy_min, agent1_attention_min
[-19.38  -0.03]
34000 50
steps: 1699950, episodes: 34000, mean episode reward: -69.88874081959305, time: 24.356
agent0_energy_min, agent0_attention_min
[-47.36  -0.31]
agent1_energy_min, agent1_attention_min
[-17.85  -0.07]
34100 50
steps: 1704950, episodes: 34100, mean episode reward: -63.743838182562115, time: 24.721
agent0_energy_min, agent0_attention_min
[-4.814e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-18.18  -0.08]
34200 50
steps: 1709950, episodes: 34200, mean episode reward: -75.80786295796702, time: 24.154
agent0_energy_min, agent0_attention_min
[-43.98  -0.2 ]
agent1_energy_min, agent1_attention_min
[-21.9   -0.16]
34300 50
steps: 1714950, episodes: 34300, mean episode reward: -64.90285518583812, time: 24.358
agent0_energy_min, agent0_attention_min
[-46.78  -0.27]
agent1_energy_min, agent1_attention_min
[-19.08  -0.28]
34400 50
steps: 1719950, episodes: 34400, mean episode reward: -74.98704311082577, time: 24.865
agent0_energy_min, agent0_attention_min
[-44.44  -0.12]
agent1_energy_min, agent1_attention_min
[-19.36  -0.6 ]
34500 50
steps: 1724950, episodes: 34500, mean episode reward: -69.69141869459115, time: 24.039
agent0_energy_min, agent0_attention_min
[-4.394e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-19.79  -0.77]
34600 50
steps: 1729950, episodes: 34600, mean episode reward: -88.54089745325942, time: 25.019
agent0_energy_min, agent0_attention_min
[-44.86  -0.14]
agent1_energy_min, agent1_attention_min
[-18.07  -0.3 ]
34700 50
steps: 1734950, episodes: 34700, mean episode reward: -65.46036043891974, time: 24.331
agent0_energy_min, agent0_attention_min
[-45.93  -0.57]
agent1_energy_min, agent1_attention_min
[-16.67  -0.55]
34800 50
steps: 1739950, episodes: 34800, mean episode reward: -69.6111798732688, time: 24.07
agent0_energy_min, agent0_attention_min
[-44.79  -0.07]
agent1_energy_min, agent1_attention_min
[-18.09  -0.1 ]
34900 50
steps: 1744950, episodes: 34900, mean episode reward: -66.43924619858143, time: 24.115
agent0_energy_min, agent0_attention_min
[-42.29   0.  ]
agent1_energy_min, agent1_attention_min
[-18.08  -0.02]
35000 50
steps: 1749950, episodes: 35000, mean episode reward: -66.83088382916759, time: 24.981
agent0_energy_min, agent0_attention_min
[-43.29  -0.05]
agent1_energy_min, agent1_attention_min
[-1.628e+01 -1.000e-02]
35100 50
steps: 1754950, episodes: 35100, mean episode reward: -75.42018041472312, time: 24.551
agent0_energy_min, agent0_attention_min
[-40.92  -5.01]
agent1_energy_min, agent1_attention_min
[-1.784e+01 -1.000e-02]
35200 50
steps: 1759950, episodes: 35200, mean episode reward: -75.96360925811564, time: 24.277
agent0_energy_min, agent0_attention_min
[-43.96  -3.39]
[-43.7   -5.21]
31600 50
steps: 1579950, episodes: 31600, mean episode reward: -71.85557012821523, time: 24.443
agent0_energy_min, agent0_attention_min
[-45.56  -4.23]
agent1_energy_min, agent1_attention_min
[-45.97  -3.24]
31700 50
steps: 1584950, episodes: 31700, mean episode reward: -65.3382356689163, time: 24.23
agent0_energy_min, agent0_attention_min
[-46.06  -3.66]
agent1_energy_min, agent1_attention_min
[-48.16  -1.44]
31800 50
steps: 1589950, episodes: 31800, mean episode reward: -64.34760967877529, time: 24.973
agent0_energy_min, agent0_attention_min
[-47.38  -2.15]
agent1_energy_min, agent1_attention_min
[-49.69  -0.21]
31900 50
steps: 1594950, episodes: 31900, mean episode reward: -44.56970593383603, time: 24.218
agent0_energy_min, agent0_attention_min
[-40.61  -0.5 ]
agent1_energy_min, agent1_attention_min
[-49.71  -0.05]
32000 50
steps: 1599950, episodes: 32000, mean episode reward: -62.10065942825563, time: 24.445
agent0_energy_min, agent0_attention_min
[-43.36  -2.85]
agent1_energy_min, agent1_attention_min
[-49.16  -0.52]
32100 50
steps: 1604950, episodes: 32100, mean episode reward: -98.51120406641225, time: 24.667
agent0_energy_min, agent0_attention_min
[-47.    -2.84]
agent1_energy_min, agent1_attention_min
[-49.32  -0.31]
32200 50
steps: 1609950, episodes: 32200, mean episode reward: -62.668095029359336, time: 24.542
agent0_energy_min, agent0_attention_min
[-48.61  -0.2 ]
agent1_energy_min, agent1_attention_min
[-46.73  -1.24]
32300 50
steps: 1614950, episodes: 32300, mean episode reward: -53.58538182204538, time: 24.331
agent0_energy_min, agent0_attention_min
[-49.31  -0.08]
agent1_energy_min, agent1_attention_min
[-48.75  -0.56]
32400 50
steps: 1619950, episodes: 32400, mean episode reward: -50.57480976196907, time: 24.725
agent0_energy_min, agent0_attention_min
[-48.55  -0.08]
agent1_energy_min, agent1_attention_min
[-48.55  -0.83]
32500 50
steps: 1624950, episodes: 32500, mean episode reward: -70.78809466806331, time: 24.513
agent0_energy_min, agent0_attention_min
[-43.54  -0.91]
agent1_energy_min, agent1_attention_min
[-48.69  -0.49]
32600 50
steps: 1629950, episodes: 32600, mean episode reward: -58.17112622307495, time: 24.753
agent0_energy_min, agent0_attention_min
[-40.79  -0.1 ]
agent1_energy_min, agent1_attention_min
[-48.51  -1.03]
32700 50
steps: 1634950, episodes: 32700, mean episode reward: -57.91102073300399, time: 24.607
agent0_energy_min, agent0_attention_min
[-48.12  -0.09]
agent1_energy_min, agent1_attention_min
[-48.47  -0.86]
32800 50
steps: 1639950, episodes: 32800, mean episode reward: -49.91082880230183, time: 24.799
agent0_energy_min, agent0_attention_min
[-49.69   0.  ]
agent1_energy_min, agent1_attention_min
[-48.14  -0.22]
32900 50
steps: 1644950, episodes: 32900, mean episode reward: -63.53664843948839, time: 24.503
agent0_energy_min, agent0_attention_min
[-49.41  -0.11]
agent1_energy_min, agent1_attention_min
[-48.66  -0.49]
33000 50
steps: 1649950, episodes: 33000, mean episode reward: -47.9455775907445, time: 24.077
agent0_energy_min, agent0_attention_min
[-49.61  -0.17]
agent1_energy_min, agent1_attention_min
[-4.922e+01 -4.000e-02]
33100 50
steps: 1654950, episodes: 33100, mean episode reward: -54.36386403911446, time: 25.495
agent0_energy_min, agent0_attention_min
[-49.61  -0.16]
agent1_energy_min, agent1_attention_min
[-48.95  -0.14]
33200 50
steps: 1659950, episodes: 33200, mean episode reward: -58.03038983588541, time: 24.765
agent0_energy_min, agent0_attention_min
[-48.5   -1.26]
agent1_energy_min, agent1_attention_min
[-49.3   -0.18]
33300 50
steps: 1664950, episodes: 33300, mean episode reward: -50.065462930832034, time: 25.032
agent0_energy_min, agent0_attention_min
[-49.3   -0.38]
agent1_energy_min, agent1_attention_min
[-49.49  -0.11]
33400 50
steps: 1669950, episodes: 33400, mean episode reward: -46.94717494856839, time: 24.875
agent0_energy_min, agent0_attention_min
[-49.35  -0.2 ]
agent1_energy_min, agent1_attention_min
[-48.84  -0.12]
33500 50
steps: 1674950, episodes: 33500, mean episode reward: -65.78147701721089, time: 24.374
agent0_energy_min, agent0_attention_min
[-49.72  -0.08]
agent1_energy_min, agent1_attention_min
[-48.59  -0.44]
33600 50
steps: 1679950, episodes: 33600, mean episode reward: -43.26720871917411, time: 24.657
agent0_energy_min, agent0_attention_min
[-4.973e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-47.53  -1.91]
33700 50
steps: 1684950, episodes: 33700, mean episode reward: -52.28477378444852, time: 24.35
agent0_energy_min, agent0_attention_min
[-49.59  -0.09]
agent1_energy_min, agent1_attention_min
[-48.64  -0.78]
33800 50
steps: 1689950, episodes: 33800, mean episode reward: -48.76643088380895, time: 24.494
agent0_energy_min, agent0_attention_min
[-4.923e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-48.82  -0.38]
33900 50
steps: 1694950, episodes: 33900, mean episode reward: -43.494035832595216, time: 24.61
agent0_energy_min, agent0_attention_min
[-45.46  -0.05]
agent1_energy_min, agent1_attention_min
[-49.19  -0.39]
34000 50
steps: 1699950, episodes: 34000, mean episode reward: -47.44255776172535, time: 24.173
agent0_energy_min, agent0_attention_min
[-49.29  -0.17]
agent1_energy_min, agent1_attention_min
[-48.86  -0.08]
34100 50
steps: 1704950, episodes: 34100, mean episode reward: -55.55994530791998, time: 25.251
agent0_energy_min, agent0_attention_min
[-49.44  -0.21]
agent1_energy_min, agent1_attention_min
[-48.39  -0.52]
34200 50
steps: 1709950, episodes: 34200, mean episode reward: -46.47411453751114, time: 25.043
agent0_energy_min, agent0_attention_min
[-4.967e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-47.75  -1.63]
34300 50
steps: 1714950, episodes: 34300, mean episode reward: -38.131283238373214, time: 24.494
agent0_energy_min, agent0_attention_min
[-49.4   -0.08]
agent1_energy_min, agent1_attention_min
[-48.21  -0.59]
34400 50
steps: 1719950, episodes: 34400, mean episode reward: -47.16828186647067, time: 25.194
agent0_energy_min, agent0_attention_min
[-46.36  -0.09]
agent1_energy_min, agent1_attention_min
[-4.769e+01 -1.000e-02]
34500 50
steps: 1724950, episodes: 34500, mean episode reward: -55.24049349074578, time: 24.735
agent0_energy_min, agent0_attention_min
[-44.86  -0.08]
agent1_energy_min, agent1_attention_min
[-48.41  -0.39]
34600 50
steps: 1729950, episodes: 34600, mean episode reward: -47.27899081008615, time: 25.765
agent0_energy_min, agent0_attention_min
[-41.1   -0.06]
agent1_energy_min, agent1_attention_min
[-47.67  -1.08]
34700 50
steps: 1734950, episodes: 34700, mean episode reward: -48.81136051430587, time: 24.455
agent0_energy_min, agent0_attention_min
[-39.38  -0.07]
agent1_energy_min, agent1_attention_min
[-48.37  -0.14]
34800 50
steps: 1739950, episodes: 34800, mean episode reward: -63.05698634093716, time: 24.944
agent0_energy_min, agent0_attention_min
[-39.83  -0.14]
agent1_energy_min, agent1_attention_min
[-47.16  -1.18]
34900 50
steps: 1744950, episodes: 34900, mean episode reward: -50.51671432252224, time: 24.606
agent0_energy_min, agent0_attention_min
[-4.783e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-46.27  -2.18]
35000 50
steps: 1749950, episodes: 35000, mean episode reward: -52.37374545916707, time: 24.434
agent0_energy_min, agent0_attention_min
[-4.44e+01 -4.00e-02]
agent1_energy_min, agent1_attention_min
[-47.79  -0.54]
35100 50
steps: 1754950, episodes: 35100, mean episode reward: -55.11543710240253, time: 25.124
agent0_energy_min, agent0_attention_min
[-4.464e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-48.08  -0.06]
35200 50
steps: 1759950, episodes: 35200, mean episode reward: -83.9499217125683, time: 24.22
agent0_energy_min, agent0_attention_min
[-47.71  -0.06]
agent1_energy_min, agent1_attention_min
[-47.97   0.  ]
35300 50
steps: 1764950, episodes: 35300, mean episode reward: -50.441152289915124, time: 24.38
agent0_energy_min, agent0_attention_min
[-44.91  -0.06]
agent1_energy_min, agent1_attention_min
[-4.888e+01 -2.000e-02]
35400 50
steps: 1769950, episodes: 35400, mean episode reward: -48.23234735861959, time: 23.921
agent0_energy_min, agent0_attention_min
[-46.3   -0.06]
agent1_energy_min, agent1_attention_min
[-46.72   0.  ] 50
steps: 1574950, episodes: 31500, mean episode reward: -71.6942379677193, time: 23.622
agent0_energy_min, agent0_attention_min
[-48.42  -0.21]
agent1_energy_min, agent1_attention_min
[-41.27  -5.02]
31600 50
steps: 1579950, episodes: 31600, mean episode reward: -66.9693629900335, time: 24.366
agent0_energy_min, agent0_attention_min
[-48.85  -0.11]
agent1_energy_min, agent1_attention_min
[-37.68  -8.19]
31700 50
steps: 1584950, episodes: 31700, mean episode reward: -58.24872100366878, time: 24.276
agent0_energy_min, agent0_attention_min
[-49.15  -0.22]
agent1_energy_min, agent1_attention_min
[-35.48  -8.56]
31800 50
steps: 1589950, episodes: 31800, mean episode reward: -64.56641108777205, time: 23.996
agent0_energy_min, agent0_attention_min
[-49.12  -0.08]
agent1_energy_min, agent1_attention_min
[-38.98  -5.98]
31900 50
steps: 1594950, episodes: 31900, mean episode reward: -81.67839992183478, time: 24.342
agent0_energy_min, agent0_attention_min
[-48.91  -0.38]
agent1_energy_min, agent1_attention_min
[-40.67  -4.34]
32000 50
steps: 1599950, episodes: 32000, mean episode reward: -62.77492420747109, time: 23.784
agent0_energy_min, agent0_attention_min
[-48.55  -0.67]
agent1_energy_min, agent1_attention_min
[-31.31  -9.15]
32100 50
steps: 1604950, episodes: 32100, mean episode reward: -79.03229658836904, time: 24.855
agent0_energy_min, agent0_attention_min
[-49.12  -0.1 ]
agent1_energy_min, agent1_attention_min
[-35.6   -2.45]
32200 50
steps: 1609950, episodes: 32200, mean episode reward: -56.83967160076373, time: 24.448
agent0_energy_min, agent0_attention_min
[-48.32  -0.95]
agent1_energy_min, agent1_attention_min
[-27.51  -6.24]
32300 50
steps: 1614950, episodes: 32300, mean episode reward: -54.29524851627891, time: 23.605
agent0_energy_min, agent0_attention_min
[-47.68  -1.36]
agent1_energy_min, agent1_attention_min
[-38.33  -4.61]
32400 50
steps: 1619950, episodes: 32400, mean episode reward: -47.26515681459043, time: 23.529
agent0_energy_min, agent0_attention_min
[-47.9   -1.14]
agent1_energy_min, agent1_attention_min
[-36.42  -3.9 ]
32500 50
steps: 1624950, episodes: 32500, mean episode reward: -54.64888548619235, time: 23.953
agent0_energy_min, agent0_attention_min
[-47.81  -1.36]
agent1_energy_min, agent1_attention_min
[-33.94  -0.92]
32600 50
steps: 1629950, episodes: 32600, mean episode reward: -51.06673622224966, time: 24.828
agent0_energy_min, agent0_attention_min
[-48.03  -1.14]
agent1_energy_min, agent1_attention_min
[-38.76  -1.51]
32700 50
steps: 1634950, episodes: 32700, mean episode reward: -56.17610603309532, time: 24.278
agent0_energy_min, agent0_attention_min
[-47.5  -1.3]
agent1_energy_min, agent1_attention_min
[-38.22  -3.22]
32800 50
steps: 1639950, episodes: 32800, mean episode reward: -39.78709810295156, time: 24.01
agent0_energy_min, agent0_attention_min
[-47.49  -1.18]
agent1_energy_min, agent1_attention_min
[-40.37  -3.07]
32900 50
steps: 1644950, episodes: 32900, mean episode reward: -52.53511224849489, time: 24.548
agent0_energy_min, agent0_attention_min
[-47.03  -1.28]
agent1_energy_min, agent1_attention_min
[-35.88  -3.87]
33000 50
steps: 1649950, episodes: 33000, mean episode reward: -47.26643237503282, time: 23.85
agent0_energy_min, agent0_attention_min
[-47.15  -1.15]
agent1_energy_min, agent1_attention_min
[-42.49  -2.02]
33100 50
steps: 1654950, episodes: 33100, mean episode reward: -51.26129493825949, time: 24.712
agent0_energy_min, agent0_attention_min
[-47.64  -1.16]
agent1_energy_min, agent1_attention_min
[-36.44  -2.74]
33200 50
steps: 1659950, episodes: 33200, mean episode reward: -68.17249413005345, time: 24.108
agent0_energy_min, agent0_attention_min
[-47.81  -1.32]
agent1_energy_min, agent1_attention_min
[-29.47  -3.39]
33300 50
steps: 1664950, episodes: 33300, mean episode reward: -59.9109597373419, time: 24.223
agent0_energy_min, agent0_attention_min
[-48.21  -0.92]
agent1_energy_min, agent1_attention_min
[-34.3   -1.75]
33400 50
steps: 1669950, episodes: 33400, mean episode reward: -92.35749301172832, time: 24.397
agent0_energy_min, agent0_attention_min
[-48.74  -0.16]
agent1_energy_min, agent1_attention_min
[-36.43  -5.07]
33500 50
steps: 1674950, episodes: 33500, mean episode reward: -65.51916209629857, time: 23.894
agent0_energy_min, agent0_attention_min
[-48.08  -0.18]
agent1_energy_min, agent1_attention_min
[-36.57  -3.16]
33600 50
steps: 1679950, episodes: 33600, mean episode reward: -55.0545771786162, time: 24.818
agent0_energy_min, agent0_attention_min
[-47.57  -1.24]
agent1_energy_min, agent1_attention_min
[-35.24  -2.7 ]
33700 50
steps: 1684950, episodes: 33700, mean episode reward: -83.53318722029293, time: 25.799
agent0_energy_min, agent0_attention_min
[-48.3   -0.09]
agent1_energy_min, agent1_attention_min
[-33.29  -5.38]
33800 50
steps: 1689950, episodes: 33800, mean episode reward: -66.37863304398742, time: 23.586
agent0_energy_min, agent0_attention_min
[-48.64  -0.08]
agent1_energy_min, agent1_attention_min
[-28.3   -3.93]
33900 50
steps: 1694950, episodes: 33900, mean episode reward: -71.89497161430356, time: 23.952
agent0_energy_min, agent0_attention_min
[-48.58  -0.06]
agent1_energy_min, agent1_attention_min
[-32.63  -4.31]
34000 50
steps: 1699950, episodes: 34000, mean episode reward: -44.743203844977415, time: 24.228
agent0_energy_min, agent0_attention_min
[-48.49  -0.14]
agent1_energy_min, agent1_attention_min
[-29.7   -3.34]
34100 50
steps: 1704950, episodes: 34100, mean episode reward: -44.10579724031621, time: 24.847
agent0_energy_min, agent0_attention_min
[-48.76  -0.17]
agent1_energy_min, agent1_attention_min
[-32.53  -2.64]
34200 50
steps: 1709950, episodes: 34200, mean episode reward: -57.09023462037369, time: 23.965
agent0_energy_min, agent0_attention_min
[-48.73  -0.11]
agent1_energy_min, agent1_attention_min
[-35.58  -5.92]
34300 50
steps: 1714950, episodes: 34300, mean episode reward: -51.95479892382477, time: 24.119
agent0_energy_min, agent0_attention_min
[-47.16  -0.1 ]
agent1_energy_min, agent1_attention_min
[-34.63  -4.38]
34400 50
steps: 1719950, episodes: 34400, mean episode reward: -48.04455087627054, time: 24.64
agent0_energy_min, agent0_attention_min
[-48.13  -0.08]
agent1_energy_min, agent1_attention_min
[-30.24  -5.98]
34500 50
steps: 1724950, episodes: 34500, mean episode reward: -44.019746574469416, time: 23.756
agent0_energy_min, agent0_attention_min
[-48.45  -0.12]
agent1_energy_min, agent1_attention_min
[-28.36  -5.53]
34600 50
steps: 1729950, episodes: 34600, mean episode reward: -46.01156554558, time: 25.153
agent0_energy_min, agent0_attention_min
[-47.79  -0.2 ]
agent1_energy_min, agent1_attention_min
[-32.37  -8.47]
34700 50
steps: 1734950, episodes: 34700, mean episode reward: -61.5607267730026, time: 24.177
agent0_energy_min, agent0_attention_min
[-46.5   -0.11]
agent1_energy_min, agent1_attention_min
[-28.98  -6.43]
34800 50
steps: 1739950, episodes: 34800, mean episode reward: -48.47475490658115, time: 24.551
agent0_energy_min, agent0_attention_min
[-48.36  -0.13]
agent1_energy_min, agent1_attention_min
[-24.84 -12.61]
34900 50
steps: 1744950, episodes: 34900, mean episode reward: -77.3603842004804, time: 24.319
agent0_energy_min, agent0_attention_min
[-48.89  -0.1 ]
agent1_energy_min, agent1_attention_min
[-25.57 -11.35]
35000 50
steps: 1749950, episodes: 35000, mean episode reward: -64.83158411843185, time: 24.182
agent0_energy_min, agent0_attention_min
[-47.99  -0.07]
agent1_energy_min, agent1_attention_min
[-26.59 -11.98]
35100 50
steps: 1754950, episodes: 35100, mean episode reward: -48.11333684573096, time: 23.932
agent0_energy_min, agent0_attention_min
[-48.16  -0.14]
agent1_energy_min, agent1_attention_min
[-25.8   -7.42]
35200 50
steps: 1759950, episodes: 35200, mean episode reward: -52.911339405776125, time: 24.088
agent0_energy_min, agent0_attention_min
[-47.77  -0.1 ]
agent1_energy_min, agent1_attention_min
[-26.89  -3.29]
35300 50
steps: 1764950, episodes: 35300, mean episode reward: -45.505353140777295, time: 24.304
agent0_energy_min, agent0_attention_min
[-48.88  -0.12]
agent1_energy_min, agent1_attention_min
[-21.8   -6.99]
35400 50
steps: 1769950, episodes: 35400, mean episode reward: -80.00182760156872, time: 24.096

[-35.32  -4.61]
31800 50
steps: 1589950, episodes: 31800, mean episode reward: -114.36534065842042, time: 24.323
agent0_energy_min, agent0_attention_min
[-29.76  -2.5 ]
agent1_energy_min, agent1_attention_min
[-43.23  -5.97]
31900 50
steps: 1594950, episodes: 31900, mean episode reward: -53.8964650580565, time: 25.134
agent0_energy_min, agent0_attention_min
[-24.48  -2.56]
agent1_energy_min, agent1_attention_min
[-39.35  -0.9 ]
32000 50
steps: 1599950, episodes: 32000, mean episode reward: -45.94329624474933, time: 24.311
agent0_energy_min, agent0_attention_min
[-32.2   -1.97]
agent1_energy_min, agent1_attention_min
[-39.13  -2.16]
32100 50
steps: 1604950, episodes: 32100, mean episode reward: -41.949214328930395, time: 24.42
agent0_energy_min, agent0_attention_min
[-29.63  -1.57]
agent1_energy_min, agent1_attention_min
[-45.43  -0.73]
32200 50
steps: 1609950, episodes: 32200, mean episode reward: -46.627878646004135, time: 24.06
agent0_energy_min, agent0_attention_min
[-27.79 -14.81]
agent1_energy_min, agent1_attention_min
[-43.43  -5.37]
32300 50
steps: 1614950, episodes: 32300, mean episode reward: -37.761666475702775, time: 24.477
agent0_energy_min, agent0_attention_min
[-29.5  -18.57]
agent1_energy_min, agent1_attention_min
[-45.18  -4.55]
32400 50
steps: 1619950, episodes: 32400, mean episode reward: -38.226304185386255, time: 24.489
agent0_energy_min, agent0_attention_min
[-29.61 -17.97]
agent1_energy_min, agent1_attention_min
[-47.45  -1.22]
32500 50
steps: 1624950, episodes: 32500, mean episode reward: -64.13675157761492, time: 24.451
agent0_energy_min, agent0_attention_min
[-40.24  -5.67]
agent1_energy_min, agent1_attention_min
[-31.73  -1.14]
32600 50
steps: 1629950, episodes: 32600, mean episode reward: -69.49492854429148, time: 25.311
agent0_energy_min, agent0_attention_min
[-33.24 -10.48]
agent1_energy_min, agent1_attention_min
[-28.63  -1.8 ]
32700 50
steps: 1634950, episodes: 32700, mean episode reward: -46.09529171392044, time: 24.373
agent0_energy_min, agent0_attention_min
[-39.66  -3.97]
agent1_energy_min, agent1_attention_min
[-36.02  -1.57]
32800 50
steps: 1639950, episodes: 32800, mean episode reward: -40.33490802747913, time: 23.873
agent0_energy_min, agent0_attention_min
[-30.26  -8.07]
agent1_energy_min, agent1_attention_min
[-44.    -0.95]
32900 50
steps: 1644950, episodes: 32900, mean episode reward: -39.01348735357107, time: 24.726
agent0_energy_min, agent0_attention_min
[-33.95  -4.49]
agent1_energy_min, agent1_attention_min
[-36.31  -0.87]
33000 50
steps: 1649950, episodes: 33000, mean episode reward: -47.45872699021169, time: 24.578
agent0_energy_min, agent0_attention_min
[-40.34  -3.92]
agent1_energy_min, agent1_attention_min
[-32.22  -0.74]
33100 50
steps: 1654950, episodes: 33100, mean episode reward: -62.375069995917826, time: 24.595
agent0_energy_min, agent0_attention_min
[-34.57 -10.81]
agent1_energy_min, agent1_attention_min
[-40.62  -0.84]
33200 50
steps: 1659950, episodes: 33200, mean episode reward: -53.026902340294384, time: 24.463
agent0_energy_min, agent0_attention_min
[-25.8  -12.74]
agent1_energy_min, agent1_attention_min
[-38.76  -1.76]
33300 50
steps: 1664950, episodes: 33300, mean episode reward: -57.882179831469045, time: 24.816
agent0_energy_min, agent0_attention_min
[-33.69 -11.27]
agent1_energy_min, agent1_attention_min
[-42.65  -1.18]
33400 50
steps: 1669950, episodes: 33400, mean episode reward: -48.94241380386782, time: 24.055
agent0_energy_min, agent0_attention_min
[-30.45 -10.37]
agent1_energy_min, agent1_attention_min
[-43.46  -1.16]
33500 50
steps: 1674950, episodes: 33500, mean episode reward: -57.410454351460395, time: 24.456
agent0_energy_min, agent0_attention_min
[-41.95  -4.66]
agent1_energy_min, agent1_attention_min
[-47.96  -0.7 ]
33600 50
steps: 1679950, episodes: 33600, mean episode reward: -52.41083425881496, time: 24.892
agent0_energy_min, agent0_attention_min
[-23.38 -15.81]
agent1_energy_min, agent1_attention_min
[-47.41  -1.3 ]
33700 50
steps: 1684950, episodes: 33700, mean episode reward: -64.23923963455577, time: 24.315
agent0_energy_min, agent0_attention_min
[-37.91  -6.81]
agent1_energy_min, agent1_attention_min
[-44.72  -1.45]
33800 50
steps: 1689950, episodes: 33800, mean episode reward: -95.54994362428123, time: 24.436
agent0_energy_min, agent0_attention_min
[-35.79 -10.25]
agent1_energy_min, agent1_attention_min
[-38.28  -1.25]
33900 50
steps: 1694950, episodes: 33900, mean episode reward: -60.051921978978946, time: 24.34
agent0_energy_min, agent0_attention_min
[-41.44  -3.96]
agent1_energy_min, agent1_attention_min
[-37.72  -1.06]
34000 50
steps: 1699950, episodes: 34000, mean episode reward: -77.22603235898305, time: 24.201
agent0_energy_min, agent0_attention_min
[-40.99  -3.09]
agent1_energy_min, agent1_attention_min
[-40.59  -1.48]
34100 50
steps: 1704950, episodes: 34100, mean episode reward: -78.11904669624087, time: 25.063
agent0_energy_min, agent0_attention_min
[-39.98  -2.32]
agent1_energy_min, agent1_attention_min
[-42.47  -1.16]
34200 50
steps: 1709950, episodes: 34200, mean episode reward: -44.0723678956841, time: 24.639
agent0_energy_min, agent0_attention_min
[-37.2   -4.01]
agent1_energy_min, agent1_attention_min
[-48.36  -1.01]
34300 50
steps: 1714950, episodes: 34300, mean episode reward: -52.66018550312202, time: 24.797
agent0_energy_min, agent0_attention_min
[-42.78  -4.3 ]
agent1_energy_min, agent1_attention_min
[-46.94  -2.19]
34400 50
steps: 1719950, episodes: 34400, mean episode reward: -79.89898466858794, time: 24.838
agent0_energy_min, agent0_attention_min
[-41.69  -5.68]
agent1_energy_min, agent1_attention_min
[-47.34  -1.97]
34500 50
steps: 1724950, episodes: 34500, mean episode reward: -52.9672014895329, time: 25.114
agent0_energy_min, agent0_attention_min
[-33.01  -8.07]
agent1_energy_min, agent1_attention_min
[-47.72  -1.91]
34600 50
steps: 1729950, episodes: 34600, mean episode reward: -61.73896562206499, time: 26.15
agent0_energy_min, agent0_attention_min
[-30.61  -3.81]
agent1_energy_min, agent1_attention_min
[-44.72  -2.31]
34700 50
steps: 1734950, episodes: 34700, mean episode reward: -39.77756360916227, time: 24.373
agent0_energy_min, agent0_attention_min
[-33.24  -4.2 ]
agent1_energy_min, agent1_attention_min
[-30.5   -1.27]
34800 50
steps: 1739950, episodes: 34800, mean episode reward: -46.18461213324788, time: 24.425
agent0_energy_min, agent0_attention_min
[-30.77  -5.48]
agent1_energy_min, agent1_attention_min
[-27.02  -2.63]
34900 50
steps: 1744950, episodes: 34900, mean episode reward: -42.012936697873656, time: 24.423
agent0_energy_min, agent0_attention_min
[-30.67  -6.28]
agent1_energy_min, agent1_attention_min
[-37.98  -2.61]
35000 50
steps: 1749950, episodes: 35000, mean episode reward: -44.28903760556045, time: 25.208
agent0_energy_min, agent0_attention_min
[-41.6   -3.94]
agent1_energy_min, agent1_attention_min
[-38.6   -3.55]
35100 50
steps: 1754950, episodes: 35100, mean episode reward: -41.37154796047752, time: 25.455
agent0_energy_min, agent0_attention_min
[-37.21  -5.01]
agent1_energy_min, agent1_attention_min
[-35.78  -6.15]
35200 50
steps: 1759950, episodes: 35200, mean episode reward: -41.726558317831085, time: 24.619
agent0_energy_min, agent0_attention_min
[-42.64  -6.44]
agent1_energy_min, agent1_attention_min
[-40.88  -5.37]
35300 50
steps: 1764950, episodes: 35300, mean episode reward: -36.02689601009806, time: 24.431
agent0_energy_min, agent0_attention_min
[-27.47 -10.97]
agent1_energy_min, agent1_attention_min
[-45.15  -4.41]
35400 50
steps: 1769950, episodes: 35400, mean episode reward: -44.973893080295454, time: 24.477
agent0_energy_min, agent0_attention_min
[-35.41  -6.16]
agent1_energy_min, agent1_attention_min
[-39.74  -4.37]
35500 50
steps: 1774950, episodes: 35500, mean episode reward: -45.161626647494515, time: 24.327
agent0_energy_min, agent0_attention_min
[-19.47 -28.94]
agent1_energy_min, agent1_attention_min
[-38.8   -4.57]
35600 50
steps: 1779950, episodes: 35600, mean episode reward: -37.94484219828258, time: 24.755
agent0_energy_min, agent0_attention_min
[-36.76 -12.91]
agent1_energy_min, agent1_attention_min
[-39.22  -4.82]
35700 50
steps: 1784950, episodes: 35700, mean episode reward: -46.93879122888637, time: 24.69
[-36.34  -7.31]
31900 50
steps: 1594950, episodes: 31900, mean episode reward: -67.5643955101697, time: 24.819
agent0_energy_min, agent0_attention_min
[-12.56 -37.04]
agent1_energy_min, agent1_attention_min
[-36.38  -9.58]
32000 50
steps: 1599950, episodes: 32000, mean episode reward: -62.67063257292671, time: 24.719
agent0_energy_min, agent0_attention_min
[ -9.35 -40.16]
agent1_energy_min, agent1_attention_min
[-34.75 -10.4 ]
32100 50
steps: 1604950, episodes: 32100, mean episode reward: -68.62221969455126, time: 24.721
agent0_energy_min, agent0_attention_min
[-11.14 -38.41]
agent1_energy_min, agent1_attention_min
[-30.91 -11.67]
32200 50
steps: 1609950, episodes: 32200, mean episode reward: -60.873489203836606, time: 24.159
agent0_energy_min, agent0_attention_min
[-15.33 -33.92]
agent1_energy_min, agent1_attention_min
[-30.85 -14.76]
32300 50
steps: 1614950, episodes: 32300, mean episode reward: -58.59142554304489, time: 24.398
agent0_energy_min, agent0_attention_min
[-13.12 -33.17]
agent1_energy_min, agent1_attention_min
[-31.93  -8.88]
32400 50
steps: 1619950, episodes: 32400, mean episode reward: -63.94253816328559, time: 24.66
agent0_energy_min, agent0_attention_min
[-15.86 -25.69]
agent1_energy_min, agent1_attention_min
[-24.49 -14.11]
32500 50
steps: 1624950, episodes: 32500, mean episode reward: -77.66630427934503, time: 24.419
agent0_energy_min, agent0_attention_min
[-19.36 -22.58]
agent1_energy_min, agent1_attention_min
[-35.72  -9.14]
32600 50
steps: 1629950, episodes: 32600, mean episode reward: -73.93439271151499, time: 24.363
agent0_energy_min, agent0_attention_min
[-20.28 -24.65]
agent1_energy_min, agent1_attention_min
[-31.63 -13.96]
32700 50
steps: 1634950, episodes: 32700, mean episode reward: -77.0174232684208, time: 24.759
agent0_energy_min, agent0_attention_min
[-18.67 -26.69]
agent1_energy_min, agent1_attention_min
[-39.35  -9.27]
32800 50
steps: 1639950, episodes: 32800, mean episode reward: -71.75416255790658, time: 24.156
agent0_energy_min, agent0_attention_min
[-17.51 -26.  ]
agent1_energy_min, agent1_attention_min
[-41.03  -7.3 ]
32900 50
steps: 1644950, episodes: 32900, mean episode reward: -63.488076647377994, time: 24.899
agent0_energy_min, agent0_attention_min
[-17.4 -29.6]
agent1_energy_min, agent1_attention_min
[-32.17 -11.3 ]
33000 50
steps: 1649950, episodes: 33000, mean episode reward: -66.03852372468168, time: 23.849
agent0_energy_min, agent0_attention_min
[-12.54 -32.85]
agent1_energy_min, agent1_attention_min
[-34.55  -9.22]
33100 50
steps: 1654950, episodes: 33100, mean episode reward: -70.01564458417042, time: 24.904
agent0_energy_min, agent0_attention_min
[-16.75 -29.08]
agent1_energy_min, agent1_attention_min
[-35.14  -7.35]
33200 50
steps: 1659950, episodes: 33200, mean episode reward: -66.32075419469605, time: 24.588
agent0_energy_min, agent0_attention_min
[-13.88 -31.89]
agent1_energy_min, agent1_attention_min
[-33.35  -8.11]
33300 50
steps: 1664950, episodes: 33300, mean episode reward: -84.42003543961742, time: 24.915
agent0_energy_min, agent0_attention_min
[-11.43 -37.07]
agent1_energy_min, agent1_attention_min
[-32.43  -8.04]
33400 50
steps: 1669950, episodes: 33400, mean episode reward: -68.7430253709332, time: 24.276
agent0_energy_min, agent0_attention_min
[ -8.56 -39.42]
agent1_energy_min, agent1_attention_min
[-30.85 -12.02]
33500 50
steps: 1674950, episodes: 33500, mean episode reward: -73.10037268267713, time: 24.881
agent0_energy_min, agent0_attention_min
[ -5.12 -43.32]
agent1_energy_min, agent1_attention_min
[-33.53 -10.59]
33600 50
steps: 1679950, episodes: 33600, mean episode reward: -83.85943239544783, time: 25.41
agent0_energy_min, agent0_attention_min
[ -4.25 -45.04]
agent1_energy_min, agent1_attention_min
[-32.62  -9.51]
33700 50
steps: 1684950, episodes: 33700, mean episode reward: -96.61213229581554, time: 24.395
agent0_energy_min, agent0_attention_min
[ -5.64 -43.69]
agent1_energy_min, agent1_attention_min
[-33.23  -6.69]
33800 50
steps: 1689950, episodes: 33800, mean episode reward: -67.52063979330421, time: 24.167
agent0_energy_min, agent0_attention_min
[ -6.24 -42.73]
agent1_energy_min, agent1_attention_min
[-38.54  -5.05]
33900 50
steps: 1694950, episodes: 33900, mean episode reward: -92.94371362025495, time: 23.572
agent0_energy_min, agent0_attention_min
[ -7.23 -42.23]
agent1_energy_min, agent1_attention_min
[-35.45  -7.  ]
34000 50
steps: 1699950, episodes: 34000, mean episode reward: -73.56532959401075, time: 24.431
agent0_energy_min, agent0_attention_min
[ -6.28 -42.91]
agent1_energy_min, agent1_attention_min
[-33.78  -8.85]
34100 50
steps: 1704950, episodes: 34100, mean episode reward: -81.12640049189423, time: 24.798
agent0_energy_min, agent0_attention_min
[ -7.22 -41.64]
agent1_energy_min, agent1_attention_min
[-33.83  -7.54]
34200 50
steps: 1709950, episodes: 34200, mean episode reward: -84.04093562141662, time: 24.291
agent0_energy_min, agent0_attention_min
[ -6.49 -42.08]
agent1_energy_min, agent1_attention_min
[-36.28  -3.18]
34300 50
steps: 1714950, episodes: 34300, mean episode reward: -63.61141927661883, time: 24.905
agent0_energy_min, agent0_attention_min
[ -8.96 -38.76]
agent1_energy_min, agent1_attention_min
[-33.77  -4.89]
34400 50
steps: 1719950, episodes: 34400, mean episode reward: -75.46700595174597, time: 24.531
agent0_energy_min, agent0_attention_min
[ -9.01 -38.66]
agent1_energy_min, agent1_attention_min
[-31.92  -8.11]
34500 50
steps: 1724950, episodes: 34500, mean episode reward: -63.652987560769795, time: 24.564
agent0_energy_min, agent0_attention_min
[ -8.09 -41.25]
agent1_energy_min, agent1_attention_min
[-36.14 -10.77]
34600 50
steps: 1729950, episodes: 34600, mean episode reward: -58.600823483783536, time: 26.63
agent0_energy_min, agent0_attention_min
[ -7.17 -42.72]
agent1_energy_min, agent1_attention_min
[-33.15  -8.22]
34700 50
steps: 1734950, episodes: 34700, mean episode reward: -62.35364796896514, time: 24.66
agent0_energy_min, agent0_attention_min
[ -9.39 -39.99]
agent1_energy_min, agent1_attention_min
[-30.33 -10.62]
34800 50
steps: 1739950, episodes: 34800, mean episode reward: -73.65639738690818, time: 24.686
agent0_energy_min, agent0_attention_min
[ -9.8  -39.99]
agent1_energy_min, agent1_attention_min
[-37.93 -10.87]
34900 50
steps: 1744950, episodes: 34900, mean episode reward: -96.17935274519071, time: 24.41
agent0_energy_min, agent0_attention_min
[-11.1  -38.62]
agent1_energy_min, agent1_attention_min
[-36.68  -8.91]
35000 50
steps: 1749950, episodes: 35000, mean episode reward: -77.10182598234218, time: 24.8
agent0_energy_min, agent0_attention_min
[ -8.51 -40.99]
agent1_energy_min, agent1_attention_min
[-33.68 -11.03]
35100 50
steps: 1754950, episodes: 35100, mean episode reward: -59.12936108765101, time: 25.056
agent0_energy_min, agent0_attention_min
[ -9.47 -39.07]
agent1_energy_min, agent1_attention_min
[-34.06  -8.9 ]
35200 50
steps: 1759950, episodes: 35200, mean episode reward: -68.26522698252387, time: 24.711
agent0_energy_min, agent0_attention_min
[ -9.88 -39.44]
agent1_energy_min, agent1_attention_min
[-31.06 -12.13]
35300 50
steps: 1764950, episodes: 35300, mean episode reward: -118.62293980984674, time: 24.597
agent0_energy_min, agent0_attention_min
[ -9.74 -39.27]
agent1_energy_min, agent1_attention_min
[-34.   -10.54]
35400 50
steps: 1769950, episodes: 35400, mean episode reward: -113.50329835165556, time: 24.143
agent0_energy_min, agent0_attention_min
[ -7.44 -41.19]
agent1_energy_min, agent1_attention_min
[-32.47 -10.69]
35500 50
steps: 1774950, episodes: 35500, mean episode reward: -205.84264600099561, time: 24.351
agent0_energy_min, agent0_attention_min
[ -7.17 -40.5 ]
agent1_energy_min, agent1_attention_min
[-27.62 -17.03]
35600 50
steps: 1779950, episodes: 35600, mean episode reward: -89.85366540657569, time: 24.829
agent0_energy_min, agent0_attention_min
[ -9.11 -39.89]
agent1_energy_min, agent1_attention_min
[-22.69 -23.66]
35700 50
steps: 1784950, episodes: 35700, mean episode reward: -65.60016213574748, time: 24.358
agent0_energy_min, agent0_attention_min
[-12.75 -37.01]
agent1_energy_min, agent1_attention_min
[-21.72 -22.09]
35800 50
steps: 1789950, episodes: 35800, mean episode reward: -98.10358928208319, time: 24.21
[-30.53 -18.25]
31900 50
steps: 1594950, episodes: 31900, mean episode reward: -128.27103357200224, time: 24.395
agent0_energy_min, agent0_attention_min
[-25.7   -0.88]
agent1_energy_min, agent1_attention_min
[-25.79 -21.68]
32000 50
steps: 1599950, episodes: 32000, mean episode reward: -96.38338196254968, time: 23.896
agent0_energy_min, agent0_attention_min
[-20.67  -4.75]
agent1_energy_min, agent1_attention_min
[-24.1  -20.66]
32100 50
steps: 1604950, episodes: 32100, mean episode reward: -53.4417631997662, time: 24.722
agent0_energy_min, agent0_attention_min
[-18.61  -5.75]
agent1_energy_min, agent1_attention_min
[-25.12 -20.78]
32200 50
steps: 1609950, episodes: 32200, mean episode reward: -87.1820107212714, time: 24.48
agent0_energy_min, agent0_attention_min
[-20.1   -8.26]
agent1_energy_min, agent1_attention_min
[-21.55 -24.  ]
32300 50
steps: 1614950, episodes: 32300, mean episode reward: -62.93156286751055, time: 24.152
agent0_energy_min, agent0_attention_min
[-21.39 -10.54]
agent1_energy_min, agent1_attention_min
[-20.72 -24.57]
32400 50
steps: 1619950, episodes: 32400, mean episode reward: -75.65959120865114, time: 24.253
agent0_energy_min, agent0_attention_min
[-21.48 -21.31]
agent1_energy_min, agent1_attention_min
[-13.16 -25.77]
32500 50
steps: 1624950, episodes: 32500, mean episode reward: -72.89253092791678, time: 24.221
agent0_energy_min, agent0_attention_min
[-19.34 -20.69]
agent1_energy_min, agent1_attention_min
[-21.26 -22.82]
32600 50
steps: 1629950, episodes: 32600, mean episode reward: -70.52329882573126, time: 24.63
agent0_energy_min, agent0_attention_min
[-21.92 -24.57]
agent1_energy_min, agent1_attention_min
[-16.65 -31.99]
32700 50
steps: 1634950, episodes: 32700, mean episode reward: -72.54875316871649, time: 24.591
agent0_energy_min, agent0_attention_min
[-21.42 -21.78]
agent1_energy_min, agent1_attention_min
[-21.04 -27.25]
32800 50
steps: 1639950, episodes: 32800, mean episode reward: -63.824061647185054, time: 24.653
agent0_energy_min, agent0_attention_min
[-21.4 -20.2]
agent1_energy_min, agent1_attention_min
[-26.47 -23.21]
32900 50
steps: 1644950, episodes: 32900, mean episode reward: -58.50421082447467, time: 24.944
agent0_energy_min, agent0_attention_min
[-18.39 -15.02]
agent1_energy_min, agent1_attention_min
[-22.74 -26.95]
33000 50
steps: 1649950, episodes: 33000, mean episode reward: -61.64816490429648, time: 24.514
agent0_energy_min, agent0_attention_min
[-20.5  -10.65]
agent1_energy_min, agent1_attention_min
[-23.14 -26.55]
33100 50
steps: 1654950, episodes: 33100, mean episode reward: -79.51467877383479, time: 25.456
agent0_energy_min, agent0_attention_min
[-18.77  -9.2 ]
agent1_energy_min, agent1_attention_min
[-21.72 -27.62]
33200 50
steps: 1659950, episodes: 33200, mean episode reward: -62.4424165609822, time: 24.69
agent0_energy_min, agent0_attention_min
[-16.38 -13.52]
agent1_energy_min, agent1_attention_min
[-24.61 -22.29]
33300 50
steps: 1664950, episodes: 33300, mean episode reward: -68.69428822489277, time: 24.625
agent0_energy_min, agent0_attention_min
[-17.01 -12.09]
agent1_energy_min, agent1_attention_min
[-22.82 -24.57]
33400 50
steps: 1669950, episodes: 33400, mean episode reward: -70.89741872561004, time: 24.79
agent0_energy_min, agent0_attention_min
[-19.44 -13.5 ]
agent1_energy_min, agent1_attention_min
[-24.8  -23.87]
33500 50
steps: 1674950, episodes: 33500, mean episode reward: -65.31575066307924, time: 24.669
agent0_energy_min, agent0_attention_min
[-18.33 -17.09]
agent1_energy_min, agent1_attention_min
[-24.98 -24.83]
33600 50
steps: 1679950, episodes: 33600, mean episode reward: -64.66754511427398, time: 24.912
agent0_energy_min, agent0_attention_min
[-20.5  -14.37]
agent1_energy_min, agent1_attention_min
[-19.65 -29.01]
33700 50
steps: 1684950, episodes: 33700, mean episode reward: -73.10546009412982, time: 24.713
agent0_energy_min, agent0_attention_min
[-25.69  -9.87]
agent1_energy_min, agent1_attention_min
[-25.25 -24.63]
33800 50
steps: 1689950, episodes: 33800, mean episode reward: -68.17835984951975, time: 24.203
agent0_energy_min, agent0_attention_min
[-28.66 -15.03]
agent1_energy_min, agent1_attention_min
[-21.81 -27.26]
33900 50
steps: 1694950, episodes: 33900, mean episode reward: -84.96714612597472, time: 24.573
agent0_energy_min, agent0_attention_min
[-25.12 -17.01]
agent1_energy_min, agent1_attention_min
[-18.35 -30.37]
34000 50
steps: 1699950, episodes: 34000, mean episode reward: -165.2276213358027, time: 24.19
agent0_energy_min, agent0_attention_min
[-19.49 -18.38]
agent1_energy_min, agent1_attention_min
[-19.66 -29.29]
34100 50
steps: 1704950, episodes: 34100, mean episode reward: -88.91917779869333, time: 24.884
agent0_energy_min, agent0_attention_min
[-26.51 -10.26]
agent1_energy_min, agent1_attention_min
[-24.68 -24.29]
34200 50
steps: 1709950, episodes: 34200, mean episode reward: -61.182217900934994, time: 24.654
agent0_energy_min, agent0_attention_min
[-26.11 -15.26]
agent1_energy_min, agent1_attention_min
[-25.08 -23.96]
34300 50
steps: 1714950, episodes: 34300, mean episode reward: -84.88509262575688, time: 24.447
agent0_energy_min, agent0_attention_min
[-25.35 -22.88]
agent1_energy_min, agent1_attention_min
[-24.94 -23.65]
34400 50
steps: 1719950, episodes: 34400, mean episode reward: -55.25353434851562, time: 24.843
agent0_energy_min, agent0_attention_min
[-26.28 -20.27]
agent1_energy_min, agent1_attention_min
[-17.94 -29.65]
34500 50
steps: 1724950, episodes: 34500, mean episode reward: -60.83030437098651, time: 24.504
agent0_energy_min, agent0_attention_min
[-23.07 -24.82]
agent1_energy_min, agent1_attention_min
[-13.66 -34.53]
34600 50
steps: 1729950, episodes: 34600, mean episode reward: -50.50687084153324, time: 25.313
agent0_energy_min, agent0_attention_min
[-23.17 -16.01]
agent1_energy_min, agent1_attention_min
[-14.01 -34.56]
34700 50
steps: 1734950, episodes: 34700, mean episode reward: -51.558575233948275, time: 23.996
agent0_energy_min, agent0_attention_min
[-21.98 -24.64]
agent1_energy_min, agent1_attention_min
[-14.84 -34.21]
34800 50
steps: 1739950, episodes: 34800, mean episode reward: -64.33134975188406, time: 24.609
agent0_energy_min, agent0_attention_min
[-21.82 -19.89]
agent1_energy_min, agent1_attention_min
[-14.83 -34.42]
34900 50
steps: 1744950, episodes: 34900, mean episode reward: -59.420078228035926, time: 25.265
agent0_energy_min, agent0_attention_min
[-24. -15.]
agent1_energy_min, agent1_attention_min
[-18.02 -30.78]
35000 50
steps: 1749950, episodes: 35000, mean episode reward: -59.44146920288261, time: 24.63
agent0_energy_min, agent0_attention_min
[-19.71 -24.45]
agent1_energy_min, agent1_attention_min
[-18.7  -28.76]
35100 50
steps: 1754950, episodes: 35100, mean episode reward: -54.868044268232126, time: 25.119
agent0_energy_min, agent0_attention_min
[-18.18 -29.15]
agent1_energy_min, agent1_attention_min
[-20.8  -28.53]
35200 50
steps: 1759950, episodes: 35200, mean episode reward: -87.40142263339516, time: 24.64
agent0_energy_min, agent0_attention_min
[-16.23 -30.97]
agent1_energy_min, agent1_attention_min
[-24.04 -25.19]
35300 50
steps: 1764950, episodes: 35300, mean episode reward: -62.37957051801854, time: 24.442
agent0_energy_min, agent0_attention_min
[-17.06 -29.82]
agent1_energy_min, agent1_attention_min
[-20.65 -26.5 ]
35400 50
steps: 1769950, episodes: 35400, mean episode reward: -59.84916717783325, time: 24.62
agent0_energy_min, agent0_attention_min
[-25.59 -23.37]
agent1_energy_min, agent1_attention_min
[-22.35 -26.73]
35500 50
steps: 1774950, episodes: 35500, mean episode reward: -96.38667906099079, time: 24.371
agent0_energy_min, agent0_attention_min
[-20.1  -27.94]
agent1_energy_min, agent1_attention_min
[-22.46 -26.68]
35600 50
steps: 1779950, episodes: 35600, mean episode reward: -167.75171937601604, time: 24.95
agent0_energy_min, agent0_attention_min
[-23.57 -24.44]
agent1_energy_min, agent1_attention_min
[-23.78 -25.42]
35700 50
steps: 1784950, episodes: 35700, mean episode reward: -69.89380875131903, time: 24.504
agent0_energy_min, agent0_attention_min
[-23.45 -25.76]
agent1_energy_min, agent1_attention_min
[-19.66 -29.31]
35800 50
steps: 1789950, episodes: 35800, mean episode reward: -98.87106842271008, time: 24.751
31700 50
steps: 1584950, episodes: 31700, mean episode reward: -101.93405566201238, time: 24.207
agent0_energy_min, agent0_attention_min
[-19.24  -1.85]
agent1_energy_min, agent1_attention_min
[-1.11 -0.84]
31800 50
steps: 1589950, episodes: 31800, mean episode reward: -104.84843856147474, time: 24.502
agent0_energy_min, agent0_attention_min
[-21.17  -0.35]
agent1_energy_min, agent1_attention_min
[-1.47 -1.19]
31900 50
steps: 1594950, episodes: 31900, mean episode reward: -128.2270083006584, time: 24.533
agent0_energy_min, agent0_attention_min
[-23.51  -0.13]
agent1_energy_min, agent1_attention_min
[-3.18 -3.  ]
32000 50
steps: 1599950, episodes: 32000, mean episode reward: -112.18220411548893, time: 25.016
agent0_energy_min, agent0_attention_min
[-26.42  -0.24]
agent1_energy_min, agent1_attention_min
[-2.22 -3.23]
32100 50
steps: 1604950, episodes: 32100, mean episode reward: -122.4159528217296, time: 25.163
agent0_energy_min, agent0_attention_min
[-21.13  -0.12]
agent1_energy_min, agent1_attention_min
[-3.23 -2.9 ]
32200 50
steps: 1609950, episodes: 32200, mean episode reward: -124.51321354783173, time: 24.419
agent0_energy_min, agent0_attention_min
[-20.    -0.03]
agent1_energy_min, agent1_attention_min
[-4.73 -3.64]
32300 50
steps: 1614950, episodes: 32300, mean episode reward: -107.27031094816597, time: 24.492
agent0_energy_min, agent0_attention_min
[-21.12  -0.03]
agent1_energy_min, agent1_attention_min
[-3.11 -1.96]
32400 50
steps: 1619950, episodes: 32400, mean episode reward: -185.6391243581229, time: 24.231
agent0_energy_min, agent0_attention_min
[-20.43   0.  ]
agent1_energy_min, agent1_attention_min
[-2.82 -1.  ]
32500 50
steps: 1624950, episodes: 32500, mean episode reward: -114.72849295504197, time: 24.762
agent0_energy_min, agent0_attention_min
[-16.28  -0.02]
agent1_energy_min, agent1_attention_min
[-2.54 -0.69]
32600 50
steps: 1629950, episodes: 32600, mean episode reward: -105.68047644747759, time: 24.825
agent0_energy_min, agent0_attention_min
[-1.624e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-3.46 -1.66]
32700 50
steps: 1634950, episodes: 32700, mean episode reward: -104.27305147267123, time: 24.815
agent0_energy_min, agent0_attention_min
[-19.46  -0.04]
agent1_energy_min, agent1_attention_min
[-5.31 -2.08]
32800 50
steps: 1639950, episodes: 32800, mean episode reward: -98.41904401322279, time: 25.05
agent0_energy_min, agent0_attention_min
[-2.101e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-3.41 -1.21]
32900 50
steps: 1644950, episodes: 32900, mean episode reward: -116.30893156017787, time: 24.886
agent0_energy_min, agent0_attention_min
[-19.09  -0.03]
agent1_energy_min, agent1_attention_min
[-3.67 -0.88]
33000 50
steps: 1649950, episodes: 33000, mean episode reward: -102.88113656393315, time: 25.213
agent0_energy_min, agent0_attention_min
[-18.72  -0.02]
agent1_energy_min, agent1_attention_min
[-1.69 -0.61]
33100 50
steps: 1654950, episodes: 33100, mean episode reward: -94.97481234737626, time: 24.928
agent0_energy_min, agent0_attention_min
[-18.15  -0.12]
agent1_energy_min, agent1_attention_min
[-0.31 -0.2 ]
33200 50
steps: 1659950, episodes: 33200, mean episode reward: -90.04030851770281, time: 25.06
agent0_energy_min, agent0_attention_min
[-1.995e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-1.36 -0.31]
33300 50
steps: 1664950, episodes: 33300, mean episode reward: -105.83163086609373, time: 24.559
agent0_energy_min, agent0_attention_min
[-20.12  -0.03]
agent1_energy_min, agent1_attention_min
[-0.78 -0.16]
33400 50
steps: 1669950, episodes: 33400, mean episode reward: -91.24409090315396, time: 24.591
agent0_energy_min, agent0_attention_min
[-1.726e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-1.5  -0.38]
33500 50
steps: 1674950, episodes: 33500, mean episode reward: -91.38037568719555, time: 24.088
agent0_energy_min, agent0_attention_min
[-18.06  -0.02]
agent1_energy_min, agent1_attention_min
[-1.48 -0.11]
33600 50
steps: 1679950, episodes: 33600, mean episode reward: -103.26130113558617, time: 25.064
agent0_energy_min, agent0_attention_min
[-18.17  -0.12]
agent1_energy_min, agent1_attention_min
[-1.81 -0.52]
33700 50
steps: 1684950, episodes: 33700, mean episode reward: -92.70569043667072, time: 24.291
agent0_energy_min, agent0_attention_min
[-16.53  -0.04]
agent1_energy_min, agent1_attention_min
[-0.49 -0.26]
33800 50
steps: 1689950, episodes: 33800, mean episode reward: -104.1193501954696, time: 24.662
agent0_energy_min, agent0_attention_min
[-19.75  -0.11]
agent1_energy_min, agent1_attention_min
[-0.23 -0.15]
33900 50
steps: 1694950, episodes: 33900, mean episode reward: -95.24439619051478, time: 25.011
agent0_energy_min, agent0_attention_min
[-18.14  -0.08]
agent1_energy_min, agent1_attention_min
[-0.73 -0.41]
34000 50
steps: 1699950, episodes: 34000, mean episode reward: -93.88602118903387, time: 24.918
agent0_energy_min, agent0_attention_min
[-20.22  -0.06]
agent1_energy_min, agent1_attention_min
[-0.32 -0.25]
34100 50
steps: 1704950, episodes: 34100, mean episode reward: -99.33334635548609, time: 25.422
agent0_energy_min, agent0_attention_min
[-29.58  -0.03]
agent1_energy_min, agent1_attention_min
[-0.38 -0.33]
34200 50
steps: 1709950, episodes: 34200, mean episode reward: -98.17398793324745, time: 24.741
agent0_energy_min, agent0_attention_min
[-2.461e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.28 -0.15]
34300 50
steps: 1714950, episodes: 34300, mean episode reward: -115.31471567827717, time: 24.035
agent0_energy_min, agent0_attention_min
[-23.61  -0.1 ]
agent1_energy_min, agent1_attention_min
[-1.32 -0.46]
34400 50
steps: 1719950, episodes: 34400, mean episode reward: -95.95506748893494, time: 24.802
agent0_energy_min, agent0_attention_min
[-21.74  -0.21]
agent1_energy_min, agent1_attention_min
[-1.7  -0.57]
34500 50
steps: 1724950, episodes: 34500, mean episode reward: -110.45139128467967, time: 25.125
agent0_energy_min, agent0_attention_min
[-24.33  -0.13]
agent1_energy_min, agent1_attention_min
[-1.4  -0.47]
34600 50
steps: 1729950, episodes: 34600, mean episode reward: -90.35269301506465, time: 26.125
agent0_energy_min, agent0_attention_min
[-18.16  -0.03]
agent1_energy_min, agent1_attention_min
[-1.21 -0.14]
34700 50
steps: 1734950, episodes: 34700, mean episode reward: -101.42284366938651, time: 24.932
agent0_energy_min, agent0_attention_min
[-19.07  -0.08]
agent1_energy_min, agent1_attention_min
[-1.01 -0.45]
34800 50
steps: 1739950, episodes: 34800, mean episode reward: -113.67079507227555, time: 24.741
agent0_energy_min, agent0_attention_min
[-18.93  -0.09]
agent1_energy_min, agent1_attention_min
[-0.41 -0.18]
34900 50
steps: 1744950, episodes: 34900, mean episode reward: -131.2322335244295, time: 24.308
agent0_energy_min, agent0_attention_min
[-19.61  -0.06]
agent1_energy_min, agent1_attention_min
[-0.59 -0.12]
35000 50
steps: 1749950, episodes: 35000, mean episode reward: -89.6144981902795, time: 24.661
agent0_energy_min, agent0_attention_min
[-2.051e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-0.19 -0.1 ]
35100 50
steps: 1754950, episodes: 35100, mean episode reward: -103.22429281531376, time: 25.051
agent0_energy_min, agent0_attention_min
[-22.9   -0.05]
agent1_energy_min, agent1_attention_min
[-0.37 -0.23]
35200 50
steps: 1759950, episodes: 35200, mean episode reward: -91.12352252227907, time: 24.637
agent0_energy_min, agent0_attention_min
[-20.82  -0.08]
agent1_energy_min, agent1_attention_min
[-0.65 -0.27]
35300 50
steps: 1764950, episodes: 35300, mean episode reward: -90.69778466488943, time: 24.72
agent0_energy_min, agent0_attention_min
[-23.99  -0.03]
agent1_energy_min, agent1_attention_min
[-1.   -0.61]
35400 50
steps: 1769950, episodes: 35400, mean episode reward: -110.083120474209, time: 26.484
agent0_energy_min, agent0_attention_min
[-26.41  -0.09]
agent1_energy_min, agent1_attention_min
[-1.1  -0.63]
35500 50
steps: 1774950, episodes: 35500, mean episode reward: -96.19141807603083, time: 24.769
agent0_energy_min, agent0_attention_min
[-15.93  -0.02]
agent1_energy_min, agent1_attention_min
[-0.74 -0.39]
35600 50
steps: 1779950, episodes: 35600, mean episode reward: -93.40498420632147, time: 25.007
agent0_energy_min, agent0_attention_min
[-10.74 -38.38]
31900 50
steps: 1594950, episodes: 31900, mean episode reward: -65.26311934705006, time: 24.071
agent0_energy_min, agent0_attention_min
[-18.36  -2.87]
agent1_energy_min, agent1_attention_min
[ -9.91 -39.67]
32000 50
steps: 1599950, episodes: 32000, mean episode reward: -72.59669627749497, time: 24.37
agent0_energy_min, agent0_attention_min
[-19.98  -3.15]
agent1_energy_min, agent1_attention_min
[-10.44 -38.25]
32100 50
steps: 1604950, episodes: 32100, mean episode reward: -74.23924291898817, time: 24.408
agent0_energy_min, agent0_attention_min
[-24.08  -1.5 ]
agent1_energy_min, agent1_attention_min
[ -8.55 -40.59]
32200 50
steps: 1609950, episodes: 32200, mean episode reward: -75.44224714083715, time: 24.867
agent0_energy_min, agent0_attention_min
[-24.74  -1.4 ]
agent1_energy_min, agent1_attention_min
[ -8.23 -38.48]
32300 50
steps: 1614950, episodes: 32300, mean episode reward: -66.77863055981032, time: 24.18
agent0_energy_min, agent0_attention_min
[-21.75  -1.22]
agent1_energy_min, agent1_attention_min
[ -9.31 -40.1 ]
32400 50
steps: 1619950, episodes: 32400, mean episode reward: -56.25350985676873, time: 24.693
agent0_energy_min, agent0_attention_min
[-20.53  -1.11]
agent1_energy_min, agent1_attention_min
[-10.37 -38.56]
32500 50
steps: 1624950, episodes: 32500, mean episode reward: -68.22461091089906, time: 24.425
agent0_energy_min, agent0_attention_min
[-16.76  -1.49]
agent1_energy_min, agent1_attention_min
[-12.22 -37.54]
32600 50
steps: 1629950, episodes: 32600, mean episode reward: -68.78927331525409, time: 25.527
agent0_energy_min, agent0_attention_min
[-19.61  -1.56]
agent1_energy_min, agent1_attention_min
[-11.17 -38.8 ]
32700 50
steps: 1634950, episodes: 32700, mean episode reward: -52.71255075188931, time: 24.098
agent0_energy_min, agent0_attention_min
[-16.19  -1.28]
agent1_energy_min, agent1_attention_min
[ -8.5  -41.31]
32800 50
steps: 1639950, episodes: 32800, mean episode reward: -64.29001331602153, time: 24.252
agent0_energy_min, agent0_attention_min
[-16.1   -3.24]
agent1_energy_min, agent1_attention_min
[ -9.69 -40.18]
32900 50
steps: 1644950, episodes: 32900, mean episode reward: -57.1191103617764, time: 24.554
agent0_energy_min, agent0_attention_min
[-15.7   -2.32]
agent1_energy_min, agent1_attention_min
[-10.08 -39.79]
33000 50
steps: 1649950, episodes: 33000, mean episode reward: -57.19871840815816, time: 24.66
agent0_energy_min, agent0_attention_min
[-15.66  -0.87]
agent1_energy_min, agent1_attention_min
[-10.26 -39.49]
33100 50
steps: 1654950, episodes: 33100, mean episode reward: -70.25658409267501, time: 25.021
agent0_energy_min, agent0_attention_min
[-19.93  -1.43]
agent1_energy_min, agent1_attention_min
[ -9.05 -40.89]
33200 50
steps: 1659950, episodes: 33200, mean episode reward: -45.296274773622024, time: 24.869
agent0_energy_min, agent0_attention_min
[-16.78  -0.78]
agent1_energy_min, agent1_attention_min
[ -8.44 -41.54]
33300 50
steps: 1664950, episodes: 33300, mean episode reward: -61.92793426316862, time: 25.056
agent0_energy_min, agent0_attention_min
[-18.92  -1.06]
agent1_energy_min, agent1_attention_min
[ -7.05 -42.83]
33400 50
steps: 1669950, episodes: 33400, mean episode reward: -57.707042859782696, time: 24.571
agent0_energy_min, agent0_attention_min
[-17.79  -0.98]
agent1_energy_min, agent1_attention_min
[ -8.66 -41.09]
33500 50
steps: 1674950, episodes: 33500, mean episode reward: -54.10685910569245, time: 24.483
agent0_energy_min, agent0_attention_min
[-16.69  -0.75]
agent1_energy_min, agent1_attention_min
[ -9.4  -40.21]
33600 50
steps: 1679950, episodes: 33600, mean episode reward: -58.50993282067081, time: 24.781
agent0_energy_min, agent0_attention_min
[-16.01  -0.94]
agent1_energy_min, agent1_attention_min
[ -8.75 -41.03]
33700 50
steps: 1684950, episodes: 33700, mean episode reward: -65.91501259401434, time: 24.209
agent0_energy_min, agent0_attention_min
[-17.38  -0.47]
agent1_energy_min, agent1_attention_min
[-12.24 -37.42]
33800 50
steps: 1689950, episodes: 33800, mean episode reward: -49.774828141357496, time: 24.772
agent0_energy_min, agent0_attention_min
[-17.28  -0.76]
agent1_energy_min, agent1_attention_min
[ -9.88 -40.  ]
33900 50
steps: 1694950, episodes: 33900, mean episode reward: -68.75231910058451, time: 24.757
agent0_energy_min, agent0_attention_min
[-15.67  -1.08]
agent1_energy_min, agent1_attention_min
[-13.28 -36.06]
34000 50
steps: 1699950, episodes: 34000, mean episode reward: -62.39731588626748, time: 24.536
agent0_energy_min, agent0_attention_min
[-17.6   -1.31]
agent1_energy_min, agent1_attention_min
[-12.75 -36.18]
34100 50
steps: 1704950, episodes: 34100, mean episode reward: -64.88185543092317, time: 25.225
agent0_energy_min, agent0_attention_min
[-15.52  -1.92]
agent1_energy_min, agent1_attention_min
[-11.43 -38.39]
34200 50
steps: 1709950, episodes: 34200, mean episode reward: -64.69087181880914, time: 25.029
agent0_energy_min, agent0_attention_min
[-14.86  -1.34]
agent1_energy_min, agent1_attention_min
[ -9.47 -39.89]
34300 50
steps: 1714950, episodes: 34300, mean episode reward: -88.98820476277234, time: 24.995
agent0_energy_min, agent0_attention_min
[-17.9   -1.44]
agent1_energy_min, agent1_attention_min
[-10.45 -38.47]
34400 50
steps: 1719950, episodes: 34400, mean episode reward: -75.67407136262028, time: 24.671
agent0_energy_min, agent0_attention_min
[-17.73  -0.87]
agent1_energy_min, agent1_attention_min
[-12.19 -36.57]
34500 50
steps: 1724950, episodes: 34500, mean episode reward: -74.83478633141027, time: 24.976
agent0_energy_min, agent0_attention_min
[-16.23  -1.47]
agent1_energy_min, agent1_attention_min
[-11.51 -37.8 ]
34600 50
steps: 1729950, episodes: 34600, mean episode reward: -88.02428638634346, time: 25.903
agent0_energy_min, agent0_attention_min
[-17.89  -1.02]
agent1_energy_min, agent1_attention_min
[-11.16 -38.18]
34700 50
steps: 1734950, episodes: 34700, mean episode reward: -107.15506173515752, time: 24.98
agent0_energy_min, agent0_attention_min
[-18.59  -2.21]
agent1_energy_min, agent1_attention_min
[-14.26 -34.66]
34800 50
steps: 1739950, episodes: 34800, mean episode reward: -132.67510662393846, time: 25.097
agent0_energy_min, agent0_attention_min
[-18.66  -2.5 ]
agent1_energy_min, agent1_attention_min
[-14.47 -33.76]
34900 50
steps: 1744950, episodes: 34900, mean episode reward: -58.974883766215754, time: 24.648
agent0_energy_min, agent0_attention_min
[-15.05  -1.65]
agent1_energy_min, agent1_attention_min
[-10.61 -38.6 ]
35000 50
steps: 1749950, episodes: 35000, mean episode reward: -72.158250643155, time: 24.243
agent0_energy_min, agent0_attention_min
[-18.07  -2.51]
agent1_energy_min, agent1_attention_min
[ -9.74 -39.01]
35100 50
steps: 1754950, episodes: 35100, mean episode reward: -57.895785750351955, time: 25.477
agent0_energy_min, agent0_attention_min
[-16.02  -1.21]
agent1_energy_min, agent1_attention_min
[ -8.9  -40.62]
35200 50
steps: 1759950, episodes: 35200, mean episode reward: -64.38879123648367, time: 24.303
agent0_energy_min, agent0_attention_min
[-15.67  -1.28]
agent1_energy_min, agent1_attention_min
[ -7.49 -42.38]
35300 50
steps: 1764950, episodes: 35300, mean episode reward: -90.47741092865303, time: 24.77
agent0_energy_min, agent0_attention_min
[-19.09  -1.2 ]
agent1_energy_min, agent1_attention_min
[ -7.92 -42.03]
35400 50
steps: 1769950, episodes: 35400, mean episode reward: -62.51068895904884, time: 24.445
agent0_energy_min, agent0_attention_min
[-18.15  -1.01]
agent1_energy_min, agent1_attention_min
[ -7.65 -42.3 ]
35500 50
steps: 1774950, episodes: 35500, mean episode reward: -58.57833727715754, time: 25.08
agent0_energy_min, agent0_attention_min
[-18.04  -0.84]
agent1_energy_min, agent1_attention_min
[ -6.25 -43.71]
35600 50
steps: 1779950, episodes: 35600, mean episode reward: -51.317030646350844, time: 25.347
agent0_energy_min, agent0_attention_min
[-16.17  -1.13]
agent1_energy_min, agent1_attention_min
[ -5.89 -43.99]
35700 50
steps: 1784950, episodes: 35700, mean episode reward: -54.63928433988568, time: 24.605
agent0_energy_min, agent0_attention_min
[-15.62  -0.83]
agent1_energy_min, agent1_attention_min
[ -8.02 -41.93]
35800 50
steps: 1789950, episodes: 35800, mean episode reward: -71.7669243537128, time: 24.468[-49.58  -0.17]
35300 50
steps: 1764950, episodes: 35300, mean episode reward: -69.12153376373209, time: 23.985
agent0_energy_min, agent0_attention_min
[-48.76  -1.2 ]
agent1_energy_min, agent1_attention_min
[-4.974e+01 -2.000e-02]
35400 50
steps: 1769950, episodes: 35400, mean episode reward: -69.1013548114041, time: 24.124
agent0_energy_min, agent0_attention_min
[-48.93  -1.03]
agent1_energy_min, agent1_attention_min
[-49.67  -0.07]
35500 50
steps: 1774950, episodes: 35500, mean episode reward: -67.68591762611227, time: 24.081
agent0_energy_min, agent0_attention_min
[-49.12  -0.86]
agent1_energy_min, agent1_attention_min
[-49.69  -0.06]
35600 50
steps: 1779950, episodes: 35600, mean episode reward: -70.34623463928989, time: 24.761
agent0_energy_min, agent0_attention_min
[-49.61  -0.37]
agent1_energy_min, agent1_attention_min
[-49.34  -0.35]
35700 50
steps: 1784950, episodes: 35700, mean episode reward: -70.37932692129421, time: 23.996
agent0_energy_min, agent0_attention_min
[-48.79  -1.2 ]
agent1_energy_min, agent1_attention_min
[-49.23  -0.5 ]
35800 50
steps: 1789950, episodes: 35800, mean episode reward: -63.97445548634056, time: 24.252
agent0_energy_min, agent0_attention_min
[-49.41  -0.58]
agent1_energy_min, agent1_attention_min
[-49.57  -0.26]
35900 50
steps: 1794950, episodes: 35900, mean episode reward: -64.8723054525108, time: 23.762
agent0_energy_min, agent0_attention_min
[-49.15  -0.83]
agent1_energy_min, agent1_attention_min
[-48.68  -1.19]
36000 50
steps: 1799950, episodes: 36000, mean episode reward: -68.7472805651844, time: 23.972
agent0_energy_min, agent0_attention_min
[-48.8   -1.19]
agent1_energy_min, agent1_attention_min
[-49.14  -0.64]
36100 50
steps: 1804950, episodes: 36100, mean episode reward: -66.25521425868713, time: 24.524
agent0_energy_min, agent0_attention_min
[-49.66  -0.29]
agent1_energy_min, agent1_attention_min
[-49.65  -0.16]
36200 50
steps: 1809950, episodes: 36200, mean episode reward: -63.33676101970322, time: 24.441
agent0_energy_min, agent0_attention_min
[-4.997e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-49.69  -0.09]
36300 50
steps: 1814950, episodes: 36300, mean episode reward: -94.25199395213407, time: 24.603
agent0_energy_min, agent0_attention_min
[-49.93  -0.05]
agent1_energy_min, agent1_attention_min
[-49.46  -0.22]
36400 50
steps: 1819950, episodes: 36400, mean episode reward: -70.78026575375901, time: 24.338
agent0_energy_min, agent0_attention_min
[-47.39  -0.87]
agent1_energy_min, agent1_attention_min
[-49.38  -0.24]
36500 50
steps: 1824950, episodes: 36500, mean episode reward: -113.69022797318492, time: 24.156
agent0_energy_min, agent0_attention_min
[-37.74  -0.06]
agent1_energy_min, agent1_attention_min
[-47.19  -2.56]
36600 50
steps: 1829950, episodes: 36600, mean episode reward: -78.37422112236464, time: 24.135
agent0_energy_min, agent0_attention_min
[-4.108e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-4.985e+01 -1.000e-02]
36700 50
steps: 1834950, episodes: 36700, mean episode reward: -64.57941154016954, time: 23.758
agent0_energy_min, agent0_attention_min
[-4.207e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-4.987e+01 -1.000e-02]
36800 50
steps: 1839950, episodes: 36800, mean episode reward: -65.34175291155175, time: 24.104
agent0_energy_min, agent0_attention_min
[-46.44  -0.05]
agent1_energy_min, agent1_attention_min
[-49.88   0.  ]
36900 50
steps: 1844950, episodes: 36900, mean episode reward: -70.96312500516069, time: 24.523
agent0_energy_min, agent0_attention_min
[-47.76   0.  ]
agent1_energy_min, agent1_attention_min
[-49.56   0.  ]
37000 50
steps: 1849950, episodes: 37000, mean episode reward: -75.39060898349325, time: 24.142
agent0_energy_min, agent0_attention_min
[-4.717e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-49.86   0.  ]
37100 50
steps: 1854950, episodes: 37100, mean episode reward: -68.27782803986618, time: 24.552
agent0_energy_min, agent0_attention_min
[-49.07   0.  ]
agent1_energy_min, agent1_attention_min
[-4.964e+01 -1.000e-02]
37200 50
steps: 1859950, episodes: 37200, mean episode reward: -73.77789137113547, time: 23.743
agent0_energy_min, agent0_attention_min
[-4.978e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-49.63  -0.17]
37300 50
steps: 1864950, episodes: 37300, mean episode reward: -77.49114700882433, time: 24.119
agent0_energy_min, agent0_attention_min
[-4.996e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-49.02  -0.64]
37400 50
steps: 1869950, episodes: 37400, mean episode reward: -67.60687955924249, time: 24.176
agent0_energy_min, agent0_attention_min
[-4.998e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-48.27  -1.34]
37500 50
steps: 1874950, episodes: 37500, mean episode reward: -76.35093880025812, time: 24.591
agent0_energy_min, agent0_attention_min
[-49.99   0.  ]
agent1_energy_min, agent1_attention_min
[-46.66  -3.07]
37600 50
steps: 1879950, episodes: 37600, mean episode reward: -90.04644368129975, time: 24.911
agent0_energy_min, agent0_attention_min
[-4.999e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-44.74  -4.8 ]
37700 50
steps: 1884950, episodes: 37700, mean episode reward: -91.40372746894627, time: 23.951
agent0_energy_min, agent0_attention_min
[-4.986e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-43.49  -5.84]
37800 50
steps: 1889950, episodes: 37800, mean episode reward: -84.19613489582491, time: 24.227
agent0_energy_min, agent0_attention_min
[-4.542e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-46.26  -3.31]
37900 50
steps: 1894950, episodes: 37900, mean episode reward: -86.16729573444009, time: 24.273
agent0_energy_min, agent0_attention_min
[-4.832e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-44.2   -5.51]
38000 50
steps: 1899950, episodes: 38000, mean episode reward: -83.07630773120368, time: 24.413
agent0_energy_min, agent0_attention_min
[-49.26   0.  ]
agent1_energy_min, agent1_attention_min
[-44.89  -4.73]
38100 50
steps: 1904950, episodes: 38100, mean episode reward: -79.30040712866133, time: 24.273
agent0_energy_min, agent0_attention_min
[-4.826e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-49.4   -0.34]
38200 50
steps: 1909950, episodes: 38200, mean episode reward: -80.58204981905915, time: 24.205
agent0_energy_min, agent0_attention_min
[-4.824e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-49.8   0. ]
38300 50
steps: 1914950, episodes: 38300, mean episode reward: -73.26934137700195, time: 24.311
agent0_energy_min, agent0_attention_min
[-4.913e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-49.79   0.  ]
38400 50
steps: 1919950, episodes: 38400, mean episode reward: -113.65016844643893, time: 24.237
agent0_energy_min, agent0_attention_min
[-4.886e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-49.66   0.  ]
38500 50
steps: 1924950, episodes: 38500, mean episode reward: -69.30365572794021, time: 24.025
agent0_energy_min, agent0_attention_min
[-4.166e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-4.981e+01 -2.000e-02]
38600 50
steps: 1929950, episodes: 38600, mean episode reward: -79.19804656601457, time: 24.656
agent0_energy_min, agent0_attention_min
[-3.578e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-49.14   0.  ]
38700 50
steps: 1934950, episodes: 38700, mean episode reward: -102.79042519669622, time: 24.106
agent0_energy_min, agent0_attention_min
[-36.96  -0.28]
agent1_energy_min, agent1_attention_min
[-4.974e+01 -2.000e-02]
38800 50
steps: 1939950, episodes: 38800, mean episode reward: -71.8281032952611, time: 24.482
agent0_energy_min, agent0_attention_min
[-48.09  -1.12]
agent1_energy_min, agent1_attention_min
[-4.962e+01 -1.000e-02]
38900 50
steps: 1944950, episodes: 38900, mean episode reward: -64.72590518088337, time: 24.642
agent0_energy_min, agent0_attention_min
[-49.59  -0.39]
agent1_energy_min, agent1_attention_min
[-4.968e+01 -2.000e-02]
39000 50
steps: 1949950, episodes: 39000, mean episode reward: -80.74051351375333, time: 24.174
agent0_energy_min, agent0_attention_min
[-49.92  -0.06]
agent1_energy_min, agent1_attention_min
[-49.87   0.  ]
39100 50
steps: 1954950, episodes: 39100, mean episode reward: -196.39901777140403, time: 24.516
agent1_energy_min, agent1_attention_min
[-20.44  -0.35]
35300 50
steps: 1764950, episodes: 35300, mean episode reward: -75.51128046624478, time: 23.697
agent0_energy_min, agent0_attention_min
[-40.08  -0.61]
agent1_energy_min, agent1_attention_min
[-17.82  -1.18]
35400 50
steps: 1769950, episodes: 35400, mean episode reward: -78.62405444322506, time: 23.729
agent0_energy_min, agent0_attention_min
[-43.43  -0.15]
agent1_energy_min, agent1_attention_min
[-15.61  -1.92]
35500 50
steps: 1774950, episodes: 35500, mean episode reward: -83.5782721223551, time: 24.001
agent0_energy_min, agent0_attention_min
[-41.87  -0.33]
agent1_energy_min, agent1_attention_min
[-18.27  -1.77]
35600 50
steps: 1779950, episodes: 35600, mean episode reward: -64.25110028453018, time: 25.139
agent0_energy_min, agent0_attention_min
[-42.02  -0.43]
agent1_energy_min, agent1_attention_min
[-20.05  -1.65]
35700 50
steps: 1784950, episodes: 35700, mean episode reward: -66.86804038339552, time: 23.98
agent0_energy_min, agent0_attention_min
[-41.32  -0.34]
agent1_energy_min, agent1_attention_min
[-20.41  -2.68]
35800 50
steps: 1789950, episodes: 35800, mean episode reward: -74.95554569134066, time: 24.061
agent0_energy_min, agent0_attention_min
[-45.7   -0.54]
agent1_energy_min, agent1_attention_min
[-24.7   -3.13]
35900 50
steps: 1794950, episodes: 35900, mean episode reward: -80.87995950038864, time: 24.158
agent0_energy_min, agent0_attention_min
[-42.12  -2.12]
agent1_energy_min, agent1_attention_min
[-24.1   -2.53]
36000 50
steps: 1799950, episodes: 36000, mean episode reward: -69.78594148871798, time: 23.628
agent0_energy_min, agent0_attention_min
[-42.75  -0.26]
agent1_energy_min, agent1_attention_min
[-21.13  -0.58]
36100 50
steps: 1804950, episodes: 36100, mean episode reward: -67.84499407156008, time: 25.131
agent0_energy_min, agent0_attention_min
[-4.159e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-21.94  -0.48]
36200 50
steps: 1809950, episodes: 36200, mean episode reward: -68.21582411545194, time: 24.44
agent0_energy_min, agent0_attention_min
[-35.32  -0.04]
agent1_energy_min, agent1_attention_min
[-19.32  -0.65]
36300 50
steps: 1814950, episodes: 36300, mean episode reward: -56.91371716174536, time: 23.873
agent0_energy_min, agent0_attention_min
[-37.16  -0.14]
agent1_energy_min, agent1_attention_min
[-18.95  -1.13]
36400 50
steps: 1819950, episodes: 36400, mean episode reward: -82.42054842384354, time: 23.932
agent0_energy_min, agent0_attention_min
[-4.061e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-24.33  -1.15]
36500 50
steps: 1824950, episodes: 36500, mean episode reward: -71.79807265368062, time: 23.797
agent0_energy_min, agent0_attention_min
[-3.928e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-23.56  -2.84]
36600 50
steps: 1829950, episodes: 36600, mean episode reward: -71.7066673946771, time: 24.969
agent0_energy_min, agent0_attention_min
[-39.32  -0.04]
agent1_energy_min, agent1_attention_min
[-21.62  -2.77]
36700 50
steps: 1834950, episodes: 36700, mean episode reward: -60.220912366385534, time: 24.099
agent0_energy_min, agent0_attention_min
[-40.97  -0.05]
agent1_energy_min, agent1_attention_min
[-21.91  -1.1 ]
36800 50
steps: 1839950, episodes: 36800, mean episode reward: -70.11027383214879, time: 24.017
agent0_energy_min, agent0_attention_min
[-3.991e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-21.23  -0.63]
36900 50
steps: 1844950, episodes: 36900, mean episode reward: -73.73183555624836, time: 23.659
agent0_energy_min, agent0_attention_min
[-41.71  -0.1 ]
agent1_energy_min, agent1_attention_min
[-24.71  -0.27]
37000 50
steps: 1849950, episodes: 37000, mean episode reward: -84.4214710003021, time: 24.39
agent0_energy_min, agent0_attention_min
[-41.72  -0.07]
agent1_energy_min, agent1_attention_min
[-23.48  -0.08]
37100 50
steps: 1854950, episodes: 37100, mean episode reward: -93.82369230242615, time: 24.512
agent0_energy_min, agent0_attention_min
[-3.784e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-26.68  -0.09]
37200 50
steps: 1859950, episodes: 37200, mean episode reward: -55.33659113369516, time: 24.6
agent0_energy_min, agent0_attention_min
[-39.83  -0.04]
agent1_energy_min, agent1_attention_min
[-16.81  -0.06]
37300 50
steps: 1864950, episodes: 37300, mean episode reward: -63.924975026835135, time: 24.043
agent0_energy_min, agent0_attention_min
[-45.55  -0.05]
agent1_energy_min, agent1_attention_min
[-19.02  -0.13]
37400 50
steps: 1869950, episodes: 37400, mean episode reward: -82.23562652367673, time: 23.738
agent0_energy_min, agent0_attention_min
[-41.74  -0.39]
agent1_energy_min, agent1_attention_min
[-24.26  -0.46]
37500 50
steps: 1874950, episodes: 37500, mean episode reward: -64.72837076949159, time: 24.418
agent0_energy_min, agent0_attention_min
[-43.01  -0.14]
agent1_energy_min, agent1_attention_min
[-23.03  -0.47]
37600 50
steps: 1879950, episodes: 37600, mean episode reward: -85.45098021613818, time: 24.867
agent0_energy_min, agent0_attention_min
[-41.87   0.  ]
agent1_energy_min, agent1_attention_min
[-22.62  -0.16]
37700 50
steps: 1884950, episodes: 37700, mean episode reward: -68.25432101152529, time: 24.309
agent0_energy_min, agent0_attention_min
[-3.794e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-27.49  -0.11]
37800 50
steps: 1889950, episodes: 37800, mean episode reward: -71.40909830197354, time: 24.185
agent0_energy_min, agent0_attention_min
[-4.e+01 -1.e-02]
agent1_energy_min, agent1_attention_min
[-36.6   -0.25]
37900 50
steps: 1894950, episodes: 37900, mean episode reward: -69.28511442004763, time: 24.202
agent0_energy_min, agent0_attention_min
[-44.38   0.  ]
agent1_energy_min, agent1_attention_min
[-33.48  -0.23]
38000 50
steps: 1899950, episodes: 38000, mean episode reward: -74.7232994563958, time: 24.09
agent0_energy_min, agent0_attention_min
[-4.308e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-29.62  -0.12]
38100 50
steps: 1904950, episodes: 38100, mean episode reward: -67.08248842885618, time: 24.284
agent0_energy_min, agent0_attention_min
[-4.442e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-29.83  -0.21]
38200 50
steps: 1909950, episodes: 38200, mean episode reward: -60.25655638077867, time: 24.414
agent0_energy_min, agent0_attention_min
[-4.418e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-27.9   -1.01]
38300 50
steps: 1914950, episodes: 38300, mean episode reward: -88.05480171639732, time: 24.304
agent0_energy_min, agent0_attention_min
[-43.16  -0.59]
agent1_energy_min, agent1_attention_min
[-24.43  -2.08]
38400 50
steps: 1919950, episodes: 38400, mean episode reward: -120.57879129170378, time: 24.128
agent0_energy_min, agent0_attention_min
[-42.92  -1.09]
agent1_energy_min, agent1_attention_min
[-21.19  -1.57]
38500 50
steps: 1924950, episodes: 38500, mean episode reward: -72.45426478713217, time: 24.314
agent0_energy_min, agent0_attention_min
[-4.622e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-21.74  -2.95]
38600 50
steps: 1929950, episodes: 38600, mean episode reward: -90.29262179057545, time: 24.613
agent0_energy_min, agent0_attention_min
[-42.2   0. ]
agent1_energy_min, agent1_attention_min
[-21.73  -0.86]
38700 50
steps: 1934950, episodes: 38700, mean episode reward: -71.56955156332101, time: 24.506
agent0_energy_min, agent0_attention_min
[-4.457e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-20.22  -0.81]
38800 50
steps: 1939950, episodes: 38800, mean episode reward: -61.35633818590399, time: 24.228
agent0_energy_min, agent0_attention_min
[-4.315e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-19.59  -0.15]
38900 50
steps: 1944950, episodes: 38900, mean episode reward: -70.57309069975163, time: 24.767
agent0_energy_min, agent0_attention_min
[-4.255e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-22.28  -0.27]
39000 50
steps: 1949950, episodes: 39000, mean episode reward: -63.46531730544673, time: 23.983
agent0_energy_min, agent0_attention_min
[-4.314e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-18.75  -0.4 ]
39100 50
steps: 1954950, episodes: 39100, mean episode reward: -66.08549465860436, time: 24.547
agent0_energy_min, agent0_attention_minagent0_energy_min, agent0_attention_min
[-46.78  -0.15]
agent1_energy_min, agent1_attention_min
[-24.49  -5.19]
35500 50
steps: 1774950, episodes: 35500, mean episode reward: -87.41615997090933, time: 24.484
agent0_energy_min, agent0_attention_min
[-4.866e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-25.59  -9.61]
35600 50
steps: 1779950, episodes: 35600, mean episode reward: -49.09354207168686, time: 24.864
agent0_energy_min, agent0_attention_min
[-47.09  -0.09]
agent1_energy_min, agent1_attention_min
[-25.42 -12.85]
35700 50
steps: 1784950, episodes: 35700, mean episode reward: -85.8452539306642, time: 24.175
agent0_energy_min, agent0_attention_min
[-44.36  -0.09]
agent1_energy_min, agent1_attention_min
[-22.  -13.9]
35800 50
steps: 1789950, episodes: 35800, mean episode reward: -60.09220090621404, time: 24.303
agent0_energy_min, agent0_attention_min
[-45.12  -0.12]
agent1_energy_min, agent1_attention_min
[-19.24 -13.98]
35900 50
steps: 1794950, episodes: 35900, mean episode reward: -67.18945122711958, time: 23.903
agent0_energy_min, agent0_attention_min
[-45.23  -0.17]
agent1_energy_min, agent1_attention_min
[-22.81 -11.98]
36000 50
steps: 1799950, episodes: 36000, mean episode reward: -71.36471240505688, time: 24.361
agent0_energy_min, agent0_attention_min
[-39.43  -0.14]
agent1_energy_min, agent1_attention_min
[-23.17 -13.84]
36100 50
steps: 1804950, episodes: 36100, mean episode reward: -66.2905982461702, time: 24.805
agent0_energy_min, agent0_attention_min
[-34.29  -0.05]
agent1_energy_min, agent1_attention_min
[-19.34 -16.52]
36200 50
steps: 1809950, episodes: 36200, mean episode reward: -60.19078821270825, time: 24.268
agent0_energy_min, agent0_attention_min
[-42.72  -0.12]
agent1_energy_min, agent1_attention_min
[-19.42 -13.55]
36300 50
steps: 1814950, episodes: 36300, mean episode reward: -74.27628174461783, time: 23.928
agent0_energy_min, agent0_attention_min
[-32.12  -0.11]
agent1_energy_min, agent1_attention_min
[-16.98 -20.06]
36400 50
steps: 1819950, episodes: 36400, mean episode reward: -66.9947054588862, time: 25.229
agent0_energy_min, agent0_attention_min
[-25.43  -0.03]
agent1_energy_min, agent1_attention_min
[-23.98 -17.33]
36500 50
steps: 1824950, episodes: 36500, mean episode reward: -61.22522147256076, time: 24.21
agent0_energy_min, agent0_attention_min
[-37.97  -0.08]
agent1_energy_min, agent1_attention_min
[-28.22 -13.39]
36600 50
steps: 1829950, episodes: 36600, mean episode reward: -57.42184898442879, time: 24.437
agent0_energy_min, agent0_attention_min
[-29.68  -0.05]
agent1_energy_min, agent1_attention_min
[-28.03 -13.91]
36700 50
steps: 1834950, episodes: 36700, mean episode reward: -63.55361784490232, time: 24.379
agent0_energy_min, agent0_attention_min
[-33.55  -0.95]
agent1_energy_min, agent1_attention_min
[-18.36 -17.08]
36800 50
steps: 1839950, episodes: 36800, mean episode reward: -47.81483451052984, time: 23.854
agent0_energy_min, agent0_attention_min
[-29.48  -0.19]
agent1_energy_min, agent1_attention_min
[-22.48 -14.53]
36900 50
steps: 1844950, episodes: 36900, mean episode reward: -45.78334068243937, time: 23.947
agent0_energy_min, agent0_attention_min
[-27.03  -0.13]
agent1_energy_min, agent1_attention_min
[-28.05 -13.31]
37000 50
steps: 1849950, episodes: 37000, mean episode reward: -64.19542196092901, time: 23.86
agent0_energy_min, agent0_attention_min
[-27.8   -1.38]
agent1_energy_min, agent1_attention_min
[-23.89 -16.21]
37100 50
steps: 1854950, episodes: 37100, mean episode reward: -57.75240471306731, time: 24.833
agent0_energy_min, agent0_attention_min
[-26.87  -0.63]
agent1_energy_min, agent1_attention_min
[-29.02 -10.04]
37200 50
steps: 1859950, episodes: 37200, mean episode reward: -50.630797014736935, time: 24.28
agent0_energy_min, agent0_attention_min
[-28.3   -0.17]
agent1_energy_min, agent1_attention_min
[-27.29 -11.41]
37300 50
steps: 1864950, episodes: 37300, mean episode reward: -90.12603355400896, time: 24.369
agent0_energy_min, agent0_attention_min
[-25.64  -0.55]
agent1_energy_min, agent1_attention_min
[-22.53 -12.83]
37400 50
steps: 1869950, episodes: 37400, mean episode reward: -78.29289204726042, time: 24.083
agent0_energy_min, agent0_attention_min
[-26.55  -0.62]
agent1_energy_min, agent1_attention_min
[-16.97 -12.52]
37500 50
steps: 1874950, episodes: 37500, mean episode reward: -50.7092960365534, time: 24.263
agent0_energy_min, agent0_attention_min
[-25.59  -0.28]
agent1_energy_min, agent1_attention_min
[-21.63  -3.98]
37600 50
steps: 1879950, episodes: 37600, mean episode reward: -362.7958623115784, time: 25.119
agent0_energy_min, agent0_attention_min
[-24.07  -0.2 ]
agent1_energy_min, agent1_attention_min
[-13.33  -3.33]
37700 50
steps: 1884950, episodes: 37700, mean episode reward: -80.80514280538414, time: 24.251
agent0_energy_min, agent0_attention_min
[-29.51  -0.3 ]
agent1_energy_min, agent1_attention_min
[-40.93  -3.17]
37800 50
steps: 1889950, episodes: 37800, mean episode reward: -53.90884703558432, time: 24.078
agent0_energy_min, agent0_attention_min
[-24.38  -0.37]
agent1_energy_min, agent1_attention_min
[-36.17  -4.91]
37900 50
steps: 1894950, episodes: 37900, mean episode reward: -65.15473165739641, time: 24.07
agent0_energy_min, agent0_attention_min
[-27.51  -0.61]
agent1_energy_min, agent1_attention_min
[-38.02  -5.37]
38000 50
steps: 1899950, episodes: 38000, mean episode reward: -53.88638374631186, time: 24.402
agent0_energy_min, agent0_attention_min
[-31.    -0.42]
agent1_energy_min, agent1_attention_min
[-37.82  -4.81]
38100 50
steps: 1904950, episodes: 38100, mean episode reward: -56.04479077333612, time: 24.557
agent0_energy_min, agent0_attention_min
[-37.36  -0.51]
agent1_energy_min, agent1_attention_min
[-39.77  -3.17]
38200 50
steps: 1909950, episodes: 38200, mean episode reward: -147.3399959159664, time: 24.68
agent0_energy_min, agent0_attention_min
[-34.65  -2.89]
agent1_energy_min, agent1_attention_min
[-38.58  -3.65]
38300 50
steps: 1914950, episodes: 38300, mean episode reward: -175.09162652213442, time: 24.436
agent0_energy_min, agent0_attention_min
[-34.44  -1.38]
agent1_energy_min, agent1_attention_min
[-36.52  -6.28]
38400 50
steps: 1919950, episodes: 38400, mean episode reward: -80.99085483329358, time: 24.217
agent0_energy_min, agent0_attention_min
[-38.05  -0.06]
agent1_energy_min, agent1_attention_min
[-33.38  -6.33]
38500 50
steps: 1924950, episodes: 38500, mean episode reward: -68.13780372529442, time: 24.143
agent0_energy_min, agent0_attention_min
[-39.45  -0.06]
agent1_energy_min, agent1_attention_min
[-38.79  -4.45]
38600 50
steps: 1929950, episodes: 38600, mean episode reward: -77.7747399455504, time: 24.959
agent0_energy_min, agent0_attention_min
[-42.03  -0.09]
agent1_energy_min, agent1_attention_min
[-34.67 -12.13]
38700 50
steps: 1934950, episodes: 38700, mean episode reward: -118.16590735885184, time: 23.976
agent0_energy_min, agent0_attention_min
[-35.45  -0.04]
agent1_energy_min, agent1_attention_min
[-31.66 -12.73]
38800 50
steps: 1939950, episodes: 38800, mean episode reward: -90.80855777843908, time: 24.491
agent0_energy_min, agent0_attention_min
[-39.1   -0.08]
agent1_energy_min, agent1_attention_min
[-36.79  -7.2 ]
38900 50
steps: 1944950, episodes: 38900, mean episode reward: -84.09024873888517, time: 24.13
agent0_energy_min, agent0_attention_min
[-44.74  -0.08]
agent1_energy_min, agent1_attention_min
[-29.51  -8.16]
39000 50
steps: 1949950, episodes: 39000, mean episode reward: -86.70495147069254, time: 24.335
agent0_energy_min, agent0_attention_min
[-44.07  -0.06]
agent1_energy_min, agent1_attention_min
[-29.54  -8.41]
39100 50
steps: 1954950, episodes: 39100, mean episode reward: -101.34535410110391, time: 23.984
agent0_energy_min, agent0_attention_min
[-43.82  -0.26]
agent1_energy_min, agent1_attention_min
[-28.74  -9.72]
39200 50
steps: 1959950, episodes: 39200, mean episode reward: -77.13472597001429, time: 23.703
agent0_energy_min, agent0_attention_min
[-41.8   -1.67]
agent1_energy_min, agent1_attention_min
[-23.11  -6.66]
39300 50
steps: 1964950, episodes: 39300, mean episode reward: -95.73535647124174, time: 24.911
agent0_energy_min, agent0_attention_min
[-41.9   -0.25]
agent1_energy_min, agent1_attention_min
35500 50
steps: 1774950, episodes: 35500, mean episode reward: -62.202471216602504, time: 24.431
agent0_energy_min, agent0_attention_min
[-4.686e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-4.542e+01 -1.000e-02]
35600 50
steps: 1779950, episodes: 35600, mean episode reward: -51.03697181114945, time: 25.36
agent0_energy_min, agent0_attention_min
[-4.192e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-4.734e+01 -1.000e-02]
35700 50
steps: 1784950, episodes: 35700, mean episode reward: -65.92589631710301, time: 24.691
agent0_energy_min, agent0_attention_min
[-4.21e+01 -1.00e-02]
agent1_energy_min, agent1_attention_min
[-46.57  -0.05]
35800 50
steps: 1789950, episodes: 35800, mean episode reward: -72.60721149137001, time: 24.121
agent0_energy_min, agent0_attention_min
[-39.47  -0.05]
agent1_energy_min, agent1_attention_min
[-45.7   -0.44]
35900 50
steps: 1794950, episodes: 35900, mean episode reward: -71.51982792139697, time: 23.778
agent0_energy_min, agent0_attention_min
[-44.53  -0.06]
agent1_energy_min, agent1_attention_min
[-45.81  -1.62]
36000 50
steps: 1799950, episodes: 36000, mean episode reward: -70.72393879609912, time: 24.802
agent0_energy_min, agent0_attention_min
[-45.95  -0.05]
agent1_energy_min, agent1_attention_min
[-49.19  -0.2 ]
36100 50
steps: 1804950, episodes: 36100, mean episode reward: -58.00119584197024, time: 25.233
agent0_energy_min, agent0_attention_min
[-47.15  -0.05]
agent1_energy_min, agent1_attention_min
[-48.98  -0.32]
36200 50
steps: 1809950, episodes: 36200, mean episode reward: -52.462952198538616, time: 25.359
agent0_energy_min, agent0_attention_min
[-46.95  -0.55]
agent1_energy_min, agent1_attention_min
[-49.1   -0.38]
36300 50
steps: 1814950, episodes: 36300, mean episode reward: -58.03431124020362, time: 24.768
agent0_energy_min, agent0_attention_min
[-47.49  -0.4 ]
agent1_energy_min, agent1_attention_min
[-48.45  -0.76]
36400 50
steps: 1819950, episodes: 36400, mean episode reward: -49.48270533292659, time: 24.975
agent0_energy_min, agent0_attention_min
[-47.22  -0.16]
agent1_energy_min, agent1_attention_min
[-49.21  -0.22]
36500 50
steps: 1824950, episodes: 36500, mean episode reward: -65.18145189752651, time: 24.513
agent0_energy_min, agent0_attention_min
[-4.884e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-47.07  -0.75]
36600 50
steps: 1829950, episodes: 36600, mean episode reward: -67.70440337721863, time: 24.863
agent0_energy_min, agent0_attention_min
[-46.54  -0.06]
agent1_energy_min, agent1_attention_min
[-43.79  -0.21]
36700 50
steps: 1834950, episodes: 36700, mean episode reward: -56.84701784821317, time: 24.127
agent0_energy_min, agent0_attention_min
[-47.    -0.11]
agent1_energy_min, agent1_attention_min
[-43.96   0.  ]
36800 50
steps: 1839950, episodes: 36800, mean episode reward: -61.49378719070044, time: 24.258
agent0_energy_min, agent0_attention_min
[-44.99  -0.08]
agent1_energy_min, agent1_attention_min
[-4.904e+01 -1.000e-02]
36900 50
steps: 1844950, episodes: 36900, mean episode reward: -80.45959576425788, time: 24.091
agent0_energy_min, agent0_attention_min
[-43.2   -1.02]
agent1_energy_min, agent1_attention_min
[-4.688e+01 -2.000e-02]
37000 50
steps: 1849950, episodes: 37000, mean episode reward: -55.078057634699846, time: 24.552
agent0_energy_min, agent0_attention_min
[-41.07  -2.15]
agent1_energy_min, agent1_attention_min
[-4.612e+01 -3.000e-02]
37100 50
steps: 1854950, episodes: 37100, mean episode reward: -60.558896523615495, time: 24.764
agent0_energy_min, agent0_attention_min
[-42.98  -2.59]
agent1_energy_min, agent1_attention_min
[-4.643e+01 -3.000e-02]
37200 50
steps: 1859950, episodes: 37200, mean episode reward: -59.4807068564846, time: 24.759
agent0_energy_min, agent0_attention_min
[-40.03  -3.87]
agent1_energy_min, agent1_attention_min
[-4.692e+01 -2.000e-02]
37300 50
steps: 1864950, episodes: 37300, mean episode reward: -52.66310637564346, time: 24.623
agent0_energy_min, agent0_attention_min
[-42.57  -3.92]
agent1_energy_min, agent1_attention_min
[-4.269e+01 -4.000e-02]
37400 50
steps: 1869950, episodes: 37400, mean episode reward: -82.6135171537592, time: 24.383
agent0_energy_min, agent0_attention_min
[-42.03  -6.85]
agent1_energy_min, agent1_attention_min
[-47.53  -0.05]
37500 50
steps: 1874950, episodes: 37500, mean episode reward: -53.487405895516105, time: 24.641
agent0_energy_min, agent0_attention_min
[-46.31  -1.92]
agent1_energy_min, agent1_attention_min
[-47.96  -0.05]
37600 50
steps: 1879950, episodes: 37600, mean episode reward: -56.09313004781468, time: 25.455
agent0_energy_min, agent0_attention_min
[-44.53  -1.01]
agent1_energy_min, agent1_attention_min
[-4.887e+01 -1.000e-02]
37700 50
steps: 1884950, episodes: 37700, mean episode reward: -63.420001781878845, time: 24.552
agent0_energy_min, agent0_attention_min
[-41.99  -1.33]
agent1_energy_min, agent1_attention_min
[-4.793e+01 -4.000e-02]
37800 50
steps: 1889950, episodes: 37800, mean episode reward: -69.31477690062576, time: 24.9
agent0_energy_min, agent0_attention_min
[-39.76  -1.39]
agent1_energy_min, agent1_attention_min
[-49.57  -0.21]
37900 50
steps: 1894950, episodes: 37900, mean episode reward: -70.30869694816433, time: 24.495
agent0_energy_min, agent0_attention_min
[-40.47  -2.13]
agent1_energy_min, agent1_attention_min
[-49.39  -0.21]
38000 50
steps: 1899950, episodes: 38000, mean episode reward: -50.67230482399084, time: 24.952
agent0_energy_min, agent0_attention_min
[-42.55  -0.51]
agent1_energy_min, agent1_attention_min
[-49.36  -0.37]
38100 50
steps: 1904950, episodes: 38100, mean episode reward: -70.32209535931673, time: 25.213
agent0_energy_min, agent0_attention_min
[-44.82  -0.07]
agent1_energy_min, agent1_attention_min
[-47.84  -0.39]
38200 50
steps: 1909950, episodes: 38200, mean episode reward: -156.15075399707447, time: 24.776
agent0_energy_min, agent0_attention_min
[-40.97  -0.12]
agent1_energy_min, agent1_attention_min
[-42.08  -0.2 ]
38300 50
steps: 1914950, episodes: 38300, mean episode reward: -73.45584888938247, time: 25.111
agent0_energy_min, agent0_attention_min
[-42.67  -0.22]
agent1_energy_min, agent1_attention_min
[-46.92   0.  ]
38400 50
steps: 1919950, episodes: 38400, mean episode reward: -55.80793722889664, time: 24.647
agent0_energy_min, agent0_attention_min
[-45.48  -0.56]
agent1_energy_min, agent1_attention_min
[-4.762e+01 -4.000e-02]
38500 50
steps: 1924950, episodes: 38500, mean episode reward: -53.16815461612557, time: 24.673
agent0_energy_min, agent0_attention_min
[-41.46  -0.58]
agent1_energy_min, agent1_attention_min
[-46.75  -0.14]
38600 50
steps: 1929950, episodes: 38600, mean episode reward: -45.35743678979693, time: 25.498
agent0_energy_min, agent0_attention_min
[-40.6   -1.62]
agent1_energy_min, agent1_attention_min
[-47.34  -0.2 ]
38700 50
steps: 1934950, episodes: 38700, mean episode reward: -43.08919390448948, time: 24.585
agent0_energy_min, agent0_attention_min
[-39.23  -0.39]
agent1_energy_min, agent1_attention_min
[-47.36  -0.41]
38800 50
steps: 1939950, episodes: 38800, mean episode reward: -55.42263688611439, time: 24.879
agent0_energy_min, agent0_attention_min
[-39.96  -0.61]
agent1_energy_min, agent1_attention_min
[-48.15  -0.48]
38900 50
steps: 1944950, episodes: 38900, mean episode reward: -46.27163743816236, time: 24.568
agent0_energy_min, agent0_attention_min
[-40.54  -2.71]
agent1_energy_min, agent1_attention_min
[-48.97  -0.42]
39000 50
steps: 1949950, episodes: 39000, mean episode reward: -44.94356090453973, time: 24.655
agent0_energy_min, agent0_attention_min
[-38.14  -0.69]
agent1_energy_min, agent1_attention_min
[-48.94  -0.48]
39100 50
steps: 1954950, episodes: 39100, mean episode reward: -59.386019336714725, time: 24.819
agent0_energy_min, agent0_attention_min
[-38.27  -1.36]
agent1_energy_min, agent1_attention_min
[-48.17  -0.69]
39200 50
steps: 1959950, episodes: 39200, mean episode reward: -40.57138109600523, time: 24.712
agent0_energy_min, agent0_attention_min
[-42.43  -1.12]
agent1_energy_min, agent1_attention_min
[-48.38  -0.31]
39300 50
steps: 1964950, episodes: 39300, mean episode reward: -46.04891471014096, time: 24.659
agent0_energy_min, agent0_attention_min
[-41.45  -1.98]
agent1_energy_min, agent1_attention_min
agent0_energy_min, agent0_attention_min
[-41.12  -8.43]
agent1_energy_min, agent1_attention_min
[-42.01  -4.83]
35800 50
steps: 1789950, episodes: 35800, mean episode reward: -35.942216151411955, time: 24.352
agent0_energy_min, agent0_attention_min
[-38.76 -10.11]
agent1_energy_min, agent1_attention_min
[-46.38  -3.02]
35900 50
steps: 1794950, episodes: 35900, mean episode reward: -38.298858053392685, time: 24.563
agent0_energy_min, agent0_attention_min
[-45.03  -4.31]
agent1_energy_min, agent1_attention_min
[-43.34  -4.45]
36000 50
steps: 1799950, episodes: 36000, mean episode reward: -48.08140705568349, time: 24.166
agent0_energy_min, agent0_attention_min
[-38.12  -7.75]
agent1_energy_min, agent1_attention_min
[-40.05  -3.75]
36100 50
steps: 1804950, episodes: 36100, mean episode reward: -45.73016651763003, time: 25.131
agent0_energy_min, agent0_attention_min
[-40.74  -5.01]
agent1_energy_min, agent1_attention_min
[-46.74  -2.84]
36200 50
steps: 1809950, episodes: 36200, mean episode reward: -45.118622641335406, time: 24.31
agent0_energy_min, agent0_attention_min
[-20.49 -28.64]
agent1_energy_min, agent1_attention_min
[-39.58  -5.37]
36300 50
steps: 1814950, episodes: 36300, mean episode reward: -45.58657286731834, time: 23.757
agent0_energy_min, agent0_attention_min
[-32.96 -15.88]
agent1_energy_min, agent1_attention_min
[-40.98  -4.37]
36400 50
steps: 1819950, episodes: 36400, mean episode reward: -39.80736835341069, time: 24.784
agent0_energy_min, agent0_attention_min
[-42.79  -6.16]
agent1_energy_min, agent1_attention_min
[-46.15  -3.01]
36500 50
steps: 1824950, episodes: 36500, mean episode reward: -40.02017518054049, time: 24.394
agent0_energy_min, agent0_attention_min
[-37.41  -4.81]
agent1_energy_min, agent1_attention_min
[-44.98  -3.49]
36600 50
steps: 1829950, episodes: 36600, mean episode reward: -42.79304518249984, time: 24.471
agent0_energy_min, agent0_attention_min
[-42.53  -5.11]
agent1_energy_min, agent1_attention_min
[-45.79  -2.67]
36700 50
steps: 1834950, episodes: 36700, mean episode reward: -50.48715261630252, time: 23.642
agent0_energy_min, agent0_attention_min
[-30.56  -8.78]
agent1_energy_min, agent1_attention_min
[-45.93  -2.38]
36800 50
steps: 1839950, episodes: 36800, mean episode reward: -44.34645332047342, time: 24.186
agent0_energy_min, agent0_attention_min
[-27.23 -11.  ]
agent1_energy_min, agent1_attention_min
[-38.97  -1.36]
36900 50
steps: 1844950, episodes: 36900, mean episode reward: -53.81675727752873, time: 24.477
agent0_energy_min, agent0_attention_min
[-38.18  -3.43]
agent1_energy_min, agent1_attention_min
[-40.07  -1.72]
37000 50
steps: 1849950, episodes: 37000, mean episode reward: -80.77809707309136, time: 24.392
agent0_energy_min, agent0_attention_min
[-31.85  -5.35]
agent1_energy_min, agent1_attention_min
[-42.64  -2.74]
37100 50
steps: 1854950, episodes: 37100, mean episode reward: -90.53611928038293, time: 24.836
agent0_energy_min, agent0_attention_min
[-34.56  -2.82]
agent1_energy_min, agent1_attention_min
[-43.79  -4.34]
37200 50
steps: 1859950, episodes: 37200, mean episode reward: -58.41423224726812, time: 24.449
agent0_energy_min, agent0_attention_min
[-30.27 -14.53]
agent1_energy_min, agent1_attention_min
[-45.45  -2.54]
37300 50
steps: 1864950, episodes: 37300, mean episode reward: -39.446949949375245, time: 23.855
agent0_energy_min, agent0_attention_min
[-44.78  -2.84]
agent1_energy_min, agent1_attention_min
[-34.61  -2.7 ]
37400 50
steps: 1869950, episodes: 37400, mean episode reward: -74.29826462645912, time: 24.007
agent0_energy_min, agent0_attention_min
[-30.72  -1.77]
agent1_energy_min, agent1_attention_min
[-39.54  -3.11]
37500 50
steps: 1874950, episodes: 37500, mean episode reward: -50.855090102349514, time: 24.091
agent0_energy_min, agent0_attention_min
[-28.49  -1.2 ]
agent1_energy_min, agent1_attention_min
[-46.74  -1.21]
37600 50
steps: 1879950, episodes: 37600, mean episode reward: -78.16001452211323, time: 24.601
agent0_energy_min, agent0_attention_min
[-25.59  -3.81]
agent1_energy_min, agent1_attention_min
[-44.03  -2.25]
37700 50
steps: 1884950, episodes: 37700, mean episode reward: -60.70623636980688, time: 24.127
agent0_energy_min, agent0_attention_min
[-20.36  -5.05]
agent1_energy_min, agent1_attention_min
[-45.88  -1.68]
37800 50
steps: 1889950, episodes: 37800, mean episode reward: -61.388486080774136, time: 24.134
agent0_energy_min, agent0_attention_min
[-23.23  -9.71]
agent1_energy_min, agent1_attention_min
[-45.09  -1.54]
37900 50
steps: 1894950, episodes: 37900, mean episode reward: -48.31982341567069, time: 24.05
agent0_energy_min, agent0_attention_min
[-23.77  -7.24]
agent1_energy_min, agent1_attention_min
[-46.86  -0.79]
38000 50
steps: 1899950, episodes: 38000, mean episode reward: -46.04387480037073, time: 24.57
agent0_energy_min, agent0_attention_min
[-23.75 -11.67]
agent1_energy_min, agent1_attention_min
[-41.76  -0.36]
38100 50
steps: 1904950, episodes: 38100, mean episode reward: -41.10244200912006, time: 24.655
agent0_energy_min, agent0_attention_min
[-26.72  -4.52]
agent1_energy_min, agent1_attention_min
[-39.82  -0.82]
38200 50
steps: 1909950, episodes: 38200, mean episode reward: -40.60586847734719, time: 23.817
agent0_energy_min, agent0_attention_min
[-38.75  -1.74]
agent1_energy_min, agent1_attention_min
[-34.72  -0.55]
38300 50
steps: 1914950, episodes: 38300, mean episode reward: -40.594348165239865, time: 23.835
agent0_energy_min, agent0_attention_min
[-33.65  -2.09]
agent1_energy_min, agent1_attention_min
[-19.04  -1.03]
38400 50
steps: 1919950, episodes: 38400, mean episode reward: -40.74411016253579, time: 24.058
agent0_energy_min, agent0_attention_min
[-21.48  -2.67]
agent1_energy_min, agent1_attention_min
[-42.16  -1.21]
38500 50
steps: 1924950, episodes: 38500, mean episode reward: -44.360338746985825, time: 24.096
agent0_energy_min, agent0_attention_min
[-20.84  -1.8 ]
agent1_energy_min, agent1_attention_min
[-44.48  -1.08]
38600 50
steps: 1929950, episodes: 38600, mean episode reward: -41.20647554783645, time: 24.093
agent0_energy_min, agent0_attention_min
[-19.06  -1.92]
agent1_energy_min, agent1_attention_min
[-46.18  -0.94]
38700 50
steps: 1934950, episodes: 38700, mean episode reward: -35.571531328020015, time: 24.03
agent0_energy_min, agent0_attention_min
[-22.06  -2.07]
agent1_energy_min, agent1_attention_min
[-44.35  -1.14]
38800 50
steps: 1939950, episodes: 38800, mean episode reward: -45.422727155783086, time: 24.029
agent0_energy_min, agent0_attention_min
[-29.79  -2.13]
agent1_energy_min, agent1_attention_min
[-40.64  -7.98]
38900 50
steps: 1944950, episodes: 38900, mean episode reward: -55.15157980794871, time: 23.799
agent0_energy_min, agent0_attention_min
[-25.44  -1.69]
agent1_energy_min, agent1_attention_min
[-38.18  -1.91]
39000 50
steps: 1949950, episodes: 39000, mean episode reward: -42.26845923921347, time: 24.252
agent0_energy_min, agent0_attention_min
[-21.16  -2.18]
agent1_energy_min, agent1_attention_min
[-36.84  -1.29]
39100 50
steps: 1954950, episodes: 39100, mean episode reward: -56.80116743154937, time: 24.439
agent0_energy_min, agent0_attention_min
[-27.24  -9.06]
agent1_energy_min, agent1_attention_min
[-36.77  -0.64]
39200 50
steps: 1959950, episodes: 39200, mean episode reward: -41.587503518863166, time: 24.168
agent0_energy_min, agent0_attention_min
[-23.05 -21.57]
agent1_energy_min, agent1_attention_min
[-46.12  -0.53]
39300 50
steps: 1964950, episodes: 39300, mean episode reward: -42.094843306011924, time: 23.707
agent0_energy_min, agent0_attention_min
[-34.67  -9.9 ]
agent1_energy_min, agent1_attention_min
[-4.863e+01 -3.000e-02]
39400 50
steps: 1969950, episodes: 39400, mean episode reward: -42.35596357321267, time: 23.896
agent0_energy_min, agent0_attention_min
[-32.27  -7.35]
agent1_energy_min, agent1_attention_min
[-4.931e+01 -3.000e-02]
39500 50
steps: 1974950, episodes: 39500, mean episode reward: -40.350179971832276, time: 23.641
agent0_energy_min, agent0_attention_min
[-32.05  -1.87]
agent1_energy_min, agent1_attention_min
[-47.56  -0.12]
39600 50
steps: 1979950, episodes: 39600, mean episode reward: -39.51554022248989, time: 25.19
agent0_energy_min, agent0_attention_min
[-30.52  -2.48]

agent0_energy_min, agent0_attention_min
[-19.34 -30.25]
agent1_energy_min, agent1_attention_min
[-20.93 -22.47]
35900 50
steps: 1794950, episodes: 35900, mean episode reward: -84.91398070683537, time: 24.928
agent0_energy_min, agent0_attention_min
[-16.92 -32.97]
agent1_energy_min, agent1_attention_min
[-24.07 -22.4 ]
36000 50
steps: 1799950, episodes: 36000, mean episode reward: -66.19276641790967, time: 24.817
agent0_energy_min, agent0_attention_min
[-14.32 -35.3 ]
agent1_energy_min, agent1_attention_min
[-19.8  -25.15]
36100 50
steps: 1804950, episodes: 36100, mean episode reward: -69.16302294631879, time: 25.138
agent0_energy_min, agent0_attention_min
[-19.1  -30.66]
agent1_energy_min, agent1_attention_min
[-18.83 -26.15]
36200 50
steps: 1809950, episodes: 36200, mean episode reward: -70.31439510254808, time: 24.479
agent0_energy_min, agent0_attention_min
[-15.91 -33.85]
agent1_energy_min, agent1_attention_min
[-17.8  -27.56]
36300 50
steps: 1814950, episodes: 36300, mean episode reward: -79.6506105881933, time: 24.466
agent0_energy_min, agent0_attention_min
[-14.66 -34.29]
agent1_energy_min, agent1_attention_min
[-21.45 -23.82]
36400 50
steps: 1819950, episodes: 36400, mean episode reward: -60.15626352044006, time: 25.037
agent0_energy_min, agent0_attention_min
[-14.7  -34.28]
agent1_energy_min, agent1_attention_min
[-18.61 -25.66]
36500 50
steps: 1824950, episodes: 36500, mean episode reward: -80.12071813659082, time: 24.538
agent0_energy_min, agent0_attention_min
[-14.29 -33.87]
agent1_energy_min, agent1_attention_min
[-20.5  -24.59]
36600 50
steps: 1829950, episodes: 36600, mean episode reward: -62.186180061141265, time: 24.982
agent0_energy_min, agent0_attention_min
[-13.47 -36.39]
agent1_energy_min, agent1_attention_min
[-22.05 -23.95]
36700 50
steps: 1834950, episodes: 36700, mean episode reward: -91.80253691236254, time: 24.616
agent0_energy_min, agent0_attention_min
[-16.73 -33.15]
agent1_energy_min, agent1_attention_min
[-32.29 -17.04]
36800 50
steps: 1839950, episodes: 36800, mean episode reward: -73.67083589958818, time: 24.48
agent0_energy_min, agent0_attention_min
[-13.39 -36.29]
agent1_energy_min, agent1_attention_min
[-30.94 -13.85]
36900 50
steps: 1844950, episodes: 36900, mean episode reward: -55.809988128988046, time: 24.548
agent0_energy_min, agent0_attention_min
[-13.61 -35.79]
agent1_energy_min, agent1_attention_min
[-27.26 -16.87]
37000 50
steps: 1849950, episodes: 37000, mean episode reward: -66.24791883636404, time: 24.186
agent0_energy_min, agent0_attention_min
[-16.08 -31.51]
agent1_energy_min, agent1_attention_min
[-30.6  -14.36]
37100 50
steps: 1854950, episodes: 37100, mean episode reward: -63.30266464724228, time: 24.415
agent0_energy_min, agent0_attention_min
[-14.62 -34.01]
agent1_energy_min, agent1_attention_min
[-29.14 -15.6 ]
37200 50
steps: 1859950, episodes: 37200, mean episode reward: -68.44692658564354, time: 24.115
agent0_energy_min, agent0_attention_min
[-14.06 -34.21]
agent1_energy_min, agent1_attention_min
[-26.47 -17.33]
37300 50
steps: 1864950, episodes: 37300, mean episode reward: -68.66334963467652, time: 24.525
agent0_energy_min, agent0_attention_min
[-15.01 -33.24]
agent1_energy_min, agent1_attention_min
[-29.49 -14.52]
37400 50
steps: 1869950, episodes: 37400, mean episode reward: -74.03351173723478, time: 24.793
agent0_energy_min, agent0_attention_min
[-14.82 -31.62]
agent1_energy_min, agent1_attention_min
[-34.58  -9.37]
37500 50
steps: 1874950, episodes: 37500, mean episode reward: -85.907151805652, time: 24.061
agent0_energy_min, agent0_attention_min
[-16.13 -16.87]
agent1_energy_min, agent1_attention_min
[-32.72 -10.62]
37600 50
steps: 1879950, episodes: 37600, mean episode reward: -90.20617778043666, time: 25.222
agent0_energy_min, agent0_attention_min
[-18.66 -17.77]
agent1_energy_min, agent1_attention_min
[-35.94 -10.69]
37700 50
steps: 1884950, episodes: 37700, mean episode reward: -115.70989574687174, time: 23.93
agent0_energy_min, agent0_attention_min
[-19.61 -12.71]
agent1_energy_min, agent1_attention_min
[-34.03 -11.76]
37800 50
steps: 1889950, episodes: 37800, mean episode reward: -83.60731084659345, time: 24.955
agent0_energy_min, agent0_attention_min
[-15.16 -20.44]
agent1_energy_min, agent1_attention_min
[-34.82 -11.73]
37900 50
steps: 1894950, episodes: 37900, mean episode reward: -144.74062192083392, time: 24.394
agent0_energy_min, agent0_attention_min
[-18.06 -16.55]
agent1_energy_min, agent1_attention_min
[-31.6  -11.66]
38000 50
steps: 1899950, episodes: 38000, mean episode reward: -67.8300419446562, time: 24.776
agent0_energy_min, agent0_attention_min
[-15.36 -18.27]
agent1_energy_min, agent1_attention_min
[-32.58 -12.03]
38100 50
steps: 1904950, episodes: 38100, mean episode reward: -73.56510186502167, time: 25.032
agent0_energy_min, agent0_attention_min
[-13.91 -21.41]
agent1_energy_min, agent1_attention_min
[-31.44 -13.15]
38200 50
steps: 1909950, episodes: 38200, mean episode reward: -94.71751675425288, time: 24.299
agent0_energy_min, agent0_attention_min
[-21.38 -15.78]
agent1_energy_min, agent1_attention_min
[-34.58 -10.16]
38300 50
steps: 1914950, episodes: 38300, mean episode reward: -76.51325209951621, time: 24.489
agent0_energy_min, agent0_attention_min
[-14.22 -23.58]
agent1_energy_min, agent1_attention_min
[-32.92 -11.42]
38400 50
steps: 1919950, episodes: 38400, mean episode reward: -94.03094532759165, time: 24.723
agent0_energy_min, agent0_attention_min
[-15.56 -24.69]
agent1_energy_min, agent1_attention_min
[-36.89  -9.55]
38500 50
steps: 1924950, episodes: 38500, mean episode reward: -144.35161689654956, time: 24.704
agent0_energy_min, agent0_attention_min
[-12.98 -35.49]
agent1_energy_min, agent1_attention_min
[-35.56  -9.96]
38600 50
steps: 1929950, episodes: 38600, mean episode reward: -87.32436012774407, time: 24.894
agent0_energy_min, agent0_attention_min
[-14.3  -35.37]
agent1_energy_min, agent1_attention_min
[-35.25  -9.47]
38700 50
steps: 1934950, episodes: 38700, mean episode reward: -102.92033025743153, time: 24.83
agent0_energy_min, agent0_attention_min
[-12.15 -37.35]
agent1_energy_min, agent1_attention_min
[-35.68  -8.1 ]
38800 50
steps: 1939950, episodes: 38800, mean episode reward: -84.37678742137173, time: 24.791
agent0_energy_min, agent0_attention_min
[-10.59 -37.89]
agent1_energy_min, agent1_attention_min
[-35.1   -9.32]
38900 50
steps: 1944950, episodes: 38900, mean episode reward: -73.42512086130202, time: 24.915
agent0_energy_min, agent0_attention_min
[-12.09 -36.54]
agent1_energy_min, agent1_attention_min
[-31.7  -11.65]
39000 50
steps: 1949950, episodes: 39000, mean episode reward: -98.27698632899988, time: 25.047
agent0_energy_min, agent0_attention_min
[ -9.91 -39.4 ]
agent1_energy_min, agent1_attention_min
[-31.52 -11.25]
39100 50
steps: 1954950, episodes: 39100, mean episode reward: -130.26831310745843, time: 25.186
agent0_energy_min, agent0_attention_min
[-11.45 -37.75]
agent1_energy_min, agent1_attention_min
[-27.01 -12.16]
39200 50
steps: 1959950, episodes: 39200, mean episode reward: -58.807772595123566, time: 24.157
agent0_energy_min, agent0_attention_min
[-10.25 -39.37]
agent1_energy_min, agent1_attention_min
[-31.33 -11.98]
39300 50
steps: 1964950, episodes: 39300, mean episode reward: -79.53385014930731, time: 24.258
agent0_energy_min, agent0_attention_min
[ -9.2  -39.56]
agent1_energy_min, agent1_attention_min
[-26.01 -17.88]
39400 50
steps: 1969950, episodes: 39400, mean episode reward: -72.91517470863157, time: 24.979
agent0_energy_min, agent0_attention_min
[-11.18 -34.11]
agent1_energy_min, agent1_attention_min
[-26.64 -17.  ]
39500 50
steps: 1974950, episodes: 39500, mean episode reward: -80.42034596244774, time: 24.844
agent0_energy_min, agent0_attention_min
[-19.9 -23.4]
agent1_energy_min, agent1_attention_min
[-28.21 -14.4 ]
39600 50
steps: 1979950, episodes: 39600, mean episode reward: -73.6233743694315, time: 25.065
agent0_energy_min, agent0_attention_min
[-15.79 -25.55]
agent1_energy_min, agent1_attention_min
[-27.06 -16.54]
39700 50
steps: 1984950, episodes: 39700, mean episode reward: -70.31486972937138, time: 24.402
agent0_energy_min, agent0_attention_min
[-13.32 -15.6 ]
agent1_energy_min, agent1_attention_min
agent0_energy_min, agent0_attention_min
[-29.99 -19.35]
agent1_energy_min, agent1_attention_min
[-18.32 -30.91]
35900 50
steps: 1794950, episodes: 35900, mean episode reward: -62.61561470266719, time: 24.231
agent0_energy_min, agent0_attention_min
[-26.21 -21.87]
agent1_energy_min, agent1_attention_min
[-19.19 -30.05]
36000 50
steps: 1799950, episodes: 36000, mean episode reward: -80.53780203239315, time: 24.477
agent0_energy_min, agent0_attention_min
[-29.7  -19.14]
agent1_energy_min, agent1_attention_min
[-20.07 -28.93]
36100 50
steps: 1804950, episodes: 36100, mean episode reward: -122.79831931755507, time: 25.058
agent0_energy_min, agent0_attention_min
[-25.24 -23.12]
agent1_energy_min, agent1_attention_min
[-21.54 -27.63]
36200 50
steps: 1809950, episodes: 36200, mean episode reward: -76.95077052698274, time: 24.399
agent0_energy_min, agent0_attention_min
[-23.52 -24.43]
agent1_energy_min, agent1_attention_min
[-28.42 -20.49]
36300 50
steps: 1814950, episodes: 36300, mean episode reward: -68.45886265076336, time: 24.838
agent0_energy_min, agent0_attention_min
[-34.41 -13.49]
agent1_energy_min, agent1_attention_min
[-27.58 -22.25]
36400 50
steps: 1819950, episodes: 36400, mean episode reward: -67.42000820097113, time: 24.602
agent0_energy_min, agent0_attention_min
[-31.96 -12.73]
agent1_energy_min, agent1_attention_min
[-26.07 -23.55]
36500 50
steps: 1824950, episodes: 36500, mean episode reward: -74.05367003157379, time: 25.686
agent0_energy_min, agent0_attention_min
[-24.42 -19.74]
agent1_energy_min, agent1_attention_min
[-22.01 -27.5 ]
36600 50
steps: 1829950, episodes: 36600, mean episode reward: -78.42349186890743, time: 24.948
agent0_energy_min, agent0_attention_min
[-18.08 -20.79]
agent1_energy_min, agent1_attention_min
[-20.71 -28.98]
36700 50
steps: 1834950, episodes: 36700, mean episode reward: -55.352991143510216, time: 24.805
agent0_energy_min, agent0_attention_min
[-26.87 -16.95]
agent1_energy_min, agent1_attention_min
[-19.99 -29.36]
36800 50
steps: 1839950, episodes: 36800, mean episode reward: -67.11446959009213, time: 24.867
agent0_energy_min, agent0_attention_min
[-30.72 -18.09]
agent1_energy_min, agent1_attention_min
[-18.4  -31.17]
36900 50
steps: 1844950, episodes: 36900, mean episode reward: -70.53168812912278, time: 24.468
agent0_energy_min, agent0_attention_min
[-29.94 -19.59]
agent1_energy_min, agent1_attention_min
[-18.18 -30.95]
37000 50
steps: 1849950, episodes: 37000, mean episode reward: -61.955831619774955, time: 23.995
agent0_energy_min, agent0_attention_min
[-27.54 -16.74]
agent1_energy_min, agent1_attention_min
[-19.74 -29.8 ]
37100 50
steps: 1854950, episodes: 37100, mean episode reward: -63.856629266393476, time: 24.195
agent0_energy_min, agent0_attention_min
[-28.09  -9.32]
agent1_energy_min, agent1_attention_min
[-19.19 -29.91]
37200 50
steps: 1859950, episodes: 37200, mean episode reward: -63.54544096307285, time: 24.159
agent0_energy_min, agent0_attention_min
[-20.99  -2.14]
agent1_energy_min, agent1_attention_min
[-17.71 -31.37]
37300 50
steps: 1864950, episodes: 37300, mean episode reward: -77.24969434309236, time: 24.6
agent0_energy_min, agent0_attention_min
[-21.27  -8.66]
agent1_energy_min, agent1_attention_min
[-16.14 -32.57]
37400 50
steps: 1869950, episodes: 37400, mean episode reward: -80.54141968030386, time: 24.065
agent0_energy_min, agent0_attention_min
[-31.7  -9.5]
agent1_energy_min, agent1_attention_min
[-21.53 -28.04]
37500 50
steps: 1874950, episodes: 37500, mean episode reward: -68.33762170492079, time: 24.324
agent0_energy_min, agent0_attention_min
[-36.96  -6.87]
agent1_energy_min, agent1_attention_min
[-21.92 -26.32]
37600 50
steps: 1879950, episodes: 37600, mean episode reward: -101.75606827170566, time: 25.056
agent0_energy_min, agent0_attention_min
[-38.78  -0.97]
agent1_energy_min, agent1_attention_min
[-19.4  -27.25]
37700 50
steps: 1884950, episodes: 37700, mean episode reward: -65.69911745191249, time: 24.789
agent0_energy_min, agent0_attention_min
[-31.9   -2.76]
agent1_energy_min, agent1_attention_min
[-16.62 -28.91]
37800 50
steps: 1889950, episodes: 37800, mean episode reward: -63.93152781260024, time: 24.365
agent0_energy_min, agent0_attention_min
[-27.82  -2.37]
agent1_energy_min, agent1_attention_min
[-23.79 -24.75]
37900 50
steps: 1894950, episodes: 37900, mean episode reward: -72.85435949933598, time: 24.271
agent0_energy_min, agent0_attention_min
[-33.16  -1.95]
agent1_energy_min, agent1_attention_min
[-23.67 -25.03]
38000 50
steps: 1899950, episodes: 38000, mean episode reward: -89.81458513646285, time: 24.819
agent0_energy_min, agent0_attention_min
[-29.59  -7.4 ]
agent1_energy_min, agent1_attention_min
[-23.73 -24.8 ]
38100 50
steps: 1904950, episodes: 38100, mean episode reward: -52.31337742424107, time: 24.587
agent0_energy_min, agent0_attention_min
[-27.53 -12.56]
agent1_energy_min, agent1_attention_min
[-14.12 -28.19]
38200 50
steps: 1909950, episodes: 38200, mean episode reward: -55.13766104679836, time: 24.172
agent0_energy_min, agent0_attention_min
[-23.44 -15.71]
agent1_energy_min, agent1_attention_min
[-21.71 -27.08]
38300 50
steps: 1914950, episodes: 38300, mean episode reward: -74.51976606449193, time: 24.199
agent0_energy_min, agent0_attention_min
[-22.95 -17.54]
agent1_energy_min, agent1_attention_min
[-22.79 -26.78]
38400 50
steps: 1919950, episodes: 38400, mean episode reward: -107.8339570926376, time: 24.518
agent0_energy_min, agent0_attention_min
[-20.29 -11.34]
agent1_energy_min, agent1_attention_min
[-27.31 -22.03]
38500 50
steps: 1924950, episodes: 38500, mean episode reward: -84.20263652199132, time: 23.914
agent0_energy_min, agent0_attention_min
[-27.11 -10.17]
agent1_energy_min, agent1_attention_min
[-28.48 -20.99]
38600 50
steps: 1929950, episodes: 38600, mean episode reward: -60.510393458190755, time: 25.509
agent0_energy_min, agent0_attention_min
[-23.6 -10.1]
agent1_energy_min, agent1_attention_min
[-21.18 -27.92]
38700 50
steps: 1934950, episodes: 38700, mean episode reward: -71.37129972104616, time: 24.688
agent0_energy_min, agent0_attention_min
[-26.1   -4.33]
agent1_energy_min, agent1_attention_min
[-21.62 -25.93]
38800 50
steps: 1939950, episodes: 38800, mean episode reward: -57.30171886840555, time: 23.662
agent0_energy_min, agent0_attention_min
[-21.6  -8.5]
agent1_energy_min, agent1_attention_min
[-19.86 -28.13]
38900 50
steps: 1944950, episodes: 38900, mean episode reward: -64.57262409593454, time: 24.765
agent0_energy_min, agent0_attention_min
[-17.59 -11.89]
agent1_energy_min, agent1_attention_min
[-24.96 -24.86]
39000 50
steps: 1949950, episodes: 39000, mean episode reward: -60.48368673916883, time: 24.519
agent0_energy_min, agent0_attention_min
[-16.92 -11.47]
agent1_energy_min, agent1_attention_min
[-19.99 -25.77]
39100 50
steps: 1954950, episodes: 39100, mean episode reward: -63.37666713364062, time: 24.817
agent0_energy_min, agent0_attention_min
[-23.44  -3.92]
agent1_energy_min, agent1_attention_min
[-16.92 -26.17]
39200 50
steps: 1959950, episodes: 39200, mean episode reward: -53.16601749012933, time: 24.12
agent0_energy_min, agent0_attention_min
[-24.99  -1.09]
agent1_energy_min, agent1_attention_min
[-23.2 -24.4]
39300 50
steps: 1964950, episodes: 39300, mean episode reward: -58.72119197499888, time: 24.228
agent0_energy_min, agent0_attention_min
[-23.57  -3.33]
agent1_energy_min, agent1_attention_min
[-19.18 -29.15]
39400 50
steps: 1969950, episodes: 39400, mean episode reward: -61.88967033581732, time: 24.657
agent0_energy_min, agent0_attention_min
[-23.19  -8.27]
agent1_energy_min, agent1_attention_min
[-13.96 -27.12]
39500 50
steps: 1974950, episodes: 39500, mean episode reward: -80.45789736618104, time: 24.79
agent0_energy_min, agent0_attention_min
[-27.98  -7.  ]
agent1_energy_min, agent1_attention_min
[-21.34 -22.42]
39600 50
steps: 1979950, episodes: 39600, mean episode reward: -61.738060758630546, time: 24.952
agent0_energy_min, agent0_attention_min
[-28.26  -2.19]
agent1_energy_min, agent1_attention_min
[-22.6  -23.17]
39700 50
steps: 1984950, episodes: 39700, mean episode reward: -55.51852824972456, time: 24.073
agent0_energy_min, agent0_attention_min
[-27.39  -2.05]
agent1_energy_min, agent1_attention_minagent1_energy_min, agent1_attention_min
[-47.22  -0.87]
39700 50
steps: 1984950, episodes: 39700, mean episode reward: -33.36785952128414, time: 23.793
agent0_energy_min, agent0_attention_min
[-26.79  -2.76]
agent1_energy_min, agent1_attention_min
[-4.969e+01 -2.000e-02]
39800 50
steps: 1989950, episodes: 39800, mean episode reward: -46.02724522993806, time: 24.508
agent0_energy_min, agent0_attention_min
[-27.2  -3. ]
agent1_energy_min, agent1_attention_min
[-46.29  -0.52]
39900 50
steps: 1994950, episodes: 39900, mean episode reward: -42.16370430930315, time: 24.139
agent0_energy_min, agent0_attention_min
[-28.78  -8.95]
agent1_energy_min, agent1_attention_min
[-42.66  -0.18]
40000 50
steps: 1999950, episodes: 40000, mean episode reward: -49.167059442848746, time: 24.217
agent0_energy_min, agent0_attention_min
[-30.91 -18.12]
agent1_energy_min, agent1_attention_min
[-36.44  -0.22]
...Finished!
Trained episodes: 1 -> 40000
Total time: 2.70 hr

agent0_energy_min, agent0_attention_min
[-15.33  -0.94]
agent1_energy_min, agent1_attention_min
[ -4.81 -45.14]
35900 50
steps: 1794950, episodes: 35900, mean episode reward: -67.7541161668121, time: 24.622
agent0_energy_min, agent0_attention_min
[-16.66  -0.78]
agent1_energy_min, agent1_attention_min
[ -6.6  -43.24]
36000 50
steps: 1799950, episodes: 36000, mean episode reward: -69.44173267660896, time: 24.683
agent0_energy_min, agent0_attention_min
[-13.19  -1.18]
agent1_energy_min, agent1_attention_min
[ -5.5  -44.46]
36100 50
steps: 1804950, episodes: 36100, mean episode reward: -57.767333509744546, time: 26.045
agent0_energy_min, agent0_attention_min
[-16.21  -0.87]
agent1_energy_min, agent1_attention_min
[ -4.12 -45.84]
36200 50
steps: 1809950, episodes: 36200, mean episode reward: -70.87945025804854, time: 24.808
agent0_energy_min, agent0_attention_min
[-18.4   -1.76]
agent1_energy_min, agent1_attention_min
[ -5.17 -44.59]
36300 50
steps: 1814950, episodes: 36300, mean episode reward: -56.383327230546385, time: 24.951
agent0_energy_min, agent0_attention_min
[-15.96  -1.34]
agent1_energy_min, agent1_attention_min
[ -7.55 -41.95]
36400 50
steps: 1819950, episodes: 36400, mean episode reward: -50.54684566337278, time: 24.537
agent0_energy_min, agent0_attention_min
[-13.72  -1.18]
agent1_energy_min, agent1_attention_min
[ -5.6  -43.34]
36500 50
steps: 1824950, episodes: 36500, mean episode reward: -50.55785144036957, time: 24.232
agent0_energy_min, agent0_attention_min
[-14.97  -1.27]
agent1_energy_min, agent1_attention_min
[ -7.58 -42.16]
36600 50
steps: 1829950, episodes: 36600, mean episode reward: -54.498762416670544, time: 25.663
agent0_energy_min, agent0_attention_min
[-15.92  -1.61]
agent1_energy_min, agent1_attention_min
[ -6.13 -43.77]
36700 50
steps: 1834950, episodes: 36700, mean episode reward: -54.9426419557286, time: 24.639
agent0_energy_min, agent0_attention_min
[-14.62  -1.24]
agent1_energy_min, agent1_attention_min
[ -9.74 -39.78]
36800 50
steps: 1839950, episodes: 36800, mean episode reward: -54.50144661047774, time: 24.115
agent0_energy_min, agent0_attention_min
[-15.61  -1.43]
agent1_energy_min, agent1_attention_min
[ -7.26 -42.59]
36900 50
steps: 1844950, episodes: 36900, mean episode reward: -65.37872604903606, time: 24.151
agent0_energy_min, agent0_attention_min
[-17.98  -1.42]
agent1_energy_min, agent1_attention_min
[ -6.62 -43.26]
37000 50
steps: 1849950, episodes: 37000, mean episode reward: -61.74977474435469, time: 25.073
agent0_energy_min, agent0_attention_min
[-17.33  -1.47]
agent1_energy_min, agent1_attention_min
[ -7.81 -42.04]
37100 50
steps: 1854950, episodes: 37100, mean episode reward: -51.474708710733466, time: 25.141
agent0_energy_min, agent0_attention_min
[-16.48  -1.71]
agent1_energy_min, agent1_attention_min
[ -5.82 -43.96]
37200 50
steps: 1859950, episodes: 37200, mean episode reward: -60.7581037376239, time: 24.694
agent0_energy_min, agent0_attention_min
[-15.82  -1.27]
agent1_energy_min, agent1_attention_min
[ -8.52 -41.37]
37300 50
steps: 1864950, episodes: 37300, mean episode reward: -55.20486777749664, time: 24.568
agent0_energy_min, agent0_attention_min
[-16.53  -1.6 ]
agent1_energy_min, agent1_attention_min
[ -6.05 -43.8 ]
37400 50
steps: 1869950, episodes: 37400, mean episode reward: -62.534199053309095, time: 24.655
agent0_energy_min, agent0_attention_min
[-15.85  -1.11]
agent1_energy_min, agent1_attention_min
[ -8.34 -41.56]
37500 50
steps: 1874950, episodes: 37500, mean episode reward: -82.80219051980292, time: 24.91
agent0_energy_min, agent0_attention_min
[-17.39  -1.12]
agent1_energy_min, agent1_attention_min
[ -6.32 -43.61]
37600 50
steps: 1879950, episodes: 37600, mean episode reward: -66.24511995558225, time: 24.898
agent0_energy_min, agent0_attention_min
[-15.45  -1.46]
agent1_energy_min, agent1_attention_min
[ -8.38 -41.44]
37700 50
steps: 1884950, episodes: 37700, mean episode reward: -88.89911589569448, time: 24.803
agent0_energy_min, agent0_attention_min
[-18.27  -1.69]
agent1_energy_min, agent1_attention_min
[ -7.45 -42.47]
37800 50
steps: 1889950, episodes: 37800, mean episode reward: -83.33221448974857, time: 25.028
agent0_energy_min, agent0_attention_min
[-18.91  -1.82]
agent1_energy_min, agent1_attention_min
[ -8.32 -41.43]
37900 50
steps: 1894950, episodes: 37900, mean episode reward: -64.00107777323562, time: 24.559
agent0_energy_min, agent0_attention_min
[-17.56  -0.93]
agent1_energy_min, agent1_attention_min
[ -8.76 -41.14]
38000 50
steps: 1899950, episodes: 38000, mean episode reward: -112.30504695034824, time: 24.606
agent0_energy_min, agent0_attention_min
[-17.01  -0.97]
agent1_energy_min, agent1_attention_min
[ -5.84 -44.05]
38100 50
steps: 1904950, episodes: 38100, mean episode reward: -82.14086471443532, time: 25.509
agent0_energy_min, agent0_attention_min
[-18.58  -1.45]
agent1_energy_min, agent1_attention_min
[ -6.18 -43.76]
38200 50
steps: 1909950, episodes: 38200, mean episode reward: -67.5079356586388, time: 25.034
agent0_energy_min, agent0_attention_min
[-18.11  -1.58]
agent1_energy_min, agent1_attention_min
[ -7.36 -42.55]
38300 50
steps: 1914950, episodes: 38300, mean episode reward: -53.651193011127496, time: 24.794
agent0_energy_min, agent0_attention_min
[-17.8   -0.93]
agent1_energy_min, agent1_attention_min
[ -8.27 -41.68]
38400 50
steps: 1919950, episodes: 38400, mean episode reward: -68.50514711470402, time: 24.901
agent0_energy_min, agent0_attention_min
[-20.74  -1.74]
agent1_energy_min, agent1_attention_min
[ -7.38 -42.47]
38500 50
steps: 1924950, episodes: 38500, mean episode reward: -86.5568955739681, time: 24.824
agent0_energy_min, agent0_attention_min
[-18.81  -1.25]
agent1_energy_min, agent1_attention_min
[ -8.96 -40.84]
38600 50
steps: 1929950, episodes: 38600, mean episode reward: -59.12355487135986, time: 25.257
agent0_energy_min, agent0_attention_min
[-18.87  -0.85]
agent1_energy_min, agent1_attention_min
[ -8.48 -41.32]
38700 50
steps: 1934950, episodes: 38700, mean episode reward: -46.86827788939327, time: 24.643
agent0_energy_min, agent0_attention_min
[-16.35  -1.11]
agent1_energy_min, agent1_attention_min
[ -7.47 -42.33]
38800 50
steps: 1939950, episodes: 38800, mean episode reward: -66.98300866083422, time: 24.764
agent0_energy_min, agent0_attention_min
[-20.01  -2.33]
agent1_energy_min, agent1_attention_min
[ -7.57 -42.25]
38900 50
steps: 1944950, episodes: 38900, mean episode reward: -67.19070028356035, time: 24.407
agent0_energy_min, agent0_attention_min
[-17.94  -2.03]
agent1_energy_min, agent1_attention_min
[-10.27 -39.59]
39000 50
steps: 1949950, episodes: 39000, mean episode reward: -48.21869537814157, time: 24.529
agent0_energy_min, agent0_attention_min
[-15.88  -2.12]
agent1_energy_min, agent1_attention_min
[-10.22 -39.59]
39100 50
steps: 1954950, episodes: 39100, mean episode reward: -60.518317921347695, time: 25.158
agent0_energy_min, agent0_attention_min
[-21.36  -2.73]
agent1_energy_min, agent1_attention_min
[ -7.63 -42.3 ]
39200 50
steps: 1959950, episodes: 39200, mean episode reward: -54.03808878240096, time: 24.63
agent0_energy_min, agent0_attention_min
[-21.15  -1.36]
agent1_energy_min, agent1_attention_min
[ -8.14 -41.48]
39300 50
steps: 1964950, episodes: 39300, mean episode reward: -65.45759821883797, time: 24.835
agent0_energy_min, agent0_attention_min
[-18.11  -1.33]
agent1_energy_min, agent1_attention_min
[ -9.37 -40.02]
39400 50
steps: 1969950, episodes: 39400, mean episode reward: -66.48344123781094, time: 24.55
agent0_energy_min, agent0_attention_min
[-23.84  -1.97]
agent1_energy_min, agent1_attention_min
[ -8.8  -41.04]
39500 50
steps: 1974950, episodes: 39500, mean episode reward: -68.86987787474747, time: 24.315
agent0_energy_min, agent0_attention_min
[-20.58  -2.01]
agent1_energy_min, agent1_attention_min
[-11.34 -38.44]
39600 50
steps: 1979950, episodes: 39600, mean episode reward: -50.89851382609636, time: 25.399
agent0_energy_min, agent0_attention_min
[-17.9   -2.46]
agent1_energy_min, agent1_attention_min
[ -7.28 -42.64]
39700 50
steps: 1984950, episodes: 39700, mean episode reward: -59.27403300360986, time: 23.501
agent0_energy_min, agent0_attention_min
[-23.29  -3.8 ]
agent1_energy_min, agent1_attention_min
[-30.8  -11.45]
39800 50
steps: 1989950, episodes: 39800, mean episode reward: -61.19323227756848, time: 24.169
agent0_energy_min, agent0_attention_min
[-15.4  -12.96]
agent1_energy_min, agent1_attention_min
[-33.52 -10.25]
39900 50
steps: 1994950, episodes: 39900, mean episode reward: -69.89197693538763, time: 23.919
agent0_energy_min, agent0_attention_min
[-14.99 -15.21]
agent1_energy_min, agent1_attention_min
[-30.86 -13.66]
40000 50
steps: 1999950, episodes: 40000, mean episode reward: -79.18028871026925, time: 24.194
agent0_energy_min, agent0_attention_min
[-16.64 -12.99]
agent1_energy_min, agent1_attention_min
[-30.51 -12.61]
...Finished!
Trained episodes: 1 -> 40000
Total time: 2.71 hr

[-17.17  -0.08]
agent1_energy_min, agent1_attention_min
[-0.64 -0.3 ]
35700 50
steps: 1784950, episodes: 35700, mean episode reward: -97.09672519869554, time: 24.912
agent0_energy_min, agent0_attention_min
[-20.71  -0.06]
agent1_energy_min, agent1_attention_min
[-0.78 -0.58]
35800 50
steps: 1789950, episodes: 35800, mean episode reward: -93.20421363278791, time: 24.189
agent0_energy_min, agent0_attention_min
[-19.33  -0.06]
agent1_energy_min, agent1_attention_min
[-0.06 -0.26]
35900 50
steps: 1794950, episodes: 35900, mean episode reward: -96.9886658888817, time: 24.777
agent0_energy_min, agent0_attention_min
[-2.085e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.32 -0.71]
36000 50
steps: 1799950, episodes: 36000, mean episode reward: -112.56902383280249, time: 25.018
agent0_energy_min, agent0_attention_min
[-2.076e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-0.82 -9.15]
36100 50
steps: 1804950, episodes: 36100, mean episode reward: -101.66200499247947, time: 25.224
agent0_energy_min, agent0_attention_min
[-19.82  -0.08]
agent1_energy_min, agent1_attention_min
[-0.48 -0.66]
36200 50
steps: 1809950, episodes: 36200, mean episode reward: -102.96496447182452, time: 24.768
agent0_energy_min, agent0_attention_min
[-22.06  -0.05]
agent1_energy_min, agent1_attention_min
[-0.12 -0.66]
36300 50
steps: 1814950, episodes: 36300, mean episode reward: -111.73799110373994, time: 24.497
agent0_energy_min, agent0_attention_min
[-18.24  -0.03]
agent1_energy_min, agent1_attention_min
[-0.05 -1.79]
36400 50
steps: 1819950, episodes: 36400, mean episode reward: -130.65383305312494, time: 24.434
agent0_energy_min, agent0_attention_min
[-18.59  -0.03]
agent1_energy_min, agent1_attention_min
[-0.14 -3.4 ]
36500 50
steps: 1824950, episodes: 36500, mean episode reward: -97.83317294008047, time: 25.05
agent0_energy_min, agent0_attention_min
[-17.99  -0.1 ]
agent1_energy_min, agent1_attention_min
[-0.25 -0.59]
36600 50
steps: 1829950, episodes: 36600, mean episode reward: -96.7269724186421, time: 25.01
agent0_energy_min, agent0_attention_min
[-22.17  -0.07]
agent1_energy_min, agent1_attention_min
[-1.14 -0.52]
36700 50
steps: 1834950, episodes: 36700, mean episode reward: -96.72843104128256, time: 24.49
agent0_energy_min, agent0_attention_min
[-17.36  -0.08]
agent1_energy_min, agent1_attention_min
[-0.95 -0.33]
36800 50
steps: 1839950, episodes: 36800, mean episode reward: -107.1375082478886, time: 24.623
agent0_energy_min, agent0_attention_min
[-18.85  -3.18]
agent1_energy_min, agent1_attention_min
[-0.86 -0.33]
36900 50
steps: 1844950, episodes: 36900, mean episode reward: -95.34093037266283, time: 24.399
agent0_energy_min, agent0_attention_min
[-17.38  -0.09]
agent1_energy_min, agent1_attention_min
[-0.17 -0.47]
37000 50
steps: 1849950, episodes: 37000, mean episode reward: -89.3963138566363, time: 24.288
agent0_energy_min, agent0_attention_min
[-18.4   -0.09]
agent1_energy_min, agent1_attention_min
[-0.39 -0.23]
37100 50
steps: 1854950, episodes: 37100, mean episode reward: -107.01303090718172, time: 25.704
agent0_energy_min, agent0_attention_min
[-18.14  -0.04]
agent1_energy_min, agent1_attention_min
[-0.49 -0.18]
37200 50
steps: 1859950, episodes: 37200, mean episode reward: -99.08649590754916, time: 25.117
agent0_energy_min, agent0_attention_min
[-17.64  -0.06]
agent1_energy_min, agent1_attention_min
[-0.41 -0.27]
37300 50
steps: 1864950, episodes: 37300, mean episode reward: -91.64789752337708, time: 24.609
agent0_energy_min, agent0_attention_min
[-15.87  -0.05]
agent1_energy_min, agent1_attention_min
[-0.26 -0.21]
37400 50
steps: 1869950, episodes: 37400, mean episode reward: -104.52411887133938, time: 24.995
agent0_energy_min, agent0_attention_min
[-17.91  -0.09]
agent1_energy_min, agent1_attention_min
[-1.16 -0.73]
37500 50
steps: 1874950, episodes: 37500, mean episode reward: -96.07863970220232, time: 24.874
agent0_energy_min, agent0_attention_min
[-17.38  -0.12]
agent1_energy_min, agent1_attention_min
[-2.22 -1.55]
37600 50
steps: 1879950, episodes: 37600, mean episode reward: -97.4758364092527, time: 24.594
agent0_energy_min, agent0_attention_min
[-19.66  -0.05]
agent1_energy_min, agent1_attention_min
[-0.16 -0.3 ]
37700 50
steps: 1884950, episodes: 37700, mean episode reward: -109.90581861692453, time: 24.516
agent0_energy_min, agent0_attention_min
[-16.98  -0.4 ]
agent1_energy_min, agent1_attention_min
[-0.18 -0.26]
37800 50
steps: 1889950, episodes: 37800, mean episode reward: -91.57555275264205, time: 24.837
agent0_energy_min, agent0_attention_min
[-16.17  -0.17]
agent1_energy_min, agent1_attention_min
[-0.06 -0.03]
37900 50
steps: 1894950, episodes: 37900, mean episode reward: -100.22901123759294, time: 24.355
agent0_energy_min, agent0_attention_min
[-19.14  -0.41]
agent1_energy_min, agent1_attention_min
[-1.76 -1.02]
38000 50
steps: 1899950, episodes: 38000, mean episode reward: -101.05933942111211, time: 24.654
agent0_energy_min, agent0_attention_min
[-20.06  -0.16]
agent1_energy_min, agent1_attention_min
[-1.17 -0.56]
38100 50
steps: 1904950, episodes: 38100, mean episode reward: -95.6251275541717, time: 25.241
agent0_energy_min, agent0_attention_min
[-17.81  -0.04]
agent1_energy_min, agent1_attention_min
[-0.58 -0.48]
38200 50
steps: 1909950, episodes: 38200, mean episode reward: -111.57500894584831, time: 24.382
agent0_energy_min, agent0_attention_min
[-19.    -0.07]
agent1_energy_min, agent1_attention_min
[-1.48 -0.58]
38300 50
steps: 1914950, episodes: 38300, mean episode reward: -97.45223292433107, time: 24.447
agent0_energy_min, agent0_attention_min
[-17.55  -0.2 ]
agent1_energy_min, agent1_attention_min
[-1.36 -0.68]
38400 50
steps: 1919950, episodes: 38400, mean episode reward: -97.56463937190273, time: 25.321
agent0_energy_min, agent0_attention_min
[-16.28  -0.06]
agent1_energy_min, agent1_attention_min
[-1.26 -0.39]
38500 50
steps: 1924950, episodes: 38500, mean episode reward: -87.41758093902985, time: 24.677
agent0_energy_min, agent0_attention_min
[-16.47  -0.08]
agent1_energy_min, agent1_attention_min
[-0.13 -0.09]
38600 50
steps: 1929950, episodes: 38600, mean episode reward: -81.81307551978598, time: 25.254
agent0_energy_min, agent0_attention_min
[-18.12  -0.04]
agent1_energy_min, agent1_attention_min
[-0.66 -0.18]
38700 50
steps: 1934950, episodes: 38700, mean episode reward: -107.20351322439161, time: 24.509
agent0_energy_min, agent0_attention_min
[-15.93  -0.09]
agent1_energy_min, agent1_attention_min
[-1.24 -0.91]
38800 50
steps: 1939950, episodes: 38800, mean episode reward: -102.89811296773189, time: 24.68
agent0_energy_min, agent0_attention_min
[-18.33  -0.73]
agent1_energy_min, agent1_attention_min
[-0.13 -0.06]
38900 50
steps: 1944950, episodes: 38900, mean episode reward: -104.66568844578444, time: 25.366
agent0_energy_min, agent0_attention_min
[-16.02  -4.31]
agent1_energy_min, agent1_attention_min
[-0.2  0. ]
39000 50
steps: 1949950, episodes: 39000, mean episode reward: -85.21074056111812, time: 24.76
agent0_energy_min, agent0_attention_min
[-16.51  -2.36]
agent1_energy_min, agent1_attention_min
[-0.13 -0.07]
39100 50
steps: 1954950, episodes: 39100, mean episode reward: -115.82282778988831, time: 25.262
agent0_energy_min, agent0_attention_min
[-17.47  -3.19]
agent1_energy_min, agent1_attention_min
[-2.94 -0.26]
39200 50
steps: 1959950, episodes: 39200, mean episode reward: -148.17037231041823, time: 24.906
agent0_energy_min, agent0_attention_min
[-17.68  -4.4 ]
agent1_energy_min, agent1_attention_min
[-10.42  -0.09]
39300 50
steps: 1964950, episodes: 39300, mean episode reward: -133.67845038422035, time: 24.526
agent0_energy_min, agent0_attention_min
[-18.7   -0.05]
agent1_energy_min, agent1_attention_min
[-20.22  -0.57]
39400 50
steps: 1969950, episodes: 39400, mean episode reward: -157.0975397068858, time: 24.745
agent0_energy_min, agent0_attention_min
[-17.12  -0.05]
agent1_energy_min, agent1_attention_min
[-19.52  -1.95]
39500 50
steps: 1974950, episodes: 39500, mean episode reward: -94.25496597387829, time: 24.994
agent0_energy_min, agent0_attention_min
[-16.43  -0.1 ]
agent1_energy_min, agent1_attention_min
[-0.4  0. ]
39600 50
steps: 1979950, episodes: 39600, mean episode reward: -96.83052706290087, time: 22.703
agent0_energy_min, agent0_attention_min
[-4.997e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-4.708e+01 -2.000e-02]
39200 50
steps: 1959950, episodes: 39200, mean episode reward: -181.68469034497403, time: 24.225
agent0_energy_min, agent0_attention_min
[-49.79  -0.05]
agent1_energy_min, agent1_attention_min
[-4.454e+01 -3.000e-02]
39300 50
steps: 1964950, episodes: 39300, mean episode reward: -162.36666918413684, time: 23.82
agent0_energy_min, agent0_attention_min
[-47.84  -2.14]
agent1_energy_min, agent1_attention_min
[-44.37  -0.09]
39400 50
steps: 1969950, episodes: 39400, mean episode reward: -182.72743727263628, time: 24.135
agent0_energy_min, agent0_attention_min
[-33.63 -16.37]
agent1_energy_min, agent1_attention_min
[-44.53  -0.54]
39500 50
steps: 1974950, episodes: 39500, mean episode reward: -179.12219694161766, time: 24.524
agent0_energy_min, agent0_attention_min
[-45.88  -2.4 ]
agent1_energy_min, agent1_attention_min
[-43.97  -0.13]
39600 50
steps: 1979950, episodes: 39600, mean episode reward: -156.3265658782121, time: 24.405
agent0_energy_min, agent0_attention_min
[-45.7  -0.7]
agent1_energy_min, agent1_attention_min
[-40.92  -0.36]
39700 50
steps: 1984950, episodes: 39700, mean episode reward: -128.9036178654629, time: 23.737
agent0_energy_min, agent0_attention_min
[-46.3   -0.24]
agent1_energy_min, agent1_attention_min
[-39.75  -0.16]
39800 50
steps: 1989950, episodes: 39800, mean episode reward: -105.9085781335993, time: 24.588
agent0_energy_min, agent0_attention_min
[-4.592e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-46.53  -0.29]
39900 50
steps: 1994950, episodes: 39900, mean episode reward: -71.74796827578847, time: 23.712
agent0_energy_min, agent0_attention_min
[-4.7e+01 -3.0e-02]
agent1_energy_min, agent1_attention_min
[-4.656e+01 -2.000e-02]
40000 50
steps: 1999950, episodes: 40000, mean episode reward: -72.34296781945713, time: 21.761
agent0_energy_min, agent0_attention_min
[-4.941e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-44.04  -0.55]
...Finished!
Trained episodes: 1 -> 40000
Total time: 2.71 hr

[-18.   -29.46]
39800 50
steps: 1989950, episodes: 39800, mean episode reward: -61.59931821076169, time: 24.807
agent0_energy_min, agent0_attention_min
[-23.03  -4.86]
agent1_energy_min, agent1_attention_min
[-17.46 -32.1 ]
39900 50
steps: 1994950, episodes: 39900, mean episode reward: -63.53224055738275, time: 23.576
agent0_energy_min, agent0_attention_min
[-21.87  -7.89]
agent1_energy_min, agent1_attention_min
[-17.46 -31.73]
40000 50
steps: 1999950, episodes: 40000, mean episode reward: -69.58235045846587, time: 21.756
agent0_energy_min, agent0_attention_min
[-24.26  -6.91]
agent1_energy_min, agent1_attention_min
[-21.07 -28.61]
...Finished!
Trained episodes: 1 -> 40000
Total time: 2.71 hr

[-21.35  -7.61]
39400 50
steps: 1969950, episodes: 39400, mean episode reward: -87.22958958054282, time: 24.347
agent0_energy_min, agent0_attention_min
[-44.86  -0.14]
agent1_energy_min, agent1_attention_min
[-26.11 -10.86]
39500 50
steps: 1974950, episodes: 39500, mean episode reward: -55.21502252807643, time: 24.129
agent0_energy_min, agent0_attention_min
[-46.99  -0.05]
agent1_energy_min, agent1_attention_min
[-30.67  -9.46]
39600 50
steps: 1979950, episodes: 39600, mean episode reward: -68.58441464674188, time: 24.898
agent0_energy_min, agent0_attention_min
[-47.98  -0.06]
agent1_energy_min, agent1_attention_min
[-27.33  -6.9 ]
39700 50
steps: 1984950, episodes: 39700, mean episode reward: -81.14059010441483, time: 24.259
agent0_energy_min, agent0_attention_min
[-48.21  -0.07]
agent1_energy_min, agent1_attention_min
[-21.57  -7.68]
39800 50
steps: 1989950, episodes: 39800, mean episode reward: -82.13213424367106, time: 24.461
agent0_energy_min, agent0_attention_min
[-4.846e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-30.25  -9.73]
39900 50
steps: 1994950, episodes: 39900, mean episode reward: -80.17157667456631, time: 23.043
agent0_energy_min, agent0_attention_min
[-48.87  -0.07]
agent1_energy_min, agent1_attention_min
[-25.   -11.21]
40000 50
steps: 1999950, episodes: 40000, mean episode reward: -69.79988276058512, time: 20.291
agent0_energy_min, agent0_attention_min
[-4.615e+01 -4.000e-02]
agent1_energy_min, agent1_attention_min
[-21.3   -9.85]
...Finished!
Trained episodes: 1 -> 40000
Total time: 2.72 hr

[-48.47  -0.11]
39400 50
steps: 1969950, episodes: 39400, mean episode reward: -55.180945230501145, time: 24.504
agent0_energy_min, agent0_attention_min
[-37.9   -2.28]
agent1_energy_min, agent1_attention_min
[-48.35  -0.72]
39500 50
steps: 1974950, episodes: 39500, mean episode reward: -92.12829462999848, time: 24.755
agent0_energy_min, agent0_attention_min
[-41.79  -1.92]
agent1_energy_min, agent1_attention_min
[-45.72  -0.77]
39600 50
steps: 1979950, episodes: 39600, mean episode reward: -57.95372877729006, time: 24.413
agent0_energy_min, agent0_attention_min
[-41.12  -0.63]
agent1_energy_min, agent1_attention_min
[-47.25  -0.11]
39700 50
steps: 1984950, episodes: 39700, mean episode reward: -51.70699700539929, time: 24.864
agent0_energy_min, agent0_attention_min
[-40.78  -0.31]
agent1_energy_min, agent1_attention_min
[-47.   -0.1]
39800 50
steps: 1989950, episodes: 39800, mean episode reward: -58.23169310466989, time: 24.361
agent0_energy_min, agent0_attention_min
[-42.06  -1.47]
agent1_energy_min, agent1_attention_min
[-46.43  -0.12]
39900 50
steps: 1994950, episodes: 39900, mean episode reward: -49.32642603099291, time: 23.156
agent0_energy_min, agent0_attention_min
[-39.74  -1.3 ]
agent1_energy_min, agent1_attention_min
[-46.44  -0.16]
40000 50
steps: 1999950, episodes: 40000, mean episode reward: -43.74963059344093, time: 20.211
agent0_energy_min, agent0_attention_min
[-41.67  -1.06]
agent1_energy_min, agent1_attention_min
[-4.66e+01 -3.00e-02]
...Finished!
Trained episodes: 1 -> 40000
Total time: 2.72 hr

[-4.246e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-21.04  -0.28]
39200 50
steps: 1959950, episodes: 39200, mean episode reward: -63.573101307382366, time: 24.475
agent0_energy_min, agent0_attention_min
[-44.04  -0.05]
agent1_energy_min, agent1_attention_min
[-17.13  -0.13]
39300 50
steps: 1964950, episodes: 39300, mean episode reward: -66.19650808616939, time: 24.519
agent0_energy_min, agent0_attention_min
[-39.09   0.  ]
agent1_energy_min, agent1_attention_min
[-18.73  -0.18]
39400 50
steps: 1969950, episodes: 39400, mean episode reward: -65.79608718086827, time: 24.3
agent0_energy_min, agent0_attention_min
[-4.082e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-18.3   -0.44]
39500 50
steps: 1974950, episodes: 39500, mean episode reward: -69.9118612997448, time: 24.152
agent0_energy_min, agent0_attention_min
[-4.236e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-18.71  -1.09]
39600 50
steps: 1979950, episodes: 39600, mean episode reward: -75.42657150264453, time: 24.387
agent0_energy_min, agent0_attention_min
[-47.81  -0.05]
agent1_energy_min, agent1_attention_min
[-19.29  -1.42]
39700 50
steps: 1984950, episodes: 39700, mean episode reward: -74.48612520574272, time: 24.011
agent0_energy_min, agent0_attention_min
[-42.52   0.  ]
agent1_energy_min, agent1_attention_min
[-19.43  -1.84]
39800 50
steps: 1989950, episodes: 39800, mean episode reward: -65.0456599025856, time: 23.274
agent0_energy_min, agent0_attention_min
[-4.456e+01 -3.000e-02]
agent1_energy_min, agent1_attention_min
[-19.14  -0.06]
39900 50
steps: 1994950, episodes: 39900, mean episode reward: -69.162324864651, time: 21.249
agent0_energy_min, agent0_attention_min
[-4.278e+01 -1.000e-02]
agent1_energy_min, agent1_attention_min
[-20.5   -0.05]
40000 50
steps: 1999950, episodes: 40000, mean episode reward: -57.442597968654255, time: 18.825
agent0_energy_min, agent0_attention_min
[-4.156e+01 -2.000e-02]
agent1_energy_min, agent1_attention_min
[-17.93  -0.07]
...Finished!
Trained episodes: 1 -> 40000
Total time: 2.71 hr

[ -9.16 -40.18]
39800 50
steps: 1989950, episodes: 39800, mean episode reward: -60.46649634334393, time: 21.711
agent0_energy_min, agent0_attention_min
[-17.77  -3.72]
agent1_energy_min, agent1_attention_min
[-15.38 -34.28]
39900 50
steps: 1994950, episodes: 39900, mean episode reward: -54.200263661622536, time: 19.177
agent0_energy_min, agent0_attention_min
[-18.25  -2.64]
agent1_energy_min, agent1_attention_min
[-12.69 -37.02]
40000 50
steps: 1999950, episodes: 40000, mean episode reward: -55.11926905698521, time: 16.044
agent0_energy_min, agent0_attention_min
[-19.11  -1.47]
agent1_energy_min, agent1_attention_min
[-12.65 -37.25]
...Finished!
Trained episodes: 1 -> 40000
Total time: 2.72 hr

agent0_energy_min, agent0_attention_min
[-20.46  -0.15]
agent1_energy_min, agent1_attention_min
[-0.19 -0.01]
39700 50
steps: 1984950, episodes: 39700, mean episode reward: -97.12780631363842, time: 19.782
agent0_energy_min, agent0_attention_min
[-19.52  -0.11]
agent1_energy_min, agent1_attention_min
[-0.74 -0.01]
39800 50
steps: 1989950, episodes: 39800, mean episode reward: -101.95496146767026, time: 16.562
agent0_energy_min, agent0_attention_min
[-18.99  -0.18]
agent1_energy_min, agent1_attention_min
[-1.25 -0.05]
39900 50
steps: 1994950, episodes: 39900, mean episode reward: -94.14024931309429, time: 15.123
agent0_energy_min, agent0_attention_min
[-17.14  -0.52]
agent1_energy_min, agent1_attention_min
[-0.42 -0.02]
40000 50
steps: 1999950, episodes: 40000, mean episode reward: -88.18568008942685, time: 14.877
agent0_energy_min, agent0_attention_min
[-15.41  -0.2 ]
agent1_energy_min, agent1_attention_min
[-0.92 -0.07]
...Finished!
Trained episodes: 1 -> 40000
Total time: 2.73 hr
