python train.py --scenario wanderer1-1 --num-episodes 10000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
python train.py --scenario wanderer1-2 --num-episodes 10000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
python train.py --scenario wanderer1-3 --num-episodes 10000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
python train.py --scenario wanderer1-4 --num-episodes 10000 --max-episode-len 50 --good-policy ddpg --adv-policy ddpg  &
Using good policy ddpg and adv policy ddpg
Starting iterations of wanderer1-1__2018-07-10_18-33-16...
100 50
steps: 4950, episodes: 100, mean episode reward: -74.36681397315174, time: 5.588
 agent0's money: -25.3
200 50
steps: 9950, episodes: 200, mean episode reward: -80.34784996798972, time: 6.254
 agent0's money: -25.8
300 50
steps: 14950, episodes: 300, mean episode reward: -59.92730833301711, time: 5.875
 agent0's money: -24.6
400 50
steps: 19950, episodes: 400, mean episode reward: -80.87959647705566, time: 5.976
 agent0's money: -25.5
500 50
steps: 24950, episodes: 500, mean episode reward: -82.09942701500243, time: 6.125
 agent0's money: -25.2
600 50
steps: 29950, episodes: 600, mean episode reward: -82.71483490063756, time: 5.934
 agent0's money: -25.6
700 50
steps: 34950, episodes: 700, mean episode reward: -73.03291510969525, time: 6.125
 agent0's money: -25.2
800 50
steps: 39950, episodes: 800, mean episode reward: -72.71994088177864, time: 5.987
 agent0's money: -25.3
900 50
steps: 44950, episodes: 900, mean episode reward: -76.60387676282421, time: 6.119
 agent0's money: -25.9
1000 50
steps: 49950, episodes: 1000, mean episode reward: -73.87174213687567, time: 5.867
 agent0's money: -25.4
1100 50
steps: 54950, episodes: 1100, mean episode reward: -506.41610987137574, time: 7.652
 agent0's money: -35.0
1200 50
steps: 59950, episodes: 1200, mean episode reward: -152.1524029585789, time: 7.715
 agent0's money: -14.0
1300 50
steps: 64950, episodes: 1300, mean episode reward: -237.05748467969184, time: 7.9
 agent0's money: -34.4
1400 50
steps: 69950, episodes: 1400, mean episode reward: -161.63058792731917, time: 7.976
 agent0's money: -4.7
1500 50
steps: 74950, episodes: 1500, mean episode reward: -124.98273349113191, time: 7.943
 agent0's money: -30.3
1600 50
steps: 79950, episodes: 1600, mean episode reward: -118.80403114103889, time: 7.939
 agent0's money: -34.8
1700 50
steps: 84950, episodes: 1700, mean episode reward: -81.35321632307381, time: 7.729
 agent0's money: -24.1
1800 50
steps: 89950, episodes: 1800, mean episode reward: -68.28831274093473, time: 7.849
 agent0's money: -23.8
1900 50
steps: 94950, episodes: 1900, mean episode reward: -52.8495199055598, time: 7.776
 agent0's money: -30.1
2000 50
steps: 99950, episodes: 2000, mean episode reward: -66.38636253153166, time: 7.757
 agent0's money: -26.3
2100 50
steps: 104950, episodes: 2100, mean episode reward: -66.66171970954385, time: 8.161
 agent0's money: -37.9
2200 50
steps: 109950, episodes: 2200, mean episode reward: -87.23751514787538, time: 7.59
 agent0's money: -35.3
2300 50
steps: 114950, episodes: 2300, mean episode reward: -92.31015282905473, time: 7.476
 agent0's money: -34.2
2400 50
steps: 119950, episodes: 2400, mean episode reward: -76.09546148067317, time: 7.724
 agent0's money: -27.1
2500 50
steps: 124950, episodes: 2500, mean episode reward: -47.53602336268343, time: 7.479
 agent0's money: -35.5
2600 50
steps: 129950, episodes: 2600, mean episode reward: -44.59347319873808, time: 7.742
 agent0's money: -37.9
2700 50
steps: 134950, episodes: 2700, mean episode reward: -52.12371884257351, time: 7.618
 agent0's money: -37.6
2800 50
steps: 139950, episodes: 2800, mean episode reward: -51.46906070047995, time: 7.552
 agent0's money: -40.8
2900 50
steps: 144950, episodes: 2900, mean episode reward: -59.007435129131984, time: 7.601
 agent0's money: -46.5
3000 50
steps: 149950, episodes: 3000, mean episode reward: -36.88779156645073, time: 7.794
 agent0's money: -42.5
3100 50
steps: 154950, episodes: 3100, mean episode reward: -42.05194439848784, time: 7.762
 agent0's money: -44.9
3200 50
steps: 159950, episodes: 3200, mean episode reward: -44.21065758606369, time: 7.737
 agent0's money: -48.9
3300 50
steps: 164950, episodes: 3300, mean episode reward: -41.483217803752076, time: 7.546
 agent0's money: -49.6
3400 50
steps: 169950, episodes: 3400, mean episode reward: -52.328156126298865, time: 7.46
 agent0's money: -49.0
3500 50
steps: 174950, episodes: 3500, mean episode reward: -59.83365294301968, time: 7.656
 agent0's money: -49.2
3600 50
steps: 179950, episodes: 3600, mean episode reward: -48.064024834521234, time: 7.844
 agent0's money: -48.8
3700 50
steps: 184950, episodes: 3700, mean episode reward: -36.689680880176205, time: 7.655
 agent0's money: -49.4
3800 50
steps: 189950, episodes: 3800, mean episode reward: -40.812400947798714, time: 7.638
 agent0's money: -48.7
3900 50
steps: 194950, episodes: 3900, mean episode reward: -45.247571602328314, time: 7.368
 agent0's money: -49.2
4000 50
steps: 199950, episodes: 4000, mean episode reward: -44.7959981803578, time: 7.47
 agent0's money: -48.9
4100 50
steps: 204950, episodes: 4100, mean episode reward: -35.48161099879166, time: 7.629
 agent0's money: -48.6
4200 50
steps: 209950, episodes: 4200, mean episode reward: -28.557807635581707, time: 7.407
 agent0's money: -49.6
4300 50
steps: 214950, episodes: 4300, mean episode reward: -32.285797789686086, time: 7.445
 agent0's money: -49.5
4400 50
steps: 219950, episodes: 4400, mean episode reward: -32.1786608292713, time: 7.369
 agent0's money: -49.4
4500 50
steps: 224950, episodes: 4500, mean episode reward: -41.23617995877075, time: 7.425
 agent0's money: -49.4
4600 50
steps: 229950, episodes: 4600, mean episode reward: -34.71386654431117, time: 7.582
 agent0's money: -49.2
4700 50
steps: 234950, episodes: 4700, mean episode reward: -40.20686164393257, time: 7.439
 agent0's money: -48.1
4800 50
steps: 239950, episodes: 4800, mean episode reward: -27.56192408114834, time: 7.479
 agent0's money: -48.5
4900 50
steps: 244950, episodes: 4900, mean episode reward: -31.048792755700898, time: 7.291
 agent0's money: -49.1
5000 50
steps: 249950, episodes: 5000, mean episode reward: -31.1192394230829, time: 7.472
 agent0's money: -47.6
5100 50
steps: 254950, episodes: 5100, mean episode reward: -31.507103796419837, time: 7.505
 agent0's money: -47.2
5200 50
steps: 259950, episodes: 5200, mean episode reward: -28.07713976570288, time: 7.437
 agent0's money: -48.2
5300 50
steps: 264950, episodes: 5300, mean episode reward: -26.371355408440216, time: 7.366
 agent0's money: -48.5
5400 50
steps: 269950, episodes: 5400, mean episode reward: -32.63821406475634, time: 7.342
 agent0's money: -48.1
5500 50
steps: 274950, episodes: 5500, mean episode reward: -27.69845753607576, time: 7.604
 agent0's money: -49.0
5600 50
steps: 279950, episodes: 5600, mean episode reward: -38.124790564373846, time: 7.868
 agent0's money: -49.0
5700 50
steps: 284950, episodes: 5700, mean episode reward: -38.14356335640669, time: 7.615
 agent0's money: -48.8
5800 50
steps: 289950, episodes: 5800, mean episode reward: -29.446303284550527, time: 7.493
 agent0's money: -49.2
5900 50
steps: 294950, episodes: 5900, mean episode reward: -38.51885135395651, time: 7.471
 agent0's money: -47.8
6000 50
steps: 299950, episodes: 6000, mean episode reward: -40.413586761874605, time: 7.338
 agent0's money: -48.1
6100 50
steps: 304950, episodes: 6100, mean episode reward: -37.54031034979486, time: 7.629
 agent0's money: -47.3
6200 50
steps: 309950, episodes: 6200, mean episode reward: -39.88582753633504, time: 7.268
 agent0's money: -48.0
6300 50
steps: 314950, episodes: 6300, mean episode reward: -34.300879172058764, time: 7.521
 agent0's money: -47.6
6400 50
steps: 319950, episodes: 6400, mean episode reward: -32.83178326006393, time: 7.547
 agent0's money: -47.1
6500 50
steps: 324950, episodes: 6500, mean episode reward: -31.381739957443173, time: 7.617
 agent0's money: -48.2
6600 50
steps: 329950, episodes: 6600, mean episode reward: -34.360055639442464, time: 7.479
 agent0's money: -46.9
6700 50
steps: 334950, episodes: 6700, mean episode reward: -26.10174888566415, time: 7.55
 agent0's money: -48.6
6800 50
steps: 339950, episodes: 6800, mean episode reward: -28.311890452671737, time: 7.841
 agent0's money: -48.1
6900 50
steps: 344950, episodes: 6900, mean episode reward: -27.099146429078925, time: 7.516
 agent0's money: -48.3
7000 50
steps: 349950, episodes: 7000, mean episode reward: -32.689533073168874, time: 7.633
 agent0's money: -49.1
7100 50
steps: 354950, episodes: 7100, mean episode reward: -29.612954115941825, time: 7.71Using good policy ddpg and adv policy ddpg
Starting iterations of wanderer1-2__2018-07-10_18-33-19...
100 50
steps: 4950, episodes: 100, mean episode reward: -81.76264056620616, time: 5.844
 agent0's money: -25.0
200 50
steps: 9950, episodes: 200, mean episode reward: -95.6758522931292, time: 5.835
 agent0's money: -25.1
300 50
steps: 14950, episodes: 300, mean episode reward: -82.62609782797279, time: 5.843
 agent0's money: -24.6
400 50
steps: 19950, episodes: 400, mean episode reward: -77.00064023171187, time: 5.769
 agent0's money: -24.5
500 50
steps: 24950, episodes: 500, mean episode reward: -88.00256489715159, time: 6.007
 agent0's money: -24.9
600 50
steps: 29950, episodes: 600, mean episode reward: -86.1408298583695, time: 6.115
 agent0's money: -24.9
700 50
steps: 34950, episodes: 700, mean episode reward: -92.92563524165149, time: 6.032
 agent0's money: -24.8
800 50
steps: 39950, episodes: 800, mean episode reward: -83.44312121606495, time: 5.986
 agent0's money: -25.0
900 50
steps: 44950, episodes: 900, mean episode reward: -91.80907084260298, time: 5.71
 agent0's money: -24.3
1000 50
steps: 49950, episodes: 1000, mean episode reward: -86.57436127869188, time: 6.018
 agent0's money: -25.1
1100 50
steps: 54950, episodes: 1100, mean episode reward: -371.7376250778967, time: 7.61
 agent0's money: -23.9
1200 50
steps: 59950, episodes: 1200, mean episode reward: -74.12845084608331, time: 7.778
 agent0's money: -26.5
1300 50
steps: 64950, episodes: 1300, mean episode reward: -219.68866140614213, time: 7.847
 agent0's money: -14.5
1400 50
steps: 69950, episodes: 1400, mean episode reward: -423.66156414050715, time: 7.824
 agent0's money: -16.7
1500 50
steps: 74950, episodes: 1500, mean episode reward: -169.4475336338876, time: 7.85
 agent0's money: -26.9
1600 50
steps: 79950, episodes: 1600, mean episode reward: -104.46124951113642, time: 7.866
 agent0's money: -3.0
1700 50
steps: 84950, episodes: 1700, mean episode reward: -84.3256758444996, time: 7.829
 agent0's money: -6.0
1800 50
steps: 89950, episodes: 1800, mean episode reward: -90.21524385868697, time: 7.831
 agent0's money: -19.4
1900 50
steps: 94950, episodes: 1900, mean episode reward: -74.46900829586514, time: 7.773
 agent0's money: -21.3
2000 50
steps: 99950, episodes: 2000, mean episode reward: -80.65237531493088, time: 7.763
 agent0's money: -31.2
2100 50
steps: 104950, episodes: 2100, mean episode reward: -70.54362396839647, time: 8.189
 agent0's money: -17.6
2200 50
steps: 109950, episodes: 2200, mean episode reward: -76.57745143142064, time: 7.643
 agent0's money: -15.3
2300 50
steps: 114950, episodes: 2300, mean episode reward: -82.51663129421156, time: 7.796
 agent0's money: -10.0
2400 50
steps: 119950, episodes: 2400, mean episode reward: -75.27914951878556, time: 7.731
 agent0's money: -14.4
2500 50
steps: 124950, episodes: 2500, mean episode reward: -72.8846414109378, time: 8.054
 agent0's money: -20.0
2600 50
steps: 129950, episodes: 2600, mean episode reward: -78.52388847824062, time: 7.885
 agent0's money: -9.3
2700 50
steps: 134950, episodes: 2700, mean episode reward: -76.54955805996816, time: 7.916
 agent0's money: -3.2
2800 50
steps: 139950, episodes: 2800, mean episode reward: -57.82889415590771, time: 7.65
 agent0's money: -23.0
2900 50
steps: 144950, episodes: 2900, mean episode reward: -67.39410386262438, time: 7.729
 agent0's money: -27.3
3000 50
steps: 149950, episodes: 3000, mean episode reward: -49.63430204597723, time: 7.979
 agent0's money: -35.1
3100 50
steps: 154950, episodes: 3100, mean episode reward: -67.58162981088617, time: 7.978
 agent0's money: -34.1
3200 50
steps: 159950, episodes: 3200, mean episode reward: -50.96823484823857, time: 7.975
 agent0's money: -30.8
3300 50
steps: 164950, episodes: 3300, mean episode reward: -54.845600534972725, time: 7.742
 agent0's money: -34.8
3400 50
steps: 169950, episodes: 3400, mean episode reward: -61.69343027856158, time: 7.786
 agent0's money: -39.1
3500 50
steps: 174950, episodes: 3500, mean episode reward: -60.25521415230277, time: 7.709
 agent0's money: -45.3
3600 50
steps: 179950, episodes: 3600, mean episode reward: -62.97357573523806, time: 7.842
 agent0's money: -47.5
3700 50
steps: 184950, episodes: 3700, mean episode reward: -59.86940021003128, time: 7.664
 agent0's money: -49.1
3800 50
steps: 189950, episodes: 3800, mean episode reward: -58.31142480683749, time: 7.831
 agent0's money: -47.3
3900 50
steps: 194950, episodes: 3900, mean episode reward: -61.21779663661177, time: 7.767
 agent0's money: -46.6
4000 50
steps: 199950, episodes: 4000, mean episode reward: -48.61258111078723, time: 7.533
 agent0's money: -45.7
4100 50
steps: 204950, episodes: 4100, mean episode reward: -56.4660828693974, time: 7.786
 agent0's money: -47.5
4200 50
steps: 209950, episodes: 4200, mean episode reward: -49.084332279320286, time: 7.734
 agent0's money: -48.6
4300 50
steps: 214950, episodes: 4300, mean episode reward: -53.20711553092572, time: 7.826
 agent0's money: -48.9
4400 50
steps: 219950, episodes: 4400, mean episode reward: -49.68891293164868, time: 7.715
 agent0's money: -47.9
4500 50
steps: 224950, episodes: 4500, mean episode reward: -52.78461609879234, time: 7.947
 agent0's money: -47.0
4600 50
steps: 229950, episodes: 4600, mean episode reward: -50.084417016824226, time: 8.121
 agent0's money: -48.0
4700 50
steps: 234950, episodes: 4700, mean episode reward: -57.38862982500088, time: 7.782
 agent0's money: -47.7
4800 50
steps: 239950, episodes: 4800, mean episode reward: -53.94174663569206, time: 7.853
 agent0's money: -47.4
4900 50
steps: 244950, episodes: 4900, mean episode reward: -46.490223182283074, time: 7.527
 agent0's money: -47.4
5000 50
steps: 249950, episodes: 5000, mean episode reward: -46.42548715791516, time: 7.826
 agent0's money: -46.8
5100 50
steps: 254950, episodes: 5100, mean episode reward: -43.30442084452202, time: 7.83
 agent0's money: -47.9
5200 50
steps: 259950, episodes: 5200, mean episode reward: -65.07725186489658, time: 7.747
 agent0's money: -47.9
5300 50
steps: 264950, episodes: 5300, mean episode reward: -58.73862066887526, time: 7.759
 agent0's money: -48.0
5400 50
steps: 269950, episodes: 5400, mean episode reward: -57.16090125808105, time: 7.655
 agent0's money: -47.7
5500 50
steps: 274950, episodes: 5500, mean episode reward: -51.47421192190458, time: 7.792
 agent0's money: -47.8
5600 50
steps: 279950, episodes: 5600, mean episode reward: -58.09375625023498, time: 8.102
 agent0's money: -43.6
5700 50
steps: 284950, episodes: 5700, mean episode reward: -54.37467440594287, time: 7.724
 agent0's money: -47.5
5800 50
steps: 289950, episodes: 5800, mean episode reward: -54.74203279079285, time: 7.807
 agent0's money: -46.5
5900 50
steps: 294950, episodes: 5900, mean episode reward: -61.5774483159732, time: 7.852
 agent0's money: -45.6
6000 50
steps: 299950, episodes: 6000, mean episode reward: -50.379121161721066, time: 7.654
 agent0's money: -47.0
6100 50
steps: 304950, episodes: 6100, mean episode reward: -53.59768943262292, time: 7.898
 agent0's money: -47.6
6200 50
steps: 309950, episodes: 6200, mean episode reward: -54.48625153616536, time: 7.614
 agent0's money: -45.1
6300 50
steps: 314950, episodes: 6300, mean episode reward: -41.58605316284853, time: 7.687
 agent0's money: -45.5
6400 50
steps: 319950, episodes: 6400, mean episode reward: -55.02073389754855, time: 7.445
 agent0's money: -45.7
6500 50
steps: 324950, episodes: 6500, mean episode reward: -50.04194176117298, time: 7.713
 agent0's money: -46.3
6600 50
steps: 329950, episodes: 6600, mean episode reward: -56.15496017139324, time: 7.75
 agent0's money: -46.4
6700 50
steps: 334950, episodes: 6700, mean episode reward: -45.8063253625799, time: 7.631
 agent0's money: -48.1
6800 50
steps: 339950, episodes: 6800, mean episode reward: -43.46431167271662, time: 7.527
 agent0's money: -48.6
6900 50
steps: 344950, episodes: 6900, mean episode reward: -47.70568912839835, time: 7.471
 agent0's money: -47.6
7000 50
steps: 349950, episodes: 7000, mean episode reward: -56.17632944479365, time: 7.366
 agent0's money: -48.8
7100 50
steps: 354950, episodes: 7100, mean episode reward: -47.127191642031256, time: 7.646Using good policy ddpg and adv policy ddpg
Starting iterations of wanderer1-3__2018-07-10_18-33-21...
100 50
steps: 4950, episodes: 100, mean episode reward: -101.46102646776205, time: 5.728
 agent0's money: -24.8
200 50
steps: 9950, episodes: 200, mean episode reward: -105.23168485357526, time: 6.086
 agent0's money: -25.1
300 50
steps: 14950, episodes: 300, mean episode reward: -96.30372639645702, time: 6.029
 agent0's money: -24.6
400 50
steps: 19950, episodes: 400, mean episode reward: -94.32308684634077, time: 6.12
 agent0's money: -25.1
500 50
steps: 24950, episodes: 500, mean episode reward: -91.77158101587948, time: 5.992
 agent0's money: -24.7
600 50
steps: 29950, episodes: 600, mean episode reward: -92.60832508985062, time: 6.054
 agent0's money: -24.9
700 50
steps: 34950, episodes: 700, mean episode reward: -90.67906020753843, time: 5.931
 agent0's money: -24.8
800 50
steps: 39950, episodes: 800, mean episode reward: -91.48086866612333, time: 5.746
 agent0's money: -25.1
900 50
steps: 44950, episodes: 900, mean episode reward: -93.27124987849498, time: 5.867
 agent0's money: -25.1
1000 50
steps: 49950, episodes: 1000, mean episode reward: -99.56133743783612, time: 5.869
 agent0's money: -25.1
1100 50
steps: 54950, episodes: 1100, mean episode reward: -498.6947097175756, time: 7.821
 agent0's money: -35.6
1200 50
steps: 59950, episodes: 1200, mean episode reward: -92.07879320643423, time: 8.031
 agent0's money: -9.8
1300 50
steps: 64950, episodes: 1300, mean episode reward: -89.32607391151001, time: 7.688
 agent0's money: -18.8
1400 50
steps: 69950, episodes: 1400, mean episode reward: -167.53805550431554, time: 7.7
 agent0's money: -11.1
1500 50
steps: 74950, episodes: 1500, mean episode reward: -326.7787536466297, time: 7.756
 agent0's money: -17.2
1600 50
steps: 79950, episodes: 1600, mean episode reward: -85.00006932847725, time: 8.082
 agent0's money: -20.9
1700 50
steps: 84950, episodes: 1700, mean episode reward: -91.97604457159156, time: 7.921
 agent0's money: -29.2
1800 50
steps: 89950, episodes: 1800, mean episode reward: -89.61798891087656, time: 7.771
 agent0's money: -36.2
1900 50
steps: 94950, episodes: 1900, mean episode reward: -106.64264313764835, time: 7.865
 agent0's money: -35.5
2000 50
steps: 99950, episodes: 2000, mean episode reward: -90.14626161515, time: 7.863
 agent0's money: -26.8
2100 50
steps: 104950, episodes: 2100, mean episode reward: -87.74507632254621, time: 8.138
 agent0's money: -27.6
2200 50
steps: 109950, episodes: 2200, mean episode reward: -77.61395122108952, time: 7.749
 agent0's money: -7.9
2300 50
steps: 114950, episodes: 2300, mean episode reward: -77.9916817117699, time: 8.02
 agent0's money: -7.9
2400 50
steps: 119950, episodes: 2400, mean episode reward: -82.75110397593355, time: 7.913
 agent0's money: -4.1
2500 50
steps: 124950, episodes: 2500, mean episode reward: -66.90124771191749, time: 7.964
 agent0's money: -2.6
2600 50
steps: 129950, episodes: 2600, mean episode reward: -72.7974262664944, time: 8.101
 agent0's money: -1.0
2700 50
steps: 134950, episodes: 2700, mean episode reward: -83.10826124774246, time: 7.908
 agent0's money: -1.4
2800 50
steps: 139950, episodes: 2800, mean episode reward: -97.92598211838119, time: 7.828
 agent0's money: -10.5
2900 50
steps: 144950, episodes: 2900, mean episode reward: -69.67791831334975, time: 8.133
 agent0's money: -2.4
3000 50
steps: 149950, episodes: 3000, mean episode reward: -80.78554248586337, time: 7.991
 agent0's money: -0.6
3100 50
steps: 154950, episodes: 3100, mean episode reward: -88.7152817309433, time: 8.194
 agent0's money: -0.3
3200 50
steps: 159950, episodes: 3200, mean episode reward: -82.85219077789301, time: 7.759
 agent0's money: -0.6
3300 50
steps: 164950, episodes: 3300, mean episode reward: -79.28331613190976, time: 7.955
 agent0's money: -0.9
3400 50
steps: 169950, episodes: 3400, mean episode reward: -65.07905635338781, time: 8.094
 agent0's money: -1.3
3500 50
steps: 174950, episodes: 3500, mean episode reward: -82.0409648398773, time: 7.847
 agent0's money: -1.1
3600 50
steps: 179950, episodes: 3600, mean episode reward: -73.03596211528685, time: 8.126
 agent0's money: -0.8
3700 50
steps: 184950, episodes: 3700, mean episode reward: -80.26952168893193, time: 7.886
 agent0's money: -0.5
3800 50
steps: 189950, episodes: 3800, mean episode reward: -78.48209664313404, time: 7.874
 agent0's money: -0.1
3900 50
steps: 194950, episodes: 3900, mean episode reward: -68.44895513780149, time: 7.796
 agent0's money: -0.3
4000 50
steps: 199950, episodes: 4000, mean episode reward: -75.92998413419639, time: 7.631
 agent0's money: -0.5
4100 50
steps: 204950, episodes: 4100, mean episode reward: -63.619105420823715, time: 8.045
 agent0's money: -0.9
4200 50
steps: 209950, episodes: 4200, mean episode reward: -69.5971538549574, time: 7.711
 agent0's money: -3.8
4300 50
steps: 214950, episodes: 4300, mean episode reward: -72.22340967911151, time: 8.008
 agent0's money: -7.5
4400 50
steps: 219950, episodes: 4400, mean episode reward: -81.6394552595557, time: 7.986
 agent0's money: -19.8
4500 50
steps: 224950, episodes: 4500, mean episode reward: -78.25507164800919, time: 8.085
 agent0's money: -15.5
4600 50
steps: 229950, episodes: 4600, mean episode reward: -72.16478173467198, time: 7.926
 agent0's money: -2.4
4700 50
steps: 234950, episodes: 4700, mean episode reward: -75.2269948288297, time: 7.935
 agent0's money: -2.6
4800 50
steps: 239950, episodes: 4800, mean episode reward: -73.76010563390788, time: 7.981
 agent0's money: -1.4
4900 50
steps: 244950, episodes: 4900, mean episode reward: -90.40868338226153, time: 7.914
 agent0's money: -2.5
5000 50
steps: 249950, episodes: 5000, mean episode reward: -70.30672228827433, time: 7.862
 agent0's money: -3.6
5100 50
steps: 254950, episodes: 5100, mean episode reward: -93.48121405741026, time: 8.172
 agent0's money: -1.8
5200 50
steps: 259950, episodes: 5200, mean episode reward: -67.0493196915939, time: 7.807
 agent0's money: -0.8
5300 50
steps: 264950, episodes: 5300, mean episode reward: -71.09395451028871, time: 8.142
 agent0's money: -4.6
5400 50
steps: 269950, episodes: 5400, mean episode reward: -64.10672344248863, time: 7.94
 agent0's money: -3.3
5500 50
steps: 274950, episodes: 5500, mean episode reward: -80.9509326199697, time: 7.938
 agent0's money: -14.7
5600 50
steps: 279950, episodes: 5600, mean episode reward: -79.12677370585001, time: 8.092
 agent0's money: -27.6
5700 50
steps: 284950, episodes: 5700, mean episode reward: -73.65713254583669, time: 7.887
 agent0's money: -24.0
5800 50
steps: 289950, episodes: 5800, mean episode reward: -76.66070538925115, time: 7.859
 agent0's money: -26.9
5900 50
steps: 294950, episodes: 5900, mean episode reward: -73.60044666414154, time: 7.708
 agent0's money: -30.5
6000 50
steps: 299950, episodes: 6000, mean episode reward: -72.22996204513973, time: 7.88
 agent0's money: -28.8
6100 50
steps: 304950, episodes: 6100, mean episode reward: -66.43601584040407, time: 8.0
 agent0's money: -28.8
6200 50
steps: 309950, episodes: 6200, mean episode reward: -59.595051377178095, time: 7.608
 agent0's money: -28.6
6300 50
steps: 314950, episodes: 6300, mean episode reward: -65.85934888689974, time: 7.881
 agent0's money: -29.5
6400 50
steps: 319950, episodes: 6400, mean episode reward: -77.99031038805028, time: 7.834
 agent0's money: -28.9
6500 50
steps: 324950, episodes: 6500, mean episode reward: -76.0991580067184, time: 7.8
 agent0's money: -28.3
6600 50
steps: 329950, episodes: 6600, mean episode reward: -77.83317296693224, time: 7.834
 agent0's money: -25.5
6700 50
steps: 334950, episodes: 6700, mean episode reward: -73.51156683990841, time: 7.923
 agent0's money: -25.7
6800 50
steps: 339950, episodes: 6800, mean episode reward: -69.66318788247136, time: 7.879
 agent0's money: -27.6
6900 50
steps: 344950, episodes: 6900, mean episode reward: -74.83878375348644, time: 7.893
 agent0's money: -23.1
7000 50
steps: 349950, episodes: 7000, mean episode reward: -92.44675462544825, time: 7.809
 agent0's money: -24.4
7100 50
steps: 354950, episodes: 7100, mean episode reward: -83.13321372533845, time: 7.961
 agent0's money: -29.0
7200 50
steps: 359950, episodes: 7200, mean episode reward: -72.32566748141225, time: 7.983Using good policy ddpg and adv policy ddpg
Starting iterations of wanderer1-4__2018-07-10_18-33-23...
100 50
steps: 4950, episodes: 100, mean episode reward: -128.98223186788687, time: 5.738
 agent0's money: -24.2
200 50
steps: 9950, episodes: 200, mean episode reward: -138.54947084679955, time: 6.016
 agent0's money: -24.2
300 50
steps: 14950, episodes: 300, mean episode reward: -134.89942496349397, time: 5.911
 agent0's money: -24.4
400 50
steps: 19950, episodes: 400, mean episode reward: -138.11160797400018, time: 5.876
 agent0's money: -24.4
500 50
steps: 24950, episodes: 500, mean episode reward: -142.26281562172397, time: 6.053
 agent0's money: -24.4
600 50
steps: 29950, episodes: 600, mean episode reward: -133.79696193963235, time: 5.94
 agent0's money: -24.5
700 50
steps: 34950, episodes: 700, mean episode reward: -146.50482401457518, time: 5.835
 agent0's money: -24.8
800 50
steps: 39950, episodes: 800, mean episode reward: -136.1811506861278, time: 5.993
 agent0's money: -24.6
900 50
steps: 44950, episodes: 900, mean episode reward: -143.40936795211417, time: 6.108
 agent0's money: -24.2
1000 50
steps: 49950, episodes: 1000, mean episode reward: -131.4962666416878, time: 5.995
 agent0's money: -24.6
1100 50
steps: 54950, episodes: 1100, mean episode reward: -470.60519306964665, time: 7.688
 agent0's money: -25.1
1200 50
steps: 59950, episodes: 1200, mean episode reward: -114.5995406424683, time: 8.115
 agent0's money: -12.6
1300 50
steps: 64950, episodes: 1300, mean episode reward: -243.5155282790269, time: 7.777
 agent0's money: -10.5
1400 50
steps: 69950, episodes: 1400, mean episode reward: -310.01278428073977, time: 7.871
 agent0's money: -12.2
1500 50
steps: 74950, episodes: 1500, mean episode reward: -99.9338310683149, time: 7.834
 agent0's money: -4.3
1600 50
steps: 79950, episodes: 1600, mean episode reward: -79.65158566099625, time: 7.778
 agent0's money: -2.7
1700 50
steps: 84950, episodes: 1700, mean episode reward: -62.30649846668851, time: 7.816
 agent0's money: -0.0
1800 50
steps: 89950, episodes: 1800, mean episode reward: -72.65743272804141, time: 7.818
 agent0's money: -0.1
1900 50
steps: 94950, episodes: 1900, mean episode reward: -68.22548658330935, time: 7.774
 agent0's money: -0.0
2000 50
steps: 99950, episodes: 2000, mean episode reward: -61.94007588209866, time: 7.863
 agent0's money: -0.0
2100 50
steps: 104950, episodes: 2100, mean episode reward: -55.61726467310018, time: 8.259
 agent0's money: -0.0
2200 50
steps: 109950, episodes: 2200, mean episode reward: -57.712350387069115, time: 7.925
 agent0's money: -0.0
2300 50
steps: 114950, episodes: 2300, mean episode reward: -70.22808990457561, time: 7.887
 agent0's money: 0.0
2400 50
steps: 119950, episodes: 2400, mean episode reward: -59.94513103793004, time: 7.884
 agent0's money: -0.0
2500 50
steps: 124950, episodes: 2500, mean episode reward: -70.82183387038125, time: 7.845
 agent0's money: -0.0
2600 50
steps: 129950, episodes: 2600, mean episode reward: -64.52142565124262, time: 8.089
 agent0's money: 0.0
2700 50
steps: 134950, episodes: 2700, mean episode reward: -64.7665022458288, time: 7.839
 agent0's money: 0.0
2800 50
steps: 139950, episodes: 2800, mean episode reward: -61.162866826973506, time: 7.889
 agent0's money: -0.0
2900 50
steps: 144950, episodes: 2900, mean episode reward: -62.23497830136001, time: 8.158
 agent0's money: -0.0
3000 50
steps: 149950, episodes: 3000, mean episode reward: -72.68292724353567, time: 7.892
 agent0's money: -0.0
3100 50
steps: 154950, episodes: 3100, mean episode reward: -60.02536312974491, time: 7.999
 agent0's money: -0.0
3200 50
steps: 159950, episodes: 3200, mean episode reward: -67.25332389697498, time: 8.084
 agent0's money: -0.0
3300 50
steps: 164950, episodes: 3300, mean episode reward: -68.042624031343, time: 7.972
 agent0's money: -0.0
3400 50
steps: 169950, episodes: 3400, mean episode reward: -68.93359931023036, time: 7.776
 agent0's money: -0.0
3500 50
steps: 174950, episodes: 3500, mean episode reward: -73.03517842560393, time: 7.934
 agent0's money: 0.0
3600 50
steps: 179950, episodes: 3600, mean episode reward: -67.67177798373628, time: 8.042
 agent0's money: -0.0
3700 50
steps: 184950, episodes: 3700, mean episode reward: -71.31539400070315, time: 7.926
 agent0's money: -0.0
3800 50
steps: 189950, episodes: 3800, mean episode reward: -62.74499270437881, time: 7.819
 agent0's money: 0.0
3900 50
steps: 194950, episodes: 3900, mean episode reward: -65.38688219537931, time: 7.817
 agent0's money: -0.0
4000 50
steps: 199950, episodes: 4000, mean episode reward: -70.68917137406306, time: 7.681
 agent0's money: -0.0
4100 50
steps: 204950, episodes: 4100, mean episode reward: -70.5861417052619, time: 8.058
 agent0's money: 0.0
4200 50
steps: 209950, episodes: 4200, mean episode reward: -62.852885884443566, time: 7.793
 agent0's money: -0.0
4300 50
steps: 214950, episodes: 4300, mean episode reward: -62.25395322836479, time: 7.769
 agent0's money: 0.0
4400 50
steps: 219950, episodes: 4400, mean episode reward: -79.33226022142306, time: 8.101
 agent0's money: -0.0
4500 50
steps: 224950, episodes: 4500, mean episode reward: -53.16042282425538, time: 8.046
 agent0's money: -0.0
4600 50
steps: 229950, episodes: 4600, mean episode reward: -67.18017340192675, time: 8.066
 agent0's money: -0.0
4700 50
steps: 234950, episodes: 4700, mean episode reward: -64.95065952407211, time: 7.942
 agent0's money: 0.0
4800 50
steps: 239950, episodes: 4800, mean episode reward: -63.77043267296313, time: 7.886
 agent0's money: -0.0
4900 50
steps: 244950, episodes: 4900, mean episode reward: -74.43540829281699, time: 7.888
 agent0's money: -0.0
5000 50
steps: 249950, episodes: 5000, mean episode reward: -57.064252342820446, time: 7.923
 agent0's money: 0.0
5100 50
steps: 254950, episodes: 5100, mean episode reward: -60.68240769414708, time: 8.051
 agent0's money: 0.0
5200 50
steps: 259950, episodes: 5200, mean episode reward: -74.02365019750405, time: 7.844
 agent0's money: -0.0
5300 50
steps: 264950, episodes: 5300, mean episode reward: -62.98728261452195, time: 7.761
 agent0's money: 0.0
5400 50
steps: 269950, episodes: 5400, mean episode reward: -65.25448755729334, time: 7.969
 agent0's money: 0.0
5500 50
steps: 274950, episodes: 5500, mean episode reward: -60.06681548202118, time: 7.746
 agent0's money: 0.0
5600 50
steps: 279950, episodes: 5600, mean episode reward: -74.1072203546056, time: 8.032
 agent0's money: 0.0
5700 50
steps: 284950, episodes: 5700, mean episode reward: -60.56895025693488, time: 7.862
 agent0's money: -0.0
5800 50
steps: 289950, episodes: 5800, mean episode reward: -71.23957827958237, time: 7.831
 agent0's money: -0.0
5900 50
steps: 294950, episodes: 5900, mean episode reward: -63.870688913028935, time: 7.861
 agent0's money: -0.0
6000 50
steps: 299950, episodes: 6000, mean episode reward: -60.08783986231672, time: 7.892
 agent0's money: -0.0
6100 50
steps: 304950, episodes: 6100, mean episode reward: -72.58069409079764, time: 7.95
 agent0's money: 0.0
6200 50
steps: 309950, episodes: 6200, mean episode reward: -62.17838893504758, time: 7.902
 agent0's money: -0.0
6300 50
steps: 314950, episodes: 6300, mean episode reward: -59.50960094922945, time: 7.932
 agent0's money: -0.0
6400 50
steps: 319950, episodes: 6400, mean episode reward: -61.84366493428531, time: 7.96
 agent0's money: -0.0
6500 50
steps: 324950, episodes: 6500, mean episode reward: -59.81200960817601, time: 7.752
 agent0's money: -0.0
6600 50
steps: 329950, episodes: 6600, mean episode reward: -66.11062950802445, time: 8.071
 agent0's money: 0.0
6700 50
steps: 334950, episodes: 6700, mean episode reward: -64.68498305003622, time: 7.949
 agent0's money: 0.0
6800 50
steps: 339950, episodes: 6800, mean episode reward: -63.52305734396021, time: 7.918
 agent0's money: -0.0
6900 50
steps: 344950, episodes: 6900, mean episode reward: -59.20171353079958, time: 7.818
 agent0's money: 0.0
7000 50
steps: 349950, episodes: 7000, mean episode reward: -69.73994035653921, time: 7.832
 agent0's money: -0.0
7100 50
steps: 354950, episodes: 7100, mean episode reward: -60.24924037470889, time: 8.021
 agent0's money: 0.0
7200 50
steps: 359950, episodes: 7200, mean episode reward: -61.448813721905275, time: 7.684
 agent0's money: -49.8
7200 50
steps: 359950, episodes: 7200, mean episode reward: -26.49308799165229, time: 7.354
 agent0's money: -49.6
7300 50
steps: 364950, episodes: 7300, mean episode reward: -29.433286814778924, time: 7.449
 agent0's money: -49.6
7400 50
steps: 369950, episodes: 7400, mean episode reward: -26.431392539633013, time: 7.496
 agent0's money: -49.3
7500 50
steps: 374950, episodes: 7500, mean episode reward: -33.141993140638085, time: 7.55
 agent0's money: -48.7
7600 50
steps: 379950, episodes: 7600, mean episode reward: -30.224813916237398, time: 7.818
 agent0's money: -49.1
7700 50
steps: 384950, episodes: 7700, mean episode reward: -35.179785598645566, time: 7.658
 agent0's money: -48.7
7800 50
steps: 389950, episodes: 7800, mean episode reward: -26.583439502273688, time: 7.405
 agent0's money: -49.1
7900 50
steps: 394950, episodes: 7900, mean episode reward: -33.26106981243763, time: 7.409
 agent0's money: -48.7
8000 50
steps: 399950, episodes: 8000, mean episode reward: -23.90130186174102, time: 7.559
 agent0's money: -49.9
8100 50
steps: 404950, episodes: 8100, mean episode reward: -32.85119631124294, time: 7.709
 agent0's money: -49.4
8200 50
steps: 409950, episodes: 8200, mean episode reward: -33.467041543778315, time: 7.491
 agent0's money: -48.6
8300 50
steps: 414950, episodes: 8300, mean episode reward: -42.519961322682796, time: 7.511
 agent0's money: -49.5
8400 50
steps: 419950, episodes: 8400, mean episode reward: -31.291302094865706, time: 7.845
 agent0's money: -48.9
8500 50
steps: 424950, episodes: 8500, mean episode reward: -21.93722147458499, time: 7.748
 agent0's money: -48.6
8600 50
steps: 429950, episodes: 8600, mean episode reward: -40.74890382556769, time: 7.894
 agent0's money: -49.1
8700 50
steps: 434950, episodes: 8700, mean episode reward: -27.948448922310444, time: 7.504
 agent0's money: -48.7
8800 50
steps: 439950, episodes: 8800, mean episode reward: -30.719597420101987, time: 7.595
 agent0's money: -48.3
8900 50
steps: 444950, episodes: 8900, mean episode reward: -26.928266475832764, time: 7.502
 agent0's money: -48.5
9000 50
steps: 449950, episodes: 9000, mean episode reward: -30.57141684324099, time: 7.452
 agent0's money: -48.6
9100 50
steps: 454950, episodes: 9100, mean episode reward: -29.21675875587412, time: 7.824
 agent0's money: -48.0
9200 50
steps: 459950, episodes: 9200, mean episode reward: -34.25955600589541, time: 7.529
 agent0's money: -48.1
9300 50
steps: 464950, episodes: 9300, mean episode reward: -25.835195050566664, time: 7.446
 agent0's money: -47.6
9400 50
steps: 469950, episodes: 9400, mean episode reward: -26.53167536841516, time: 7.536
 agent0's money: -47.7
9500 50
steps: 474950, episodes: 9500, mean episode reward: -27.20228341130038, time: 7.562
 agent0's money: -47.6
9600 50
steps: 479950, episodes: 9600, mean episode reward: -25.561578570649576, time: 7.666
 agent0's money: -48.7
9700 50
steps: 484950, episodes: 9700, mean episode reward: -37.0451458389611, time: 7.35
 agent0's money: -47.2
9800 50
steps: 489950, episodes: 9800, mean episode reward: -25.710499894932862, time: 7.598
 agent0's money: -48.4
9900 50
steps: 494950, episodes: 9900, mean episode reward: -25.52842924994785, time: 7.621
 agent0's money: -48.0
10000 50
steps: 499950, episodes: 10000, mean episode reward: -40.714731304851874, time: 7.473
 agent0's money: -48.2
...Finished!
Trained episodes: 1 -> 10000
Total time: 0.21 hr

 agent0's money: -48.6
7200 50
steps: 359950, episodes: 7200, mean episode reward: -44.37362584780569, time: 7.517
 agent0's money: -47.8
7300 50
steps: 364950, episodes: 7300, mean episode reward: -49.0330144896486, time: 7.539
 agent0's money: -49.2
7400 50
steps: 369950, episodes: 7400, mean episode reward: -44.828879198002134, time: 7.566
 agent0's money: -48.3
7500 50
steps: 374950, episodes: 7500, mean episode reward: -48.778525708607404, time: 7.442
 agent0's money: -47.7
7600 50
steps: 379950, episodes: 7600, mean episode reward: -53.86747613185492, time: 7.575
 agent0's money: -46.2
7700 50
steps: 384950, episodes: 7700, mean episode reward: -41.8935827693601, time: 7.514
 agent0's money: -47.3
7800 50
steps: 389950, episodes: 7800, mean episode reward: -43.68760900222626, time: 7.315
 agent0's money: -47.8
7900 50
steps: 394950, episodes: 7900, mean episode reward: -44.460626711551434, time: 7.377
 agent0's money: -48.3
8000 50
steps: 399950, episodes: 8000, mean episode reward: -41.40503101305671, time: 7.45
 agent0's money: -47.0
8100 50
steps: 404950, episodes: 8100, mean episode reward: -54.37083883683534, time: 7.7
 agent0's money: -46.9
8200 50
steps: 409950, episodes: 8200, mean episode reward: -46.069610956609694, time: 7.535
 agent0's money: -47.4
8300 50
steps: 414950, episodes: 8300, mean episode reward: -47.62879671246268, time: 7.557
 agent0's money: -46.8
8400 50
steps: 419950, episodes: 8400, mean episode reward: -37.945364638929135, time: 7.529
 agent0's money: -47.3
8500 50
steps: 424950, episodes: 8500, mean episode reward: -39.80997915298965, time: 7.526
 agent0's money: -48.2
8600 50
steps: 429950, episodes: 8600, mean episode reward: -46.41098484675434, time: 7.816
 agent0's money: -44.4
8700 50
steps: 434950, episodes: 8700, mean episode reward: -43.353310412876226, time: 7.635
 agent0's money: -47.7
8800 50
steps: 439950, episodes: 8800, mean episode reward: -49.376524201247584, time: 7.449
 agent0's money: -46.2
8900 50
steps: 444950, episodes: 8900, mean episode reward: -40.88377004440822, time: 7.562
 agent0's money: -48.0
9000 50
steps: 449950, episodes: 9000, mean episode reward: -45.31701120898547, time: 7.298
 agent0's money: -47.1
9100 50
steps: 454950, episodes: 9100, mean episode reward: -36.454689511758495, time: 7.689
 agent0's money: -48.6
9200 50
steps: 459950, episodes: 9200, mean episode reward: -39.67721515810799, time: 7.325
 agent0's money: -48.8
9300 50
steps: 464950, episodes: 9300, mean episode reward: -46.390281366132356, time: 7.449
 agent0's money: -47.8
9400 50
steps: 469950, episodes: 9400, mean episode reward: -36.001960843259155, time: 7.496
 agent0's money: -49.1
9500 50
steps: 474950, episodes: 9500, mean episode reward: -36.76323494437793, time: 7.434
 agent0's money: -48.9
9600 50
steps: 479950, episodes: 9600, mean episode reward: -38.29505463547685, time: 7.591
 agent0's money: -49.1
9700 50
steps: 484950, episodes: 9700, mean episode reward: -39.497035220587485, time: 7.439
 agent0's money: -49.7
9800 50
steps: 489950, episodes: 9800, mean episode reward: -39.190139074276814, time: 7.284
 agent0's money: -49.2
9900 50
steps: 494950, episodes: 9900, mean episode reward: -38.71469842118488, time: 7.425
 agent0's money: -49.3
10000 50
steps: 499950, episodes: 10000, mean episode reward: -44.22912808322023, time: 7.224
 agent0's money: -49.3
...Finished!
Trained episodes: 1 -> 10000
Total time: 0.21 hr

 agent0's money: -27.8
7300 50
steps: 364950, episodes: 7300, mean episode reward: -74.17514936696287, time: 7.818
 agent0's money: -26.8
7400 50
steps: 369950, episodes: 7400, mean episode reward: -80.07406821369636, time: 7.873
 agent0's money: -30.2
7500 50
steps: 374950, episodes: 7500, mean episode reward: -73.77638234429895, time: 7.828
 agent0's money: -24.9
7600 50
steps: 379950, episodes: 7600, mean episode reward: -71.76270839288537, time: 8.182
 agent0's money: -27.0
7700 50
steps: 384950, episodes: 7700, mean episode reward: -73.49447589367259, time: 7.814
 agent0's money: -28.2
7800 50
steps: 389950, episodes: 7800, mean episode reward: -99.49119310913532, time: 7.877
 agent0's money: -36.2
7900 50
steps: 394950, episodes: 7900, mean episode reward: -88.10465130022088, time: 7.963
 agent0's money: -44.9
8000 50
steps: 399950, episodes: 8000, mean episode reward: -113.98277244933553, time: 8.0
 agent0's money: -44.3
8100 50
steps: 404950, episodes: 8100, mean episode reward: -76.31519353591095, time: 8.082
 agent0's money: -45.8
8200 50
steps: 409950, episodes: 8200, mean episode reward: -72.66322968800615, time: 7.889
 agent0's money: -37.5
8300 50
steps: 414950, episodes: 8300, mean episode reward: -69.64584617143208, time: 7.821
 agent0's money: -13.7
8400 50
steps: 419950, episodes: 8400, mean episode reward: -78.70104445170965, time: 8.271
 agent0's money: -4.6
8500 50
steps: 424950, episodes: 8500, mean episode reward: -76.43257653106319, time: 7.897
 agent0's money: -6.1
8600 50
steps: 429950, episodes: 8600, mean episode reward: -67.96096049949904, time: 8.115
 agent0's money: -8.7
8700 50
steps: 434950, episodes: 8700, mean episode reward: -74.27905146914713, time: 7.884
 agent0's money: -25.6
8800 50
steps: 439950, episodes: 8800, mean episode reward: -60.875160845769614, time: 7.735
 agent0's money: -12.1
8900 50
steps: 444950, episodes: 8900, mean episode reward: -69.80392874798873, time: 7.99
 agent0's money: -2.0
9000 50
steps: 449950, episodes: 9000, mean episode reward: -59.83592237939799, time: 7.766
 agent0's money: -21.8
9100 50
steps: 454950, episodes: 9100, mean episode reward: -64.99932192787402, time: 8.0
 agent0's money: -13.9
9200 50
steps: 459950, episodes: 9200, mean episode reward: -85.8681962556182, time: 7.918
 agent0's money: -5.8
9300 50
steps: 464950, episodes: 9300, mean episode reward: -63.43706019206735, time: 7.755
 agent0's money: -16.9
9400 50
steps: 469950, episodes: 9400, mean episode reward: -63.43348495755269, time: 8.012
 agent0's money: -21.9
9500 50
steps: 474950, episodes: 9500, mean episode reward: -57.721149396408094, time: 7.806
 agent0's money: -18.8
9600 50
steps: 479950, episodes: 9600, mean episode reward: -72.65605586078597, time: 8.007
 agent0's money: -21.4
9700 50
steps: 484950, episodes: 9700, mean episode reward: -58.806134133849646, time: 7.229
 agent0's money: -25.2
9800 50
steps: 489950, episodes: 9800, mean episode reward: -58.16860626747667, time: 6.985
 agent0's money: -27.3
9900 50
steps: 494950, episodes: 9900, mean episode reward: -58.410573236834765, time: 7.001
 agent0's money: -37.5
10000 50
steps: 499950, episodes: 10000, mean episode reward: -65.78656765360152, time: 6.859
 agent0's money: -20.2
...Finished!
Trained episodes: 1 -> 10000
Total time: 0.21 hr

 agent0's money: 0.0
7300 50
steps: 364950, episodes: 7300, mean episode reward: -63.93369223769758, time: 8.152
 agent0's money: -0.0
7400 50
steps: 369950, episodes: 7400, mean episode reward: -67.32555640496716, time: 7.784
 agent0's money: -0.0
7500 50
steps: 374950, episodes: 7500, mean episode reward: -67.87551469486333, time: 7.861
 agent0's money: -0.0
7600 50
steps: 379950, episodes: 7600, mean episode reward: -64.16580208207934, time: 7.899
 agent0's money: -0.0
7700 50
steps: 384950, episodes: 7700, mean episode reward: -69.74249632133007, time: 7.985
 agent0's money: -0.0
7800 50
steps: 389950, episodes: 7800, mean episode reward: -67.8107184155263, time: 7.76
 agent0's money: 0.0
7900 50
steps: 394950, episodes: 7900, mean episode reward: -61.152286880889626, time: 8.01
 agent0's money: 0.0
8000 50
steps: 399950, episodes: 8000, mean episode reward: -60.535646250653926, time: 7.863
 agent0's money: 0.0
8100 50
steps: 404950, episodes: 8100, mean episode reward: -75.22122428026034, time: 8.238
 agent0's money: -0.0
8200 50
steps: 409950, episodes: 8200, mean episode reward: -74.65182897035292, time: 7.802
 agent0's money: 0.0
8300 50
steps: 414950, episodes: 8300, mean episode reward: -63.10790206680651, time: 8.045
 agent0's money: -0.0
8400 50
steps: 419950, episodes: 8400, mean episode reward: -73.27079084488177, time: 8.21
 agent0's money: -0.0
8500 50
steps: 424950, episodes: 8500, mean episode reward: -60.55677901606612, time: 7.985
 agent0's money: 0.0
8600 50
steps: 429950, episodes: 8600, mean episode reward: -64.93179616194544, time: 8.048
 agent0's money: 0.0
8700 50
steps: 434950, episodes: 8700, mean episode reward: -65.11370860055037, time: 7.964
 agent0's money: -0.0
8800 50
steps: 439950, episodes: 8800, mean episode reward: -60.50762439272375, time: 8.045
 agent0's money: 0.0
8900 50
steps: 444950, episodes: 8900, mean episode reward: -64.62705266399469, time: 8.03
 agent0's money: -0.0
9000 50
steps: 449950, episodes: 9000, mean episode reward: -66.79157478610273, time: 8.023
 agent0's money: 0.0
9100 50
steps: 454950, episodes: 9100, mean episode reward: -59.92709077018941, time: 8.249
 agent0's money: 0.0
9200 50
steps: 459950, episodes: 9200, mean episode reward: -63.26000096379798, time: 7.914
 agent0's money: 0.0
9300 50
steps: 464950, episodes: 9300, mean episode reward: -60.30829716551281, time: 7.831
 agent0's money: 0.0
9400 50
steps: 469950, episodes: 9400, mean episode reward: -75.31405233117599, time: 7.742
 agent0's money: -0.0
9500 50
steps: 474950, episodes: 9500, mean episode reward: -61.13592012523943, time: 7.888
 agent0's money: 0.0
9600 50
steps: 479950, episodes: 9600, mean episode reward: -76.18608589502081, time: 8.21
 agent0's money: -0.0
9700 50
steps: 484950, episodes: 9700, mean episode reward: -63.70242397937211, time: 7.505
 agent0's money: 0.0
9800 50
steps: 489950, episodes: 9800, mean episode reward: -68.08688856877035, time: 6.968
 agent0's money: -0.0
9900 50
steps: 494950, episodes: 9900, mean episode reward: -66.70974326371396, time: 6.96
 agent0's money: -0.0
10000 50
steps: 499950, episodes: 10000, mean episode reward: -70.01211451305228, time: 6.838
 agent0's money: -0.0
...Finished!
Trained episodes: 1 -> 10000
Total time: 0.21 hr
